МОДЕЛИ И ПРОЕКТНЫЕ РЕШЕНИЯ СИСТЕМЫ ХРАНЕНИЯ   И ОБРАБОТКИ ИССЛЕДОВАТЕЛЬСКИХ ДАННЫХ ECCLESIA  

В ходе научных исследований порождается большое количество данных в цифровом формате, и для после дующего использования этих данных (обработки, анализа, публикации) их необходимо организованно собирать  и хранить. Построение информационной инфраструктуры для решения этих задач – одна из наиболее актуальных  проблем в области организации работы с экспериментальными данными. Авторами настоящей статьи разра батывается информационная система для автоматизации сбора, хранения и анализа данных, в качестве отправной  точки для которой используются три задачи обработки данных из области физиологии. Рассмотрены и проана лизированы возникающие в процессе разработки такой системы проблемы, а также существующие подходы  и готовые решения этих и схожих задач. На основе результатов проведенного анализа предложен ряд моде лей и механизмов для решения возникших проблем. Разработанные решения включают в себя модели  и механизмы сбора и хранения экспериментальных данных, модель для описания и формализации сценариев обработки данных и механизмы для обработки собранных данных в распределенной вычислительной системе.  В результате представлена архитектура вычислительной системы для сбора, хранения и обработки эксперимен тальных данных. Система предлагается в качестве инструмента для решения широкого спектра задач, возни кающих при проведении научных исследований и требующих сбора, хранения и многоэтапной обработки  различных типов данных. : управление научными данными, информационная система, обработка и анализ данных, дан ные физиологических исследований, объектное хранилище данных, функциональный язык, распределенные вы числения. 

В современных исследованиях часто приходится сталкиваться с большим объемом экс периментальных данных, получаемых из различных источников. Вс чаще данные собира ются и сохраняются с расчетом на то, что некоторые задачи их анализа будут поставлены в будущем. Перспективные задачи могут предполагать использование дополнительных данных, собранных независимо, в другое время другими исследователями. Нарастающие проблемы организации исследовательских данных и систематизации работы с ними стали, таким образом, самостоятельной задачей. Управление научными исследовательскими данными research data management и циф ровое курирование digital curation 1 к настоящему моменту являются устоявшимися терминами, выражающими потребности научного сообщества в инструментах и сервисах для работы с генерируемыми данными. В то время как в Европе и США эта проблематика вынесена на государственный и даже межгосударственный уровень поддерживаются и раз виваются узкоспециализированные инфраструктуры для хранения научных данных, напри мер DataONE, разрабатываются и реализуются крупные программы, направленные на обоснование необходимости развития таких инфраструктур и проработку соответствующей нормативной базы, которая, в частности, будет стимулировать исследователей делиться своими данными см. проект Research Data e-Infrastructures Framework for Action in H2020 . В обзоре 1 приводится западная оценка общей стоимости формирования инфра структуры научных данных 1015 от стоимости всей инфраструктуры науки. При этом в России на уровне федеральных властей обсуждение необходимости и путей создания инфраструктуры для науки, основанной на цифровых данных, активизировалось только в 20162017 гг. в связи с разработкой и принятием программы Цифровая экономика 2, хотя отдельные инициативы в этом направлении реализовывались и ранее 3 4. Несмотря на более чем 10-летнюю историю вопроса, работа с исследовательскими дан ными, за исключением отдельных научных направлений например, 5, остается слабо упорядоченной и в лучшем случае организуется путем составления и следования инструк циям, таким как Data management Helping MIT faculty and researchers manage, store, and share data they produce . Такое положение дел в дальнейшем будет только сдерживать раз витие науки, поэтому исследователи нуждаются в создании инструментов, которые позволят им решать задачи организации сбора, хранения, обработки и анализа данных, обмена ими и их публикации. В работе 6 предлагается подход к систематизации и соответствующей автоматизации процессов, связанных с согласованным хранением и обработкой неоднородных исследова тельских данных. В общем виде рассмотрены требования к организации специализированной информационно-аналитической системы, представлено видение е архитектуры, описано состояние развития инфраструктуры Института вычислительных технологий ИВТ СО РАН для работы с научными данными. В настоящей работе представлен следующий этап в рамках инкрементального подхода к созданию этой информационно-аналитической системы поддержки научных исследований. Анализируется опыт Лаборатории технологий анализа и обработки биомедицинских данных ИВТ СО РАН в решении задач сбора, хранения и анализа данных, возникших в рамках ряда физиологических исследований. На основе этого анализа формулируются минимальные тре бования к информационно-аналитической системе для работы с такими данными, предла гаются основные проектные решения по созданию ее прототипа системы Ecclesia. Одним из немногих проектов, нацеленных на целостное решение проблемы автомати зации сбора, хранения, обработки и публикации научных данных, является проект раз работки платформы и сервиса для биомедицинских исследований Galaxy Project . Несмотря на направленность проекта на конкретную предметную область, результаты его могут быть использованы и в других областях научных знаний. Однако сервис достаточно сложен в освоении, не поддерживает включение интерактивных сессий с пользователями в качестве этапов автоматически выполняющихся сценариев обработки данных и более приспособлен к накоплению отдельных объектов данных, воспроизводимости отдельных сценариев обра ботки данных, чем к систематизации накопления и автоматизации применения знаний о предметной области. Системы для хранения или обработки данных в целом можно разделить на три класса системы общего назначения например, Dell EMC Elastic Cloud, Globus, специфичные для предметной области например, SIMBioMS, CARMEN, XTENS 2 и решающие частные задачи например, МedMining 7. В системах общего назначения особое внимание уде ляется надежности хранения, но не предоставляются инструменты для описания данных и их связей. Системы для решения частных задач, напротив, поддерживают связи между дан ными, но в рамках специфичной для задачи схемы, которая чаще всего не переносима на другие задачи. Среди специфичных для предметной области систем рассматривались системы хранения биомедицинских данных 810. Достаточной степенью универсальности не обладает ни одна система. Так, например, они не поддерживают возможность проверки структуры загруженных данных и не позволяют вводить и тем более строить новые связи между данными. Среди систем формирования и исполнения сценариев обработки данных также можно выделить системы общего назначения например, Google Cloud Dataflow или ActiveEon ProActive Workflows Scheduling и системы, специфичные для предметной области на пример, LabView и Unipro UGENE 11. Системы общего назначения по большей части направлены на пользователей с навыками программирования. Важным примером системы, позволяющей создавать предметно-ориентированные визуальные языки программирования, является CoCoViLa 12, которая для этого требует от пользователя решать более широкую задачу, чем задание и выполнение отдельных сценариев обработки данных. Узкопредметные системы избавляют пользователей от таких сложностей, но изначально не приспособлены для решения междисциплинарных задач. Разрешению обозначенных проблем различных систем для работы с данными и посвя щена наша работа. В основе требований, предъявляемых к разрабатываемой системе, лежит опыт решения задач сбора, хранения и анализа данных для ряда физиологических исследований и резуль таты обсуждения соответствующих проблем со специалистами-физиологами. Рассматривается задача создания велотренажера для реабилитации больных после ин сульта. Врач задает программу тренировки пациента с помощью графиков требуемой ско рости вращения педалей и величины сопротивления тренажера кручению педалей. Эти значения преобразуются мобильным приложением в управляющие воздействия контроллера тренажера. Необходимо индивидуально подбирать программу тренировки так, чтобы па циент получил нагрузку, адекватную его состоянию. Для этого необходимо собирать и ана лизировать данные, характеризующие фактическое прохождение тренировки. Собираемые данные включают в себя частоту сердечных сокращений ЧСС и реальную скорость кру чения педалей. Мобильное приложение собирает данные и формирует пары вида отметка времени, значение ЧСС и отметка времени, значение реальной скорости. Для анализа процесса тренировки требуется сохранять и визуализировать получаемые данные, сопоставляя их с программой тренировки. Все данные являются одноканальными временными рядами ОВР. Программу тренировки также можно представить в виде ОВР. Требуется делать выборки в заданных временных интервалах как отдельных рядов, так и их совокупностей, совмещенных по времени. Предложено ввести абстракцию ОВР на уровне решения для хранения, что позволяет унифицировано представлять данные. Помимо данных ряда предложено сохранять ряда 1 тип ряда в данном случае некоторые идентификаторы, позволяющие отличать ряды ЧСС от рядов скорости кручения педалей и др. 2 идентификатор устройства-источника 3 время начала и окончания записи. Доступ к системе хранения данных предоставляется через веб-сервис, который позволяет сохранять и извлекать ОВР. Данные ОВР хранятся в бинарных файлах, атрибуты отдельных записей со ссылкой на бинарный файл хранятся в реляционной БД. Решение позволяет уни фицировано сохранять и извлекать ОВР и независимо разрабатывать различные клиентские приложения для работы с ними. В частности, реализовано сохранение данных в мобильном приложении и выгрузка данных в веб-интерфейс для визуализации. Поскольку на уровне понятий в системе была поддержана логика работы с ОВР, поль зователи получили возможность выбирать данные в веб-интерфейсе по заданным временным промежуткам записи и типу ряда, а не по именам или датам создания файлов. С поль зователей также сняты типичные задачи организации данных в некоторую структуру ди ректорий, запоминания этой структуры и ручного поиска в ней. В ходе решения задачи проявилась необходимость обеспечивать в рамках информацион но-аналитической системы реализацию понятий предметной области и поддержку работы с соответствующими объектами данных в терминах предметной области на уровне програм мных и пользовательских интерфейсов. Типичная система организации данных в виде файлов, собранных в структуры директорий, является в подобных ситуациях неадекватной задачам поиска и обработки данных. Запись электроэнцефалограммы ЭЭГ состоит из каналов, в которых фиксируется ди намика разности потенциалов между электродами и электродом-референтом. ЭЭГ-записи могут использоваться для выявления схожести и различий в реакции пациентов на одина ковые стимулы 13, для восстановления позиций источников сигналов в мозге 14 и др. Однако предваряет содержательный анализ данных очистка ЭЭГ-записей от шумов 15. В рамках этапа очистки от шумов используются запись сигналов ЭЭГ, а также инфор мация о размещении электродов на голове пациента 16, время подачи стимулов, протокол эксперимента, в котором описаны детали проведения эксперимента. Приемы очистки записи могут применяться отдельно либо в некоторой последовательности. Наиболее распростра ненные из них 1 применение частотных фильтров для удаления известных помех 2 выявление экспертом зашумленных каналов и их удаление 3 смена электрода-референта и соответствующий перерасчет значений ЭЭГ во всех ка налах 17 4 усиление значимого сигнала за счет суммирования выровненных по моменту предъ явления стимула участков записи, так называемых эпох 5 коррекция нулевой линии baseline correction 18 6 выявление экспертом поврежденных эпох и их удаление 7 применение анализа независимых компонент 19, выявление экспертом шумовых ком понент и их удаление каждая компонента при этом визуализируется в виде карты актив ности мозга. Как правило, в физиологических лабораториях можно наблюдать, что все собираемые данные, а также данные, получаемые в ходе этапов обработки, хранятся как отдельные фай лы протокол эксперимента и вовсе может храниться в бумажном лабораторном журнале, структурирование которых в упорядоченные системы каталогов, именование, формирование наборов данных для очередных этапов обработки осуществляются вручную. Автоматизация сбора и обработки должна освободить исследователей от этого рутинного труда и ликви дировать ошибки, обусловленные человеческим фактором. Должна быть обеспечена возмож ность формировать и автоматически выполнять сценарии, состоящие из набора связанных операций обработки данных, а перенос данных между операциями должен быть автома тизирован. На практике в ходе обработки данных от пользователя требуется выбор конкретных методов. Например, существует множество алгоритмов для проведения ICA 20, нужно сделать выбор частотных фильтров и т. д. Не все эксперты в предметной области задачи яв ляются экспертами в математической обработке данных, и для них были бы ценны советы при выборе методов обработки. Для этого целесообразно, чтобы система собирала и накап ливала опыт других пользователей в составлении сценариев. Нужно учитывать, что некоторые операции обработки данных пока или принципиально не могут быть автоматизированы, поэтому может потребоваться анализ и принятие решения экспертом. Таким образом, должна быть заложена возможность включать сессии взаимодей ствия с пользователями в качестве этапов сценариев обработки данных. Задача состоит в поиске нейрональных сетей на основе анализа выявляемой с помощью функциональной магнитно-резонансной томографии фМРТ активности мозга пациента на пример, 2123. С помощью фМРТ измеряется связанная с активностью нейронов гемо динамика. Каждый снимок фМРТ характеризует насыщенность крови кислородом в раз личных областях головного мозга. Дискретное представление насыщенности основано на разбиении куба, в который вписана голова пациента, на кубические единичные объемы воксели. Снимок фМРТ представляет собой, таким образом, трехмерный массив чисел. В ходе решения задачи анализируется последовательность фМРТ-снимков головы па циента. В каждом снимке выделяются группы вокселей по выбору исследователя, и для каждой группы строится индекс активации некоторое усреднение значений всех вокселей группы. Эти операции повторяются для всей последовательности снимков, таким образом получается временная развертка индексов активации. Представляет интерес выделение групп вокселей, демонстрирующих различную или сходную динамику индекса активации 24. Для одного эксперимента в этой задаче нужно обработать тысячи групп вокселей во временной развертке. Каждая группа вокселей может быть рассмотрена независимо, что позволяет обрабатывать их параллельно. Таким образом, задачу целесообразно решать на параллельных вычислительных системах. На основе анализа пользовательских историй в совокупности с общими представления ми о назначении системы 6 сформулированы требования к минимальному жизнеспо собному продукту MVP Minimal Viable Product. Необходимо обеспечить следующее 1 возможность сохранять и извлекать разнородные экспериментальные данные вместе с информацией об их структуре и связях с другими данными 2 возможность модифицировать сведения о данных и связях между ними в любой мо мент времени 3 проверку соответствия данных заданной структуре с возможностью исправления выяв ленных несоответствий при сохранении в системе 4 возможность задавать сложные пользовательские сценарии обработки данных 5 обращение к данным и сохранение новых данных из сценариев 6 выполнение сценариев на параллельных вычислительных системах, при этом поль зователь должен быть по возможности избавлен от необходимости императивного парал лельного программирования 7 возможность интерактивного вмешательства пользователя в ход исполнения сценария 8 накопление знаний о предметной области и поддержку действиям пользователя в по строении сценария 9 автоматизированный анализ и оптимизацию процессов обработки данных. На основе выявленных требований к системе в ходе проектирования были выделены три ее относительно самостоятельные подсистемы 1 хранения и управления данными 2 формирования сценариев 3 организации распределенной обработки. Для возможности независимой разработки подсистем и применения различных тех нологий для их реализации выбрана микросервисная модель архитектуры системы, пред ставленная на рис. 1. реализуется в виде надстройки над су ществующим распределенным высоконадежным хранилищем. Надстройка представляет со бой промежуточный сервер менеджер данных, организующий данные пользователя в соот ветствии с предлагаемой моделью представления данных см. ниже и предоставляющий программный интерфейс API Application Programming Interface для работы с этими дан ными. На основе API менеджера данных независимо могут быть построены различные клиентские приложения. Базовым пользовательским интерфейсом является веб-интерфейс с функциями загрузки и извлечения данных, просмотра каталога данных и поиска в нем. Для обеспечения хранения и извлечения разнородных экспериментальных данных вместе с информацией об их структуре и связях предложена следующая модель представления дан ных. Вводится понятие как единицы хранения. Для каждого объекта при создании формируется его идентификатор. Все объекты автоматически или по указанию пользователя относятся к одному из, зарегистрированных в системе, в одном из Таким образом, любой файл или некоторым образом структури рованный набор файлов, будучи сохраненными в качестве объекта данных, могут быть со держательно интерпретированы системой. Например, данные одного ЭЭГ-исследования на энцефалографах BrainVision сохраняются в виде тройки файлов запись сигналов ЭЭГ в файле формата .eeg, файл разметки ЭЭГ по времени подачи стимулов .vmrk и файл, содержащий информацию о каналах энцефалографа .vhdr. После загрузки файлов в си стему хранения эта тройка рассматривается как один объект данных типа в формате Такой подход отражает связь между файлами, позволяет обращаться к ним совместно и избегать ошибок совмещения сигналов и времени подачи стимулов от разных записей при многократном обращении. Для обеспечения расширяемости подсистемы хранения предлагается механизм введения нового типа. Новый тип в системе задается, списком возможных задаются строковыми идентификаторами и набором, которые могут при нимать на вход или вырабатывать в качестве своего результата объекты данного типа, возможно, наряду с объектами других типов см. раздел Подсистема организации рас пределенной обработки Схема метаданных задает название типа, синонимы для названия и текстовое описание типа, а также специфицирует набор свойств объектов данного типа в виде множества пар атрибут, тип. Атрибут произвольная строка, имя некоторого свойства объекта данных, тип строковый идентификатор типа значения атрибута, выбирается из типов, зарегист рированных в системе, например атрибут Дата регистрации, тип Дата. Одним из типов является ссылка на другой объект данных по идентификатору объекта. Ссылки в метаданных на другие объекты позволяют задавать произвольные между данными. С каждым объ ектом данных хранятся его метаданные. Значения атрибутов заполняются пользователем или автоматически, например, некоторым клиентским программным обеспечением. Типы, у которых задана только схема метаданных, называются и мо гут быть включены в определения схем метаданных других типов для переиспользования набора атрибутов, заданных в типе-стикере. Экземпляр такого типа, стикер, объект мета данных, содержание которого составляют только метаданные с присвоенными атрибутам значениями. Стикер может быть прикреплен к произвольному объекту данных, даже если этот стикер не включен в схему метаданных типа данного объекта. С помощью атрибутов-ссылок и стикеров можно, в частности, сохранить связь между исходным объектом, например записью ЭЭГ, и преобразованным, например ЭЭГ, отфильт рованной от наведения электросети. Для этого нужно создать и прикрепить к полученному после фильтрации объекту стикер с названием Без наведения с атрибутом Получено из типа для сохранения ссылки на исходный объект и атрибутом Частота на ведения типа вещественное число для сохранения параметров фильтрации рис. 2. Согласно требованию о проверке структуры загружаемых данных, в подсистеме вводится понятие операции проверки соответствия структуры данных заданному типу и формату этих данных. Вызов этих операций при загрузке данных в хранилище позволяет автоматически выявлять несоответствие между содержанием объекта данных и указанными пользователем или автоматически определенными типом и форматом объекта данных. Разработан программный интерфейс веб-сервиса доступа к данным в терминах управ ления ресурсами сервиса, согласно архитектурному стилю REST 25. Типы ресурсов сервиса имеют прямое соответствие терминам модели представления данных тип данных, формат данных, стикер, операция, объект. Таким образом, каждый тип данных, каждый объект и т. д., а также коллекция таких сущностей, является ресурсом в терминах REST и получает имя URI Uniform Resource Identifier, посредством которого клиенты сервиса могут обра щаться к ресурсу и осуществлять действия из набора CRUD 26. Относительно способов передачи значений при запросе объектов типы разделены на два класса. 1. . В результате запроса объекта по его идентификатору клиенту ин терфейса возвращается информация URL Unified Resource Locator о том, как может быть получен доступ непосредственно к данным объекта. К этому классу относятся все сложные типы например, запись ЭЭГ. Для получения данных в случае записи ЭЭГ в формате BrainVision это тройка файлов, описанная выше необходимо сделать отдельный запрос по URL. Ссылочные типы позволяют вынести в отдельный блок работ исследование и внед рение механизмов оптимизации доступа к данным, например, таких, как размещение копий данных кэши ближе к месту их использования. 2. Объекты таких типов возвращаются клиенту непосредственно при обращении по идентификатору объекта. К этому классу относятся примитивные типы на пример, числа и строки. Предложенная модель доступа к данным предоставляет инструменты доступа к системе хранения как из клиентских приложений веб-интерфейс системы хранения, приложения для персональных компьютеров и мобильных устройств, программное обеспечение регистри рующего оборудования собираемые устройствами данные могут непосредственно отправ ляться в хранилище, и т. д., так и из подсистемы распределенной обработки данных. Поскольку одним из требований к системе является выполнение сценариев на различных параллельных вычислителях, то предлагается модель, в которой вычислитель может испол нять сценарии, описанные в виде частично упорядоченного множества операций. Операция характеризуется множеством входов, множеством выходов, а также именем функции, кото рую она применяет к входам для получения выходов. Входы и выходы это объекты дан ных. Предполагается, что по имени функции может быть найдена конкретная программная реализация этой функции программа, которую может исполнить вычислитель. Все объекты неизменяемы и либо известны до исполнения сценария входные данные сценария, либо являются выходами операций. Каждая операция имеет список зависимостей список операций, которые должны быть выполнены до исполнения этой задачи. Операция может быть исполнена, если нет неис полненных операций, от которых она зависит. Таким образом, множество списков зави симостей определяет частичный порядок на множестве операций. Списки зависимостей фор мируются разработчиком сценария либо, как будет представлено далее, компилятором высокоуровневого языка описания сценариев. Возможность задавать произвольный порядок помимо обусловленного зависимостями по данным позволяет использовать операции с по бочными эффектами, при этом с исполнительной системы планировщика снимается задача отслеживания и обработки побочных эффектов. Примерами побочных эффектов могут быть операции ввода вывода или инициализации ресурсов вычислителя например, буфера па мяти GPU в одной из операций, потребление в другой. Вычислитель принимает на вход тройку множеств, где множество опе раций, множество зависимостей между операциями, таблица сопоставления объ ектов данных, являющихся входными для сценария, с их именами мнемониками, исполь зуемыми в сценарии. В таблице указывается URI объекта, если это ссылочный тип, или непосредственно некоторая сериализация объекта в противном случае. Запись сценария в виде тройки, называется внутренним представлением сценария. Такая модель абстрагирует подсистему формирования сценариев от деталей реализации вычислителя, позволяет создавать варианты языков описания сценария текстовые, визуаль ные и оставить свободу выбора конкретной реализации сценария подсистеме организации распределенной обработки см. ниже. Для накопления знаний предлагается использовать методы машинного обучения. Бла годаря этому система сможет самостоятельно извлекать взаимосвязи между объектами пред метной области исходя из действий пользователей. У подхода есть свои недостатки. Так, методы машинного обучения не дают однозначной интерпретируемости и доказуемой кор ректности вывода, но для целей создаваемой системы достаточно, чтобы сохранялась информация об истории происхождения того или иного утверждения. Основная идея состоит в том, чтобы оценивать вероятность использования пользователем функции в контексте при формировании сценария на основе статистики других пользова телей. Для этого адаптируется задача анализа рыночной корзины, сформулированная в 27 и получившая широкое развитие в 2006 г. во время конкурса Netflix Prize по предсказанию пользовательских оценок фильмам и рекомендациям фильмов на их основе 28. Задача конкурса формулировалась так есть множество пользователей и множество фильмов . Известна матрица размерностью, содержащая пользовательские оценки фильмов. Требуется научиться предсказывать оценку пользователя и предлагать пользователю фильмы с наивысшей предсказанной оценкой. Для этой задачи эффективным решением оказались латентные модели 28. В задаче рекомендации функций есть заметные отличия 1 пользователь не ставит оценки функциям это сильно отличается от основных пользо вательских задач и будет отвлекать пользователя 2 так как система рекомендаций нужна для помощи неопытным пользователям, необ ходимо строить рекомендации только на основе действий более опытных пользователей, т. е. информации от одних пользователей система должна доверять меньше, чем информации от других. Для решения этих проблем предлагается следующее. 1. В качестве оценки функции здесь берется вероятность применения пользователем конкретной функции в сценарии с учетом контекста набора других использованных в сце нарии функций. Эта вероятность для каждого пользователя рассчитывается эмпирически на основе анализа статистики применения функций в разработанных пользователем сце нариях. 2. Вводится мера доверия системы пользователю, которая используется как вес поль зователя при обучении латентной модели. При расчете вероятности использования функций пользователем делаются два предпо ложения. Первое заключается в том, что распределение вероятности использования функций пользователем не меняется со временем это предположение можно смягчить, если рассмат ривать только сценарии не старше некоторого порогового значения, второе вероятность использования функций в сценарии не зависит от других сценариев. Для вычисления меры доверия пользователю используются следующие эвристики 1 чем больше используется различных функций, тем лучше пользователь владеет мето дами обработки данных 2 чем больше в среднем функций в сценариях пользователя, тем они сложнее и тем лучше он владеет методами обработки данных. Исходя из этого мера доверия пользователю вычисляется следующим образом, где количество различных методов, применяемых пользователем, среднее ко личество методов в сценариях пользователя, веса, константа-смещение сейчас характеризует экспертную оценку навыка пользователя при его регистрации в системе. Изначально веса устанавливаются вручную и при необходимости будут скорректированы по мере появления новых пользователей. В будущем при увеличении количества пользовате лей планируется собрать экспертные оценки их навыка и на их основе обучить модель линейной регрессии для автоматической настройки весов. В качестве базового языка описания сценариев разработан текстовый язык, за основу которого принят язык F по следующим причинам 1 F является функциональным языком, что позволяет извлекать из кода информацию о функциональных зависимостях между операциями, абстрагирует от деталей исполнения сценария на конкретной вычислительной системе 2 синтаксис F, как и Python который является де-факто стандартом в анализе данных, основан на отступах, в нем нет избыточных ключевых слов, поэтому код на F краток и легко читаем 3 F основан на системе типов Хиндли Милнера 29, поэтому в программах, как и в Python, не требуется явно указывать типы при определении значений и функций при этом язык является статически типизированным, что позволяет обнаруживать большое коли чество ошибок до отправки сценария на исполнение 4 компилятор F обладает открытым исходным кодом, а также предоставляет програм мный интерфейс для анализа кода на предмет наличия ошибок, построения типизированного и нетипизированного абстрактного синтаксического дерева, а также поддержку таких функ ций интегрированных сред разработчика IDE Integrated Developer Environment, как автозавершение кода и сборка inline-документации. Для адаптации языка к целям формирования сценариев, а также спецификации генери руемых параллельных программ изменена семантика некоторых конструкций языка 1 let-связывание связывает объект данных константу или выход функции с мнемо никой, но при этом не определяет порядок вычислений и не задает других зависимостей, помимо зависимостей по данным 2 do-связывание служит для явного обозначения побочных эффектов например, опе раций ввода-вывода, если это требуется вычислителем, в случае использования do-связыва ния с операцией все остальные операции, описанные в сценарии после нее, получают за висимость от этой операции см. пример на рис. 3 3 директива open используется как для подключения наборов сигнатур функций, до ступных на вычислителе, так и для переиспользования других сценариев пользователя. Набор сигнатур это множество объявлений функций, реализации которых доступны на вычислителе в качестве исполняемых программ. Объявления оформляются в виде функ ций на языке F. Они необходимы для того, чтобы произвести проверку соответствия типов в сценарии. На первом этапе наборы сигнатур добавляются в систему вручную совместно с добавлением реализаций функций в подсистему организации распределенной обработки. Впоследствии они будут генерироваться автоматически по описаниям операций. Перед запуском код сценария обрабатывается компилятором, который анализирует сце нарий на наличие ошибок, выявляет зависимости между операциями и транслирует его во внутреннее представление сценария, формируя множества, . Наборы сигнатур функций, как и сценарии, могут также подключать другие наборы и сценарии с помощью директивы open см. рис. 3. Таким образом, исходные коды, необ ходимые для компиляции, образуют направленный ациклический граф. Информация о связях между исходными кодами дугах в графе исходных кодов выявляется компилятором и хра нится совместно с исходными кодами в системе. Подсистема состоит из следующих компонентов 1 графический интерфейс пользователя UI User Interface позволяет пользователю вво дить сценарии обработки данных на языке описания сценариев, инициирует компиляцию сценария во внутреннее представление и передает его менеджеру сценариев 2 компилятор сценариев анализирует сценарий на корректность и преобразует его во внутреннее представление 3 менеджер сценариев принимает запросы от графического интерфейса, собирает инфор мацию о сценарии в форме внутреннего представления и инициализирует его выполнение 4 менеджер зависимостей хранит исходные коды сценариев и наборы сигнатур функций, а также связи между ними 5 сервис анализа пользовательской статистики собирает информацию о запусках пользо вательских сценариев, инициирует создание моделей машинного обучения, рассчитывает, какие функции можно предложить пользователю. В предложенной архитектуре менеджер сценариев и компилятор никак не связаны, ме неджер сценариев работает напрямую с внутренним представлением сценария. Это сделано для того, чтобы можно было подключать к системе и другие средства описания сценария, которые компилируются во внутреннее представление, например визуальные. Все компо ненты представляют собой веб-сервисы и общаются друг с другом через REST API. Обработка собранных данных зачастую является ресурсоемкой задачей из-за их большого объема или же вследствие вычислительной сложности используемых для обработки алго ритмов. Одним из возможных решений для сокращения времени обработки является использо вание высокопроизводительных вычислительных систем ВВС. Это решение позволяет су щественно сократить время выполнения ресурсоемких этапов обработки, однако может быть неуместно для этапов с низкой вычислительной сложностью. Ввиду этого выполнение об работки данных исключительно на ВВС не решает проблему в полной мере, требуется оптимизация использования привлекаемых вычислительных ресурсов. В то же время сценарии обработки данных, имеющие вид, естественным об разом выполняются в распределенной вычислительной среде операции обработки, не зави сящие друг от друга могут выполняться параллельно. Также при организации распределен ной обработки собранных данных можно использовать гетерогенное множество вычислительных систем, включающее в себя как высокопроизводительные узлы для выполнения ресурсоемких этапов обработки, так и узлы для выполнения менее требователь ных к вычислительным ресурсам операций. Более того, при использовании гетерогенного множества вычислителей становится возможным включать в систему специализированные узлы, более эффективно выполняющие определенные виды обработки например, распола гающие ускорителями GPU, а также вычислительные мощности, предоставляемые пользова телями системы. Именно такой подход распределенная обработка данных на гетерогенном множестве вычислительных систем и закладывается в систему. На основе выбранного подхода разработана модель распределенной обработки данных в системе. Модель предполагает централизованное управление процессом обработки дан ных, реализуемое отдельным сервисом. Здесь с каждой операцией из внутреннего представ ления сценария сопоставляется реализующая ее программа, написанная на некотором языке программирования может быть несколько таких реализаций, отличающихся нефункцио нальными свойствами, например, предназначенных для исполнения на различных устрой ствах. Эти программы обработки данных выполняются на некотором подмножестве доступных вычислительных систем, требования к системам определяются по имеющейся об операции информации метод обработки данных, размер входных данных, нефункциональ ные свойства реализаций. Распределение операций по вычислительным системам проис ходит при составлении плана выполнения сценария. Нужно учесть, что некоторые вычислительные системы могут и не находиться под пол ным контролем системы подсистемы организации распределенной обработки. Например, представляет интерес использование ресурсов суперкомпьютерных центров, однако уста новка системного программного обеспечения для управления обработкой данных на таких вычислителях затруднена. Решением является отказ от использования в обязательном по рядке связующего программного обеспечения, разворачиваемого на используемых вычисли тельных системах. Вместо этого взаимодействие с вычислительными узлами решено осуществлять через штатные для используемых вычислительных систем механизмы уда ленного доступа. Также если вычислительная система использует некоторую систему управления прохождением задач СУПЗ, то задачи обработки данных Ecclesia будут ста виться в очередь СУПЗ на общих основаниях. Для обеспечения расширяемости системы новыми типами поддерживаемых вычислительных систем, механизмы взаимодействия с вычислителями выделяются в изолированные модули внутри системы с единым внешним интерфейсом. Ограниченность контроля над вычислительными системами также требует создания виртуальной среды для всех процессов обработки данных внутри узла, для чего используется технология Docker . Для эффективного использования распределенной системы реализуется механизм опти мизирующего планирования. Используется алгоритм RDPSO Revised Discreet Particle Swarm Optimization поиска приближенного решения задачи в многомерном пространстве, имити рующий движение роя частиц, адаптированный для работы с дискретным пространством решений 30. Алгоритмом составляется план выполнения всего сценария до начала вы числений. Не всегда можно заранее составить план выполнения всего сценария. В сценарии могут присутствовать операции, требующие взаимодействия с пользователем например, обработки данных человеком-экспертом. Предсказать время выполнения таких операций в общем случае не представляется возможным, что делает невозможной и оптимизацию времени выполнения сценария целиком. Также к неточности оценок времени выполнения может приводить невозможность в некоторых случаях предсказать объем входных данных для некоторых операций, поскольку время выполнения операций в существенной мере зависит от объема входных данных. Эта ситуация может возникать, например, при очистке данных с различного рода датчиков от шума соотношение объема исходных и очищенных дан ных неизвестно, поэтому объем очищенных данных после выполнения такой операции трудно предсказать. Для решения этой проблемы предлагаются следующие механизмы планирования и испол нения операций обработки данных в распределенной системе. Планирование производится в несколько проходов для подмножеств операций в сцена рии. Для каждой вычислительной системы формируются очереди задач в рамках подсистемы организации распределенных вычислений. Эти очереди в контексте обсуждения алгоритма планирования следует отличать от очередей СУПЗ, которые, возможно, используются на не которых из вычислительных систем. Для каждого прохода выбираются операции, удовлетво ряющие всем следующим условиям операция еще не выполняется на некоторой вычислительной системе операция не зависит ни от одной незавершенной операции, требующей взаимодействия с пользователем операция не зависит ни от одной операции, объем выходных данных которой не из вестен. По мере выполнения сценария таким образом может быть запланировано выполнение всех операций в сценарии операции, требующие взаимодействия с пользователем, и опе рации с неизвестным объемом выходных данных выполняются, необходимая для оценки вре мени выполнения информация становится известна. При использовании такого механизма планирования порядок поступления операций в очереди вычислительных систем не связан ни с порядком поступления сценариев обра ботки данных в систему, ни с желаемыми сроками завершения выполнения сценариев. Это может привести к завершению сценариев в сроки, значительно превышающие желаемые даже в случаях, когда нагрузка на распределенную систему и ее конфигурация позволяют завершить сценарий в срок, а также к бесконечному ожиданию для задач некоторых сценариев. Чтобы избежать возникновения перечисленных проблем, предложен следующий меха низм управления очередями операций для каждой вычислительной системы. 1. В процессе статического анализа сценария и оценки времени выполнения операций, проводимых перед каждым проходом планирования, для каждой операции вычисляется ее собственный желаемый срок завершения. Эти сроки определяются на основе желаемого вре мени завершения для сценария и оценки относительной длительности выполнения операции. 2. На основе собственных желаемых сроков завершения операции из всех выполняемых сценариев объединяются в группы в одну группу попадают операции, время завершения ко торых попадает во временное окно некоторой длительности например, один час. 3. Очереди операций каждой вычислительной системы приоритезируются на основе рас пределения операций по группам операции из групп с более ранними желаемыми сроками завершения имеют более высокий приоритет. При оценке времени выполнения операций, помимо времени выполнения непосредст венно вычислений, учитываются временные затраты на передачу данных на вычислительную систему и задержки перед началом выполнения задачи на вычислительной системе напри мер, вызванные наличием других задач в очереди на выполнение на этой системе. Поставлена проблема разработки информационной системы инструмента для решения задачи работы с исследовательскими данными полного цикла сбора данных, их хране ния, обработки и анализа, с возможностью построения сценариев обработки и сохранения истории данных, формирования и обмена знаниями об обработке данных, как и самими данными на любой стадии работы с ними. На основе трех пользовательских историй сформулирован ряд требований к системе для сбора, хранения и обработки исследовательских данных в ее минимальном жизне способном варианте продукте, MVP minimal viable product. В двух из этих историй ав торы участвовали, разрабатывая простые программные решения для упрощения работы с данными и организации обратной связи системы сбора и обработки данных с участниками эксперимента, третья история является основой для разработки настоящего MVP. Сформулированные требования позволили разработать следующие модели 1 модель представления данных, позволяющую исследователям самостоятельно расши рять и настраивать описания данных и их связей под нужды текущих исследований и сразу пользоваться внесенными изменениями при поиске и доступе к данным 2 модель организации доступа к данным, позволяющую автоматизировать передачу данных между этапами обработки 3 модель абстрактного параллельного вычислителя и язык описания сценариев, что поз воляет описывать сценарии обработки данных в функциональном стиле и автоматически генерировать по этому описанию параллельные программы 4 модель организации распределенной обработки данных на гетерогенном множестве вычислительных узлов. Кроме того, предложены подходы к накоплению знаний о предметной области, которые будут применяться для поддержки составления новых сценариев. В частности, для этого адаптирована задача об анализе рыночной корзины. Продолжение работы будет направлено на реализацию разработанной концепции и проектных решений, их детализацию и уточнение в ходе тестирования прототипа MVP, а именно 1 разработку или подбор визуального языка описания сценария 2 улучшение системы рекомендаций методов на основе статистики работы реальных пользователей 3 исследование возможностей оптимизации различных этапов работы с данными, в том числе для минимизации задержек при обращении к данным 4 исследование альтернативных алгоритмов планирования для различных классов сце нариев обработки данных, в том числе на основе обратной связи с использованием машин ного обучения для предсказания наиболее подходящей схемы планирования 5 исследование возможностей построения вероятностной модели сценария в конкретной предметной области, чтобы можно было полностью генерировать новый сценарий, фиксируя пользовательские параметры. 