АРХИТЕКТУРА АВТОНОМНОГО  МИКРОГИПЕРВИЗОРА РЕАЛЬНОГО ВРЕМЕНИ  И АВТОМАТИЗИРОВАННОЕ ИЗМЕРЕНИЕ  ЕГО ВРЕМЕННЫХ ХАРАКТЕРИСТИК 

гипервизоры и виртуальные машины приобрели популярность в последнее десятилетие благодаря своим многочисленным преимуществам. Однако есть и обратная сторона этого положения, особенно для компаний, разрабатывающих системы с особыми требованиями безопасности. Программное обеспечение становится слишком сложным, чтобы быть совместимым со всеми версиями и конфигурациями оборудования. Как следствие, подобное программное обеспечение трудно сертифицировать на соответствие требованиям стандартов безопасности, таким как IEC 61508. Целью исследования является разработка аппаратно-зависимого гипервизора на «пустом» аппаратном обеспечении без установленной операционной системы с фиксированной конфигурацией, запускающего три гостевые операционные системы. Результаты: написан гипервизор реального времени с микроядерной архитектурой, использующий технологию VT-d для проброса устройств в гостевые операционные системы и технологию VT-x для виртуализации процессора. Доказана возможность создания микроядерного гипервизора реального времени для жестко заданной аппаратной платформы с объемом исходных кодов менее 10 тыс. строк. Разработан и проверен метод и аппаратно-программное обеспечение для тестирования характеристик рельного времени программ. Практическая значимость: представленный подход к написанию гипервизора делает возможным создание компактного микрогипервизора рельного времени небольшой командой разработчиков. Предложенный метод тестирования характеристик реального времени позволяет автоматизировать этот процесс. 

Концепция виртуальной машины как совокупности ресурсов, которые эмулируют поведение реальной машины, появилась в Кембридже в конце 1960-х гг. С тех пор ее очевидные преимущества повышение изоляции, безопасность, распределение ресурсов, постоянная доступность, повышение качества администрирования и т. д. 1 из года в год получали дальнейшее развитие. Резкий толчок бурному развитию дала аппаратная поддержка виртуализации на самой популярной платформе x86, когда в середине 2000-х компании Intel и AMD анонсировали технологии VT-x и AMD-V соответственно. До этого события первой попыткой корпорации Intel внедрить в свои процессоры технологии аппаратной виртуализации был режим виртуального процессора 8086 в процессоре 80386, который появился в 1985 г. Возможность аппаратной виртуализации добавила к вышеупомянутым преимуществам еще целый ряд упрощение разработки программных платформ виртуализации за счет предоставления аппаратных интерфейсов управления и поддержки виртуальных гостевых систем возможность увеличивать быстродействие платформ виртуализации улучшение защищенности, возможность переключения между несколькими запущенными независимыми платформами виртуализации на аппаратном уровне запуск 64-битных гостевых систем на 32битных хостовых системах. К сожалению, стоит также отметить, что аппаратная виртуализация потенциально несет в себе не только положительные моменты. Возможность управлять гостевыми системами посредством гипервизора и простота написания платформы виртуализации с использованием аппаратных техник позволяют разрабатывать вредоносное программное обеспечение ПО, которое после получения контроля над хостовой операционной системой ОС виртуализует ее и осуществляет все действия за ее пределами 2. Программа, которая обеспечивает или позволяет одновременное, параллельное выполнение нескольких или даже многих ОС на одном и том же хост-компьютере, называется гипервизором, или монитором виртуальных машин. Общепринятая классификация гипервизоров 3 рис. 1 автономный гипервизор тип 1. Имеет свои встроенные драйверы устройств, модели драйверов и планировщик и поэтому не зависит от базовой ОС. Так как автономный гипервизор работает непосредственно на оборудовании, то он более производителен 4. Пример VMware ESX на основе базовой ОС тип 2. Этот компонент работает в одном кольце с ядром основной ОС кольцо 0. Гостевой код может выполняться прямо на физическом процессоре, но доступ к устройствам ввода-вывода компьютера из гостевой ОС осуществляется через второй компонент, обычный процесс основной ОС монитор уровня пользователя. Примеры Microsoft Virtual PC, VMware Workstation, QEMU, Parallels, VirtualBox гибридный тип 1. Гибридный гипервизор cостоит из двух частей из тонкого гипервизора, контролирующего процессор и память, а также работающей под его управлением специальной сервисной ОС в кольце пониженного уровня 5. Через сервисную ОС гостевые ОС получают доступ к физическому оборудованию. Примеры Xen, Citrix XenServer, Microsoft Hyper-V. В настоящее время существует, помимо упомянутых, огромное количество всевозможных гипервизоров, в том числе сертифицированных для промышленных приложений, например, с особыми требованиями к надежности, безопасности и пр. Такие разработчики, как Wind River Systems, Green Hills Software, SYSGO AG и т. д. настоящие лидеры рынка, и угнаться за ними очень сложно. Чтобы избежать громоздкости универсальных продуктов и обеспечить возможность сертификации, было решено разработать гипервизор с фиксированной конфигурацией, запускающий три гостевые системы рис. 2. Был выбран гипервизор 1-го типа с целью увеличить производительность системы. В качестве платформы взят четырехъядерный процессор Intel Core i5. Таким образом, мы избавились от бесчисленного множества нюансов, связанных с поддерживаемыми функциями процессоров, версиями и т. д., которые существенно усложняют ПО. Лишив продукт гибкости, мы получили возможность минимизировать объем кода гипервизора. В нашем понимании микрогипервизор должен содержать не более 10 тыс. строк кода. Это позволяет упростить архитектуру ПО, сократить трудоемкость, срок разработки и облегчить сертификацию. Вот почему разработанный гипервизор характеризуется как микро, аппаратно-зависимый и автономный. Наша концепция направлена на то, что проще разрабатывать отдельные версии компонентного ПО гипервизора для каждой аппаратной конфигурации, нежели одну универсальную на всех. Известны несколько продуктов, именуемых микрогипервизорами 1 NOVA, OKL4, Codezero, XVisor. Рассмотрим некоторые из них более подробно. NOVA NOVA OS Virtualization Architecture это исследовательский проект, нацеленный на создание безопасной виртуализационной среды с малым объемом исходного кода 6. NOVA состоит из микрогипервизора и пользовательской среды для базовых функций системы. Будучи микроядром третьего поколения, NOVA использует возможность авторизации на основе модели и предоставляет только базовые механизмы виртуализации, пространственное и временное разграничение, планирование, коммуникацию и управление платформой ресурсов. Разделенная многосерверная среда реализует дополнительные сервисы ОС в режиме пользователя, такие как драйверы устройств, стеки протоколов и политики. На машинах с поддержкой аппаратной виртуализации NOVA может запустить несколько немодифицированных ОС одновременно. Каждая виртуальная машина имеет свой собственный монитор, который работает в качестве непривилегированного пользователя приложения поверх гипервизора. Микровизор OKL4 разработки Open Kernel Labs 7 основан на концепции микроядра, основная идея которой состоит в том, чтобы уменьшить код ядра фундаментальных механизмов и реализации реальных системных служб на уровне пользователя серверов. Такой дизайн делает взаимодействие клиента и сервера критичным к производительности, поэтому микроядро требует очень быстрого механизма межпроцессорного взаимодействия. Микроядро должно быть достаточно общим, чтобы поддержать надстройку любых систем. Название микровизор отражает тот факт, что встроенный гипервизор реализуется на основе микроядра виртуализации L4 как его неотъемлемой подсистемы. Сравнение микроядерных и традиционных архитектур мониторов виртуальных машин как подходов для встраиваемых гипервизоров является предметом продолжающихся дебатов 8. Микровизор OKL4 является микроядром L4 третьего поколения. Он широко используется в мобильных беспроводных устройствах в связи с растущим спросом на высокоэффективные платформы виртуализации во встраиваемых системах. Встраиваемый гипервизор Codezero 1 это новый гипервизор, основанный на архитектуре микроядра L4, но написанный с нуля, чтобы воспользоваться преимуществами новейших исследований в микроядерной архитектуре. Он следует фундаментальным принципам микроядер в том, что реализует адресные пространства, управление потоками и межпроцессорным взаимодействием только в привилегированном микроядре, наряду с возможностями виртуализации. Codezero реализует типовой уровень абстракции над аппаратной платформой. Уровень абстракции реализует многопоточность, межпроцессорный обмен, адресное пространство управления, отображение адресного пространства, безопасность, питание и восстановление после ошибок управления. Представляемый гипервизор вобрал в себя некоторые идеи из упомянутых выше. Однако мы подчеркиваем некоторые принципиальные отличия, одними из которых являются следующие применяется экзоядро, которое допускает прямой доступ к аппаратным средствам, таким образом устраняя абстракции и сокращая издержки при обмене уровней гипервизор предназначен для использования на конкретной платформе каждое ядро и периферийные устройства жестко привязаны к какой-либо гостевой ОС отсутствуют средства обмена между гостевыми ОС гостевые ОС не видят друг друга они полностью изолированы гостевая ОС может исполняться в реальном времени, при этом ее поведение становится детерминированным. Архитектура гипервизора построена по компонентному принципу рис. 3. Все компоненты имеют четко очерченные интерфейсы. Такой подход является очень важным, чтобы упростить модификации при переходе на другую платформу. Как уже говорилось, каждая версия нашего гипервизора работает только на определенной фиксированной аппаратной конфигурации. Это необходимо для того, чтобы ПО содержало только необходимый в текущий момент функционал. Чем проще тем надежнее, проще верификация и сертификация. Компоненты делятся на три слоя низкоуровневые драйверы управление платформой и отладочные утилиты управление виртуализацией. Уровень драйверов подразделяется на два блока ядро и вводвывод. В первый входит управление сегментированной и страничной памятью, таблицей прерываний, функциями ядра процессора и Local APIC. Вводвывод включает следующие устройства графический дисплей, клавиатуру, последовательный и параллельный порты. Следующий уровень компонентов это логическая надстройка над драйверами. HPET high-precision event timer используется для средств синхронизации и работы профилировщика. Модуль IO APIC предназначается для конфигурации распределения прерываний по ядрам. Модуль ACPI позволяет получать информацию о конфигурации оборудования, реализовывать программный сброс и выключение. Модуль SMP имеет реализацию функций для запуска, приостановки и сброса ядер. Блок управления отладкой включает многооконную консоль для каждого ядра, обработчик команд и ведения журнала протоколирования. На самом верхнем уровне располагается слой компонентов менеджера виртуальных машин и самих гостевых машин. На рисунке показаны только основные компоненты системы. На самом деле их намного больше, но даже несмотря на это система достаточно компактная за счет включения только самого необходимого. Еще раз повторим, что единственный минус такой архитектуры полное отсутствие гибкости. Для загрузки гипервизора рис. 4 9, конфигурационного файла и образов гостевых систем мы используем multiboot-совместимые средства, такие как GRUB для загрузки с файловой системы компьютера или PXELINUX для загрузки по сети. Multiboot-загрузка является очень удобным средством, поскольку устраняет необходимость реализовывать файловую систему в ядре гипервизора для загрузки модулей. Также она автоматически переводит ядро в защищенный режим и выдает информацию о карте памяти. Загрузка осуществляется на так называемом boot-strap processor BSP, назначаемом BIOS при старте системы. Как правило, это ядро с нулевым идентификатором. На BSPядре выполняется основной код гипервизора. После серии инициализаций это ядро переводит остальные три ядра в режим исполнения кода, инициализирует их, переводит в 64-битный режим и запускает на виртуальных машинах загруженные образы ОС. Поскольку в SMPсистемах все ядра являются равнозначными одно ядро не может управлять другими, ПО гипервизора распределено между ядрами. После этого гипервизор переходит в режим контроля виртуальными машинами с помощью консольного терминала и средств ведения журнала. После перехода процессора из PIC-mode в symmetric mode IO APIC перенаправляет прерывания от параллельного и последовательного портов на 1-е и 2-е ядро соответственно. Виртуальные машины, запущенные на этих ядрах, используют интерфейсы портов в качестве внешних. Виртуальная машина на третьем ядре не имеет внешних интерфейсов и применяется только для загрузки ядра. Это необходимо для определения взаимного влияния ядер на производительность. Как известно, компьютеры x86-архитектуры имеют память с дырами рис. 5 10. Это связано со свойственной ей традиционной обратной совместимостью. Основная часть кода гипервизора лежит в области больше 1 МБ. В основной памяти располагается часть кода, необходимая для вызова 16-битных функций модуля SMP. Каждой виртуальной машине выделено по 256 МБ оперативной памяти. Эти области изолируются таким образом, что виртуальная машина не может получить доступ к другой области памяти. Образы виртуальных машин, загружаемые с помощью Multiboot 9, также располагаются в расширенной памяти. Результирующие данные по разработанному коду показаны в табл. 1. Код содержит около сотни файлов. Основная его часть написана на Си с использованием ассемблерных функций. Код содержит обильные комментарии. И самое важное, что текущая функциональность уложилась в 8500 строк кода, что дает нам основание полагать, что код действительно можно характеризовать как микро. Для разработки и отладки гипервизора мы использовали стенд, схема которого представлена на рис. 6. Мы используем три компьютера один для разработки, второй является целевой платформой, и третий в качестве терминала последовательного порта. Параллельный порт целевой платформы подключен к осциллографу для измерения задержки обработки прерывания. В верхней части рисунка показан перечень ПО, которое используется на соответствующих компьютерах. На компьютере разработчика установлены симуляторы QEMU и Bochs. Для отладки на целевой платформе используется загрузка по сети PXE с помощью утилиты PXELINUX. Как известно, все ядра в симметричной многопроцессорной системе равноправны рис. 7 11. Единственное отличие заключается в том, что ядро, загружаемое BIOS, помечается флагом как boot-strap processor. У каждого ядра имеется встроенный local APIC 12, который соединяется со специальной шиной прерываний. По этой шине ядра получают прерывания от IO APIC 13, отвечающего за routing прерываний, а также имеют возможность генерировать межпроцессорные прерывания. Последние используются для синхронизации, инициализации ядра и запуска на нем процедур с указанного адреса. Помимо шины прерываний, процессоры имеют соединения еще с двумя шинами шиной памяти и шиной портов вводавывода. Через порты ввода вывода процессор имеет возможность управлять периферийными устройствами. Шина памяти используется для доступа к RAM и регистрам, которые отображают в память PCI, HPET, ACPI, IO APIC, Local APIC и другие устройства 14. Основные характеристики тестового стенда ЦПУ Intel Core i5 650 3.20 Гц x 4 чипсет Intel 3450 память 8 ГБ DDR3 1333 MГц. В рамках этого проекта измерение задержки обработки прерывания осуществляется с помощью параллельного порта LPT. Схема эксперимента изображена на рис. 8. Используются три вывода параллельного порта заземление GND, данные D0 и подтверждение ACK. Последний служит для выдачи сигнала прерывания IRQ 7 вводавывода APIC в контроллере. При замыкании линии прерывания на землю нисходящий фронт вызывается обработчик прерывания, который последовательно выключает и включает D0. Прерывание также возникает при отсоединении контакта от земли передний фронт. Передний фронт используется для запуска осциллографа. Все события отображены на экране осциллографа рис. 9. В среднем достигаются задержки на прерывания 5 мкс с разбросом 0,3 мкс. Природа разброса, по-видимому, связана с некоторой емкостью в кабеле и логикой срабатывания в контроллере прерывания, что видно из плавно восходящего фронта прерывания. Самое сложное в данном проекте заключается в том, что ПО разрабатывается на пустом аппаратном обеспечении отсутствует ОС. Одновременно возникают проблемы с тестированием потому, что многократная перезагрузка компьютера при отладке это очень трудоемкая работа. К счастью, в настоящее время можно до определенного этапа разработки использовать эмуляторы QEMU. Во время исследования были опробованы различные средства для отладки табл. 2. Как показала практика, наиболее удобным и достаточно адекватным средством оказался эмулятор QEMU. Однако, к сожалению, пользоваться им можно только до тех пор, пока можно обойтись 64-битным режимом и инструкциями VMX, поскольку они не поддерживаются. Затем на помощь приходит Bochs. Разработка и отладка с помощью симуляторов существенно ускоряются. Тем не менее требуются периодические запуски на реальном стенде. Это процесс гораздо более медленный. Запуск программы по сети с помощью PXE в нашем случае, например, длится 35 с. Причем для следующей попытки нужна перезагрузка целевой машины. Тестирование проводилось на машине на базе четырехъядерного Intel Core i5. Одно из ядер процессора занято выполнением программного кода гипервизора, остальные выполняют тестовые виртуальные машины. Гипервизор сконфигурирован таким образом, что прерывания поступают напрямую к ядрам. Разрешены 2 вида прерываний прерывание на порте LPT и прерывание на порте COM. Первое сразу же направляется на 2-е ядро, а второе на 3-е. В данной работе не рассматривается работа с COM-портом и третьим ядром. Для задач тестирования используются LPT-порт и 2-е ядро рис. 10. Для нужд профилирования было разработано специальное ПО. Аппаратный профилировщик базируется на стандартной плате отладки фирмы Xilinx. Плата построена на основе ПЛИС Virtex-5. На ней размещены различные коммуникационные интерфейсы. В данной работе использовались только Ethernet, COMи LPT-порты платы. Плату можно смонтировать в корпус тестируемой системы посредством порта PCI-e, что даст возможность обращаться к плате как к стандартному RAM-контроллеру. Смонтированный таким образом профилировщик может генерировать прерывания и различную активность на портах вводавывода. В свою очередь, данная активность может перенаправляться одному из ядер для обработки в ПО. То же самое может быть получено при использовании LPT-порта. Сценарий тестирования состоит из трех фаз 1-я фаза профилировщик генерирует прерывание и запускает высокоточный таймер 2-я фаза профилировщик переходит в состояние ожидания реакции тестируемой системы в момент прихода отклика тестируемой системы таймер на профилировщике останавливается и время реакции записывается 3-я фаза. Затем тест повторяется для получения статистически обоснованного результата. Интервал между тестами может быть произвольным. Разрешение измерений таймера 50 нс максимальное время измерения 1 мкс. Для построения гистограммы профилировщик хранит во внутренней памяти последние 256 событий с временем реакции на каждое. Также профилировщик считает максимальное и минимальное время реакции для каждого типа события. Через присутствующий на плате профилировщика сетевой порт Ethernet пользователь может получить доступ ко всем хранящимся данным измерений. Согласно конфигурации и сценарию тестирования рис. 11, профилировщик генерирует прерывание на LPT-порте тестируемой системы. На это прерывание реагирует программный обработчик, запущенный на тестируемой системе. Его ответ выражается в изменении состояния одного из битов порта LPT, что вызовет изменение уровня сигнала на соответствующем контакте данного порта. Время от момента генерирования прерывания до получения ответа называется временем отклика. Профилировщик хранит два вида событий соответствующих переднему и заднему фронту сигнала. При ответе обработчик сигнала инвертирует 1 бит порта LPT. Записанные профилировщиком события показаны на рис. 12. Максимальное и минимальное время отклика составило, соответственно, 11,65 и 10,7 мкс для обоих типов событий, среднее время отклика 11,1 мкс. В данной работе обоснована необходимость разработки аппаратно-зависимого автономного микрогипервизора, позволяющего запускать одновременно три виртуальные машины на отдельных ядрах четырехъядерного PC c x86-архитектурой. Показано, как компонентная модель архитектуры микрогипервизора позволяет уложиться в 8500 строк кода. Также замерен один из основных показателей систем реального времени задержка обработки прерывания для ISA-устройства, которая равна 11,1 мкс. В настоящее время идут работы над реализацией технологии виртуализации PCI-устройств VT-d планируется адаптация кода аппаратно-зависимого микрогипервизора для восьмиядерной платформы Intel Core i7. 