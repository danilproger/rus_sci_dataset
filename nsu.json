{"title": "ПРОЕКТИРОВАНИЕ ИНФОРМАЦИОННОЙ СИСТЕМЫ   ПРЕДСТАВЛЕНИЯ РЕЗУЛЬТАТОВ КОМПЛЕКСНОГО АНАЛИЗА   ПОЭТИЧЕСКИХ ТЕКСТОВ  ", "absract": "В рамках проекта по автоматизации работы с поэтическими текстами, реализуемого на базе Института вычислительных технологий СО РАН, ведется комплекс исследований, связанных с анализом поэтических текстов. Каждый компонент проекта относится к одному из структурных уровней анализа текста: структурный, семантический, прагматический. Структурный анализ поэтического текста связан с выделением его метроритмических характеристик. В рамках семантического анализа ведутся исследования по выделению смысловых конструкций из произведения. Прагматический уровень включает в себя исследования по автоматическому определению высокоуровневых характеристик поэтического текста, таких как жанр и стиль. В данной работе описан процесс проектирования и реализации информационной системы представления результатов анализа поэтических текстов. На этапе проектирования сформулированы задачи, которые призвана решать информационная система, а также изложены требования в порядке приоритета для общего проекта. Представленная информационная система объединяет в себе разнородную информацию о результатах анализа поэтических текстов, полученных на каждом из уровней представления. Исходя из потребностей потенциальных пользователей, выполнено описание внешних взаимодействующих элементов системы. Разработан тестовый интерфейс для доступа к хранилищу информационной системы. Реализация информационной системы обеспечит существенное упрощение исследований поэтических текстов. ", "text": " Одной из актуальных задач в области использования информационных технологий для гуманитарных исследований является создание программного приложения для автоматизации комплексного анализа поэтических текстов, призванного облегчить труд филологов. Комплекс таких разработок ведется в Институте вычислительных технологий ИВТ СО РАН, концепция создаваемой информационной системы изложена в работах 1 2. Среди аналогичных исследований других авторов следует назвать, прежде всего, статью 3, в которой была намечена большая программа исследований метрических, ритмических и фонетических включая рифму характеристик русских поэтических текстов. Эта программа опиралась, в свою очередь, на систему STARLING, которая являлась частью проекта Автоматизированный лингвостиховедческий анализ русских поэтических текстов после ухода из жизни руководителя проекта С. А. Старостина работы в этом направлении были прекращены. Именно на основе названных исследований нами реализовано действующее в настоящее время программное средство анализа метроритмических характеристик поэтических текстов, описанное в работе 2. Однако алгоритм из работы 3 носит полуэмпирический характер, что снижает его точность в случаях сложной акцентуации, поэтому для дальнейших исследований нами реализуется более строго обоснованный алгоритм из статьи 4, модифицируемый с учетом неоднозначной акцентуации текстов на русском языке. Больших успехов достиг коллектив авторов под руководством И. А. Пильщикова и А. С. Старостина начиная с 2008 г. выполнен ряд работ, посвященный автоматическому распознаванию метра в силлабо-тонических стихах 57. В 2016 г. в устном докладе Инструментальная среда для работы с русскоязычными стихотворными корпусами и их специализированной разметкой продемонстрирована инструментальная компьютерная среда РМС Рабочее место стиховеда описана возможность эвристической акцентуации несловарных слов, создание интерфейса редактора шаблонов, визуализация результатов автоматического анализа метрики и ритмики стиха. Однако нам неизвестны работы, в которых авторы проводили исследование автоматизации анализа характеристик более высокого уровня например, определение жанра. Так как задачи анализа фонетических и лексических характеристик текста менее специфичны и решаются намного чаще, чем характерная именно для поэтических текстов задача анализа метроритмических характеристик, то для решения этих задач нами используются более или менее стандартные алгоритмы, изложенные в статье 2. Наконец, для определения стилей и жанровых характеристик текстов используются наиболее известные приемы ансамблирования базовых алгоритмов в композиции, такие как взвешенное голосование, бустинг и стекинг 8 аналогичные подходы используются для других текстов в 9 10. Рассмотрим некоторые из существующих информационных систем, предназначенных для исследования тех или иных характеристик поэтических текстов проект Конкорданс к текстам Ломоносова, система SPARSAR, веб-приложение Metricalizer. Проект Конкорданс к текстам Ломоносова начат в 2009 г. и строится на основе корпуса авторских текстов, снабженных структурной, филологической и грамматической разметкой. Проект доступен через веб-интерфейс и представляет собой как алфавитно-частотный конкорданс к текстам, так и сборник изданий текстов Ломоносова. Технологическая цепочка работы с корпусом включает в себя немалую долю ручной разметки корпуса и сегментации текста с помощью парсера выполняется морфологический разбор с последующей постобработкой снятие омонимии, исправление ошибок. Практическая реализация упрощала взаимодействие с созданным конкордансом пользователь может в интерактивном режиме выбрать подходящий термин для работы с ним. Проект не был завершен авторами. Описанная в работе Р. Дельмонте 11 система SPARSAR предполагает автоматический комплексный анализ поэтических текстов с целью изучения их стиля. SPARSAR выполняет анализ каждого стихотворения на разных уровнях на уровне предложения, на уровне строки и на уровне строфы. Такая информационная система была бы полезна авторам статьи, однако детальное описание внутренней структуры уделяется модулю, связанному с автоматическим чтением текста TextToSpeech 12. Веб-приложение Metricalizer, разработанное К. Боббенхаузеном и Б. Хаммерихом, позволяет производить автоматический анализ метрических характеристик немецких стихов 13. В системе предусмотрены метрический анализ стихотворения, создание XML-докумен тов по результатам проводимого анализа, разбор текстов по акцентуации и рифмовке, фонетический разбор слов в формате X-SAMPA Extended Speech Assessment Methods Phonetic Alphabet, расширенный фонетический алфавит методов оценки речи. Упомянутая система наиболее релевантно соотносится со структурой, которую можно применить для информационной системы в ИВТ СО РАН, однако в работе 13 детальная структура системы Metri calizer не представлена. Разнообразие алгоритмов обработки поэтических текстов, несомненно, является важным фактором успешного решения описываемой задачи. Однако во многих случаях остается актуальным вопрос реализации алгоритма в виде отчуждаемого программного продукта и его использование без непосредственного участия авторов. В силу этого программное приложение должно представлять собой некую информационную подсистему со специфическими входными и выходными данными. Важно настроить взаимодействие подсистемы как с конечным пользователем, так и с другими подсистемами. Таким образом, необходимо разработать подход к проектированию и реализации системы анализа поэтических текстов, учитывающий ее сложную модульную структуру. Цель данной статьи заключается в описании процесса проектирования информационной системы автоматизации комплексного анализа поэтических текстов. Процесс анализа поэтических текстов сводится к следующим последовательным шагам рис. 1, на которых осуществляется анализ характеристик текста инициализация формирование корпуса поэтических текстов и его предобработка для последующего анализа структурный анализ определение низкоуровневых характеристик поэтического текста фонетика и метроритмика стихотворения семантический анализ определение смысловых конструкций с учетом поэтической синонимии прагматический анализ экспертная оценка принадлежности к определенным стилевым характеристикам для поэтического текста жанр, стиль и др. синтез проведенных исследований определение влияния низших уровней поэтических текстов на более высокие, а также объединение результатов в удобном для восприятия и поиска виде. Концептуальное проектирование включало в себя формирование возможностей создаваемой информационной системы. Создаваемая система должна обладать следующими возможностями. 1. Обеспечение доступа к корпусам поэтических текстов. При этом к текстам могут предъявляться дополнительные требования. Например, в процессе обработки важно учитывать особенности старой времени создания текста орфографии. 2. Автоматизированная обработка корпуса поэтических текстов, хранящихся в БД а определение фонетических характеристик текста б исследование метроритмических характеристик метрика, стопность рифмовка строфики и др. с указанием неоднозначностей, которые не могут быть разрешены автоматически, в определение лексических характеристик текста г определение жанрово-стилевых характеристик текста. 3. Занесение полученных характеристик в хранилище базу данных. 4. Статистическая обработка полученных характеристик и их представление в удобном для исследователя виде. 5. Возможность импорта корпусов поэтических текстов из баз данных и файлов и их экспорта в другие информационные системы для дальнейшей автоматизированной обработки. Алгоритмы, реализуемые при прохождении перечисленных выше этапов анализа структурного, семантического, прагматического, изложены в работах авторов под руководством В. Б. Барахнина 2 8 14. Однако остается актуальной задача синтеза проводимых исследований в пределах общей информационной системы, пригодной для использования экспертами-филологами. В рамках текущего исследования все подсистемы проекта будут рассматриваться в виде черного ящика ведущую роль играют данные, подаваемые на вход и получаемые на выходе. В качестве базового инструмента проектирования на начальном этапе использовались интеллект-карта и диаграмма прецедентов. На рис. 2 процесс анализа поэтических текстов представлен в нотации IDEF0. Выделяются следующие бизнес-про цессы верхнего уровня. 1. Предобработка текста процесс А1 на вход поступает необработанный текст возможно, в дореформенной орфографии с информацией об этом тексте. Под управлением правил формирования дореволюционной и современной орфографии происходит преобразование текста в соответствии с современной орфографией с занесением результатов в систему хранения. Дальнейшая обработка текста осуществляется в современной орфографии. 2. Структурный анализ процесс А2 на основании формализованных правил построения метра и ритма поэтического текста выполняется извлечение его структурных характеристик тип рифмы, количество женских и мужских окончаний и др. 3. Семантический анализ процесс А3 на основании формализованных правил построения словосочетаний выполняется извлечение синтаксических конструкций из поэтического текста и их идентификация с использованием базового словаря, учитывающего синонимию. 4. Прагматический анализ процесс А4 с использованием системы классификации жанров и стилей на выходе формируется гипотеза о принадлежности поэтического текста к определенному жанру и стилю. Информационная система ИС должна учитывать этапы анализа поэтических текстов. Структура системы состоит из компонентов, перечисленных при описании постановки задачи. Связи в структуре показаны на рис. 3. Компонент фонетического анализа включен в систему как готовый модуль, ранее разработанный в ИВТ СО РАН, он осуществляет акцентуацию расстановку ударений и транскрипцию слов. Включенные в модуль элементы метроритмики используют входные данные, получаемые на этапе структурного анализа. Учет вхождений слов и словосочетаний в те или иные поэтические тексты связан с задачей составления частотных справочников и конкордансов. При прагматическом анализе определяются жанр и стиль произведения. Компоненты пользовательского интерфейса представляют собой ключевые возможности по работе с системой просмотр характеристик и сравнение поэтических текстов по ним, а также поиск произведений. Технические требования, предъявляемые к разрабатываемой ИС, отражены в таблице см. далее. Для каждого требования выставлен приоритет его выполнения высокий выполнение таких требований необходимо средний выполнение таких требований желательно низкий выполнение таких требований необязательно. Требования, предъявляемые к ИС The requirements for the information system Требование Приоритет Учитывать вышеописанные этапы комплексного анализа Высокий Отображать метроритмические характеристики Высокий Отображать результаты семантического анализа по каждому отдельному произведению Средний Разработать функционал ручной корректировки данных экспертом Средний Реализовать доступ к ИС для конечного пользователя Высокий Предусмотреть логику работы системы для повторяющихся значений Средний Спроектировать логику работы системы для дальнейшего ее масштабирования Высокий Разработать API программный интерфейс приложения для доступа к ИС Низкий На рис. 4 представлена диаграмма прецедентов. Система проектируется с учетом того, что в процессе работы она будет использоваться различными категориями пользователей и взаимодействовать с другими системами. В качестве акторов были выбраны пользователь филолог, проводящий исследование поэтических текстов программист-исследователь лицо, ответственное за наиболее полную реализацию функционала и бесперебойную работу системы, а также за математическую обработку результатов администратор системы лицо, ответственное за использование особых технических средств, добавление нового контента, актуализацию данных и т. п. внешняя система та или иная подсистема проекта по автоматизации анализа поэтических текстов, упомянутая ранее экспортирует результаты проведенных исследований в разрабатываемую систему для комплексного отображения результатов. Роли программиста-исследователя и пользователя могут быть объединены в зависимости от специфики выполняемой филологической задачи. Кроме того, пользователь, как эксперт, может проводить оценку данных, выводимых системой, и в случае возникновения спорных моментов выполнить редактирование данных в ИС. Все действия в системе должны протоколироваться администратором например, при импорте данных от подсистем проекта могут возникнуть непредвиденные технические проблемы, которые необходимо устранить вручную. Далее приведем некоторый сценарий взаимодействия возможных участников системы согласно диаграмме прецедентов. Пользователь ИС имеет возможность просматривать информацию о произведениях, после проведения экспертной оценки и в случае нахождения спорных данных пользователь-филолог отправляет запрос на доступ к редактированию или информирует администратора БД о результатах экспертной оценки и решении об изменении данных. Администратор БД проверяет экспортируемые данные от внешних систем, которые проводят анализ поэтических текстов на технические ошибки в случае если внешняя система получила ошибки при результате анализа. Программист-исследователь будет иметь возможность с помощью API организовать пакетную выгрузку данных о проанализированных поэтических текстах. Поскольку текущий функционал отражен в требованиях к системе как требование с низким приоритетом, работа над API находится на стадии проектирования. Внешние системы подсистемы с помощью заранее установленных протоколов взаимодействия загружают результаты анализа лирических произведений, полученные при работе отдельных алгоритмов в том числе из подсистемы, описанной в 2. В перспективе разрабатывается вариант взаимодействия, при котором подсистемы в качестве входных параметров используют данные описываемой информационной системы. Основная часть ИС реализована в виде базы данных, хранящей в себе как сами стихотворения, так и их характеристики. Концептуальная ER-модель системы показана на рис. 5. Для стандартизации описания метаданных использовался ГОСТ Р 7.0.10-2010, опирающийся на набор элементов Дублинского ядра норматива для общесистемного описания информационных ресурсов. Сущность POEMS включает в себя 1 фонетические характеристики сущность PHONETICS, на основании которых определяются метроритмические характеристики сущность MRSTATISTICS последняя, в свою очередь, включает в себя метаданные, приведенные на рис. 2 2 словарь слов сущность DICTIONARY связан с сущностями словосочетания COLLOCATIONS, которые извлекаются из текста ключевыми метаданными сущно сти COLLOCATIONS являются статистика упоминания в произведении PoemStatistics и у данного автора AuthorStatistics вообще. 3 характеристики высокого уровня сущность HIGH LEVEL CHARACTERISTICS включают в себя данные о жанре GENRE и стиле STYLE 4 другие характеристики сущность OTHERS являются вспомогательными и служат для хранения разнородной внешней информации о произведениях, например источник Source, сведения об издании Publisher и др. Для организации доступа к ИС был спроектирован и разработан интерфейс пользователя рис. 6, доступный через веб-браузер клиента. Запросы к базе данных организованы в формате SQL, что повышает универсальность использования системы. Интерфейс ИС доступен по адресу httpdb4.sbras.rupoemsuserIS. При тестовой реализации системы в качестве экспериментального корпуса текстов было решено использовать цикл лирических произведений А. С. Пушкина, написанных в 1830 г., в так называемую Болдинскую осень. Выбирая доступные произведения автора меню слева, пользователь получает возможность просмотреть само произведение и ознакомиться с его характеристиками. Для некоторых произведений приведена ссылка на рукописный оригинал использовались ресурсы Института русской литературы ИРЛИ РАН. Дополнительное окно словосочетаний открывается при нажатии на одноименную ссылку в режиме просмотра произведения пользователь имеет возможность просмотреть выделенные словосочетания и сочетания слов и при наличии соответствующих прав доступа изменить их после проведения экспертной оценки. Реализована функциональность сравнения нескольких произведений пользователь выбирает необходимые для анализа произведения для просмотра отображается сводная таблица произведений с ключевыми характеристиками. Таким образом, в результате выполнения работы осуществлено проектирование и реализация информационной системы, осуществляющей интеграцию созданных ранее в ИВТ СО РАН модулей, предназначенных для решения отдельных задач комплексного анализа поэтических текстов. Разработан прототип информационной системы. С помощью диаграммы прецедентов показано, какие действия может выполнять каждый участник системы. Реализован графический интерфейс информационной системы. Результаты работы показали принципиальную возможность интеграции упомянутых выше компонентов системы, что открывает перспективы создания весьма востребованного филологами инструментария автоматизации комплексного анализа поэтических текстов на русском языке. "}
{"title": "ПРОГРАММНОЕ ОБЕСПЕЧЕНИЕ НА ОСНОВЕ ВЕБ-ТЕХНОЛОГИЙ  ДЛЯ ГЕОНАВИГАЦИИ НЕФТЕГАЗОВЫХ СКВАЖИН  ", "absract": "Для эффективного освоения залежей углеводородов чрезвычайно важной становится высокая точность проводки горизонтальных скважин в целевых пластах-коллекторах. В процессе бурения геонавигация скважины со сложной траекторией выполняется по геофизическим данным в реальном масштабе времени. Представленная работа посвящена разработке нового программного обеспечения для геонавигации нефтегазовых скважин с горизонтальным завершением. Для решения задач геонавигации используются алгоритмы, основанные  на методах корреляции каротажных данных и численной инверсии измерений электромагнитного каротажа. Разработанное новое программное приложение основано на веб-технологиях и имеет клиент-серверную архитектуру. Для оптимизации времени выполнения ресурсоемких расчетов используются высокопроизводительные облачные вычисления. ", "text": " В связи с повсеместным переходом в бурении от вертикальных скважин к скважинам с горизонтальным завершением существенно усложняется и расширяется круг задач про мысловой геофизики. При бурении горизонтального участка скважины применяют геонавигацию оперативную корректировку траектории бурения с целью ее удержания в целевом нефтеносном пласте. Следует отметить, что геонавигация это сложный процесс, требующий использования дорогостоящего оборудования и программного обеспечения ПО, а также работы квалифицированных геофизиков-геонавигаторов. Решение о корректировке траектории принимают непосредственно в процессе бурения на основе каротажных данных с использованием приборов, входящих в состав буровой колонны. Стандартные программные комплексы, предназначенные для интерпретации каротажных данных из вертикальных скважин, не подходят для проведения геонавигации, что приводит к необходимости разработки специализированного ПО. Каротаж в процессе бурения начал активно развиваться еще в 80-х гг. прошлого столе тия 1. Несмотря на это, в России для каротажа в процессе бурения до сих пор используют приборы в основном только крупных иностранных нефтесервисных компаний, . В рамках реализации программ импортозамещения НПП ГА Луч, Новосибирск и ИНГГ СО РАН, Новосибирск разработан и опробован на месторождениях Западной Сибири аппаратурный комплекс ЛУЧ. Комплекс включает в себя ряд приборов для проведения каротажа в процессе бурения, при этом набор геофизических измерений достаточен для проведения как геонавигации, так и петрофизической интерпретации. Оперативная интерпретация данных каротажа в процессе бурения может проводиться либо самим заказчиком нефтедобывающей компанией, либо теми же нефтесервисными компаниями. Для нефтедобывающих компаний на российском рынке в настоящее время представлен ряд программных решений для геонавигации Геонафт от компании, Geosteering office от, StarSteer от . Однако вс перечисленное ПО обладает одним недостатком не использует наиболее продвинутые подходы для задач геонавигации, основанные на алгоритмах численных решений прямых и обратных задач электродинамики в классе реалистичных интерпретационных моделей. Сервисные компании используют ПО, узко ориентированное на свои приборы. В связи с этим в ИНГГ СО РАН разработано ПО, позволяющее проводить геонавигацию скважин с использованием комплекса ЛУЧ двумя методами корреляции каротажных данных и численной инверсии измерений электромагнитного каротажа ЭМК. Приборы, входящие в состав комплекса каротажа в процессе бурения рис. 1, позволяют проводить геофизические исследования в скважинах следующими методами многозондовый высокочастотный индукционный каротаж ВИКПБ боковой сканирующий каротаж БКС гамма-каротаж ГК нейтрон-нейтронный каротаж по тепловым нейтронам ННК-Т гамма-гамма плотностной каротаж ГГК-П другие измерения инклинометрия, положения угла отклонителя, температура, ударные нагрузки. Для решения ключевых задач геологического сопровождения бурения используют данные ЭМК из-за его наибольшей радиальной глубинности. Входящий в аппаратурный комплекс ЛУЧ прибор ВИКПБ, основанный на методе высокочастотного индукционного каротажа ВИКИЗ 2 3, выполняет измерения относительных амплитудно-фазовых характеристик эдс, наведенной в приемных катушках. Измерения эдс проводятся в двух основных и четырех дополнительных трехкатушечных зондах с длинами от 0,7 до 1,4 м на двух частотах 0,88 и 3,5 МГц. Зонды одинаковой длины различаются базой, т. е. расстоянием между дальней и ближней приемными катушками. В парах приемных катушек регистрируются разности фаз наведенных эдс и отношения амплитуд A, а также выполняется их трансформация в кажущееся удельное электрическое сопротивление УЭС. Проведенные опытно-промышленные испытания приборов каротажа в процессе бурения ЛУЧ на месторождениях АО НК Роснефть и АО Сургутнефтегаз показывают, что приборы соответствуют техническим и эксплуатационным требованиям для бурения наклонно направленных и горизонтальных скважин 4 5. Однако для успешной проводки скважины недостаточно одних приборов каротажа в процессе бурения, необходимо также и специализированное ПО для оперативной интерпретации геофизических данных. Разработанное ПО для геонавигации представляет собой веб-приложение, состоящее из трех основных структурных блоков клиентского, серверного и вычислительного рис. 2. а б Клиент отвечает только за визуализацию данных, что сводит к минимуму требования, предъявляемые к оборудованию. Использовать такое ПО можно на любых устройствах от персональных компьютеров до смартфонов. Требуется лишь наличие веб-браузера и доступ к серверу по сети. При этом обновление приложения выполняется для всех клиентов одновременно благодаря использованию единого ресурса. Серверная часть обрабатывает пользовательские запросы, управляет очередностью выполнения ресурсоемких задач и возвращает результаты расчетов клиентам. В вычислительной части непосредственно производятся расчеты на серверах кластерах с использованием распределенных масштабируемых и высокопроизводительных параллельных вычислений. Ниже приведен полный стек технологий, использованный при разработке ПО TypeScript и JavaScript языки программирования ЯП, используемые для создания графического интерфейса, отображаемого в браузерах Angular платформа для сборки веб-приложений из созданных компонентов и используемых библиотек D3 библиотека для визуализации в формате SVG сложных элементов траектории скважины, моделей геологических пластов, каротажных данных NodeJS платформа, позволяющая разрабатывать серверную часть на языке JavaScript MongoDB нереляционная база данных для хранения учетных записей и пользовательских данных RabbitMQ брокер сообщений для взаимодействия сервера с вычислительными модулями Docker платформа для создания кроссплатформенных вычислений С, Fortran ЯП, позволяющие разрабатывать высокопроизводительные вычислительные алгоритмы. Интерфейс, с которым работает пользователь, отображается в веб-браузере. За счет этого достигается кроссплатформенность клиентской части, поскольку веб-браузеры есть практически во всех операционных системах. Движок JavaScript V8, считывающий и исполняющий исходный код на JavaScript, а также другие аналоги встроены в большинство браузеров. Однако не все браузеры в одинаковой степени хорошо поддерживают новые стандарты ЯП. Поэтому для полной совместимости необходимо транслировать код в более старые версии JavaScript. Для этого в проекте используется язык TypeScript. Кроме того, статическая типизация, которая вводится TypeScript, фиксирует несоответствия типов на этапе трансляции в необходимый стандарт JavaScript до непосредственного выполнения программы. Это облегчает читаемость кода, а также помогает осуществлять поиск ошибок на этапе разработки и компиляции. Для упрощения и ускорения разработки существуют различные фреймворки, определяющие структуру веб-приложения. Одним из наиболее известных является активно развивающийся Angular. Его отличительная особенность состоит в том, что он предназначен для разработки приложений именно на TypeScript. Для создания интуитивно понятного интерфейса используется библиотека Angular Material, являющаяся адаптацией Google Material Design . Этот пакет упрощает создание таких компонентов взаимодействия с интерфейсом, как кнопки, переключатели, вкладки и пр. В вышеописанной библиотеке реализованы только простые компоненты, поэтому не все элементы интерфейса могут быть отображены с ее помощью. Более сложные элементы, такие как каротажные диаграммы и графические изображения моделей, визуализируются с помощью библиотеки D3. Она отличается высокой производительностью, гибкостью и возможностью работы с масштабируемой векторной графикой. Серверная часть принимает запросы пользователей, выполняет их обработку, взаимодействует с вычислительной частью и отправляет результаты обратно клиенту. Для обеспечения доступности возможности всегда отвечать на запросы пользователей сам сервер не выполняет сложных вычислений. При получении запроса на проведение расчетов происходит генерация входных данных для вычислительных алгоритмов. Они добавляются в очередь сообщений с заданной меткой, затем выполняются расчеты, и результаты возвращаются обратно в очередь сообщений. Последние изымаются и обрабатываются, а пользователю отправляются данные для отображения. Для разработки серверной части выбрана программная платформа NodeJS, позволяющая разрабатывать серверную и клиентскую части на одном ЯП. NodeJS основана на движке V8, транслирующем JavaScript в машинный код. Поскольку для введения типизации используется TypeScript, перед запуском код транслируется в JavaScript, используя компилятор TypeScript. Для хранения пользовательских учетных записей и геофизических данных используется NoSQL база данных MongoDB. MongoDB предназначена для хранения данных без задания схем. Это позволяет проще менять формат хранимой информации, в сравнении с SQL решениями. Для взаимодействия с вычислительной серверная часть использует очередь сообщений RabbitMQ. Это делает их слабо зависимыми друг от друга, а также решает задачу сохранения еще не выполненных задач. Алгоритмы численной инверсии, лежащие в основе одного из методов геонавигации, требуют значительных вычислительных мощностей, особенно для трехмерных моделей среды. Для повышения быстродействия используются распределенные масштабируемые и высокопроизводительные параллельные вычисления. Численная инверсия данных ЭМК выполняется последовательно в заданных интервалах скважины инверсионных окнах. Это делает возможным организацию параллельных вычислений на графических ускорителях и сопроцессорах 6. Высокопроизводительные вычисления требуют распараллеливания кода на низкоуровневых ЯП С Fortran. Использование таких языков требует предварительной компиляции кода со всеми необходимыми зависимостями под каждый вычислительный ресурс. Для проверки корректности работы алгоритма его необходимо тестировать на каждой машине в отдельности. Альтернативным вариантом является запуск программы с помощью платформы Docker. Достаточно поместить вычислительную программу и все ее зависимости в Dockerконтейнер вместе со скриптом, передающим данные из очереди сообщений в программу и возвращающим результаты. Такой контейнер работает быстро и надежно вне зависимости от вычислительного окружения, как на Linux, так и на Windows. Разработанное ПО позволяет проводить оперативную интерпретацию данных каротажа в процессе бурения, полученных комплексом ЛУЧ. За проведение геонавигации отвечают модули Корреляция и Инверсия, использующие методы корреляции каротажных данных и численной инверсии соответственно. Большая часть существующих программных решений для геонавигации основана на идей но близких методах, имеющих в литературе различные названия модельно-стратиграфиче ский, сравнения каротажных данных, матчинг, model-compare-update 7 8. Их суть состоит в сопоставлении данных, измеряемых приборами в процессе бурения, и синтетических данных, полученных в моделях среды, построенных по опорным скважинам. По этим априорным данным создается двумерная модель части разреза, в которой предполагается проводить горизонтальный участок скважины. Синтетические диаграммы каротажа вычисляются в такой модели на проекции запланированной траектории горизонтальной скважины. Начальная модель корректируется так, чтобы добиться совпадения между синтетическими и практическими данными. В разработанном ПО каротажные данные пилотной субвертикальной скважины, приведенные к истинной вертикальной глубине, распространяются по латерали, тем самым формируя стартовую двумерную модель геологической среды. Синтетические каротажные диаграммы в горизонтальной скважине, как правило, получают путем линейной интерполяции данных модели среды в точках с соответствующими вертикальными глубинами. Однако линейная интерполяция не учитывает влияния прилегающих пластов вмещающей среды на сигналы ЭМК, которое обусловлено большой глубинностью метода. В связи с этим синтетические сигналы ВИКПБ рассчитываются с помощью специально разработанных алгоритмов численного моделирования 9. Геонавигатор работает с данными, привязанными к глубине по стволу скважины, а также с их проекциями на вертикальную и горизонтальную оси. Стартовая модель разбивается на блоки по горизонтали, при этом для каждого из блоков задается свой угол наклона рис. 3. При наличии предпосылок в модель могут вводиться разломы, т. е. линии, на которых происходит скачкообразное изменение параметров модели. После каждого изменения параметров модели или траектории скважины синтетические каротажные диаграммы рассчитываются заново, и процесс подбора повторяется. Достоверность модели, полученной в результате таких операций, достигается за счет наилучшего совпадения синтетических и практических данных каротажа в процессе бурения. Совпадение признается достаточным, если различие между практическими и синтетическими данными в среднем не превышает погрешности измерений. Однако метод геонавигации на основе корреляции каротажных данных обладает существенным недостатком. Поскольку датчики каротажных приборов располагаются на некотором удалении от бурового долота, пересечение геологической границы определяется лишь постфактум. Траекторию скважины корректируют, чтобы вернуться в пласт, а не просто удержаться в нем. Такие способы геонавигации принято называть реактивными. Незапла нированные пересечения геологических границ зачастую приводят к нежелательным последствиям. В частности, пересечение водонефтяного контакта может привести к поступлению воды в скважину, а вскрытие газовой шапки и вовсе к аварийной ситуации. В противоположность реактивным выделяют проактивные методы геонавигации, когда траекторию скважины корректируют до того, как произойдет нежелательное пересечение геологической границы буровым долотом 1013. Радиальная глубинность исследования ВИКПБ может достигать 3 м 14 15. Это позволяет проводить проактивную геонавигацию и картировать геоэлектрические границы коллектора в процессе бурения, используя алгоритмы численной инверсии сигналов прибора. Численная инверсия данных ЭМК представляет собой целенаправленный подбор параметров геоэлектрической модели путем минимизации функционала невязки измеренных и синтетических данных 1618. В разработанном ПО моделирование синтетических данных проводится путем численного решения прямой задачи ЭМК в классе слоисто-однородных моделей методом разделения переменных. Минимизация функционала невязки выполняется с использованием алгоритма на основе метода деформируемых многогранников. Разработанное ПО предоставляет пользователю гибкий интерфейс для выполнения пооконной инверсии сигналов ВИКПБ в автоматическом и ручном режимах рис. 4. Геонавигатор загружает входные данные, выбирает интервал для инверсии, устанавливает ширину и перекрытие окон. Стартовая модель для инверсии подбирается, исходя из априорных данных, либо импортируется из модуля геонавигации методом корреляции каротажных данных. Алгоритм численной инверсии позволяет использовать произвольные комбинации сигналов из полного набора измерений ВИКПБ. Благодаря этому при ограниченной скорости передачи данных в реальном времени для инверсии можно задействовать только часть измеряемых сигналов. Уточнить параметры модели можно, получив всю информацию из памяти прибора, после его подъема из скважины на поверхность. Применение метода геонавигации с использованием численной инверсии данных ВИКПБ позволяет картировать границы пласта-коллектора и заблаговременно корректировать траекторию скважины в процессе бурения, не пересекая сами границы. Такой подход значительно повышает эффективную длину ствола скважины, т. е. расстояние, пройденное скважиной внутри продуктивного пласта. Помимо этого, инверсия данных ЭМК позволяет изучать электрофизические характеристики отложений, не вскрытых скважиной и располагающихся ниже по разрезу. Методы геонавигации скважин развиваются в связи с возникновением практической потребности нефтегазовой отрасли в высокоточной проводке скважин с горизонтальным завершением во все более сложных геологических условиях. При этом ключевую роль играет развитие аппаратурной базы наклонно направленного бурения и каротажа в процессе бурения. Дальнейшее развитие методического аспекта ПО связано с внедрением модуля интерпретации скважинных имиджей УЭС, предоставляемых азимутальным прибором БКС 1921. Разработано ПО для геологического сопровождения бурения с использованием данных аппаратурного комплекса для каротажа в процессе бурения ЛУЧ. Алгоритмическая составляющая ПО реализует два метода геонавигации. Первый использует традиционный подход корреляции каротажных данных, второй численную инверсию данных ЭМК. Использование этих методов в комплексе позволяет повысить достоверность результатов интерпретации данных каротажа в процессе бурения, что приводит к более эффективной проводке скважины. Предложен облачный сервис для обработки и интерпретации геофизических данных с использованием кроссплатформенных распределенных масштабируемых вычислений. Использование современных вычислительных технологий позволяет значительно ускорить решение задачи численной инверсии, что необходимо для оперативной геонавигации. "}
{"title": "МОДЕЛИРОВАНИЕ СТРУКТУРНОЙ ОРГАНИЗАЦИИ   ЕДИНОГО ИНФОРМАЦИОННОГО ПРОСТРАНСТВА ПРЕДПРИЯТИЯ –   РАЗРАБОТЧИКА МИКРОЭЛЕКТРОННЫХ СИСТЕМ  ", "absract": "При формировании единого информационного пространства (ЕИП) широко используется моделирование как объектов информационного обмена, так и инфраструктуры ЕИП. Несмотря на большое разнообразие подходов к решению данной задачи, в частности с использованием метода матрицы структуры проекта, предлагаемые решения не обеспечивают непосредственную связь между элементами описываемой структуры и используемыми аппаратными и программными средствами. Также существующие подходы к моделированию информационной структуры не учитывают возможные внешние и внутренние ограничения, накладываемые  на размещение компонентов ЕИП в пространстве предприятия. В работе предлагается подход к формализации структуры ЕИП предприятия – разработчика микроэлектронных систем, призванный устранить данные недостатки. В статье рассмотрена обобщенная модель структурной организации ЕИП по параллельному методу интеграции средств поддержки жизненного цикла изделия. Модель включает в себя описание элементов структуры информационного пространства, каналов связи, их статических и динамических характеристик. Предложенная модель также учитывает ограничения, накладываемые на формирование структуры ЕИП. Имитационное моделирование структурной организации ЕИП, представленной в виде совокупности многоканальных систем массового обслуживания, позволило сделать выводы о пропускной способности и надежности рассматриваемых вариантов организации ЕИП с учетом предлагаемых к использованию аппаратных (серверное решение) и программных (система управления базами данных) средств. ", "text": " Реализация конструкторского проектирования КП микроэлектронных систем МЭС предполагает активное использование программных и аппаратных средств поддержки проектирования с последующей их интеграцией в единую среду информационной поддержки КП МЭС. Существующие решения по информационной поддержке этапов жизненного цикла ЖЦ МЭС можно подразделить на средства интеграции по последовательной и параллельной модели. Решения первого типа предоставляются компаниями разработчиками элементной базы и систем автоматизированного проектирования, ориентированных на приборостроительную отрасль 1, также они включают средства преобразования описания процесса функционирования МЭС на языке высокого уровня в описание на уровне регистровых передач 24. Решения второго типа предполагают обмен информацией посредством системы управления данными об изделии, при этом формируется единое информационное пространство ЕИП предприятия, позволяющее централизованно управлять информацией об изде лии 5, 6. Подобные системы поставляются в составе средств автоматизации проектирования общего назначения, или как часть комплекта бизнес-приложений. ЕИП, как и большинство типов информационных систем, создается прежде всего для удовлетворения потребностей специалистов участников ЖЦ изделия в автоматизации их профессиональной деятельности и обеспечении информационного обмена. При этом необходимо отметить, что участники ЖЦ изделия могут быть распределены по территориально несвязанным друг с другом площадкам с формированием виртуального предприятия 7. Вопрос информационной поддержки изделия связан не только со способами представления и управления конструктивными решениями, но и с формализацией и анализом структурной организации ЕИП с учетом ограничений на размещение ее компонентов. При формировании ЕИП как распределенной информационной системы широко используется моделирование и объектов информационного обмена, и инфраструктуры ЕИП. Моделирование позволяет структурировать разрабатываемую систему, выделить основные объекты и субъекты, обнаружить закономерности и связи между элементами системы, а также сформулировать критерии оптимизации и существующие при этом ограничения 810. Вне зависимости от способа интеграции отдельных компонентов моделирование структуры ЕИП предполагает описание элементов структуры системы описание статических и динамических характеристик элементов структуры и каналов связи выделение множества свойств и характеристик как системы в целом, так и отдельных компонентов. Несмотря на большое разнообразие подходов к решению данной задачи, в частности с использованием метода матрицы структуры проекта, предлагаемые решения не обеспечивают непосредственную связь между элементами описываемой структуры и используемыми аппаратными и программными средствами. Также существующие подходы к моделированию информационной структуры не учитывают возможные внешние и внутренние ограничения, накладываемые на размещение компонентов ЕИП в пространстве предприятия 1113. Предлагаемый ниже подход к формализации структуры ЕИП предприятия разработчика МЭС призван устранить данные недостатки. Рассмотрим структуру ЕИП организации разработчика МЭС по параллельной модели интеграции рис. 1. Объектом информационного обмена в ЕИП является электронный конструкторский документ ЭКД. ЕИП 1 включает следующие основные составляющие СУД 2 информационная система, представляющая унифицированный обменный формат ЭКД, реализующая модель представления конструкторских данных об изделии, а также функций обработки данных и обеспечения взаимодействия между участниками ЖЦ процесса конструкторского проектирования поставщики и потребители информации стационарные и портативные рабочие станции, измерительное оборудование и т. д., способные взаимодействовать с ЕИП посредством сетевых интерфейсов развернутые на базе аппаратных средств. Основными источниками конструкторских данных в ЕИП являются системы автоматизированного проектирования и моделирования, а также интегрированные среды разработки встроенного программного обеспечения МЭС. Приведение разнородных документов от программных и аппаратных систем сторонних разработчиков к унифицированному формату осуществляется посредством программы-посредника. Процесс конструкторского проектирования изделия, равно как и любая другая стадия ЖЦ МЭС, может быть представлен в виде совокупности этапов, задач и процедур. Тип задачи или процедуры зависит от осуществляемой формы преобразования информации создание, редактирование, актуализация, поиск и т. д.. Для любого подмножества процедур и задач могут существовать соответствующе, выполняющие преобразование информации, тип которого зависит от поддерживаемой задачи или процедуры. Совокупность средств поддержки конструкторского проектирования, связанных множеством каналов связи, а также СУД образуют структуру ЕИП предприятия, в которой каждое из множества средств поддержки может быть представлено в виде набора программных и аппаратных средств обработки информации и абонентов участников КП МЭС, обслуживающих эти средства. Переход изделия на следующую задачу, этап КП или ЖЦ в целом приводит к изменению структуры ЕИП с появлением новой формы реализации структуры ЕИП новой структуры связей между элементами ЕИП новых свойств структуры ЕИП в целом. Таким образом, ЕИП это динамическая система, структурная организация которой может быть сведена к обобщенной модели, включающей в себя следующие элементы рис. 2 1 абоненты участники конструкторского проектирования, 1, множество номеров абонентов 2 первичные средства обработки информации аппаратное обеспечение, 1, множество номеров первичных источников 3 вторичные средства обработки информации программное обеспечение, 1, множество номеров вторичных источников 4 первичные объекты информационного обмена, используемые первичными средствами обработки, 1, множество номеров объектов 5 вторичные объекты информационного обмена, используемые вторичными средствами обработки, 1, множество номеров объектов. Реализацию структуры информационного пространства определяет множество схемотехнических решений, которое включает в себя модель представления конструкторских данных, функции обработки данных, функции обеспечения информационного взаимодействия абонентов, программно-аппаратную реализацию серверной составляющей СУД, включающую в себя сервер баз данных СБД и файловый сервер ФС. Для обработки информации в режиме мягкого реального времени также вводится множество, ограничивающее множество преобразований на множестве решений . Средняя допустимая длительность обработки входного запроса принята равной трем секундам, что соответствует установленным требованиям к информационным системам электронного документооборота . На форму реализации структуры ЕИП и его характеристики влияют ограничения, накладываемые со стороны пользователя, размещением компонентов ЕИП и абонентов на предприятии, характеристиками аппаратного и программного обеспечения и формой представления объекта информационного обмена . Множество составляющих ЕИП образует пространство альтернативных вариантов схемотехнического решения при заданных ограничениях множество декартовых произведений . Цель формирования структуры ЕИП состоит в обеспечении информационного взаимодействия между участниками КП изделия. Задача заключается в поиске оптимального схемотехнического решения организации взаимодействия компонентов ЕИП с учетом заданных ограничений, при ограничениях на множество преобразований, . Результатом поиска является конкретное схемотехническое решение, определяющее структуру и конфигурацию аппаратного и программного обеспечения ЕИП, необходимого для обеспечения информационной поддержки сопровождаемой стадии ЖЦ изделия. Структурная организация ЕИП описывается множеством характеристик аппаратных и программных средств табл. 1. Множество характеристик структурной организации ЕИП Characteristics of the UIS Structural Organization Характеристика Описание Характеристики структуры ЕИП 1., 1, множество абонентов участников жизненного цикла 2., 1, множество серверов баз данных 3., 1, множество файловых серверов Характеристики участников информационного взаимодействия 1., 1, множество приложений источников запросов 2., 1, множество типов запросов 3., множество способов ввода-вывода информации клиент сервер, сервер клиент Статические характеристики ЕИП 1. скорость передачи данных по каналу связи, Мбитс 2. постоянная задержка передачи данных по каналу связи, мс 3. постоянная задержка обработки данных в СБД, мс 4. постоянная задержка обработки данных в ФС, мс Динамические характеристики ЕИП 1. множество интенсивностей запросов на считывание данных, запросс 2. множество интенсивностей запросов на запись данных, запросс Статические характеристики ЕИП определяются параметрами используемых аппаратных и программных средств. Оценки параметров СП и СБД значения характеристик определяются исходя из параметров центрального процессора число вычислительных ядер, максимальная тактовая частота и максимальный объем сегмента и дисковой подсистемы среднее время доступа к данным и потоковая скорость передачи данных. Характеристики канала связи зависят от полосы пропускания канала связи, мощности сигнала и определяются по теореме Шеннона Хартли. Множество характеристик структурной организации ЕИП можно представить в виде двух групп матриц распределения, описывающих межсоединения элементов пространства, и информационное взаимодействие между ними, также выделяется матрица связей между группами средств обработки информации верхнего уровня по серверам баз данных, 1, 1, средств обработки информации верхнего уровня по файловым серверам, 1, 1, серверов баз данных по файловым серверам, 1, 1, средств обработки информации верхнего уровня по способам ввода-вывода запросов, 1, 1,2 типов запросов по способам ввода-вывода запросов, 1, 1,2 источников информационных сообщений по типам запросов, 1, 1, матрица связей между группами приложениями источниками запросов и абонентами, 1, 1, . Элементы матриц, могут принимать значение 1 или 0 наличие или отсутствие связи между элементами, . Любой узел ЕИП характеризуется тройкой значений, описывающей все множество его связей с другими компонентами. Элементы матриц, могут принимать непрерывные значения от 0 до 1, соответствующие вероятности того, что запросы, генерируемые данным источником, характеризуются определенным способом ввода-вывода и типом запроса. Источник запросов в системе характеризуется тройкой значений, которая описывает формат создаваемых им запросов в большинстве возможных ситуаций. Графически взаимодействие между элементами матриц, показано на рис. 3. Куб со сторонами, представляет собой модель соединений компонентов ЕИП и соответствует сетевому уровню модели 3. Куб со сторонами, представляет собой модель информационного взаимодействия компонентов ЕИП и соответствует представительскому и прикладному уровням модели 6 и 7 соответственно. Представленные матрицы распределения соответствуют матричному описанию структуры системы массового обслуживания СМО. Так, для рассматриваемой клиент-серверной архитектуры модель структурной организации ЕИП рис. 4 можно представить в виде совокупности СМО взаимодействие клиентской и северной составляющих системы и СМО взаимодействие серверов баз данных и файловых серверов. В рассматриваемой модели приняты следующие ограничения для представления СБД и ФС СБД и ФС считаются независимыми СБД и ФС обладают накопителями ограниченной емкости входной поток запросов соответствует распределению Пуассона поведение СМО во времени описывается марковским процессом с непрерывным временем и дискретным множеством состояний. Математическое описание структурной организации ЕИП в виде СМО было выполнено в виде системы дифференциальных уравнений Колмогорова Чепмена для вероятностей состояний 14. Решение системы осуществлялось методом Рунге Кутты с переменным шагом 15. Многоканальная модель СМО позволяет учесть использование многопроцессорных и рас пределенных серверных решений и программного обеспечения с различными процедурами обработки информационных сообщений. Кратко рассмотрим начальные условия и результаты моделирования структурной организации единого информационного пространства КП МЭС. Значения начальных условий при проведении моделирования зависят от существующих ограничений на пропускную способность оборудования и каналов связи статические характеристики ЕИП и состава участников ЕИП характеристики структуры ЕИП. Для автоматизации процесса формирования номенклатуры средств реализации инфраструктуры ЕИП целесообразно использовать программные средства параллельного моделирования и параметрической оптимизации, такие как и . Аппаратная реализация моделируемой структуры ЕИП включает в себя следующие ключевые компоненты серверное решение СБД и ФС 630 система управления базами данных 2012 центральный процессор 5-2699 2.3 ГГц, 18 ядер, 36 потоков, количество 2 шт. оперативная память 4 4-21300 8 Гб, 2133 МГц, количество 12 шт. внешняя память 1200 0129 1,2 Тб, количество 1 шт. линия связи экранированная витая пара 5 1943 м. При проведении моделирования СМО были приняты следующие начальные условия интенсивность обслуживания 0,7 интенсивность входного потока заявок от 1,0 до 5,5 с шагом 0,5 обслуживание заявок в режиме разделения времени интенсивность ухода заявок из очереди 1,5 допустимое число запросов в системе 10 число активных абонентов в единицу времени от 2 до 5. Данные начальные условия соответствуют организации разработчику МЭС дизайнцентру с тремя основными структурными подразделениями лабораториями системного проектирования, топологического проектирования и подготовки к производству с числом активных пользователей 60 человек и 45 обращениями к СУД от одного пользователя в час. Примерами подобной специализированной проектной организации являются Высшая техническая школа, Цюрих, Швейцария Технопарк Стамбула, Турция Технологический институт, Бандунг, Индонезия Дизайн-центр микроэлектроники Институт точной механики и вычислительной техники РАН, Москва. В ходе моделирования регистрировались следующие параметры СМО вероятность отказа в обслуживании относительная пропускная способность абсолютная пропускная способность вероятность наличия очереди вероятность загрузки всех каналов обслуживания среднее количество заявок среднее время пребывания заявки средняя длина очереди среднее время пребывания заявки в очереди. Пример результатов моделирования СМО, характеризующих общую пропускную способность и надежность рассматриваемой структуры вероятность отказа в обслуживании, относительная пропускная способность, абсолютная пропускная способность, представлены в табл. 2. Параметры СМО, характеризующие структурную организацию ЕИП The Parameters of the QS, Describing the Structural Organization of the UIS Эксперимент СМО типа Пример графика распределения вероятностей состояния СМО при заданном значении представлен на рис. 5. Моделирование показало, что введение дополнительного СБД или ФС дает снижение вероятности отказа в обслуживании на 0,86, увеличение относительной и абсолютной пропускной способности на 0,86 и 4,66 . При использовании только комбинации сервер баз данных файловый сервер значения данных параметров составляют 0,012, 0,965 и 5,310, что соответствует требованиям к обеспечению информационной поддержки КП изделия. Таким образом, введение дополнительных серверов обработки данных при достаточно низкой частоте поступления запросов на получение доступа к информации относитель но производительности используемых средств обработки данных, дает положительный эффект с точки зрения надежности информационной структуры, но он незначителен и не окупает дополнительных финансовых затрат. В результате работы получена обобщенная модель структурной организации единого информационного пространства по параллельному методу интеграции средств поддержки жизненного цикла изделия. Данная модель включает в себя описание элементов структуры информационного пространства, каналов связи, их статических и динамических характеристик. Предложенная модель также учитывает ограничения, накладываемые на формирование структуры ЕИП. Выполнено имитационное моделирование структурной организации ЕИП, представленной в виде совокупности многоканальных систем массового обслуживания. По результатам моделирования сделаны выводы о пропускной способности и надежности рассматриваемого варианта организации ЕИП с учетом предлагаемых к использованию аппаратных серверное решение и программных система управления базами данных средств. "}
{"title": "ПРИМЕНЕНИЕ МЕТОДА  ", "absract": " Рассматривается проблема защиты от несанкционированного доступа к данным путем идентификации пользователей по биометрическим характеристикам, а именно по клавиатурному почерку. Для решения этой задачи авторами была проведена серия опытов для получения статистической выборки образцов клавиатурного почерка, которые используются в качестве биометрической характеристики для установления личности ее владельца. Для анализа данных и определения автора конкретного образца почерка в работе рассматривается метод k -средних, являющийся одним из наиболее простых и эффективных статистических методов классификации в случае, когда число кластеров заранее известно. Оценка эффективности предложенного метода для решения поставленной задачи оценивается с помощью коэффициентов ложного доступа и ложного отказа  в доступе, которые являются основными характеристиками биометрических систем аутентификации. Полученные результаты позволяют сделать вывод о наличии ряда ограничений при использовании данного метода, возникающих в силу того, что данная задача является слабоформализуемой, зависящей от множества факторов, в том числе и не поддающихся математическому описанию, таких как нестабильность клавиатурного почерка, объясняемая изменением психофизиологического состояния пользователя, эргономичностью клавиатуры и т. д. Учитывая упомянутые особенности, дальнейшее решение задачи предлагается рассматривать  в перспективе использования методов, основанных на интеллектуальной обработке данных, которые позволяют обнаруживать в потоке данных скрытые закономерности и зависимости. ", "text": " Одной из наиболее активно возрастающих угроз безопасности информационных систем является проблема утечки данных. Для современных организаций она становится все более актуальной вместе с ростом интенсивности использования информационных технологий. Значительную опасность представляют угрозы, возникающие при обработке конфиденциальной информации в организациях, и в первую очередь это угроза несанкционированного доступа к данным . Аналитики центра InfoWatch, занимающегося изучением вопросов защиты от утечек информации, отмечают, что лишь в 22 случаев утечка информации происходила в результате хакерской активности, в большинстве случаев 75 информация утекала по вине внутреннего нарушителя . Отследить факты появления внутренних угроз гораздо сложнее, по скольку в отличие от внешних угроз их нельзя достаточно точно контролировать с помощью аппаратно-технических мер. На сегодняшний день одним из наиболее простых и распространенных средств защиты данных является парольная идентификация. В работе 1 отмечаются основные недостатки данного метода неоднозначность идентификации оператора ключевой системы, возможность обмана системы защиты, например путем кражи или взлома пароля, невозможность обнаружения подмены законного авторизированного пользователя. В данном случае злоумышленник может нанести вред обрабатываемой КС информации, когда оператор оставляет без присмотра КС с пройденной процедурой авторизации 1. В качестве перспективного варианта решения проблемы возможно применение биометрических систем идентификации пользователя. Актуальность выбора данного метода описана в работах 2 3. Такой подход имеет ряд преимуществ по сравнению с другими средствами идентификации, описанными в работах 1 35 и др. На сегодняшний день биометрическая идентификация личности является одним из перспективных направлений в сфере информационной безопасности и характеризуется такими преимуществами, как неотделимость биометрической характеристики от владельца и крайняя сложность подделки 2. Кроме того, в отличие от парольных средств защиты, которые человек может непреднамеренно или по своему умыслу сообщить злоумышленнику, или от различных карт и ключей, которые могут быть утеряны или украдены, биометрические характеристики позволяют однозначно идентифицировать человека 6. В рамках данной работы предложено использование клавиатурного почерка, поскольку из всех биометрических методов защиты информации данный метод идентификации является самым простым для внедрения и наименее затратным 4, не требует установки специальных аппаратных средств, не нуждается в сопровождении, является прозрачным для конечного пользователя 5, т. е. не причиняет ему неудобств и позволяет проводить скрытую аутентификацию. Анализ работ по данной теме показал, что для классификации образцов клавиатурного почерка с целью установления личности его владельца и защиты данных компьютерной системы от несанкционированного доступа наибольшее распространение получила обработка данных с использованием методов математической статистики и теории вероятностей либо методы, используемые в совокупности с дополнительными механизмами защиты парольной защитой либо использованием дополнительных аппаратных средств. Необходимость двухфакторной идентификации обусловлена тем, что значения коэффициентов ложного доступа и ложного отказа в доступе, являющихся основными критериями надежности биометрических систем, достаточно высоки. Использование методов математической статистики основано на анализе усредненных значений временных параметров, характеризующих манеру работы пользователя с клавиатурой, поэтому результаты, полученные при их применении, не позволяют произвести процедуру идентификации достаточно эффективно 6. В рамках данной работы рассмотрено использование альтернативного метода обработки данных, такого как метод -средних, который является одним из наиболее простых и эффективных методов машинного обучения для решения задач классификации, характеризуется простотой реализации и возможностью распространения полученных решений на новые наблюдения 7. Кроме того, данный метод не требует вычисления и хранения матрицы расстояний и позволяет распараллеливать процесс вычислений. Задачей данного исследования является необходимость оценить эффективность использования метода -средних для решения задачи идентификации пользователя по клавиатурному почерку и сделать дальнейшие выводы о возможности его применения или необходимо сти модификации с целью получения максимального значения целевой функции, характери зующей определение вероятности принадлежности образца почерка конкретному пользова телю 8. Клавиатурный почерк представляет собой набор характеристик работы пользователя на клавиатуре и характеризуется множеством параметров, описанных в работах 3 5. На основании описанных характеристик была произведена серия опытов по их регистрации. Для их проведения были использованы фразы-панграммы, включающие в себя все буквы алфавита, в частности, такие как съешь ещ этих мягких французских булок, да выпей же чаю в чащах юга жил-был цитрус... да, но фальшивый экземпляр и т. п. Результаты проведенных экспериментов представлены в виде графиков. Для более наглядного представления результатов на графиках отображена только часть набранных фраз, так, например, на рис. 1 представлена динамика написания слова каждый, которая является схожей во всех проведенных сериях опытов. Это утверждение верно и при наборе каждой фразы целиком. На данном графике по оси ординат обозначено время удержания нажатой клавиши, на оси абсцисс соответствующая буква. Опыт проводился одним и тем же пользователем 10 раз. Кроме того, на рис. 1 видно, что числовые характеристики почерка каждого человека остаются схожими вне зависимости от количества опытов, но в то же время почерк отдельного человека очевидно отличим от других. На основании полученных результатов можно сделать вывод о том, что клавиатурный почерк является достаточно информативной биометрической характеристикой, и его использование возможно для определения личности владельца почерка. Однако клавиатурный почерк как динамическая поведенческая характеристика пользователя подвержен влиянию множества факторов, что делает его весьма нестабильным. Основные сложности при работе с клавиатурным почерком связаны с большим разнообразием навыков набора текста у пользователей. Процедура идентификации может быть неэффективной или невозможной для лиц, не имеющих стойких навыков работы с клавиатурой. Из теории машинописи и делопроизводства установлено, что срок, необходимый для формирования устоявшегося клавиатурного почерка, составляет не менее 6 месяцев. Кроме того, на характеристики набора текста влияют факторы, обусловленные психологическим состоянием человека сонливость, тревога, усталость. Не менее значимыми являются и другие объективные причины, например травма кисти или пальца, использование устройств ввода нестандартного размера, обладающих другой эргономичностью 1. Все эти факторы снижают достоверность идентификации. В связи с этим выбор метода обработки параметров клавиатурного почерка является сложной задачей, требующей тщательного анализа используемых методов обработки данных. Поставленная задача по своей сути является задачей классификации, так как образцы клавиатурного почерка представляют собой конечное множество объектов, которое нужно соотнести с некоторым множеством классов. Для ее решения возможно использование таких методов, как регрессионный анализ, метод -средних, метод главных компонент и т. д., которые позволят отсеять наименее информативные признаки клавиатурного почерка и, как следствие, предварительно уменьшить размерность обучающей выборки. При использовании регрессионного анализа для решения поставленной задачи авторами был выявлен ряд ограничений, влияющих на достоверность идентификации, что подробно рассмотрено в 8. В данной работе предложено использование метода -средних, поскольку он эффективен в случае, когда число кластеров заранее известно, достаточно прост в реализации, поэтому его можно использовать для анализа больших объемов данных. Кроме того, данный метод может учитывать весовые коэффициенты, что является несомненным преимуществом, поскольку одной из задач исследовательской работы авторов является оценка значимости параметров клавиатурного почерка. Метод -средних основан на вычислении расстояния от объекта до ближайших соседей, причем число задается индивидуально для каждого случая. Под соседями в данном случае будем понимать объекты, близкие к исследуемому. Определение принадлежности объекта к тому или иному классу кластеру производится на основе вывода о том, к какому классу относятся его ближайшие соседи 9. На практике вопрос выбора оптимального значения параметра является достаточно сложным, поскольку от правильности его выбора зависит правильность решения задачи о принадлежности объекта к некоторому классу. Так, если взять слишком малым, возможна ситуация, при которой единственным ближайшим соседом окажется объект с неверно определенным классом, что приведет к принятию неверного решения о принадлежности данного объекта. Если же взять, напротив, слишком большим, например равным количеству объектов, то расстояние до центра не будет иметь вообще никакого значения. В рамках поставленной задачи классификация данных производилась путем разбиения множества объектов 100 на 10 кластеров, поскольку требуется идентификация 10 человек, предоставивших образцы почерка. В качестве меры близости объекта к центру кластера можно использовать расстояние Евклида, манхеттеновское расстояние, формулу Минковского и др. В данном случае используется Евклидово расстояние, поскольку реализация метода -средних осуществлялась с использованием программной среды Statistica, в вычислительный алгоритм которой заложена именно эта мера, где пространство множества объектов, координаты объекта в пространстве. Применение данного метода было реализовано в программной среде Statistica. Для получения статистических данных в эксперименте приняли участие 10 пользователей, каждый из которых предоставил по 10 образцов клавиатурного почерка. Таким образом, в целом была получена выборка данных объемом 100 образцов клавиатурного почерка. В качестве текста для набора были использованы фразы-панграммы, примеры которых были приведены ранее. Выбор такого варианта текста для набора основан на том, что данные фразы позволяют максимально эффективно оценить все параметры клавиатурного почерка. В работах 2 3 отмечалось, что каждый образец почерка характеризуется 17 параметрами. Таким образом, вся статистическая выборка представляет собой матрицу размером 100 17. Классификация данных производилась путем разбиения множества объектов 100 на 10 кластеров, поскольку поставленная задача требует идентификации 10 человек, предоставивших образцы почерка. На рис. 2 представлено окно описания параметров в программе Statistica. Одним из важнейших показателей эффективности применения метода идентификации является достоверность аутентификации пользователей 4. При принятии решения о личности владельца почерка система идентификации может выдать как неправильное решение, приняв нелегального пользователя за легального, так и противоположное решение, отказав авторизованному пользователю в доступе. На основании этих факторов оценка эффективности применения данного метода производилась путем вычисления значений коэффициента ложного доступа FAR и коэффициента ложного отказа в доступе FRR. Коэффициент FAR False Acceptance Rate возникает в случае, когда зарегистрированный пользователь аутентифицируется как не имеющий доступа к системе, а коэффициент FRR False Rejection Rate характеризует ситуацию, при которой пользователь, не имеющий прав доступа, аутентифицируется как зарегистрированный 4. При определении принадлежности образца почерка CaseNo определенному кластеру Cluster в программе Statistica учитывалось его расстояние от центра данного кластера, вычисленного на основании данных о координатах элементов, ближайших к рассматриваемому. Окно результатов оценивания представлено в формате таблицы Word. Результаты классификации Classification Result образца почерка CaseNo кластера Cluster Расстояние до центра кластера Distance Таблицы, аналогичные представленной, получены для каждого из 10 выделенных кластеров. На основании полученных результатов вычислялось среднее значение коэффициентов FAR и FRR, которые являются основными характеристиками биометрических систем аутентификации. Их значения составили 28 и 30 соответственно. Полученные результаты являются неудовлетворительными, поскольку стандартным порогом доступа биометрических систем является значение 90 1. Оценивая результаты, следует отметить, что использование данного метода для решения поставленной задачи имеет ряд ограничений, к которым можно отнести необходимость хранения всей выборки данных для проведения классификации, что требует выделения большого объема памяти использование данных без возможности дообучения, что критично для решения поставленной задачи, поскольку клавиатурный почерк представляет собой динамическую биометрическую характеристику, т. е. может изменяться с течением времени близкую расположенность центров кластеров друг к другу в силу небольшого размаха значений выборки в некоторых случаях разница в тысячные доли, что приводит к увеличению значений FRR и FAR. На рис. 3 видно, что центры кластеров, характеризующих пользователей 2, 5, 6, 9 практически совпадают, и результаты классификации данных, соответствующих этим пользователям, показали самые высокие значения ошибки. На основании описанных выше недостатков данного метода для повышения эффективности идентификации пользователя по клавиатурному почерку предложено использовать интеллектуальные методы, в частности искусственные нейронные сети. Применение метода -средних показало, что центры кластеров находятся слишком близко друг к другу, поэтому плохо различимы. Такая ситуация может привести к тому, что значения, соответствующие разным пользователям, могут быть идентифицированы как принадлежащие одному человеку, и наоборот, что может привести к увеличению значений FRR и FAR. Точности метода не хватает для учета таких ограничений, в то же время нейронные сети обладают более высокой способностью к разграничению данных, что позволяет выдвинуть предположение о том, что их применение позволит получить более высокий результат. Кроме того, использование данного метода подразумевает использование статистики без возможности дообучения, что не позволяет учитывать факт изменения клавиатурного почерка пользователя со временем или под влиянием каких-либо внешних факторов. В то же время одним из важнейших преимуществ нейронных сетей является способность обучаться на основе данных окружающей среды и в результате обучения повышать свою производительность посредством интерактивного процесса корректировки синаптических весов и порогов. Кроме того, ИНС обладают такими преимуществами, как возможность выявлять скрытые закономерности и зависимости в потоке данных, а также обеспечивать более высокое быстродействие по сравнению с другими методами за счет распараллеливания процесса обработки данных. В работе рассматривается задача идентификации пользователя по клавиатурному почерку. После анализа существующих методов решения данной задачи авторами предложено использование метода -средних, являющегося одним из наиболее простых в реализации методов машинного обучения для решения задач классификации. В ходе проведенных экспериментов получены результаты, представленные в виде значения ошибок первого и второго рода, которые являются стандартными критериями оценок надежности всех биометрических систем. Анализ полученных результатов показал, что пороговые значения доступа ниже, чем стандартные пороговые значения для биометрических систем. В связи с этим авторами предложено использование альтернативных методов для обработки статистических данных. "}
{"title": "СИСТЕМА КАТАЛОГИЗАЦИИ И МОНИТОРИНГА   ТЕРРИТОРИАЛЬНО РАСПРЕДЕЛЕННЫХ ВЫЧИСЛИТЕЛЬНЫХ УЗЛОВ   В СРЕДЕ WPS СЕРВИСОВ ДЛЯ РЕШЕНИЯ ГЕОЛОГИЧЕСКИХ ЗАДАЧ ", "absract": " Данная работа посвящена разработке подхода к каталогизации разнородных веб-сервисов территориально распределенных вычислительных узлов в вычислительно-аналитической геологической среде, а также принципов по созданию системы мониторинга веб-сервисов, присутствующих в каталоге. Для этого в статье рассматриваются используемые в мире подходы по организации каталогов веб-сервисов на основе SOAP (Simple Object Access Protocol) протокола, с использованием UDDI (Universal Description Discovery and Integration) реестров. На основе исследованного материала предлагается схема для описания разнородных веб-сервисов  с возможностью дальнейшего создания каталога веб-сервисов, включающего функции поиска и получения метаинформации о каждом сервисе в каталоге. Также в статье кратко описываются принципы, на основе которых функционирует вычислительно-аналитическая геологическая среда, в рамках которой разрабатывается система каталогизации и мониторинга, и приводится список территориально распределенных веб-сервисов  по обработке разнородных данных, используемых в данной среде. ", "text": " С развитием информационных технологий вс больше программных продуктов, направ ленных на решение различных научных задач, предоставляются пользователям в виде об лачных сервисов. При использовании данного подхода проблемы, связанные с обеспечением необходимых вычислительных мощностей, подготовкой специализированного программного окружения и поддержкой актуальности программного продукта, решаются на стороне сервиса. Существует ряд сервисов, предоставляющих возможность обработки и анализа на учных данных в режиме онлайн. Такие сервисы расположены на территориально распре деленных вычислительных узлах, которые разрабатываются в научных институтах, универ ситетах и коммерческих компаниях, специализирующихся на обработке и анализе различных типов данных 1. Построение вычислительно-аналитических систем по обработке данных, основанных на взаимодействии с пользователем через веб-интерфейс, активно ведется в различных пред метных областях. Так, в области обработки спутниковых данных к подобным системам можно отнести проект NASA-Giovanni, систему Google Earth Engine, платформы ESA G-POD, а также системы See the Sea, Вега-Science и др., созданные в Институте космических технологий РАН на основе авторской технологии GEOSMIS 2. В области обработки и ана лиза пространственных данных примером такой информационной системы является ArcGIS Online. В настоящее время актуальной является разработка тематических вычислительно-анали тических сред, имеющих единые точки доступа к территориально распределенным вычис лительно-аналитическим ресурсам, позволяющие в рамках единой системы решать раз личные задачи по обработке и анализу в заданной предметной области. A. M. Федотовым, В. Б. Барахниным и др. 3 предложена концепция распределенной ин формационно-аналитической среды для исследований экологических систем. В статье опи сывается модель виртуальной среды, определяются категории данных, объекты среды и при водится пример схемы среды с описанием используемых технологий. Е. П. Гордовым, В. Н. Крупчатниковым и др. 4 представлен проект по созданию темати ческой виртуальной исследовательской среды для анализа, оценки и прогнозирования воздействия глобального изменения климата. Проект среды разрабатывается с целью обеспе чения свободного доступа к различным ресурсам данных и службам обработки через веб браузер. В работе L. Candela и др. 5 приводится общий обзор существующих виртуальных иссле довательских сред, выделяются общие и отличительные особенности различных подходов к построению таких сред, разбираются проблемы, которые необходимо решать в данной об ласти. И. В. Бычковым, Г. М. Ружниковым и др. 6 7 разработана и успешно функционирует среда сервисов обработки геоданных WPS. Эта среда поддерживает вызов сервисов обработ ки, построенных с использованием интерфейса OGC WPS Web Processing Service. В среде реализована возможность построения цепочек обработки с использованием языка javascript для формирования сценария обработки. Создание подобных сред подразумевает необходимость разработки методов и технологий каталогизации и мониторинга состояния сервисов. Решение задачи каталогизации сервисов представлено в 2000 г. в виде стандарта для раз мещения веб-сервисов UDDI. Основная идея данного подхода создание каталогов реестров веб-сервисов на основе языка описания веб-сервисов WSDL Web Services De scription Language, которые бы позволяли осуществлять быстрый поиск и получение инфор мации о сервисах, а также интегрировать различные сервисы в сторонние системы. Однако стандарт UDDI не получил дальнейшего развития в силу ограничений, не учитывающих специфику сервисов в различных предметных областях. Стандарт WSDL разработан для веб-сервисов на основе протокола SOAP Simple Object Access Protocol, предназначенного для обмена XML eXtensible Markup Language сообщениями. Однако в настоящее время множество веб-сервисов по обработке и анализу научных данных используют другие технологии реализации интерфейсов, в частности интер фейсы на основе REST Representational State Transfer архитектуры. В публикации И. В. Бычкова, Г. М. Ружникова и др. 6 предлагается подход к созданию каталога WPS-сервисов, обеспечивающего функции поиска сервисов и возможность предва рительной верификации входных данных перед использованием сервиса. Каталог WPS-сер висов реализован в виде программного модуля для системы управления контентом, исполь зуемой в среде. Данный подход предлагает каталогизацию локальных и внешних сервисов на основе OGC WPS интерфейса. Использование сервисов на основе других интерфейсов взаимодействия в каталоге не предполагается. Целью данной работы является создание подхода к организации системы каталогизации и мониторинга территориально распределенных вычислительно-аналитических узлов в рам ках разрабатываемой вычислительно-аналитической среды по обработке и анализу геологи ческих данных. В научных геологических исследованиях используются разнотипные данные количест венные, спутниковые, пространственные, текстовые, медиаданные и т. д. Для обработки ка ждого из перечисленных типов данных используются различные методы, реализованные в специализированных программных системах. Наличие необходимого набора внешних сер висов позволяет создать специализированную вычислительно-аналитическую среду для ре шения научных геологических задач, в том числе и крупных комплексных задач. Нами разработана и реализуется вычислительно-аналитическая геологическая среда 1. Среда построена с использованием принципов слабосвязанной архитектуры, где каждый эле мент функционирует независимо друг от друга. Основные элементы среды рис. 1 платформа обработки, обеспечивающая пользовательский интерфейс система управления обработкой, обеспечивающая разграничение доступа и контроли рующая очередь выполнения процессов обработки система хранения данных, обеспечивающая временное хранение пользовательских данных и результатов обработки территориально распределенные узлы обработки поставщики сервисов по обработке и анализу данных. Взаимодействие пользователя и внешних сервисов обработки происходит через единую точку входа, предоставляемую платформой обработки. Существует возможность взаимодей ствия с платформой обработки в режиме система система через программный интерфейс приложения. Платформа позволяет загружать данные для обработки непосредственно с ком пьютера пользователя либо по ссылке с внешнего ресурса. В настоящее время вычислительно-аналитическая геологическая среда включает в себя следующие узлы обработки. . Включает в себя набор методов для много мерного анализа количественных данных, таких как факторный анализ, кластерный анализ, регрессионный анализ и др. В качестве компонента для реализации модуля статистического анализа количественных данных был выбран язык программирования R 8. Интерфейс вза имодействия с сервисами построен с использованием модуля Rserve. Узел разработан и под держивается в Государственном геологическом музее им. В. И. Вернадского РАН. . Включает в себя методы первичной обработки спутниковых данных, такие как калибровка и пространственная привязка данных некоторых спутников 9. Узел разработан и поддерживается в Институте автоматики и процессов управления ДВО РАН. . В Институте физики Земли РАН раз работана интерактивная база методов обработки петролого-геохимических данных 10. Эта система предоставляет сервисы построения спайдерграмм, гистограмм и классификационных диаграмм сервис идентификации минералов по их химическому составу сервис интерпре тации состава минерала и разложение на миналы и т. д. Интерфейс взаимодействия с серви сами построен на основе REST архитектуры. . В междисциплинарном центре математического и вычислительного моделирования Университет Варшавы, Польша разработан сервис для извлечения метаданных из научных публикаций 11. Метаданные включают в себя авторов, аффилиацию, аннотацию, ключевые слова, название журнала, объем, год выпуска, разобран ные библиографические ссылки, структуру разделов документа, заголовки разделов и абза цы. Интерфейс взаимодействия с сервисами построен на основе REST архитектуры. . В Университете Шеффилда в рамках проекта GATE General Architecture for Text Engineering разработан ряд сервисов по обработке текстовых данных для различных языков 12. Для обработки текстовых данных на русском языке пре доставляются сервисы по определению частей речи слов, а также выделению именованных сущностей, таких как имена и фамилии, названия организаций, географические названия, даты, денежные единицы и т. д. Интерфейс взаимодействия с сервисами построен на основе REST архитектуры. Предполагается, что создаваемая вычислительно-аналитическая геологическая среда должна обеспечить пользователям доступ к хранилищам современных наукоемких алго ритмов и вычислительным ресурсам, необходимым для оперативной обработки больших массивов разнородных данных Big Data. Используя внешние сервисы обработки, необходимо учитывать возможность временного ограничения доступа к определенным сервисам из-за различных технических проблем со стороны владельцев сервисов или линий передачи данных, а также возможность измене ния интерфейса доступа к сервисам со стороны поставщиков сервисов. Для этого необходи мо организовать систему мониторинга работы территориально распределенных сервисов, позволяющую оперативно реагировать на возможные технические проблемы в автоматиче ском или ручном режиме. В рассматриваемой вычислительно-аналитической среде для обеспечения единого под хода к вызову территориально распределенных сервисов обработки и анализа данных ис пользуется стандарт OGC WPS в качестве промежуточного интерфейса. Данный интерфейс разработан в качестве стандарта для веб-сервиса по выполнению процедур обработки дан ных. В первую очередь этот стандарт разрабатывался для процедур обработки простран ственных данных, однако он имеет универсальный интерфейс для использования процедур обработки других видов данных. Использование стандарта OGC WPS для вызова сервисов обработки и анализа данных позволяет организовать работу разнородных сервисов в рамках единой вычислительно-аналитической среды. Каждый метод для обработки и анализа данных в среде представлен в виде отдельного процесса WPS. Такой подход позволяет организовать единый интерфейс вызова внешних разнородных сервисов. Система управления обработкой позволяет контролировать распре деление ресурсов между процессами, а также ограничивать доступ к различным процессам на основе прав пользователя. Обработка некоторых типов геологических данных может за нимать продолжительное время, поэтому такие методы обработки вызываются в асинхрон ном режиме с возможностью отслеживания пользователем статуса выполнения процесса на всм протяжении обработки. При решении комплексных задач существует возможность передачи результата одного выполняемого процесса в качестве входных данных для другого процесса. Поддерживается возможность параллельного выполнения нескольких процессов, результаты которых передаются на вход одному процессу, как только все требуемые для его запуска процессы успешно завершатся. Используя интерфейс OGC WPS для вызова внешних сервисов обработки, можно также отслеживать статус выполнения WPS процесса, соответствующего определенному внешнему сервису обработки. После завершения выполнения каждого процесса в базу данных поступа ет отчет о выполнении процесса, включающий параметры запуска сервиса, время выполне ния, статус и результат. Данная информация также может быть использована в разрабаты ваемой системе мониторинга для более детального отслеживания состояния работы конкрет ного сервиса. Для добавления внешнего вычислительно-аналитического сервиса в среду достаточно реализовать возможность вызова данного сервиса в виде WPS процесса. Для решения задачи каталогизации сервисов разработан единый формат для описания от дельного сервиса на каждом вычислительном узле. Описание сервиса содержит набор ин формации, позволяющий осуществлять мониторинг любого сервиса среды с учетом исполь зуемых протоколов взаимодействия и интерфейсов доступа. На основе компонентов для описания веб-сервисов в UDDI реестрах нами предложены параметры описания веб-сервисов в создаваемой среде Основная информация Идентификатор Название Описание Область применения Ключевые слова Поставщик сервиса Название организации Контактное лицо Контактный адрес Контактный телефон Веб-сайт Служебная информация IP адрес доменное имя Порт Протокол Версия протокола Описание интерфейса доступа Авторизация Логин Пароль Ключ доступа Точка доступа Структура описания сервиса состоит из трех основных частей. В первой части содержится основная информация о сервисе, позволяющая осуществлять поиск сервисов по названию, описанию, ключевым словам и т. д. Вторая часть содержит описание поставщика сервиса, включая информацию для связи с поставщиком. В третьей части располагается служебная информация, которая необходима для непосредственного взаимодействия с сервисом. Предложенную структуру описания предлагается использовать в качестве метаданных для веб-сервисов. На основе разработанной структуры метаданных предлагается создание ка талога веб-сервисов, предоставляющего пользователям и сторонним информационным си стемам информацию о сервисах в стандартном виде рис. 2. Информация о сервисе также формируется в форматах XML и JSON рис. 3. Для обеспечения высокого уровня надежности работы сервисов в рамках вычислительно аналитической среды разработана система мониторинга, позволяющая оперативно реаги ровать на изменения в работе сервисов. Использование разнородных сервисов, взаимодей ствие с которыми осуществляется с помощью различных протоколов и по различным ин терфейсам, подразумевает ряд ограничений на предмет мониторинга. Таким образом, имея общую техническую информацию о каждом сервисе веб-адрес сервиса, протокол, версия протокола и т. д., можно реализовать следующие общие виды проверок а проверка доступности удаленного узла б проверка работоспособности сервиса на удаленном узле по требуемому протоколу вза имодействия в проверка наличия изменений в работе сервиса на основе тестовых запросов к WPS процессам. Более сложные виды проверок состояния сервисов требуют знания детального описания интерфейса взаимодействия, что делает такой вид проверок зависимым от конкретной реа лизации сервиса. Используя описанные методы проверки состояния сервисов, можно формировать ста тистику доступности отдельных сервисов. В случае проблем с доступом к определенному сервису можно предлагать пользователям альтернативные реализации подобного сервиса при наличии их в среде. Мониторинг территориально распределенных узлов вычислительно-аналитической среды осуществляется с использованием вышеописанных параметров мониторинга. Проверка доступности узла а производится раз в минуту путем отправки запроса по ука занному адресу узла по протоколу ICMP Internet Control Message Protocol или TCP Transmission Control Protocol по определенному порту в случае блокировки ICMP запросов со стороны удаленного узла. Проверка доступности сервиса б производится раз в минуту путем отправки запроса, подтверждающего возможность установления соединения с сервисом, с использованием ука занных адреса, порта и протокола сервиса. Проверка сервиса на изменения в производится каждые 30 минут путем отправки одного или нескольких тестовых запросов к сервису и сравнения результатов работы сервиса с имеющимися в системе мониторинга. Она позволяет выявить изменения в параметрах вы зова сервиса и в результатах работы сервиса. В случае отсутствия доступа к узлу или сервису система уведомляет администратора вы числительно-аналитической среды и помечает сервис недоступным для использования. Периодичность проверки каждого параметра мониторинга выбрана исходя из количества времени и вычислительных мощностей, необходимых для соответствующего типа проверки достаточной оперативности для принятия соответствующего решения со стороны системы мониторинга результатов работы системы мониторинга в тестовый период. Результаты работы системы мониторинга в период с 5 апреля 2019 г. по 6 мая 2019 г. Вычислительный узел и сервисы Владелец узла Доступность, Измене ние сервисов в, узла а сервисов б Многомерные методы анализа данных 1 описательная статистика 2 регрессионный анализ 3 метод главных компонент 4 тройная диаграмма 5 иерархический кластерный анализ 6 метод -средних 7 факторный анализ 8 линейный дискриминантный анализ 9 анализ канонических переменных ГГМ РАН 100 98,873 0 Обработка петролого-геохимических данных 1 построение классификационных диаграмм 2 система идентификации минералов 3 минералогические пересчеты 4 интерпретация состава минерала и разложение на миналы 5 оценка PT условий с помощью геосенсоров ИФЗ РАН 99,952 99,952 0 Обработка спутниковых данных узел в разработке 1 калибровка 2 пространственная привязка 3 атмосферная коррекция ИАПУ ДВО РАН 0 0 0 Обработка естественного языка 1 распознавание понятий в тексте 2 распознавание частей речи Универ ситет Шеффилда 99,963 99,963 0 Структурный анализ публикаций 1 извлечение метаданных из научных статей Варшав ский Уни верситет 100 100 0 Используя полученные результаты, можно сделать вывод, что все территориально рас пределенные узлы, за исключением узла обработки спутниковых данных, находящего в раз работке на текущий момент, показывают высокий уровень надежности для дальнейшего их использования в качестве источника сервисов обработки и анализа данных. Вычислительно-аналитическая среда по обработке и анализу данных для научных иссле дований в геологии httpservice.geologyscience.ru разрабатывается в рамках работ Государ ственного геологического музея им. В. И. Вернадского РАН ГГМ РАН по созданию ин формационно-аналитической геологической среды httpgeologyscience.ru. Авторами предложен подход к организации системы каталогизации и мониторинга тер риториально распределенных вычислительных узлов для вычислительно-аналитической сре ды обработки и анализа геологических данных. Предложенный подход реализован в виде программного модуля, встроенного в вычислительно-аналитическую среду. Предложенные принципы организации каталогизации и мониторинга веб-сервисов по зволяют обеспечить более высокий уровень надежности работы вычислительно-аналити ческой геологической среды, предоставляя пользователю информацию о надежности работы конкретного веб-сервиса в рамках среды. На основе данных подходов разработана про граммная реализация каталога веб-сервисов и системы мониторинга в виде работающего прототипа на основе существующей вычислительно-аналитической геологической среды. "}
{"title": "АВТОМАТИЧЕСКИЙ РЕФАКТОРИНГ JAVA-КОДА   С ИСПОЛЬЗОВАНИЕМ STREAM API  ", "absract": "Долгое время функциональное программирование на Java было невозможно. Однако в 8-й версии Java появились лямбда-выражения. Благодаря поддержке стандартных библиотечных классов (Stream, Optional и т. д.)  на Java стало возможно описывать преобразования над данными в функциональном стиле.  Java – достаточно старый язык, на нем написано большое количество императивного кода. Для того чтобы воспользоваться преимуществами нового подхода, требуется выполнить нетривиальный рефакторинг, что  в случае осуществления человеком может быть весьма утомительным, легко совершить ошибку. К счастью, для достаточно большого количества ситуаций данный рефакторинг можно безопасно осуществить автоматически. На основе IntelliJ Idea был разработан программный инструмент, который позволяет обнаружить места, где возможно автоматическое преобразование императивного кода в эквивалентный с использованием Stream API, а также автоматическое исправление, которое позволяет произвести замену. Рефакторинг пользуется средствами IntelliJ Idea для анализа Java-кода, а также интегрируется в саму IDE. Одним из основных критериев корректности работы алгоритма является безопасность данного преобразования. Пользователь не может доверять инструменту, если преобразование может изменять семантику кода. В данной статье рассматриваются различные ограничения, которые накладываются на шаблоны кода для того, чтобы преобразование без искажения семантики было возможно. Данный рефакторинг был протестирован на различных библиотеках для проверки сохранения семантики путем проверки результатов тестирования до и после применения рефакторинга. В статье не будет обсуждаться влияние использования Stream API на производительность приложения. ", "text": " Целью данной работы было создание инструмента для автоматического преобразования кода на Java, написанного в императивном стиле, в код на функциональном стиле с использованием цепочки Stream API, а также интеграция этого инструмента в среду разработки IntelliJ Idea. Использование Stream API вместо традиционных циклов имеет весьма значительные преимущества возможна автоматическая параллелизация, которая может дать прирост производительности, часто такой код намного более короткий и лаконичный, а также более четко выражает намерение автора . Для среды разработки крайне важно предлагать различные варианты преобразования кода, так как каждый из них может обладать своими преимуществами и недостатками, и программист может сам решать, какой из них лучше в данной ситуации. Благодаря инфраструктуре IDE данные автоматические преобразования могут производиться в одно нажатие кнопки. Несмотря на то, что в IDE NetBeans данный рефакторинг уже присутствует, в нем было обнаружено значительное количество недостатков и возможностей улучшения, которые учтены при разработке. Данный рефакторинг было решено разрабатывать для IDE IntelliJ Idea, поскольку она является самой распространенной IDE для Java. Использовать разработки других IDE не представлялось возможным из-за больших различий в семантической модели Java, а также из-за того, что модель рефакторинга там значительно более проста. Stream API предоставляет возможность обработки совокупности однотипных данных. Сценарий обработки записывается декларативно посредством цепочки вызовов. Типичный пример использования Stream API выглядит следующим образом Здесь у каждой строки из списка listOfStrings удаляются начальные и концевые пробелы с помощью операции map затем пустые строки отфильтровываются с помощью filter после этого результат ограничивается десятью строками с помощью limit, и, наконец, выполняется сборка в результирующий список с помощью collect. Здесь имеются операции различных типов. Источник потока метод stream входит в интерфейс List, создает поток из списка. Имеются другие виды источников, которые, например, создают поток из массива, из строк файла, из целых чисел в заданном диапазоне и т. д. Источник возвращает объект типа Stream. Промежуточные intermediate операции map, filter и limit. Эти операции также возвращают объект типа Stream, позволяя объединять в цепочку несколько промежуточных операций. Важная особенность заключается в том, что промежуточные операции всегда ленивы они не производят вычислений, а только запоминают действия, которые необходимо выполнить. Имеются и другие промежуточные операции distinct удалить повторяющиеся элементы, skip пропустить заданное количество первых элементов и т. д. Концевая terminal операция collect. Именно при выполнении концевой операции производится вся цепочка вычислений и сбор результатов. Операция collect принимает так называемый коллектор объект, специфицирующий способ объединения результатов. В данном случае используется коллектор toList, который собирает результаты в список. Другие коллекторы могут собирать в множество, ассоциативный массив, в строку с заданным разделителем и т. д. Помимо collect имеются и другие концевые операции. Например, count просто подсчитывает количество результатов, а anyMatch проверяет, имеется ли хоть один результат, удовлетворяющий заданному условию. Промежуточные операции делятся на операции без состояния map и filter и операции с состоянием limit или distinct. Операции без состояния значительно проще по своей сути они единообразно обрабатывают каждый элемент, при этом порядок их обработки неважен. Обычно такие операции легко выражаются в традиционном цикле. Например, операции map соответствует присваивание или объявление переменной, а операции filter условный оператор if. Операции с состоянием сложнее состояние необходимо хранить в дополнительной переменной либо получать неявно. В традиционных циклах соответствующая семантика выражается разными способами, и их поддержка в процессе преобразования цикла в цепочку Stream API представляет определенную трудность. Ниже приводится два способа выразить тот же алгоритм с помощью традиционного цикла В первом варианте для подсчета количества добавленных элементов используется дополнительная переменная-счетчик count. Во втором способе мы пользуемся размером результирующего списка, который изначально пуст, и на каждом шаге туда добавляется ровно одна запись. Второй способ короче, но менее универсален. К примеру, он не сработает, если результаты требуется собрать не в список, а в множество или в строку с разделителем. Оба приведенных варианта IntelliJ Idea поддерживает, но возможны и другие варианты некоторые предпочитают проверять счетчик перед добавлением элемента, считать в обратном порядке от 10 до 0 и т. д. У операции limit есть другая важная особенность это так называемая короткозамкнутая операция. Она может завершить весь процесс до того, как закончатся входные данные. Короткозамкнутыми могут быть как промежуточные, так и концевые операции. Пример концевой короткозамкнутой операции anyMatch. Эта операция возвращает булеву истину, если хоть один элемент потока удовлетворяет условию, переданному в виде лямбда-выражения параметром anyMatch. При этом, естественно, обработка прекращается. Поток элементов объектного типа имеет тип java.util.stream.StreamT. Так как в языке Java примитивный тип не может являться аргументом обобщенного типа, невозможно создать, к примеру, поток элементов типа float. Однако для удобства и повышенного быстродействия три примитивных типа int, long и double поддерживаются специально для них имеются потоковые типы IntStream, LongStream и DoubleStream. Далее под поддерживаемым типом мы будем иметь в виду любой тип, который может быть элементом потока либо любой объектный тип, либо int, long или double. Другие примитивные типы boolean, short и т. д. назовем неподдерживаемыми типами. Также для простоты под StreamT мы будем иметь в виду поток элементов любого поддерживаемого типа если T соответствует типу int, то вместо Streamint подразумевается IntStream. Будем называть фрагментом Java-выражение expression глава 15 JLS, Java-утверждение statement, JLS 14.5 либо совокупность из нескольких подряд идущих Java-утверждений в пределах одного блока JLS 14.2. Возможен также пустой фрагмент, не содержащий никаких утверждений и выражений. Фрагмент можно преобразовать в тело лямбда-выражения для потоковой операции при соблюдении трех условий. У1. Фрагмент не должен ссылаться на локальные переменные и параметры, которые определены за пределами этого фрагмента и не являются финальными и эффективно-фи нальными. У2. Фрагмент не должен бросать проверяемых исключений. У3. Фрагмент не должен содержать операторов, передающих управление за пределы данного фрагмента за исключением оператора throw. Условие У1 необходимо для любого лямбда-выражения Java в соответствии с 15.27.2 спецификации языка Java 8 далее JLS . Понятие финальной и эффективно-финальной переменной приводится в JLS 4.12.4. Основное требование заключается в том, чтобы значение присваивалось переменной ровно один раз на каждом пути управления. Условие У2 не требуется для любых лямбда-выражений. Лямбда-выражение может бросать проверяемые исключения, если соответствующий абстрактный метод функционального интерфейса JLS 9.8 их объявляет. Однако ни один из функциональных интерфейсов, используемых в Stream API к примеру, java.util.function.Predicate, не объявляет проверяемых исключений. Условие У3 также требуется для любых лямбда-выражений в соответствии с их семантикой в языке Java в отличие, например, от языка Kotlin, где в ряде случаев возможна нелокальная передача управления из лямбда-выражения. Оператор throw, бросающий исключение, допустим, так как, по спецификации Stream API, любое исключение, выброшенное из лямбда-выражения, используемого в цепочке операций, будет выброшено наружу. Разумеется, в соответствии с У2, допустимы только непроверяемые исключения. Условие У2 можно проверить для всего цикла если в цикле есть хоть одна операция, бросающая проверяемое исключение, то преобразование цикла в Stream API невозможно. С другой стороны, условие У1 для всего цикла проверять неоправданно. Во-первых, изменение переменной может не попасть в лямбда-выражения, а стать результатом цепочки вызовов Stream API, как, к примеру, в следующем листинге Здесь переменная count не является эффективно-финальной модифицируется в цикле и объявлена за пределами цикла. Однако этот код легко трансформировать с использованием Stream API Поэтому каждый фрагмент, который необходимо превратить в лямбда-выражение, следует проверять отдельно. В данном примере лямбда-выражением становится только условие s.isEmpty, для которого У1 выполняется. Также возможна ситуация, когда переменная, не являющаяся эффективно-финальной в исходном цикле, станет таковой после преобразования. Тогда преобразование все еще возможно. К примеру, рассмотрим такой цикл Здесь требуется преобразовать в лямбда-выражение вызов метода System.out.printlni, который ссылается на изменяемую переменную i, определенную за пределами выражения. Однако после преобразования цикла i становится неизменяемой Условие У3 также не стоит проверять для всего цикла сразу. Действительно, лямбдавыражение не может содержать операторов типа break если только само не содержит цикл, а оператор return завершит только само лямбда-выражение, но не окружающий его метод. Однако многие циклы, содержащие операторы управления потоком, все-таки можно преобразовать в цепочку Stream API. Операторы break и return иногда можно трансформировать в короткозамкнутую операцию. Оператор continue, переходящий на следующую итерацию цикла, допустим в качестве тела условного оператора if. К примеру, следующие два фрагмента семантически эквивалентны Для обсуждения алгоритма преобразования циклов в вызовы Stream API нам потребуется несколько определений. Для заданной переменной Java-кода V будем обозначать через T ее тип. Подфрагментом F фрагмента F назовем фрагмент, целиком содержащийся во фрагменте F являющийся его частью и не совпадающий с F. Обозначим F F. Генератор GV, S, F это совокупность выходной переменной V поддерживаемого типа, Java-выражения S, имеющего тип StreamT, и фрагмента F. Представление генератора GV, S, F есть следующий Java-цикл Имеются простые и составные генераторы. Простой генератор создается непосредственно по Java-циклу L таким образом, что представление этого генератора семантически эквивалентно исходному циклу L. Определим несколько видов простых генераторов, каждый из них соответствует определенному виду циклов табл. 1. Определения генераторов Generator Definitions Название Вид цикла Операция Обход коллекции forT V EXPR F EXPR имеет тип java.util.Collection G V, EXPR.stream, F Обход массива forT V EXPR F EXPR имеет тип массива G V, Arrays.streamEXPR, F Диапазон чисел forT V START V BOUND V F T либо int, либо long G V, IntStream LongStream.rangeSTART, BOUND, F Диапазон чисел закрытый forT V START V BOUND V F T либо int, либо long G V, IntStream LongStream.rangeClosedSTART, BOUND, F Строки BufferedReader String V whileV BR.readLine null F BR имеет тип java.io.BufferedReader G V, BR.lines, F Преобразование XE функция от Java-выражения типа Stream, которая возвращает новое Java-выражение типа Stream возможно, с другим типом элементов. В большинстве случаев преобразование добавляет новый вызов к существующей цепочке вызовов. К примеру, фильтрующее преобразование может выглядеть так Filt, E E.filterV - P, где V переменная, E Java-выражение, имеющее тип StreamT, а P Java-выражение, представляющее собой предикат от переменной V условие фильтрации и удовлетворяющее условиям У1У3. Результирующее выражение также имеет тип StreamT . Операция OV, F это функция от входной переменной V и фрагмента, которая возвращает тройку V, X, F, состоящую из выходной переменной V, преобразования X и выходного фрагмента F, который является подфрагментом F . Операции определены только для некоторых фрагментов. К примеру, операция фильтрации определена для фрагментов вида ifP F и возвращает тройку V, Filt, F. Всякая операция O обладает следующим свойством для любого генератора GV, S, F, для которого OV, F определена и возвращает тройку V, X, F, представление генератора G семантически эквивалентно представлению генератора GV, XS, F . Генератор G назовем составным генератором. Мы определили следующие операции определена для фрагментов вида ifP F. Возвращает тройку V, E - E.filterV - P, F определена для фрагментов вида ifP continue F. Возвращает тройку V, E - E.filterV - P, F определена для фрагментов вида T V R F, где V объявленная переменная поддерживаемого типа T, причем V используется только в выражении R и не используется в F. Возвращает тройку V, E - E.mapV - R, F. Если тип входной или выходной переменной примитивный, вместо map может использоваться другой метод Stream API например, mapToInt, boxed, asLongStream и т. д. определена для фрагментов вида V R F. Возвращает тройку V, E - E.mapV - R, F определена для фрагментов, являющихся циклами, для которых существует простой генератор GV, S, F, причем V не используется в F. Возвращает тройку V, E - E.flatMapV - S, F. Если тип входной или выходной переменной примитивный, могут использоваться конструкции вида E.flatMapToIntV - S или E.mapToObjV - S.flatMapFunction.identity. Расширенное преобразование назовем функцией EXFb E Fa, которая возвращает новое Java выражение. В отличие от преобразования, помимо непосредственно выражения типа Stream, принимает еще и 2 фрагмента, которые расположены непосредственно до внешнего цикла и после внешнего цикла. Назовем терминалом функцию TG, Fb, Fl, Fa, где GV, S, F, которая для S возвращает расширенное преобразование X. Так же, как и операция, может быть определена не для всех фрагментов. Определим следующие терминалы табл. 2. В табл. 2 для краткости префикс Fb E Fa - был опущен. Данный список не является полным, рефакторинг содержит значительно больше вариантов преобразований, в табл. 2 приведены примеры из каждого класса терминалов. Определения терминалов Terminal Definitions Название терминала Требования к фрагментам Расширенное преобразование Нахождение первого элемента Fb вида OptionalT x Optional.empty Fl вида if P result R break OptionalT x E.findFirstV - P Fa Редукция элементов Fb вида T a I Fl вида for T x c a x, где одна из операций, T a I A E.reduceI, a, b - a b Fa, где I значение идентичности identity value для данной операции, а переменные a и b уникальные в данной области видимости Нахождение минимального максимального элемента Fb вида T a I Fl вида for T x c if x a a x, где обозначает или T a opI, E.max Fa, где op max или min, в зависимости от Сохранение в список Fb вида ListT l new ArrayList Fl вида for T x c l.addx E.collectCollectors.toList Fa Склейка строк Fb вида StringBuilder sb new StringBuilderprefix Fl вида boolean isTail false for T e collection if isTail sb.appenddelimiter else isTail true sb.appendF Fa вида sb.appendsuffix.toString где F содержит только переменную e или другие финальные переменные E.mapF.collectCollectors.joiningd elimiter, prefix, suffix Применение операции для каждого элемента Отсутствуют Fb E.forEachV - Fl Fa Рассмотрим подробнее алгоритм преобразования императивного кода в функциональный. Далее приводится псевдокод данного алгоритма Полагаем, что Fb фрагмент контекста до цикла, Fl фрагмент цикла, Fa фрагмента контекста после цикла, а G базовый генератор для текущего шага рекурсии. Следует пояснить, что operationMatchers и terminalMatchers соответствуют описанию операций и терминалов, которые были рассмотрены ранее. Нетрудно заметить, что подход основан на преобразовании некоторых шаблонов кода, из которых и строится цикл. В статьях 13 были исследованы различные шаблоны ко да в открытых кодовых базах, большая их часть была поддержана в данном рефакторинге. Данная реализация рефакторинга не была первой, аналоги есть в других IDE для Java Eclipse и NetBeans. Далее мы приведем их сравнение с рефакторингом в IntelliJ Idea. Аналогичная возможность реализована в рамках проекта LambdiFicator 4 5 для IDE NetBeans 8.1. По сравнению с разработкой, представленной в данной статье, эта реализация обладает рядом недостатков. 1. Из промежуточных операций поддерживаются только операции filter и map. Операции flatMap, distinct, limit, sorted не поддерживаются ни в каком виде. 2. Из концевых операций поддерживаются только reduce, forEach, anyMatch и noneMatch. Не поддерживаются такие важные способы завершения потока, как collecttoList collectjoining toArray findFirst. 3. Примитивные типы отождествляются с соответствующими им объектными типами к примеру, тип int с типом java.lang.Integer, в то время как Stream API обеспечивает специальную поддержку примитивных типов int, long, double с помощью интерфейсов IntStream, LongStream и DoubleStream соответственно. Такое отождествление не только ухудшает производительность результирующего кода, но и в некоторых случаях может опасным образом изменить семантику кода. Рассмотрим, к примеру, следующий листинг Данная Java-программа при выполнении выдает 1, 3, так как в цикле вызывается метод удаления элемента списка по индексу removeint. IDE NetBeans заменяет цикл следующим образом При этом тип переменной idx меняется на java.lang.Integer, и уже вызывается метод удаления элемента списка, эквивалентного заданному removeInteger. В результате изменяется семантика программы при выполнении она выдает 2, 3. Для сравнения, IntelliJ Idea предлагает заменить тот же самый цикл следующим образом В данном случае благодаря применению операции mapToInt StreamInteger превращается в IntStream, и изменения семантики не происходит. В IDE Eclipse данная функциональность планировалась к реализации с использованием плагина Convert-For-Each-Loop-to-Lambda-Expression-Eclipse-Plugin 6. Плагин не был доведен до рабочего состояния на момент 19 декабря 2018 г., даже базовая функциональность не поддерживается. Код проекта может быть найден на GitHub в репозитории IntelliJ Idea . Точка входа класс StreamApiMigrationInspection, он предназначен для обнаружения шаблонов кода, подходящих для преобразования. После того как подходящий кусок кода найден, будет предложен вариант миграции объект, класс которого BaseStreamApiMigration. Непосредственно преобразованием кода занимается класс MigrateToStreamFix. Здесь же находятся классы StreamSource и Operation, наследники которых соответствуют определению простого генератора и операции соответственно из статьи. Классу TerminalBlock напрямую не соответствует терминал из модели, он обозначает фрагмент, который еще не был обработан и, возможно, содержит терминал. Данный автоматический рефакторинг активирован только для версий Java больше 7. В данной статье была выстроена модель Stream API, на основании нее реализован рефакторинг для преобразования циклов в цепочки вызовов Stream API и внедрен в платформу IntelliJ Idea. Сейчас это преобразование доступно к использованию у миллионов пользователей IDE. Данный рефакторинг успешно распознает большую часть распространенных способов преобразования данных. Корректность обеспечивается сотнями интеграционных тестов и проверками на реальном программном обеспечении, в частности самом коде IntelliJ Idea. "}
{"title": "СИСТЕМЫ АВТОМАТИЗИРОВАННОЙ ОЦЕНКИ ЗАДАНИЙ   ПО ПРОГРАММИРОВАНИЮ: РАЗРАБОТКА, ИСПОЛЬЗОВАНИЕ И ПЕРСПЕКТИВЫ  ", "absract": "Приводится обзор существующих систем проверки заданий по программированию, кратко описано современное состояние архитектуры системы NSUts, созданной в Новосибирском государственном университете,  и практика ее использования в учебном процессе и в олимпиадах по программированию различных уровней. Приведен анализ опыта использования таких систем и обозначены перспективы их развития. ", "text": " Идея создания автоматизированной тестовой системы для проверки заданий по программированию не нова. Попытки создания таких систем предпринимались еще в 80-е гг. XX в. 1. Можно выделить две основные проблемы, которые затруднили обретение самостоятельности этим направлениям исследований. Во-первых, многие из разработчиков систем такого рода используют слова автоматизированное тестирование в описании задачи, поэтому соответствующие исследования относят либо к автоматизированному контролю качества программного обеспечения, либо к педагогическому тестированию 24. Задача автоматизированного контроля навыков программирования хотя и находится в родстве с обоими названными направлениями, но требует иных подходов и иных инструментов. Во-вторых, многие разработчики таких систем ставят задачу слишком узко. Так, разработчики системы ejudge описывают свой программный продукт как систему для проведения различных мероприятий, в которых необходима автоматическая проверка программ, а краткое описание системы на английском языке звучит как contest management system. В англоязычной литературе также нет единого термина для обозначения программных продуктов такого типа. Так, организаторы международных командных соревнований по программированию ACM ICPC ACM International Collegiate Programming Contest называют систему, используемую для проведения соревнований, Programming Contest Control System система управления программными соревнованиями . В настоящее время в качестве такой системы используется система Kattis, авторы которой называют ее Automated assessment system автоматизированная система оценки 5. Еще один термин, часто встречающийся в англоязычных названиях систем такого рода, Online judge, вне контекста этот термин допускает множество неверных толкований. С 1998 г. в НГУ ведутся работы по автоматизированной проверке заданий по программированию 6. Было создано несколько поколений систем такого типа. Первая программа объемом около 1 000 строк была написана на языке Perl. В настоящее время в олимпиадном программировании и в учебном процессе используется система NSUts. В результате работы в ней, а также знакомства с другими подобными системами как российскими, так и зарубежными, удалось сформулировать требования к программным разработкам такого рода 7, провести анализ отличия олимпиадных систем от систем поддержки обучения 8. Одной из первых российских систем автоматизированной проверки была система TRun для MS-DOS, которая состояла из двух программ run и t. Первая из них осуществляла запуск решений с ограничением по времени работы, а вторая проверяла решения на заданных тестах. Это простое решение во многих случаях является и достаточным. Будучи дополнена набором командных файлов MS-DOS, TRun успешно обеспечивала тестирование решений даже на Всероссийских олимпиадах школьников по информатике. Сейчас TRun представляет ограниченный интерес из-за малой применимости к решениям, написанным под операционную систему Windows. После системы TRun на Всероссийских олимпиадах использовалась система Cyber Judge, созданная М. А. Бабенко. Это сложное и расширяемое решение основано на платформе .NET. Дописывание к ней небольшого модуля позволило, например, демонстрировать фотографии участников, вызываемых на личное тестирование, во время проведения XIII Всероссийской олимпиады. Но использование этой системы затруднительно, поскольку ее можно применять только в присутствии автора. Это связано с тем, что, во-первых, настройка не ориентирована на пользователя и предполагает редактирование файлов конфигурации. Во-вторых, по системе нет документации. В-третьих, часто настройка системы предполагает дописывание к ней небольших модулей для конкретной олимпиады, что при отсутствии документации является большим препятствием даже для профессиональных программистов. В следующей системе olympiads.ru содержится, кроме программы запуска решений с контролем времени работы и использования памяти, еще база данных задач. Эта система уже имеет простой графический интерфейс пользователя, с помощью которого осуществляется редактирование базы данных и запуск решений на проверку. Появление в системе самотестирования базы данных и интерфейса отражает потребность участников в упрощении настройки систем тестирования. Между тем к появлению базы данных ведет и другое требование автоматизация деятельности жюри по подсчету баллов и подведению итогов. Примером системы самотестирования является tchoose, которая использовалась на Всероссийской олимпиаде по информатике для отображения результатов работы правильных и неправильных решений на подготовленных тестах. Отображение результатов тестирования в графическом виде кажется перспективной возможностью, удобной не только при подготовке олимпиад, но и во время тренировок. Объединение двух систем Automated Programming Problem Evaluation System APPES на Java и Programming Contest Management System PCMS на Delphi, созданных в СанктПетербургском государственном институте точной механики и оптики, и их последующее развитие превратилось в проект PCMS2 . Гибкость этой системы достигается низкой связностью модулей и качественным выделением высокоуровневых концепций. В плане возможностей PCMS2 значительно превосходила на тот момент все современные требования 9. Однако такая гибкость имеет высокую цену. Даже использование настроенного сервера PCMS2 требует предварительного обучения и понимания синтезированных концепций, не относящихся к предметной области. Кроме того, настроенным PCMS2 никогда не бывает, поскольку большинство действий в нем осуществляется написанием файлов конфигурации, а пользовательский интерфейс имеет преимущественно информационные функции. Файлы конфигурации в формате XML составляют значительную часть системы как по важности, так и по объему, связывая ее модули вместе. Одни XML-файлы описывают формат других XMLфайлов, внутри текстовых строк применяется особо разработанный синтаксис подстановок, некоторые XML-файлы представляют собой программы на специально созданном языке сценариев. Отдельные части системы еще не до конца разработаны, поэтому часть настроек выполняется путем написания и подключения специализированных модулей, что также могут выполнить только авторы системы Г. А. Корнеев и А. С. Станкевич. Отметим, что сервер PCMS2 поддерживает только ОС Windows. Связано это с различиями в способах запуска решений и замера потребления ресурсов под разными операционными системами. В Московском государственном университете была создана система ejudge, которая поддерживает только операционную систему Linux. Она написана на языке Cи и предоставляет определенный набор функций, удовлетворяющих современным требованиям. В системе ejudge имеются вс те же конфигурационные файлы, описанные в документации. Многие действия требуется выполнять из командной строки запуском соответствующих утилит. Базовые возможности администрирования доступны через веб-интерфейс. В системе ejudge можно отметить три недостатка, которые следуют из того, что тестирование проводится на той же машине, что и серверная часть системы. Первый из них это возможная конкуренция за ресурсы между тестируемым решением и самой системой. В результате система может выдавать ложный вердикт превышен лимит времени для решений, которые на выделенной машине вполне уложились бы в этот лимит. Для обхода этой проблемы ejudge использует многократную прогонку решений с вердиктом превышен лимит времени. Но очевидно, что это только снижает вероятность возникновения проблемы, а не решает ее. Ко второму недостатку можно отнести ограниченные возможности горизонтального масштабирования. Это означает, что подключить дополнительные машины, кроме той, на которой проходит тестирование, физически невозможно. Единственное, что можно сделать, это запускать несколько процессов проверки, по числу процессорных ядер на сервере. Но это может привести к конкуренции решений за оперативную память, т. е. к росту числа ложных вердиктов превышен лимит времени. При проверке решений на олимпиадах могут случаться значительные задержки между отправкой решения и получением вердикта. Третий недостаток состоит в том, что тестирование возможно только под той же ОС, под которой работает сама система, т. е. под Linux. Это ограничивает применение системы, особенно для школьных соревнований, где правила требуют ОС Windows и компиляторы, доступные только для Windows или для учебных курсов, где ОС и язык программирования заданы программой курса. Система автоматической проверки с архивом задач в испанском городе Вальядолиде была создана гораздо раньше аналогичных российских разработок и получила большую популярность среди студентов. Для ее работы используется операционная система Linux, поддерживаются языки программирования GNU C, GNU C, Free Pascal. Архив постоянно пополняется новыми задачами и тестами. Для каждой задачи приводится статистика отношение числа правильных решений задачи к общему числу попыток сдать данную задачу. Недостатком системы является тот факт, что вся коммуникация с участниками ведется через электронную почту. Также для многих неудобным является использование системы Linux. Система развернута на серверах университета Вальядолид. Доступ к этим серверам бесплатен, но скачать программное обеспечение и развернуть его на своем оборудовании невозможно. Также все изменения в системе добавление языков и версий компиляторов, изменение правил подсчета рейтинга возможны только с разрешения и при активном участии ее разработчиков. Главным же недостатком данной системы и ряда рассматриваемых далее систем является то, что они используют модель Software as Service SaS. По такой модели программное обеспечение не устанавливается на компьютеры пользователей, а развертывается на серверах поставщика услуг. Фактически, пользуясь услугой, клиент получает и программу, и вычислительные ресурсы для ее работы. Часто программное обеспечение вообще не доступно конечному пользователю. Данная модель используется как для коммерческих, так и для бесплатных или условно-бесплатных услуг. Например, такие популярные сервисы, как Gmail или Yandex mail, работают именно по этой модели. Для многих сценариев использования эта модель привлекательна, поэтому она и получает широкое распространение. Но эта модель имеет и ряд недостатков, часть из которых существенна для учебного процесса и долгоиграющих мероприятий, таких как проводимая на протяжении десятилетий ежегодная олимпиада. Наиболее очевидный недостаток это полная зависимость от поставщика услуги. Если поставщик резко изменит условия или вообще откажется от данного сер виса, пользователь, в данном случае организатор олимпиады, ничего сделать не сможет. Он может даже потерять доступ к данным старых мероприятий. Также данная модель затрудняет доработку системы под нужды конкретного пользователя или конкретного мероприятия. Если организаторы олимпиады захотят поменять правила, они вынуждены обращаться к поставщику SaS, который может и не выполнить этот запрос. Известна система автоматической проверки timus Уральского государственного университета с архивом задач. Система используется для проверки олимпиад, при этом участникам предоставляется набор языков программирования C, С и Pascal Delphi. Эта система предоставляется по модели SaS и поэтому обладает недостатками, характерными для этой модели и изложенными ранее. В последние годы широкую известность в России получила система Yandex Contest компании Яндекс . Она также предоставляется на условиях SaS. С 2013 г. она используется для проведения ряда соревнований, а также в учебном процессе, например в курсах Школы анализа данных Яндекс. Тестирование проводится под ОС Linux, и ей присущи недостатки, изложенные при описании системы ejudge. Кроме того, тестирование проводится на виртуальных машинах, а не на выделенных физических машинах. Это удешевляет развертывание системы, но создает опасность ложных вердиктов превышено время тестирования из-за конкуренции процессорных ядер за доступ к ОЗУ и накладных расходов виртуализации. Система Yandex Contest имеет ограниченные возможности увеличения емкости, что наблюдалось на региональных этапах Всероссийской олимпиады школьников по информатике 20172018 г. в тех регионах, где соревнования проводились на Yandex Contest. Время ожидания вердикта системы было довольно продолжительным. Возможно, это связано с архитектурными ограничениями на количество или размещение тестирующих машин. С помощью автоматизированной системы NSUts проводятся соревнования по правилам ACM-ICPC и по правилам Всероссийской олимпиады школьников. Система поддерживает тестирование программ на языках C, C, Java, Pascal, Pyton, Kotlin, C для Win32. В рамках одного тура можно проводить проверку программ на нескольких диалектах одного языка, например Visual C или Borland C, так как компилятор языка программирования явно указывается участником при отправке задания. Для отправки задач участники используют вебинтерфейс системы, в котором можно отслеживать состояние тестирования, просматривать рейтинг, а также общаться с жюри. Для хранения задач, очереди тестирования и рейтинга используется реляционная СУБД. Заметим, что сохраняются все попытки отправки решений, все исходные тексты и точные значения времени их отправки. Это важно для проведения апелляций и для выявления попыток мошенничества. Время исполнения задачи в многозадачной среде определяется сложными сценариями конкуренции за разные ресурсы, такие как оперативная память, кэш процессора, время переключения контекста процессора и т. д. Поэтому проверка решений проводится на выделенных компьютерах, что сводит влияние такой конкуренции к минимуму. К автоматизированным системам тестирования знаний предъявляются следующие требования обеспечение глубокого и адекватного тестирования знаний и навыков эффективная защита от мошенничества 10 простота в эксплуатации для специалистов средней квалификации. В системе NSUts 6 можно выделить три основные составляющие сервер олимпиад клиентское программное обеспечение тестирующий клиент. Главной частью системы является сервер. Тестирующих клиентов в системе может быть несколько. К клиентскому программному обеспечению относятся браузер и среда разработки для создания и отладки решений. Оно должно быть установлено на компьютере пользователя, и не предоставляется системой, но принимает активное участие в работе. Олимпиада это основной объект, над которым производятся действия сервера. Она может включать несколько туров. Каждый тур это олимпиада с точки зрения участников, которая состоит из набора задач, представляющихся им для решения. Сервер тестирования осуществляет проведение олимпиады тура. Он предоставляет участникам и членам жюри веб-интерфейс для взаимодействия с системой тестирования, автоматизирует управление олимпиадой туром. Под управлением олимпиадой понимается осуществление хранения в базе данных условий задач, тестов и решений проверка решений участников и визуализация ее результатов создание и отображение рейтинга мест, которые заняли участники соревнования генерация отчетов о проведении олимпиады тура предоставление средств для перетестирования решений участников поддержка системы регистрации участников, обеспечение обратной связи с жюри и решение других организационных задач администрирование олимпиад и туров. Тестирующий клиент забирает решения участников, полученные сервером, из очереди решений, и выполняет их проверку на наборе тестов. В процессе обработки решения он получает исходный код, информацию о требуемом компиляторе и тестовые данные. Результат проверки решения передается обратно серверу, который производит его обработку, включающую отправку его участнику и создание рейтинга. Взаимодействие с системой участников олимпиад и членов жюри осуществляется посредством веб-интерфейса, который исключает обращение к тестирующему клиенту напрямую. Тестирующие клиенты взаимодействуют с сервером через протокол HTTP, поэтому они могут быть размещены как на той же физической машине, что и сервер, так и на выделенных машинах, физических или виртуальных. В НГУ для тестирования олимпиад используются тестирующие клиенты на выделенных физических машинах. Проведем сравнение системы NSUts, например, с системой Yandex Contest. 1. Система NSUts развернута на инфраструктуре разработчиков, и ее исходный код доступен НГУ. Это позволяет планировать мероприятия, в том числе статусные или просто ответственные, без согласований с внешними для НГУ организациями. При проведении ответственного мероприятия на системе Yandex Contest необходимо это согласовывать с компанией Yandex, так как в ней на это время могут быть запланированы профилактические или другие работы, закрывающие или ограничивающие доступ. Изменять правила соревнований, добавлять или исключать языки программирования невозможно без согла сования с внешними организациями. На Открытой Всесибирской олимпиаде им. И. В. Поттосина традиционно проводится первый тур по нестандартным правилам. Стандартные правила ACM хоть и медленно, но также изменяются. Языки и версии компиляторов требуется добавлять каждый год. Нужно иметь возможность дорабатывать и адаптировать систему в любом желательном для НГУ направлении, например добавить MathLab для приема задач у физиков. 2. В системе NSUts тестирование происходит на выделенных компьютерах под опера ционной системой Windows. Это решение обеспечивает адекватное судейство, связанное, во-первых, с точным подсчетом процессорного времени, поскольку правила большинства мероприятий предусматривают ограничение времени на исполнение программы. Во-вторых, обеспечивается возможность проводить школьные олимпиады и использовать компиляторы, доступные только под Windows Visual Studio, Delphy. Yandex Contest использует виртуальные машины с операционной системой Linux. У используемых компиляторов есть аналоги под систему Linux Mono для C, Free Pascal, но все-таки сами компиляторы и среды исполнения не тождественным тем, что указаны в правилах соревнований, а это дает основания для апелляций и иногда приводит к реальным проблемам. 3. В системе NSUts хранится история олимпиад, проводившихся в НГУ с 2010 г. История знает немало случаев, когда публичные сервисы внезапно закрывались или изменяли политику до неприемлемой, самый известный пример Sourceforge, который после смены собственника начал подкладывать программные модули, показывающие рекламу adware, в размещенные на нем программные проекты. Для многолетней деятельности этот риск вполне реалистичен и неприемлем. 4. Yandex Contest заявляют одновременную поддержку 1 000 пользователей, сервер NSUts тоже на такую нагрузку регулярно тестируется. Как было отмечено, система NSUts создана для обеспечения проверки решений участников олимпиад по программированию, поэтому главной частью ее использования является проведение олимпиад по программированию всех уровней, в том числе открытых интернетолимпиад. Она используется при проведении Открытой Всесибирской олимпиады по программированию им. И. В. Поттосина 11, районных и региональных школьных олимпиад по программированию в Новосибирской области . В первых этапах Всероссийской олимпиады школьников по информатике, проводимых в Новосибирской области с помощью системы NSUts, одновременно участвовало несколько сотен школьников, было проверено свыше тысячи решений. Некоторые студенческие олимпиады собирают около 1 000 участников, при этом проверяется в онлайн-режиме более 10 000 решений в течение одного тура. Приведем некоторые цифры по Открытой Всесибирской олимпиаде по программированию им. И. В. Поттосина. Олимпиада является командной, каждая команда состоит из трех участников. Имея один компьютер, команда стремится сдать как можно больше задач. Олимпиада проводится с 2000 г. Первые годы эта олимпиада проводилась в три тура. Первые два тура были отборочными с помощью Интернета, третий очный. В последние годы олимпиада проводится в два тура первый, отборочный, интернет-тур проходит заочно по традиционным правилам международного студенческого чемпионата АСМ-ICPC. Второй тур очный, состоит из двух номинаций. Первая номинация проводится по правилам, напоминающим Marathon Match на TopCoder . В нем предлагается одна игровая или исследовательская задача на 5 часов работы. Как правило, для него жюри разрабатывает оригинальный проект, а также интерфейс и модули, которые позволяют встраивать решения участников в интерфейс, визуализировать и проигрывать их на сайте олимпиады. Для проведения этой номинации выполняется специальная настройка автоматизированной системы тестирования NSUts. Вторая номинация проводится по правилам международного чемпионата ICPC-ACM, а результат определяется по сумме двух номинаций. 30 сентября 2018 г. прошел интернет-тур XIX Олимпиады . В нем участвовало 411 команд более чем из 100 университетов и 100 школ 21 страны. Результаты тура приведены на сайте олимпиады. По правилам ACM-ICPC задача считается непринятой до тех пор, пока не пройдет все тесты жюри. Поэтому многие команды в течение тура на одну задачу отправляют на проверку несколько решений. Всего во время тура было отправлено около 4 000 решений. Очный тур прошел с 17 по 19 ноября 2018 г. В нем приняло участие 40 команд из Абакана, Барнаула, Екатеринбург, Ижевска, Иркутска, Кирова, Красноярска, Москвы, Новосибирска, Омска, Перми, Рубцовска, Санкт-Петербурга, Томска, Тюмени, Якутска. I номинация была проведена 17 ноября 2018 г. Команды получили игровую задачу. В данной задаче требовалось написать программу Умный Пилот для управления космической ракетой. Цель полета взлететь с поверхности Земли и выйти на эллиптическую орбиту с перигейным расстоянием не меньше заданного. Перигей точка орбиты, ближайшая к центру Земли, а перигейное расстояние расстояние от перигея до центра Земли. В условии задачи описано строение ракеты, ее управление и физика задачи, представлен протокол взаимодействия, описан статус ракеты и программа-интерактор, которая после статуса выдает текущее состояние ракеты. В архиве с игрой представлены все материалы, необходимые для работы с данной задачей, а также приведены примеры решений. Помимо описания задачи и протокола работы для нее представлены требования к программе, система оценки, генератор тестов. Для тестирования первой номинации использовались средства NSUts. Участники сдавали свои решения через нее, результаты промежуточной проверки тоже отображались в системе. Однако проверяющая программа была реализована специально для данной задачи отдельно от системы. Вторая номинация была проведена 18 ноября 2018 г. Результаты обеих номинаций и общие результаты тура представлены на сайте олимпиады. Статистика за последние одиннадцать лет в табл. 1. Статистика Открытой Всесибирской олимпиады им. И. В. Поттосина 20082018 гг. Pottosin Open Widesiberia Olympiad Statistics 20082018 Год Количество команд интернет-тура Количество участников округленно Количество команд участниц очного тура Количество вузов школ Количество стран 2008 274 820 46 67 14 7 2009 272 820 48 98 30 7 2010 259 760 49 96 23 7 2011 301 870 49 95 29 7 2012 253 850 48 78 21 6 2013 228 680 51 82 12 8 2014 341 1000 48 98 74 7 2015 372 Более 1 000 50 96 39 12 2016 393 Более 1 000 47 96 24 12 2017 379 Более 1 000 46 101 27 31 2018 411 Более 1 000 42 106 11 22 В течение последних семи лет система NSUts активно используется преподавателями НГУ для промежуточного контроля заданий студентов по дисциплине Программирование. Отметим ряд свойств системы NSUts, которые дали возможность использовать ее в учебном процессе. 1. В NSUts реализована двухуровневая система организации данных. На первом уровне выделены в качестве основных объектов олимпиады, а на втором, внутри олимпиад, туры. Каждый тур содержит некоторое количество задач. Применительно к учебному процессу под олимпиадами можно понимать годовой или семестровый практический курс, а каждый тур рассматривать как недельное задание, состоящее из задач, объединенных темой, которая разбирается на семинарских занятиях. Регистрация на такую олимпиаду ограничена студентами одной группы, таким образом обеспечивается некоторая конфиденциальность информации. 2. Студенты могут сдавать задачи в систему в любое время суток, что поддерживает их самостоятельную работу. 3. Набор задач каждого тура вместе с тестами подготавливается заранее и может исполь зоваться в течение многих лет. Решения студентов проверяются на этих тестах, что значи тельно экономит время преподавателя при проверке заданий. На занятиях остается больше времени для обсуждения методов кодирования алгоритмов или правил оформления текстов программ. Интерфейс системы NSUts предоставляет преподавателю средства, позволяющие проверять задания студентов удаленно и во внеурочное время. Заметим, что автоматизиро ванная проверка программ не может исключить личного общения преподавателя со сту дентом. Преподаватель, например, может не зачесть решение студента, которое прошло все тесты и получило вердикт принято, если посчитает, что студент не до конца понимает суть решаемой задачи, не может ее объяснить или решил задачу несамостоятельно. 4. Еженедельную работу студентов можно стимулировать системой баллов, которые не посредственно влияют на общую оценку. При этом важно учитывать время сдачи задания, оно хранится в системе NSUts для каждой посылки. Объявленные заранее правила получения оценок порождают стремление студентов сдать все задачи в кратчайшие сроки, что, несо мненно, идет на пользу обучению. 5. Использование автоматизированной проверки задач способствует формализации отно шений между преподавателем и студентом, практически исключает необъективность и пред взятость. Рассмотрим статистику использования NSUts на первом курсе ФИТ НГУ за шесть лет табл. 2. В первом семестре требовалось выполнять по одному заданию в неделю, всего 15 заданий. В каждое задание входило от трех до восьми задач. Всего за семестр нужно было сдать 60 задач различного уровня сложности. При успешной сдаче решения задачи в систему в течение первой недели со дня выдачи задания за нее начисляется 10 баллов, а далее баллы понижаются. При сдаче программы в первый день после соответствующего семинара за нее начисляется еще один бонусный балл. Результаты работы студентов за семестр Students Work Statistics for Semester Количество баллов, набранное студентами за семестр Количество задач, решенных студентами за семестр, из 60 возможных Среднее 350 442 507 519 440 520 39 49 54 53 48 53 Максимальное 537 621 648 653 647 637 52 59 60 60 60 60 Минимальное 157 205 128 159 202 304 24 28 31 35 24 34 Студенту выставляется отличная оценка, если он набирает не менее 75 от базового количества баллов, что составляет не менее 450 баллов. Из приведенной в табл. 2 статистики видно, что среднее количество баллов, которое набирали студенты, очень близко к этой циф ре, а в половине случаев даже ее превосходит. Максимальное же количество баллов значительно превосходит 600. Это говорит о том, что в каждой группе были студенты, которые стремились все сдать в первый день и получить за каждую задачу по 11 баллов. Процентное соотношение набранных баллов по годам показано на рисунке. Поскольку система NSUts изначально создавалась не для использования ее в учебных занятиях, в ней не была предусмотрена соответствующая функциональность. Отметим некоторые ее особенности, которые хотелось бы модифицировать и развить. 1. Большой проект, состоящий из нескольких модулей, в данной системе проверить нельзя, так как решение участника для проверки записывается в одном файле. 2. Для усвоения некоторых структур данных, таких как списки, стеки, очереди, деревья, необходимо научиться эти структуры обрабатывать. Для этого часто требуется уметь писать функции, которые для построенных структур должны выдавать результат преобразования. В системе NSUts, как и в любой другой системе проверки решений, этого сделать нельзя, поскольку входные и выходные данные для решения должны быть записаны в файлы. Следо вательно, студенту дополнительно нужно строить саму структуру, что является отдельной задачей. 3. Никакая система не может заменить преподавателя, который должен проверять код студента. Иначе может оказаться, что система при проверке решения выдала вердикт при нято, но задача решена не та, которая была поставлена. 4. В системе рейтинг участников строится в туре. Построение общего рейтинга по всем турам осуществимо только внешними средствами. Автоматизация процесса построения такого рейтинга была бы желательна. 5. В олимпиадах по программированию доступ к набору тестов имеет только жюри, в учебном процессе в этой роли выступает преподаватель. Было бы полезно давать воз можность студентам видеть тесты, это часто помогает отладить программу. Многолетний опыт использования нескольких поколений систем автоматической оценки заданий по программированию 6 позволил разработать мощное и гибкое решение, применимое для широкого спектра мероприятий проведения олимпиад, практикумов по программированию, тренировок олимпиадных команд и др. Но в процессе работы определились направления развития системы. Одним из них является адаптация системы к требованиям учебного процесса. Хотелось бы, например, реализовать в системе поддержку для различных стратегий обучения. Также имеется большая потребность создать и поддерживать банк задач без привязки к конкретной олимпиаде или туру. Это связано с тем, что накопилось большое количество задач разных уровней сложности и тематики, все они хранятся в своих турах, что усложняет их поиск. В настоящее время ведутся работы по переходу сервера на клиент-серверную архитектуру AJAX 12. Большая часть системы реализована по технологии динамического HTML, когда сервер полностью генерирует код страницы и передает ее клиентскому браузеру на каждый запрос. При характерной для NSUts нагрузке, когда разные пользователи в большинстве случаев видят разные данные, это приводит к тому, что сервер делает много лишней работы, и невозможно использовать кэширование. AJAX подход к разработке современных вебсайтов, используемый ведущими интернет-сервисами Gmail, Facebook, Vkontakte и др., состоящий в том, что сервер генерирует только данные в компактном формате, например в формате JSON, а генерация и отрисовка всего пользовательского интерфейса производится на клиентском браузере при помощи JavaScript. Это позволяет решить проблемы с лишней работой для сервера и кэшированием, задействовать процессоры клиентских компьютеров когда сервер один, а клиентских компьютеров сотни, преимущества кажутся очевидными, а также ввести ряд полезных функций, уже реализованных в других системах автообновление очереди и рейтинга, оповещение об изменениях рейтинга. Существующая система уже начинает испытывать нехватку ресурсов, если в ней оказывается больше 1 000 пользователей. Созданы прототипы новой архитектуры, которые обеспечивают приемлемую производительность вплоть до 23 тысяч пользователей. В результате модернизации системы ожидается повышение ее производительности под высокими нагрузками, кратное повышение емкости, а также снижение потребности сервера в ОЗУ в десятки или сотни раз, по сравнению с текущими 16 Gb. Система NSUts постоянно развивается, предполагаются дополнительные направления ее доработки, такие как выкладывание исходного кода системы в открытый доступ, улучшение дизайна системы и ее эргономики. "}
{"title": "МЕТОДОЛОГИЧЕСКИЕ АСПЕКТЫ ПРИМЕНЕНИЯ ИНСТРУМЕНТАРИЯ ГИС   ДЛЯ УПРАВЛЕНИЯ ТРУДОУСТРОЙСТВОМ ВЫПУСКНИКОВ   РЕГИОНАЛЬНЫХ ВУЗОВ  ", "absract": " Целью данного исследования является совершенствование механизма трудоустройства выпускников вузов  по специальностям с учетом нужд региона с использованием современных компьютерных технологий. В статье рассматриваются преимущества и методологические аспекты применения инструментария географических информационных систем, которые являются симбиозом возможностей управления большими базами данных и пространственной визуализации, характерной для топографических карт с использованием QGIS. Каждый информационный слой представлен таблицей реляционной базы данных или электронной таблицей,  в которых имеется поле привязки к географическому положению, что позволяет разместить данные на карте. Научная значимость статьи обусловлена тем, что данная технология способствует созданию единого информационного пространства рынка работодателей по востребованным специальностям, а также активному налаживанию сотрудничества между вузами и работодателями с целью совершенствования механизма трудоустройства выпускников вузов на основе компетентностного подхода. Результатом исследования являются методологические аспекты применения открытой геоинформационной системы QGIS для управления трудоустройством молодых специалистов. Кроме того, поставлены задачи для перспективного развития механизма применения геоинформационных технологий в трудоустройстве выпускников вузов. ", "text": " Применение географических информационных систем ГИС в управлении трудоустройством выпускников вузов это внедрение современных компьютерных технологий в процесс управления трудоустройством кадров, являющих собой карты или типографические ресурсы нового поколения, позволяющие собирать, хранить и отображать данные на экране в электронном виде. Применительно к рынку работодателей ГИС могут содержать помимо географии местности и информацию по статистике, демографии, которая позволяет делать анализ. В решении проблемы управления трудоустройством выпускников вузов ГИС это симбиоз возможностей управления большими базами данных БД и пространственной визуализации, характерной для топографических карт. Многослойная тематическая информация, в частности по востребованным специальностям на рынке работодателей, хранящаяся в базах данных системы, имеет привязку к их географическому местоположению. Использование ГИС с целью трудоустройства выпускников вузов имеет преимущества пространственное, 3D-представление параметров, что облегчает восприятие предоставляет возможности интеграции данных из различных источников в единый массив для общего пользования обеспечивает автоматический анализ пространственной географической информации и отчетность дает возможность расшифровки данных спутниковой съемки, полученных ранее схем и планов местности. Функции, выполняемые ГИС представлены на схеме рис. 1. Согласно данным Статистического управления Республики Узбекистан, по состоянию на 01.01.2017 функционирующих в стране юридических лиц по регионам визуально можно представить на карте рис. 2. Распределение функционирующих в республике предприятий по видам экономической деятельности представлено на рис. 3. Наша задача заложить методологические аспекты представления данных такого типа в разрезе востребованных специальностей каждого вида деятельности в регионах и визуализация их посредством ГИС технологий. Маркетинговые исследования зарубежного опыта трудоустройства выпускников вузов 1 показывают, на сколько актуально решение этой проблемы в Республике Узбекистан. Модернизация государства, либерализация экономики на пути поступательного реформирования обеспечили стабильный рост количества зарегистрированных субъектов малого предпринимательства. Для сравнения по состоянию на 01.01.2017 их число составило около 233 тыс. ед., что по сравнению с 01.01.2013 выросло на 27 тыс. ед. Если в 2012 г. соотношение вновь созданных субъектов малого предпринимательства к общему количеству действующих субъектов малого предпринимательства составляло 11, то в 2016 г. данный показатель превысил 14 . С целью визуализации данных по рынку труда посредством современного технологического аппарата, а именно ГИС карты, предварительно необходимо создать единое информационное пространство всех специальностей, востребованных работодателями по видам экономической деятельности юридических лиц как государственного, так и частного сектора. Предлагаемая нами методология предполагает использование открытой геоинформационной системы QGIS, которая дает нам возможность, в частности, применять ее в управлении трудоустройством выпускников вузов, изучать принципы ее работы и модифицировать, распространять копии, совершенствовать и опубликовывать разработанные нами продукты для массового доступа. Мы намерены рассмотреть объекты ГИС, которые представлены в виде слоев. Каждый слой состоит из однотипных данных, соответствующих группе объектов на карте, и хранится в таблице QGIS. Помимо данных, отражающих, например, владельца помещения, юридический адрес, площадь зданий и конструкций, вид деятельности юридического лица, наименование и количество вакансий на предприятии, в таблице QGIS отводится место для невидимого столбца, в котором содержатся пространственные данные, дающие возможность отобразить на топографической карте каждый объект, описанный в соответствующей строке этой таблицы. Для создания ГИС карты возможно использование данных из Интернета, находящихся в открытом доступе векторные слои границы административно-территориального округа, пункты проживания населения, дорожные развязки, маршруты транспорта, интересующие объекты и т. п.. Возможны несколько вариантов просмотра спутникового изображения региона. Самый популярный картографический ресурс Google-maps. Однако он не является бесплатными и не работает в режиме реального времени. Второй способ просмотра карты региона это карты Yandex. Опять же мы увидим изображение со спутника, сохраненное некоторое время назад. Третий вариант спутникового просмотра вашего региона это приложение Google планета Земля. Для его установки уходит около 5 минут. Наименование приложения Google-earth, с его помощью можно побывать в любой точке земного шара. Кроме прочего, здесь имеется огромное количество приложений, обеспечивающих дополнительной информацией. Также есть специальная картографическая и навигационная программа SASPlanet полностью бесплатная и позволяющая работать с большим количеством онлайн карт находим населенный пункт, выбираем из списка доступных карт карты от Bing бесплатный аналог Google-maps в Яндекс. Выбираем масштаб 20 самый крупный из возможных, нажимаем Начать, чем запускаем операцию приклеивания объектов на карту. Для разработки технологии создания ГИС карты трудоустройства выпускников вузов необходимо освоить навыки по установке и поддерживанию QGIS в рабочем состоянии по настройке интерфейса и расширению возможностей системы дополнительными модулями по управлению данными, находящимся в произвольных системах координат и ортогоналей по осуществлению привязки сканированных карт и изображений по созданию векторных изображений, контролю их топологии и заполнению атрибутов по визуализации векторных слоев по обработке и визуализации растровых изображений оцифрованного рельефа поверхности, спутниковой съемки по созданию и подготовке к печати карты по работе с дополнительными источниками данных БД, услугами WMS и WFS использованию дополнительно других полезных приложений 24. Известно, что изображения в компьютерной графике либо растровые, либо векторные. Это относится и к объектам визуализации, наносимым на карты. В качестве векторных объектов используются точки, прямые и полигоны контуры территорий. Создается проект, в котором создаются новые слои. Можно также занести в проект созданные ранее либо находящиеся в открытом доступе таблицы слоев, используя различные форматы файлов, в том числе .shp, включая продукты QGIS. Возможны варианты с использованием БД, слоев из различных сервисов Интернета. Тогда при передаче картографической информации с целью ее дальнейшего применения отправляется либо отдельный файл .shp, либо архив папки с файлами всего проекта. Как было отмечено, геометрия хранится в отдельном поле таблицы. Если такого поля не предусмотрено, то его создают самостоятельно. К примеру, вполне возможно присоединение к проекту электронной таблицы приложения Excel, в которой хранится информация различного характера и в любом количестве, например, о работодателях в формате .csv, с последующим созданием в нем поля пространственных координат или конвертацией в стандарт .shp с целью визуализации данных в ГИС. Но возможно и присоединение к проекту иных форматов файлов .csv, MapInfo с последующей конвертацией их в формат .shp с целью произведения над ними дополнительных действий, например коррекции стиля. Часто возникает проблема, когда код текста присоединенного слоя ошибочен. Тогда из свойств слоя подбирается подходящий вариант кодирования, и проблема будет решена. После интеграции слоев в проекте все изменения сохраняются в исходные файлы, поэто му их можно будет увидеть во всех приложениях, которые используют данные из этой таблицы. Присоединенные к проекту слои не подвержены редакции, поэтому, если появится необходимость нанести новые слои, внести изменения в данные полей, добавлять новые поля невозможно. Чтобы открыть доступ к этим действиям надо выделить слой и нажать кнопку редактирования. Только после этих действий станет возможным его редактирование. Все текущие правки могут быть произведены только в выделенном слое. Если произошло переключение с текущего слоя на другой, то невозможно отметить на карте новый объект из прежней таблицы слоя вплоть до активации исходного слоя. Изменения, производимые в проекте, периодически необходимо сохранять. Итак, будем исходить из того, что одна таблица это один слой с однотипными данными. QGIS разделяет действия, связанные с хранением таблицы и управлением ее стилем. Стиль настраивается по усмотрению пользователя и, как правило, определяет такие характеристики, как цвет, тип обозначений и растров положение и добавление надписей к соответствующим объектам и полей, коммутирующих с ними масштаб надписей, обеспечение связи оформления слоя на карте и полей текущей или коммутирующей таблицы. Для трудоустройства выпускников вуза посредством ГИС на региональной карте разными знаками оформляются рынок работодателей, предлагаемые ими вакансии по каждой специальности. С другой стороны, можно визуализировать рынок образовательных услуг, по цветовой гамме соответствующих требованиям работодателей. Дополнительно настраиваются действия, производимые посредством щелчка мыши по топографическому обозначению с целью визуализации дополнительной информации. Для отправки топографической информации, как правило, пользуются интернет-сервиса ми WMS или WFS. Интернет-услуга WMS обеспечивает отправку графической информации о топографическом ресурсе как растры с привязкой к системе координат. Сервис WFS обеспечивает возможность запроса и редакции векторных данных, таких, например, как дорожные развязки, очертания берегов и территорий. Из модуля QGIS QuickMapServices, кроме услуг WMS, можно воспользоваться множеством других сервисов массовой доступности с целью визуализации топографического ресурса, для чего активизируется элемент управления получить источники данных из настроек загрузить сервисы. Тогда появится возможность воспользоваться кадастровой картой массового пользования, фото местностей Google, Yandex, станет доступной карта из OpenStreetMap OSM, а также другие информационные таблицы, которые могут быть размещены в генерируемой ГИС. Существует много дополнительных интернет-сервисов, обеспечивающих полезной информацией и дающих возможность анализа топографических элементов. В частности, в OSM можно извлечь карту с цифровыми идентификаторами всех дорог области и их параметрами, что может быть использовано для создания слоя с местонахождением работодателей и другой связанной с ними дополнительной информацией. Применив функцию геокодинг к информации, сохраненной в Excel с атрибутами работодателей и предлагаемых ими вакансий, ее можно проанализировать на карте в QGIS таблица из csv файла конвертируется в слой .shp модуль RuGeocoder. Тогда в таблице будет получено скрытое пустое поле, содержащее геометрию. Этот же продукт позволяет воспользоваться процедурой геокодинг с указанием готовой таблицы слоя и ее поля с адресами. В этом случае выбирается поставщик услуги например, для работы с почтовыми адресами на русском языке выбирается Yandex. Запускается процедура геокодинга, в результате которой все обрабатываемые объекты расставляются на карте. Местоположение объектов в ГИС определяется в заданном варианте системы координат. Например, если это широты и долготы точек на плоской модели земной поверхности карте, то их измеряют градусами и десятичными дробями градусов. Локально же, на маленькой территории от фиксированной нулевой точки, возможно применение Декартовой системы координат, в связи с чем она и называется локальной системой координат, в которой полагается, что Земля на этой территории плоская. Поскольку такая система через несколько сот километров из-за неучтенного искривления поверхности планеты будет давать большую погрешность, то в QGIS предусмотрена возможность применения для разных слоев разных систем координат с последующей конвертацией их из одного типа в другой. Для этого слой сохраняется в shape файл или в БД, и в качестве параметра выбирается новая система. Но при выводе проекта на экран все слои приводят в единую координатную плоскость 57. Если информация о типе системы координат отсутствует, тогда будет необходимо открыть таблицу объектов этого слоя, выделить любую строку и нажать кнопку перехода к объекту. В случае отображения на экране неправильной карты делаем вывод, что QGIS не распознал систему координат. Для этого необходимо уточнить информацию о системе координат, в которых хранятся данные, и установить ее для этого слоя в QGIS. Порой приходится самим создавать нужную систему или так называемую пользовательскую систему координат, если таковая отсутствует. С этой целью используется запрос с наименованием искомой системы плюс, например, система координат QGIS пользователя в Google. Если слои реестра землепользователей сдвигаются относительно снимков, снятых со спутника, то это озадачивает и не позволяет оценить контуры территории. Подобный казус наблюдается в случае добавления слоя реестра землепользователей массовой доступности в QGIS совместно со снимками Yandex, Google. Для исправления нюанса рекомендуется подобрать параметры для слоев карты экспериментально и создать собственную систему координат. Таким образом проблема будет решена. Резюмируя изложенное, можно предположить следующие перспективы использования формата ГИС карты при анализе рынка труда и трудоустройства выпускников вузов ГИС карта рынка работодателей является удобным инструментом содействия трудоустройству выпускников вузов для повышения эффективности ГИС карты возможна разработка клиентского приложения для мобильных устройств рекомендуется создание единого информационного пространства для рынка работодателей рекомендуется обеспечить автоматизацию пополнения БД появляющихся рабочих мест из доступных источников ГИС технологии рекомендованы для использования при трудоустройстве выпускников вузов на всех закрепленных территориях региона. "}
{"title": "КОД «ВИРТУАЛЬНЫЙ ПЛАНЕТАРИЙ»   ДЛЯ МОДЕЛИРОВАНИЯ АСТРОФИЗИЧЕСКИХ ОБЪЕКТОВ:   МАТЕМАТИЧЕСКАЯ МОДЕЛЬ, МЕТОДОЛОГИЯ И ПЕРВЫЕ РЕЗУЛЬТАТЫ  ", "absract": " Сложность астрофизических процессов заключается в совместном рассмотрении компонент различной природы. Так, например, в задаче столкновения галактик рассматривается трехмерная динамика межзвездного газа и звездной компоненты. В основе моделирования этих компонент могут лежать совершенно разные классы численных методов. Одним из возможных решений этой проблемы является использование эйлероволагранжева подхода, в котором физические величины сосредоточены в материальных точках, что характерно для метода SPH (Smoothed Particle Hydrodynamics), а расчет сил производится на адаптивной сетке, привязанной к системе материальных точек. Такой подход единообразно учитывает динамику как сплошной среды, так и дискретных частиц, а также позволяет устранить ряд недостатков, присущих оригинальному методу. Расчет гравитационного взаимодействия осуществляется путем решения уравнения Пуассона для гравитационного потенциала. При этом все частицы проецируются на расчетную сетку, и уже по ней вычисляются значения потенциала в каждой ячейке. Решение уравнения Пуассона для гравитационного потенциала выполняется с использованием быстрого преобразования Фурье. В статье описан новый код «Виртуальный планетарий» для моделирования астрофизических объектов на основе метода SPH, дополненного методом Годунова для вычисления потоков давления и импульса между частицами и методом быстрого преобразования Фурье для решения уравнения Пуассона для гравитационного потенциала. В работе описано обоснование для перехода  к такой вычислительной модели, детально описаны кинетические и гидродинамические подходы. Выполнено моделирование коллапса изотермического газового облака, показана возможность метода воспроизводить развитие неустойчивостей в виде образования двух рукавов плотности. ", "text": " Современная теоретическая астрофизика практически исчерпала возможности аналитических и полуаналитических решений, которые можно получить при допущениях простран ственной симметрии или рассматриваемых процессов. В настоящее время основным инструментом теоретической астрофизики стал вычислительный эксперимент. Сложность астрофизических процессов заключается в совместном рассмотрении компонент различной природы. Так, например, в задаче столкновения галактик рассматривается трехмерная динамика межзвездного газа и звездной компоненты 1. Для описания такого процесса требуется разрешение уравнений гидродинамики для описания движения газа и решение кинетического уравнения для записи движения звезд. В основе методов решения лежат совершенно разные классы численных методов. Один из трендов для разрешения подобных проблем заключается в использовании лагранжево-эйлеровых методов Arbitrary Lagrangian-Eulerian ALE в зарубежной литературе, которые одновременно подходят как для решения уравнений гидродинамики, так и для описания движения частиц. Хотя следует отметить, что существуют работы по модификации математических моделей для описания различных компонент единым классом гиперболических уравнений 2. Мы остановимся на развитии лагранжевоэйлерового подхода. В последнее десятилетие в области вычислительной астрофизики было создано несколько кодов, успешно и в то же время различным образом реализующих лагранжево-эйлеровый подход. Среди них коды AREPO 3, BETHE-HYDRO 4, GIZMO 5. Так или иначе, все коды основаны на представлении решения в виде набора материальных точек с размещенными в них физическими характеристиками, что характерно для метода сглаженных частиц 6 Smooth Particles Hydrodynamics SPH в зарубежной литературе. Далее используются различные механизмы способа взаимодействия с соседними точками, в частности способ построения сеток. Остановимся на описании каждого из кодов чуть подробнее. В основе кода AREPO лежит технология подвижных сеток на основе триангуляции Вороного и Делоне c регуляризацией Ллойда. Такой подход позволяет адаптировать сетку под решение. В качестве основного метода решения уравнений гидродинамики используется классический метод Годунова. Это связано с тем, что достаточно тяжело построить схему более высокого порядка на подвижной сетке. Для решения уравнения Пуассона используется подход на основе записи уравнения для полной механической энергии в уравнение для суммы всех видов энергии внутренняя, кинетическая и потенциальная. Такое уравнение для полной энергии имеет в правой части производную по времени от потенциала и его градиента, что вычисляется с помощью интеграла Пуассона методами типа частица сетка. Для интегрирования по времени используется индивидуальный шаг по времени для различных ячеек. При всех достоинствах такого подхода он достаточно тяжелый в плане вычислительных затрат, а также остается открытым вопрос о качестве решения в областях, описываемых менее подробными сеточными ячейками. Однако код AREPO является одним из наиболее используемых в мире в данный момент. В основе кода BETHE-HYDRO лежит ALE-подход, сочетающий достоинства как эйлерова так и лагранжева подходов. Уравнения гидродинамики формулируются в лагранжевой неконсервативной форме и решаются на неструктурированной сетке. В основе численного метода операторный подход, который позволяет построить согласованные схемы для аппроксимации операторов градиент и дивергенция. Для решения уравнения Пуассона в одномерной постановке используется метод прогонки или метод Томаса в зарубежной литературе. В двумерной постановке уравнение Пуассона решается с помощью метода сопряженных градиентов. Далее происходит коррекция потенциала для сохранения полной энергии сумма кинетической, внутренней и потенциальной энергий системы. Отметим, что сохранить полную энергию системы все равно не удается, но ошибка на задаче коллапса составляет порядка 10 процента, что очень незначительно. К сожалению, код не был развит для трехмерного случая. В программном коде GIZMO разработан и реализован новый бессеточный подход к решению уравнений гравитационной газовой динамики. Подход основан на комбинации классических сеточных методов и метода SPH. Метод состоит в использовании уравнений газовой динамики в эйлеровых координатах, которые с использованием вариационного принципа Галеркина умножаются на пробные функции. Особенностью этих функций является то, что они привязаны не к расчетной сетке, а к отдельным частицам, аналогичным по своей природе SPH частицам. Для определения значений на границах области используется решение задачи Римана с использованием метода Годунова. Анализ этих кодов показывает, что основной вычислительной проблемой является построение сетки или ее аналога для описания взаимодействия между частицами. При этом во всех методах сохранена идеология кинетического подхода на основе описания движения материальных точек. В этой концепции разработана вычислительная модель, описанная и в данной статье. Для организации вычислений мы будем использовать равномерную кубическую сетку, в которой будет помещаться облако частиц. Такой подход позволяет достаточно просто организовать эйлеров этап вычислений. Описание вычислительной модели мы разобьем на две части. Сначала опишем динамику частиц на основе сил гравитации. Эта модель соответствует газу с нулевым давлением pressureless hydrodynamics в зарубежной литературе. Затем добавим силы давления при использовании адиабатического уравнения состояния. Запишем уравнения гравитационной гидродинамики с нулевым давлением в виде законов сохранения массы и момента импульса в эйлеровых координатах 0, 1, 2 дополненные уравнением Пуассона для гравитационного потенциала 4, где плотность, вектор скорости, гравитационный потенциал, гравитационная постоянная. Будем рассматривать динамику материальной точки частицы с произвольным номером . Закон сохранения массы частицы получается естественным образом при интегрировании уравнения 1 в малой окрестности точки, в которую не попадают другие частицы. Второй закон Ньютона для частицы с номером запишем, используя уравнение 2 в лагранжевой постановке . 3 В уравнении 3 необходимо сократить функцию плотности, которая в малой окрестности точки отлична от нуля. В результате получим уравнения для движения частиц, . 4 Для решения уравнений 4 нам необходимо вычислить градиент потенциала. Для этого введем равномерную кубическую эйлерову сетку с шагом по каждому направлению, и каждую частицу спроецируем на соответствующую ячейку. Другими словами, каждая частица будет давать вклад в массу соответствующей ячейки, . Таким образом, в каждой ячейке мы можем вычислить плотность по формуле, 5 где это масса частицы, попадающей в ячейку, . Зная плотность в каждой ячейке расчетной области, с помощью метода, основанного на использовании быстрого преобразования Фурье, мы можем найти гравитационный потенциал. Для этого необходимо с помощью прямого преобразования Фурье перейти от функции плотности к ее амплитудам в пространстве гармоник, затем перейти к амплитудам гармоник потенциала c помощью формулы 2 3 2sin 2sin 2sin 1 1 1 1 3 3, 3 6 где, размер расчетной сетки по каждому из направлений в настоящей статье эти величины принимаются равными, так как используется равномерная кубическая сетка. Затем с помощью обратного преобразования Фурье из амплитуд гармоник потенциала восстанавливаются значения функции потенциала в соответствующих ячейках . Исследование и описание метода решения уравнения Пуассона подробно описано в работах 7 8. Так как функция гравитационного потенциала суть гладкая функция, то для нахождения градиента потенциала мы будем использовать центральные разности, 2 2 . 2 Для разрешения уравнений 4 для частицы на временном шаге мы будем использовать двухслойную схему с перешагиванием, где скорости вычисляются по формуле, 2, 2, 2 7 а координаты с использованием формулы, . 8 Такая схема соответствует эйлерово-лагранжеву подходу, использованному коллективом авторов ранее 2 7 8. Важным условием устойчивости численной схемы является выбор шага по времени. Для этого будем использовать условие Куранта для введенной сетки, max 9 где 1 число Куранта Фридрихса Леви. При использовании гидродинамической модели вычислительная процедура осложняется введением новой силы давления. Основная сложность заключается в том, что функция давления в общем случае разрывная функция, и для определения его градиента необходимо использовать решение задачи о распаде разрыва. Последовательно опишем изменения в вычислительной модели. Уравнения гравитационной гидродинамики в виде законов сохранения массы и момента импульса в эйлеровых координатах записываются в виде 0, 10 . 11 Уравнения 10, 11 дополнены уравнением Пуассона для гравитационного потенциала 3 4, где плотность, вектор скорости, давление, гравитационный потенциал, гравитационная постоянная. Уравнения замкнуты уравнением состояния для адиабатического газа, где показатель адиабаты, значение энтропии. Выше было описано, как получить плотность газа в ячейке и восстановить гравитационный потенциал. Опустив очевидные выкладки, уравнения 4 перепишем в виде, . 12 Для разрешения уравнений 12 для частицы на временном шаге мы будем использовать двухслойную схему с перешагиванием, где, сохранив способ пересчета координат 8, изменим формулу для определения скорости 7, которая записывается в виде, 2, 2, 2 13 где величины поток давления, получаемый в результате решения задачи о распаде разрыва для эйлерова этапа численного метода. Для аппроксимации потока рассмотрим комбинацию правой и левой расчетных ячеек, получим 7 . 2 2 14 В случае адиабатического уравнения состояния в этом случае величина энтропии суть постоянная величина для всех материальных точек, уравнение 14 записывается в виде . 2 2 В случае изотермического уравнения состояния суть энтропии температура, показатель адиабаты 1 уравнение 14 записывается в еще более простой форме . 2 2 Перепишем уравнения 13 для изотермического газа 2, 2 2, 2 2 . 2 15 Как уже говорилось ранее, формула пересчета координат 8 осталась без изменений. Важным моментом в формуле 15 является проекция скоростей материальных точек в ячейку. Для этого мы будем использовать весовую функцию по массе точек, 16 где и это масса и соответствующие компоненты скорости всех частиц, попадающих в ячейку, . Далее перейдем к основным этапам реализации программного кода. В этом разделе приведем описание алгоритма, приведя все расчетные формулы для каждого этапа. Не снижая общности, мы остановимся на случае периодических граничных условий и изотермическом процессе. Также будем считать, что трехмерное преобразование Фурье уже реализовано в библиотеке например, в работе 9 в виде процедуры FFT3D. 1. Определим значения размер расчетной области, размер расчетной сетки, количество материальных точек, температура газа, шаг по пространству, определим число Куранта, масса каждой частицы. Моделировать динамику газа будем до момента времени . 2. Для всех частиц определим координаты и вектор скорости . 3. Обнулим время динамики системы 0. 4. Если переходим к шагу 5, в противном случае процесс моделирования заканчиваем. 5. Для каждой ячейки, определяем ее плотность по формуле 5. 6. В случае использования гидродинамической модели нам необходима сеточная функция скорости. Для этого в каждой ячейке, определяем компоненты скорости по формулам 16. 7. Определяем шаг по времени из условия 9. . max 8. Прибавляем к текущему времени временной шаг . 9. Делаем прямое преобразование Фурье для функции плотности 3 . 10. Решаем уравнение Пуассона в пространстве гармоник по формуле 6. 11. Делаем обратное преобразование Фурье для гармоник потенциала 3 . 12. Для каждой частицы пересчитываем ее скорость по формуле 15. 13. Для каждой частицы пересчитываем ее координату с использованием формулы 8 и полученных скоростей. 14. Переходим на шаг 4. Как уже было сказано, при использовании кинетической модели шаг 6 пропускается. Далее мы обсудим дискуссионные вопросы по вычислительной модели и перспективы развития модели для более сложных случаев. Опишем дискуссионные моменты, связанные с построенной вычислительной моделью и программной реализацией. Эти моменты пока не включены в код, однако могут быть использованы в развитии кода. 1. Во введении было сказано об использовании только равномерной кубической сетки. Это сделано только для упрощения описания вычислительной модели и ее использования для нужд новосибирского планетария. Конечно, использование материальных точек позволяет нам достаточно простым и естественным образом вводить адаптивные сетки, используя соответствующие численные методы для восстановления гравитационного потенциала. В дальнейшем мы планируем развить наш подход в этом направлении. 2. Мы использовали адиабатическое и изотермическое уравнения состояния, которые зависят только от функции плотности. Для проекции частиц на эйлерову сетку для определения плотности достаточно использовать закон сохранения масс. Однако для описания идеального газа необходимо использовать термодинамическую переменную энтропию, и способ проекции, аналогичный проекции скоростей материальных точек на ячейку. 3. Для нахождения потока давления через границу использовалась схема первого порядка точности из работы 7. Использование равномерной сетки позволяет достаточно просто повысить порядок точности схемы, например, как это было сделано в работе 8. 4. Также в статье была использована простейшая проекция материальных точек на расчетную сетку. Для устранения вычислительных шумов необходимо использовать ядра сглаживания, аналогичные методам SPH и методам типа частиц-в-ячейках. В дальнейшем при необходимости вопрос выбора ядра будет рассмотрен отдельно. 5. Формулы пересчета скоростей и координат материальных точек 7, 8 и 15 явно записываются в векторной форме, что делает логичным использование векторных SSE расширений, встроенных в процессоры Intel и AMD современных персональных компьютеров, для которых и рассчитан программный код из этой статьи. Также большинство персональных компьютеров оснащено графическими ускорителями NVIDIA, для которых в рамках технологии CUDA созданы специальные библиотеки для расчета быстрого преобразования Фурье например, cuFFT. В качестве модельной задачи будем рассматривать коллапс изотермического облака в безразмерных переменных. Для этого в кубической области размером 3,2 введем вспомогательную расчетную сетку 128 . В начальный момент времени в сфере единичного радиуса равномерно распределим частицы единичной суммарной массы с модельной температурой 0,1 и кеплеровской скоростью вращения. В нашей модельной задаче мы бу дем исследовать поведение ансамбля частиц газа при различных значениях дисперсии скоростей . Проблема исследования фрагментации вращающегося холодного облака особенно интересна в контексте эволюции эллиптических галактик 10. Анализ результатов моделирования при различных показывает см. рисунок, что при увеличении дисперсии скоростей до 0,5 для одинакового начального распределения плотности имеет место развитие неустойчивостей виде двух рукавов плотности. В рамках настоящей статьи мы не планируем проводить анализ развития неустойчивостей, подобных описанным в работе 8. Основной результат вычислительных экспериментов это возможность воспроизведения подобных возмущений разработанной вычислительной моделью. В дальнейшем мы более подробно рассмотрим развитие неустойчивостей в системе многих тел в контексте моделирования планетных систем и галактик 11. В статье приведено описание нового кода Виртуальный планетарий для моделирования астрофизических объектов. Код основан на эйлерово-лагранжевой комбинации метода сглаженных частиц и метода Годунова. В работе описано обоснование для перехода к такой вычислительной модели. С помощью разработанного кода смоделирован коллапс вращающегося газового облака. "}
{"title": "РАЗРАБОТКА СРЕДЫ ПРОГРАММИРОВАНИЯ ДЛЯ МОБИЛЬНЫХ УСТРОЙСТВ   ПОД УПРАВЛЕНИЕМ ОПЕРАЦИОННОЙ СИСТЕМЫ ANDROID  ", "absract": "Мобильные устройства часто используются для образовательных целей в связи с их высокой доступностью  и портативностью. Однако образовательные возможности мобильных устройств ограничены из-за отсутствия качественных IDE. Большинство сред разработки языка C++ для Android не имеют автодополнения и анализа кода, а остальные предоставляют эти возможности с крайне низкой производительностью. В этой работе мы описываем технологию переноса программного обеспечения, примененную к компилятору Clang (и другим необходимым инструментам), и предлагаем метод ускорения компиляции, автодополнения и анализа кода  в нашей IDE. Наряду с этим мы предлагаем методы оптимизации пользовательского интерфейса. В работе описан основанный на регулярных выражениях эвристический метод для генерации предкомпилированных заголовков, который имеет низкие требования к процессору и ОЗУ. Эффективность метода проверена на различных образовательных примерах. ", "text": " Развитие мобильных устройств приводит к значительному расширению числа областей, в которых они могут использоваться. Одной из таких новых областей является мобильное образование. В магазинах приложений популярных мобильных операционных систем появились приложения, обучающие языкам, точным и гуманитарным наукам 1. Присутствуют в магазинах и приложения, обучающие различным языкам программирования. Растущая производительность мобильных устройств позволила перенести на них и среды разработки языков программирования. В частности, существуют такие приложения, как Pydroid, интегрированная среда разработки языка Python, или C4droid, среда разработки языка C. Данные приложения позволяют обучающимся избежать необходимости брать с собой на место учебы ноутбуки или же и вовсе заменяют персональный компьютер, что наиболее важно в странах, где учащиеся зачастую могут позволить себе смартфон, но не могут приобрести ноутбук. Существуют и случаи замены персональных компьютеров в терминальных классах на планшеты под управлением операционной системы Android с установленной мобильной средой разработки . Как правило, под интегрированной средой разработки понимают программный продукт, обладающий следующими возможностями редактирование текста компиляция или интерпретация исходного кода подсветка синтаксиса автоматическое дополнение кода проверка ошибок во время редактирования установка и подключение сторонних программных библиотек. Некоторые из данных возможностей требовательны к ресурсам процессора. В случае языка C для автоматического дополнения кода и проверки ошибок в реальном времени требуется произвести большую часть шагов, обычно выполняемых при компиляции кода, за исключением связывания и трансляции программы в язык ассемблера. Подходы, используемые в средах программирования, предназначенных для рабочих станций, зачастую неприменимы на мобильных устройствах, поскольку в силу меньшей производительности последних не обеспечивают комфортной работы в режиме реального времени. Существуют и особенности, связанные с размером экранов мобильных устройств многим интегрированным средам разработки для обычных компьютеров свойственно наличие большого числа пунктов меню и кнопок, которые невозможно разместить в мобильном приложении 2. Операционная система Android использует свою стандартную библиотеку языка Си, Bionic. По этой причине пользователи не могут работать со статическими или динамическиим библиотеками, загруженными с их официальных сайтов количество библиотек, собранных для Bionic, очень мало, большинство библиотек собраны для библиотек языка Си популярных дистрибутивов Linux или операционной системы Windows. Единственным оставшимся путем является самостоятельная сборка библиотек из исходного кода, что затруднительно для целевой аудитории программ такого рода студентов и школьников. Целью данной работы является разработка мобильной среды программирования языка C, обладающей средствами автодополнения кода и проверки ошибок в режиме реального времени, а также удобным для мобильного устройства интерфейсом и возможностью легкой установки популярных библиотек. В работе описывается процесс переноса необходимых программных библиотек и программ на платформу Android, описан процесс сборки библиотек для программ конечного пользователя, а также рассмотрены методы оптимизации пользовательского интерфейса. Наряду с этим анализируются существующие подходы для ускорения автодополнения и анализа кода, а также описывается новый алгоритм, разработанный в рамках данной работы. Также приводится сравнение производительности разработанной среды программирования со всеми популярными конкурентами. Типичным для программирования является следующий набор программных инструментов командный интерпретатор компилятор набор утилит для работы с исполняемыми файлами система автоматизации сборки программ из исходного кода. В качестве командного интерпретатора был выбран проект BusyBox, поскольку он обладает небольшими требованиями к производительности, а также позволяет встроить базовый набор утилит командной строки, которые могут присутствовать не на всех версиях операционной системы Android, решая проблему совместимости. В качестве компилятора был выбран проект ClangLLVM, поскольку он предоставляет наиболее широкие возможности по анализу и автодополнению кода, а также обладает удобной лицензией. Для работы с исполняемыми файлами был выбран проект GNU Binutils, поскольку он является самым популярным и стабильным проектом такого рода. В первую очередь данный проект обеспечивает связывание объектных файлов в исполняемый файл при помощи лин кера. Системой сборки, используемой для проектов, состоящих из нескольких файлов, была выбрана пара CMake и GNU Make. CMake легче в освоении для начинающих пользователей и позиционируется как более дружественный к кросс-компиляции, что обеспечивает возможность работы с одним и тем же проектом и на ПК, и на мобильном устройстве. Однако CMake не осуществляет непосредственную сборку, а только генерирует промежуточные файлы для других систем, поэтому возникла необходимость перенести и программу GNU Make. Последний, в свою очередь, может пригодиться и более опытным пользователям программы, предпочитающим эту систему сборки. Кросс-компиляция процесс сборки исходного кода на одной платформе для исполнения на другой. Для операционной системы Android официально рекомендуется использование программного инструментария Android NDK, позволяющего собирать код для мобильных устройств с использованием персонального компьютера 3. На практике список поддерживаемых Android NDK по умолчанию систем сборки невелик поддерживаются Soong, Android.mk и CMake. Первые две системы сборки эксклюзивны для операционной системы Android, поэтому мало полезны для переноса программного обеспечения, написанного для других платформ. CMake более применимая в этом отношении система сборки, однако в случае использования ее с Android NDK возникают некоторые нюансы, например необходимость ручного редактирования файлов конфигурации. Поскольку необходимое для проекта программное обеспечение использует различные системы сборки, не поддерживаемые Android NDK, было решено собрать более традиционный набор инструментов для кросс-компиляции, совместимый с системами сборки GNU Make и GNU Autotools 4. Для этого был использован сценарий командной строки make-standalone-toolchain.sh, доступный в комплекте поставки Android NDK. При сборке инструментов были выбраны библиотека языка C LLVM libc и компилятор Clang. Данный выбор параметров обусловлен тем, что позволяет переиспользовать собранные на рабочей станции библиотеки непосредственно в мобильной среде разработки. Поскольку библиотека языка Си, библиотека языка C и компилятор совпадают, была обеспечена полная двоичная совместимость между библиотеками и заголовками кросс-ком пилятора и целевой системы. Таким образом, при помощи этой же системы сборки можно собирать и образовательные библиотеки, предназначенные для использования непосредственно в пользовательских программах. Полный список необходимых для воспроизведения результатов параметров различных систем сборки приведен в табл. 1, значением перемен ной окружения PREFIX является полное имя целевой платформы например, arm-linuxandroideabi для устройства с ARM процессором и ОС Android. Параметры, использованные для различных систем сборки Parameters Used for Different Build Systems Система сборки Имя переменной параметра Значение GNU Make CC PREFIX-clang CXX PREFIX-clang GNU Autotools --host PREFIX --target PREFIX CMake CMAKESYSTEMNAME Android CMAKECCOMPILER PREFIX-clang CMAKECXXCOMPILER PREFIX-clang К сожалению, на практике стандарты языков программирования не всегда соответствуют тому, что ожидают увидеть пользователи. В разных средах программирования на различных операционных системах могут присутствовать некоторые уникальные функции, не описанные в стандартах. Хорошими примерами таких функций являются Windows API, доступный на операционной системе Windows, или iostream.h заголовочный файл Borland C, использовавшийся во времена, когда язык программирования C еще не был стандартизован. Был проведен анализ отрицательных отзывов у приложений-конкурентов, доступных в Google Play, в результате чего был выделен следующий список возможностей, критичных для достаточно большого числа пользователей. Команды systemcls и systempause. Данные команды операционной системы Windows используются для того, чтобы очистить экран или ожидать нажатия клавиши. Несмотря на то, что существуют более удачные способы осуществления данных операций, было решено написать свою реализацию этих команд, исполняемые файлы cls и pause были собраны при помощи кросс-компилятора, пути к ним добавлены в переменную окружения PATH. Заголовочный файл conio.h. Данный заголовочный файл использовался в операционной системе MS-DOS для создания текстового интерфейса пользователя. Было решено реализовать наиболее популярные функции этого заголовочного файла с использованием управляющих последовательностей ANSI традиционного в Linux способа организации текстового интерфейса. Команда fflushstdin. Данная команда, по мнению пользователей, должна очищать буфер стандартного потока ввода, однако стандарт не гарантирует данное поведение функция fflush определена только для потоков вывода. Изучение исходного кода библиотеки языка Си Android показало, что на этой операционной системе fflush потоков ввода ничего не делает. Более ожидаемое поведение было реализовано при помощи вызова fpurge, реализация была добавлена в статическую библиотеку libandroidsupport, включаемую в каждую программу пользователя. Функция названа fflushcompat, а в заголовочный файл stdio.h добавлено переопределение всех вызовов fflush на fflushcompat. Это решение позволяет сохранить полную совместимость с библиотеками, которые ожидали вызов оригинальной функции fflush. В ходе разработки было уделено отдельное внимание удобству интерфейса. Под удобством понималось соответствие ожидаемого поведения программы действительному, а также общая скорость выполнения различных операций пользователем. Исследование проводилось в два этапа. На первом этапе была выбрана небольшая группа пользователей для качественного исследования наиболее часто используемых функций путем опроса, согласно 5. Выделен следующий список наиболее часто используемых функций ввод особых символов, специфичных для программирования, однако недоступных без дополнительных действий на большинстве программных клавиатур общего назначения автоматическая компиляция и запуск программы по нажатию на одну кнопку автодополнение кода проверка кода в реальном времени установка библиотек форматирование кода. Далее был спроектирован интерфейс программы наиболее часто используемые функции были размещены в зоне быстрого доступа в соответствии с исследованием 6, а функции, к которым обращаются реже, перенесены в зоны с меньшей доступностью. Прототип был представлен крупной группе потенциальных пользователей программы для количественной оценки качества спроектированного прототипа. В ходе оценки качества выявлено, что часть функций не пользуется ожидаемой популярностью, поэтому эти функции были перенесены в зону меньшей доступности, а на их место перенесены функции, оказавшиеся более популярными. Кроме того, было подтверждено соответствие функций элементов интерфейса их иконкам по результатам измерений, пользователи без труда находили запрашиваемое действие среди предложенных иконок. После выпуска первой версии продукта для принятия решений стал использоваться способ АБ тестирования. Части случайно выбранных пользователей в количестве 30, установивших приложение из Google Play Store, предоставлялся доступ к А-версии продукта версии с некоторыми изменениями, которые нужно было проверить, а другой части доступ к Б-версии первоначальной версии, выступающей в качестве эталона. По прошествии двух недель измерялись ключевые показатели качества продукта вовлеченность пользователей частота совершения определенных действий в приложении среднее время нахождения в приложении количество пользователей, запустивших приложение хотя бы раз на второй и седьмой дни эксперимента. При помощи данного тестирования удалось определить оптимальный порядок и состав пунктов меню приложения в частности, расположение кнопки запуска в строке заголовка приводило к снижению вовлеченности пользователей, в то время как расположение кнопки ближе к правому нижнему углу оказалось предпочтительным, хотя на первый взгляд приводит к уменьшению рабочего пространства редактора. Снимки экрана двух вариантов, использованных в эксперименте с расположением кнопки запуска, представлены на рис. 1. Традиционный процесс автодополнения и проверки кода требует полной обработки исходного текста с самого начала каждый раз, когда вызывается автодополнение или проверка. Так работают некоторые настольные среды разработки, поскольку даже средний персональный компьютер имеет достаточную производительность, для того чтобы выполнять эти задачи в режиме реального времени. Большинство программ на языке C используют различные заголовочные файлы, которые включаются в программу с использованием специальной директивы компилятора, include. Эти заголовочные файлы часто достаточно велики, чтобы занимать большую часть времени компиляции, более того, существуют библиотеки, состоящие только из заголовочных файлов, которые полностью компилируются каждый раз, когда пользователь компилирует основную программу. Этот процесс может быть оптимизирован с использованием предкомпилированных заголовков, специальных файлов, которые содержат закэшированное состояние компилятора после обработки некоторого списка заголовочных файлов 7. Большинство сред разработки, однако, требует ручного создания данных файлов значимым примером является файл stdafx.h, используемый Microsoft Visual Studio, что может быть затруднительно для пользователя мобильного устройства, поскольку ему придется редактировать несколько файлов и переключаться между ними каждый раз, когда он захочет добавить в программу очередной заголовочный файл. Поэтому возникла необходимость реализации алгоритма, который сочетал бы в себе удобство традиционного медленного подхода и скорость подхода, использующего предкомпилированные заголовки. После автоматического анализа исходного кода многих популярных C проектов с открытым исходным кодом и ручной проверки выводов на простых учебных программах мы пришли к следующим выводам программы могут иметь информацию о лицензии и авторе, расположенную в комментарии в самом начале исходного текста директивы define используются для констант и макросов реже, они также часто появляются в начале программы директивы include обычно располагаются до объявленных пользователем функций, неподалеку от макросов и констант но не всегда. На основании анализа истории изменений проектов с открытым исходным кодом было установлено, что упомянутые части меняются достаточно редко в сравнении с остальным кодом. Из этого можно сделать вывод, что данные части программы являются хорошими кандидатами на включение в кэш компилятора. Было решено встроить технологию оптимизации в процесс проверки исходного кода мы можем безопасно генерировать предкомпилированные заголовки, только если текущая программа является корректным исходным кодом C. Если проверка исходного кода не находит ошибок, мы создаем новый текст предкомпилированного заголовка с использованием регулярных выражений, и тогда, только если закэшированного заголовка с таким текстом не существует, мы собираем его в фоновом потоке. Если сгенерированный текст предкомпилированного заголовка совпадает с одним из существующих файлов кэша, автодополнение кода и проверка ошибок выполняются в ускоренном режиме с заменой текста на включение единственного закэшированного заголовочного файла. Схема алгоритма представлена на рис. 2. Для генерации кэшируемого текста было решено использовать наиболее простое возможное регулярное выражение, поскольку это часто выполняемая операция 8. В результате в кэшируемый текст были включены следующие части однострочный и многострочный комментарии любая директива компилятора, начинающаяся с символа пустые строки. Существует, однако, важное замечание алгоритм также проверяет, что количество включенных в заголовок директив if и ifdef равно количеству endif. Хотя данные конструкции сравнительно нечасто используются в коде образовательных программ особенно в опасной для алгоритма форме, по разные стороны от пользовательских объявлений переменных и функций, их игнорирование приводит к ошибке компиляции, что недопустимо для надежного алгоритма. Чтобы оценить производительность алгоритма, было решено сравнить производительность автодополнения кода с наиболее популярными приложениями-конкурентами, доступными в магазине приложений Google Play Cppdroid и C4droid. Производительность проверки кода не замерялась, поскольку реализована только в приложении Cppdroid, в котором, в свою очередь, был дополнительно доступен статический анализатор, что могло повлиять на достоверность результатов. Для замеров использован набор исходных текстов образовательных программ, разбитый на несколько категорий 1 примеры языка Си 2 примеры языка C, базовое использование стандартной библиотеки шаблонов STL, разрешен только заголовок iostream 3 примеры языка C, обычное использование STL, разрешены заголовок iostream и контейнеры например, vector и map 4 примеры языка C, расширенное использование STL, разрешено вс, включая последние стандарты 5 примеры языка C с использованием библиотеки Boost. Для замера времени выполнения операции автодополнения был выбран метод записи экрана и последующего перевода числа кадров во время, поскольку этот метод позволяет непосредственно оценить отзывчивость программы, а также избегает необходимости в обратной разработке программ, что может быть запрещено их лицензионным соглашением. Устройством для произведения замеров был выбран планшетный компьютер Google Nexus 7 2013, поскольку его невысокая производительность позволяет оценить снизу скорость работы программы на реальных устройствах, а также понижает относительную погрешность измерений за счет больших временных интервалов. В результате проведения серий экспериментов, были получены результаты, представленные в табл. 2. Отношение производительности работы к усредненному конкуренту 0,59 4,52 3,53 5,76 34,54 В результате выполнения работы на платформу Android были успешно перенесены инструменты Clang, GNU Binutils, BusyBox, их зависимости, а также набор популярных библиотек, таких как Boost, GMP, libcurl. Был разработан оптимизированный для мобильных устройств интерфейс. Возможности по анализу и автодополнению кода были реализованы при помощи Clang. Создан алгоритм ускорения упомянутых возможностей, проверена его производительность и корректность. Все данные компоненты объединены в мобильную среду разработки языка C. Эксперименты показали, что разработанная среда программирования является единственной, обеспечивающей работу автодополнения и анализа кода в режиме реального времени в любых сценариях использования. Прирост производительности в среднем составил 300, когда используется стандартная библиотека шаблонов языка C, достигая 3 350, когда используется библиотека Boost. Присутствует небольшая потеря производительности при использовании языка Си, однако она незначительна в абсолютной величине и не влияет на возможность использования продукта в реальном времени. "}
{"title": "РАЗРАБОТКА ПРОГРАММНЫХ СРЕДСТВ ПРОЗРАЧНОГО УДАЛЕННОГО ДОСТУПА   К ТЕХНОЛОГИЧЕСКИМ ПАРАМЕТРАМ БУРЕНИЯ И ДАННЫМ СКВАЖИННОЙ   ТЕЛЕМЕТРИЧЕСКОЙ СИСТЕМЫ В УСЛОВИЯХ НЕСТАБИЛЬНОЙ СВЯЗИ  ", "absract": "В процессе бурения нефтегазовых скважин требуется оказание удаленной поддержки с использованием существующих каналов связи с офисом, заключающейся в контроле параметров и принятии неотложных решений. Наиболее распространена спутниковая и мобильная связь, для которой характерна низкая скорость приема  и передачи данных, частые разрывы, использование NAT. В рамках данной работы разработано программное средство прозрачного доступа к параметрам бурения и данным скважинной телеметрической системы с целью организации удаленного сопровождения по существующим каналам связи с учетом их ограничений.  В основу программного средства легла реализация протокола SSH, что обеспечило сжатие и шифрование передаваемых данных и прозрачный доступ к TCP-сервисам на буровой. Благодаря этому возможно использование существующего ПО для доступа к данным телеметрической системы, что позволяет снизить объем передаваемых данных в сравнении с ПО удаленных рабочих столов. Программное средство прошло апробацию в условиях, близких к полевым, и показало свою пригодность  к решению поставленных задач. ", "text": ", При бурении нефтегазовых скважин возникают нештатные ситуации, требующие принятия неотложных решений. Промедление с разрешением таких ситуаций может привести к тяжелым последствиям для персонала, оборудования, ствола скважины, к трате ресурсов на устранение этих последствий. Для контроля параметров бурения и принятия неотложных решений привлекаются высококвалифицированные специалисты 1 2, чаще работающие в офисе и занимающиеся надзором над бурением сразу нескольких скважин. Выезд специалистов на буровые площадки нежелателен с экономической точки зрения и происходит только в экстренных случаях. Существует типичный набор средств, применяемых для решения задачи удаленного сопровождения бурения, но специалисты, работающие с ними, сталкиваются с ограничениями, связанными с особенностями каналов связи офиса и буровых, организацией вычислительных сетей предприятия, вопросами информационной безопасности, простотой применения данных средств. Например, при использовании спутникового канала связи ПО удаленного рабочего стола может в сжатые сроки истратить значительную часть отведенного на месяц работы трафика буровой. Использование мобильной связи накладывает ограничения на использование ПО, требующего прямого подключения к ПК буровой, изза механизма преобразования сетевых адресов. В рамках работы была поставлена задача разработать программное средство прозрачного удаленного доступа к технологическим параметрам бурения и данным скважинной телеметрической системы в условиях нестабильной связи с целью сопровождения бурения и оказания помощи инженерам наклонно направленного бурения. Задача была разбита на этапы 1 определить основных организаторов и участников процесса удаленного сопровождения бурения и их роли выделить функциональные требования к программному средству основываясь на характеристиках каналов связи офиса и буровой, на предпочтениях участников процесса, определить нефункциональные требования 2 провести анализ технических средств, пригодных для удовлетворения поставленных требований и выбрать из них наиболее подходящие для реализации программного средства 3 спроектировать программное средство, основанное на выбранном наборе технических средств понять, каким образом пользователи будут с ним взаимодействовать, на какие функциональные блоки оно будет декомпозировано, проработать сценарии внедрения и поддержки 4 определить методику тестирования и наладки, подобрать необходимые инструменты 5 реализовать программное средство 6 провести тестирование и отладку, сделать замеры использования сетевых ресурсов, времени безотказной работы, проверить пригодность разработанного средства для решения поставленных задач 7 апробировать разработанное программное средство для сопровождения бурения нефтегазовых скважин с телеметрической системой Луч. Обычно удаленное сопровождение бурения проходит с использованием существующих каналов связи с буровой. Далее приведены наиболее распространенные варианты организации связи с их характерными особенностями. 1. Спутниковая связь. Зачастую это единственный вариант, доступный в полевых условиях из-за удаленности от населенных пунктов. Задержка передачи данных при таком способе соединения достигает нескольких сотен миллисекунд. Скорость приема данных обычно лежит в интервале от 64 кбитc до 6 Мбитc, скорость передачи от 32 кбитс до 2 Мбитс. Часто указанная пропускная способность разделяется между несколькими буровыми. Максимально возможная скорость приема-передачи данных зависит от множества физических параметров, от погодных условий, однако телекоммуникационное оборудование рассчитано на работу на скорости сотен мегабит в cекунду. Обычно на буровых устанавливается спутниковый модем с маршрутизатором. 2. Мобильная связь GPRS, 3G, 4G вблизи населенных пунктов, в зонах покрытия сети. Она имеет меньшие задержки передачи данных, проще в организации. Как правило, устройство абонента не имеет адреса в Интернете, поэтому прямой доступ к ПК на буровой затруднен, и приходится использовать ПО, в котором соединения устанавливаются недоступной через Интернет стороной например, Teamviewer. 3. Кабельная связь обладает наивысшей скоростью передачи данных, но применяется редко из-за дороговизны строительства сетей в труднодоступных районах. В таких случаях ее владельцем является нефтегазовая компания, и сеть организуется с учетом требований, связанных с удаленным доступом. Но, как правило, эта сеть недоступна подрядным сервисным организациям, в том числе занимающимся строительством новых скважин. Параметрами бурения можно считать данные забойной телеметрической системы, данные геолого-технологических исследований, наземных датчиков, видео с камер наблюдения на буровой и т. д. В зависимости от набора используемого ПО эти данные можно получать как в специальных форматах, предназначенных для машинной обработки, так и только в виде изображения пользовательского интерфейса. На основании того, какие форматы данных доступны, как устроена связь офиса с буровыми, выбираются инструменты для контроля параметров бурения. Довольно распространенный способ организации контроля за бурением накопление нужных данных на ПК буровой и периодическая например, после пробуривания скважины на длину одной трубы ручная отправка их по электронной почте заказчику буровых работ для анализа и сопоставления фактических результатов измерений с геологической моделью и планом строительства скважины. В случае несоответствия этих данных бурение может быть временно остановлено для корректировки модели или вообще прекращено. Для минимизации времени простоя буровой и оперативного выявления таких несоответствий полезной является возможность наблюдения за параметрами непосредственно в процессе бурения. Проведем краткий анализ инструментов, применяемых для удаленного контроля параметров бурения. 1. Специализированное клиентское ПО программное обеспечение для контроля параметров бурения с клиент-серверной архитектурой, поддерживающее работу со специализированными форматами для машинной обработки. Данные каротажа обычно хранятся на сервере и могут быть представлены в разных форматах, например в текстовом LAS Log ASCII Standard, PDF каротажный материал в графическом виде. Доступ к данным, хранящимся на сервере, может осуществляться по различным протоколам как открытым WITS, так и проприетарным, специфичным только для определенного ПО. Примером такого ПО может служить RealDepth 5 для работы с телеметрической системой Луч 3, использующее специально разработанный протокол, который позволяет передавать не только глубинные, но и временные данные. Часто реализуются системы сбора и интерпретации данных, создаваемые для решения узкоспециализированных задач 4. 2. Удаленный рабочий стол обобщенное название приложений для удаленного управления рабочим столом с клиент-серверной архитектурой например, TightVNC, Radmin. 3. TeamViewer это приложение для удаленного управления и организации конференций. Отличие этого средства от удаленного рабочего стола заключается в использовании промежуточного сервера, доступного обеим сторонам, для установления соединения. Это позволяет подключаться к рабочим столам пользователей, чьи ПК недоступны из-за NAT. 4. VPN это обобщенное название технологий, позволяющих обеспечить одно или несколько сетевых соединений логическую сеть поверх другой сети. Используется вместе с клиентским ПО из п. 1, 2. 5. SSH port forwarding это технология и тип SSH-канала, предусмотренные стандартом протокола SSH . Поддержка таких каналов на стороне SSH-сервера позволяет перенаправлять TCPIP соединения с определенного порта сервера на определенный адрес и порт со стороны клиента. Используется вместе с клиентским ПО из п. 1, 2. Было проведено сравнение этих инструментов по нескольким параметрам, связанным с особенностями удаленного сопровождения бурения нескольких скважин см. таблицу 1 скорость пригодность для использования в условиях низкой пропускной способности канала связи 2 конфиденциальность обеспечение конфиденциальности передаваемых данных 3 прозрачность возможность использовать специализированное клиентское ПО, установленное на ПК специалиста. Это может быть полезным, когда на ПК специалиста уже настроено свое привычное окружение 4 привилегии отсутствие необходимости изменения системных параметров на ПК буровой или топологии существующей сети не требуется привлечение системного администратора для настройки средства для удаленного доступа и поддержания его в работоспособном состоянии 5 простота простота настройки в полевых условиях инженерами наклонно направленного бурения 6 интерфейс наличие единого интерфейса для отображения информации о множестве буровых состояние и параметры подключения, иная дополнительная информация. Результаты сравнения инструментов The Results of the Comparison Tools Средство Параметр Скорость Конфиденциальность Прозрачность Привилегии Простота Интерфейс Специализированное клиентское ПО Удаленный рабочий стол TeamViewer VPN SSH portfwd По результатам анализа см. таблицу, ни одно из рассмотренных средств в полной мере не учитывает всех важных особенностей удаленного сопровождения бурения. Разрабатываемое программное средство рассматривалось с нескольких точек зрения. 1. С точки зрения ведущих инженеров наклонно направленного бурения, работающих в офисе. В их интересах иметь средство для оперативного доступа к данным бурения, чтобы контролировать параметры совместно с полевыми инженерами наклонно направленного бурения. В разных ситуациях могут быть удобными разные решения сеанс удаленного рабочего стола, если у полевого инженера возникли проблемы с настройкой ПО, или подключение клиентским ПО забойной телеметрической системы. По сравнению с использованием удаленного рабочего стола это позволяет экономно расходовать отведенный объем трафика. Поэтому было предложено с помощью разрабатываемого программного средства предоставлять доступ к нескольким сервисам, запущенным на ПК буровой. Было предложено реализовать монитор, отображающий состояние программного средства на ПК буровой и доступность указанных сервисов, способ подключения к этим сервисам. Кроме того, при разборе нештатных ситуаций возникает потребность понять, находился ли полевой инженер на рабочем месте в определенный момент времени, чем он был занят. Для этого было предложено собирать с ПК буровых снимки экранов и наличие пользовательского ввода, отображать эти данные в мониторе ведущего инженера и иметь возможность сформировать из них отчет за указанный промежуток времени. 2. С точки зрения системных администраторов, работающих в офисе, занимающихся разворачиванием и настройкой программного средства. В их задачи входит сетевое администрирование и формирование списка зарегистрированных ПК буровых, чтобы ведущие инженеры имели доступ только к нужным буровым. Месячный трафик нескольких буровых ограничен, поэтому для контроля над расходом трафика средством удаленного контроля было предложено встроить в него сбор статистики использования сети и инструмент для просмотра этой статистики за определенный временной интервал. В случае аномального расхода трафика средством удаленного контроля системные администраторы смогут установить причину данного явления. 3. С точки зрения полевых инженеров наклонно направленного бурения инженеров телеметрической службы, ГТИ. Основная их работа планирование и организация работ по геонавигационному сопровождению скважин, и непосредственно сопровождение. Предполагалось, что их участие в процессе настройки и эксплуатации программного средства удаленного контроля потребуется только в целях диагностики. Основными нефункциональными требованиями были 1 ограничение на объем передаваемых собственных данных программного средства 2 сжатие и шифрование всего трафика программного средства 3 простота в обращении для полевых инженеров отсутствие надобности читать руководство по эксплуатации для выполнения основных действий с программным средством в идеальном случае отсутствие какого-либо взаимодействия полевого инженера по наклонно направленному бурению с программным средством 4 длительное время стабильной работы программного средства 5 работоспособность программного средства в условиях плохой связи с частыми разрывами соединения 6 возможность запуска на ОС Windows 7, 8, 10, Linux. В основу разрабатываемого средства было решено положить технологию SSH port forwarding перенаправление портов, так как ее настройка и использование не требуют изменения системных параметров. Из этого выбора следует, что архитектура разрабатываемого программного средства должна быть клиент-серверной, где клиентами будут являться узлы, расположенные на буровых, на которых запущены сервисы, предоставляющие по TCPIP доступ к технологическим параметрам бурения и данным скважинной телеметрической системы рис. 1. На сервере должна быть запущена командная оболочка, через которую клиенты будут передавать данные о своем состоянии. Настройки клиентов хранятся на сервере и отдаются по запросу, переданному в командную оболочку при установке соединения. Это позволяет задавать настройки каждого из клиентов через интерфейс администратора. Интерфейс для отображения списка подключенных клиентов и их состояния было решено реализовать в виде постоянно обновляющейся веб-страницы. При переезде или расформировании партии ИТС или ГТИ, при отправке неисправных компьютеров на ремонт возможен несанкционированный доступ к серверу. Поэтому в системе должна быть предусмотрена возможность закрывать указанному клиенту доступ на сервер. Было рассмотрено два технических решения, одно из которых основывается на работе с пользователями ОС, другое на использовании списка авторизованных публичных ключей SSH. Для реализации был выбран второй вариант, так как он требует меньших привилегий в ОС. Кроме того, в реализации -сервера есть возможность гибко управлять ресурсами, доступными клиенту параметры Permit, в том числе прошедшему аутентификацию с помощью заданного публичного ключа Это немаловажно с точки зрения безопасности, так как можно быть уверенным, что клиент не использует не предназначенные для него ресурсы. Идентификация пользователя в системе осуществляется с помощью 128-битного отпечатка fingerprint публичного ключа. Клиентское ПО состоит из функциональных блоков сервисов, которые включаются и настраиваются автоматически на основании ответа сервера на запрос получения конфигурации клиента. Реализовано четыре типа сервисов, нужда в которых продиктована требованиями к программному средству. 1. RemoteTunnel запускает механизм перенаправления портов для указанных локальных TCP-серверов например, RealDepth5 5, служащего для чтения и обработки данных скважинной телесистемы и наземных датчиков, TightVNC VNC для удаленного управления компьютером и передачи файлов, отправляет состояние перенаправления локальную доступность сервиса ошибки при открытии порта на сервере на сервер через командную оболочку. 2. Screenshot периодически делает снимки экрана и отправляет их через командную оболочку. В веб-интерфейсе реализована функциональность просмотра снимков экрана для заданного клиента, а также построения отчетов об активности клиентов во времени на основании наличия снимков экранов. 3. Netstat ведет учет использования сети клиентом, периодически отправляет статистику на сервер через командную оболочку. 4. Bootstrap сервис, создающий все остальные на основе конфигурации, полученной от сервера. Видимое состояние сервисов состоит из двух логических переменных исправность локальной и удаленной части сервиса. Данные понятия интерпретируются по-разному в зависимости от типа сервиса. В результате была выработана архитектура программного средства для удаленного сопровождения бурения, показанная на рис. 1. С учетом возможностей и ограничений выбранных средств были разработаны сценарии взаимодействия клиента с сервером, пользователей с программным средством во время регистрации на сервере и в нормальном рабочем режиме, при котором происходит процесс удаленного сопровождения бурения. Сценарий регистрации клиента на сервере. 1. Клиентское ПО генерирует пару ключей для шифрования. 2. Клиентское ПО проходит аутентификацию на сервере с заранее известным паролем и через командную оболочку передает серверу запрос на регистрацию с данными о себе имя ПК, публичный ключ. При таком режиме аутентификации это единственный доступный клиенту запрос. 3. На сервере указанный клиент попадает в множество кандидатов на регистрацию. 4. Администратор или ведущий инженер через веб-интерфейс выбирает кандидатов на регистрацию и переносит их в основной список клиентов для сопровождения. После этого клиенту доступны аутентификация с помощью публичного ключа и множество запросов на передачу служебной информации. 5. Клиентское ПО переподключается к серверу автоматически и проходит аутентификацию с помощью публичного ключа, получает от сервера свою конфигурацию и проходит настройку в соответствии с конфигурацией. После этого клиентское ПО начинает периодически передавать на сервер служебную информацию и переходит в состояние готовности к удаленному подключению из офиса. Типичный сценарий подключения к сервису на ПК буровой. 1. Клиентское ПО подключается автоматически к серверу и проходит описанный в предыдущем сценарии процесс настройки. 2. Ведущий инженер через веб-интерфейс наблюдает за состоянием работоспособность, номер TCP-порта интересующего его сервиса на ПК полевого инженера. Если сервис доступен, ведущий инженер вводит настройки подключения клиентского ПО, адрес сервера удаленного сопровождения и номер соответствующего сервису порта, подключается к сервису на буровой и осуществляет сопровождение бурения в соответствии с установленными стандартами. Разработанное программное средство нуждалось в тщательном тестировании на соответствие поставленным требованиям. При несоответствии критически важным требованиям, связанным со временем непрерывной работы ПО, расходом трафика буровой, разработанное программное средство не нашло бы практического применения. Для проверки соответствия программного средства требованиям, связанным со скоростью передачи данных и их объемом, было предложено искусственно ограничивать максимальные скорости приема и передачи данных для клиентского приложения и наблюдать за его работоспособностью при выставленных ограничениях. Для этого использовалось ПО NetLimiter. Кроме того, с помощью отладочного вывода проверялось, возобновляется ли передача крупных посылок при восстановлении соединения после разрыва, типичного для спутникового или мобильного канала связи. Вероятны были неполадки клиентского ПО, которые с трудом воспроизводились бы на ПК разработчика. Для диагностики причин этих неполадок и их устранения записывались файлы журнала, которые извлекались с клиентского ПК вместе с образом процесса приложения, а затем анализировались вручную. В числе нефункциональных требований указано длительное время стабильной работы программного средства. Поскольку формальное доказательство корректности программы трудозатратно, был предложен следующий критерий на ПК разработчиков программное средство должно проработать без ошибок в течение 10 дней. Это срок, сравнимый со временем нахождения телеметрической системы под столом ротора буровой. Режим использования ПК на буровой схож с режимом использования разработчиками их компьютеров, поэтому предполагалось, что такой критерий должен подойти. В ходе разработки приветствовалось использование свободно распространяемого программного обеспечения. Поэтому в качестве ОС для сервера был использован дистрибутив CentOS 7 Linux. Среди других он выделялся наибольшим сроком поддержки и выпуска обновлений. Файлы сервера и скрипты для установки были упакованы в пакет RPM, так как часть задач при установке сервера удаленного сопровождения бурения выполняет менеджер пакетов, а обновление или удаление можно провести штатными инструментами. Для реализации программного средства был взят OpenSSH сервер версии 7.8, поскольку в настройках этой версии появились необходимые опции для ограничения возможностей подключенных клиентов. Например, используется параметр PermitListen для задания доступного клиенту диапазона портов сервера, на которых можно запускать механизм перенаправления. Также используется переменная среды SSHUSERAUTH появилась в версии 7.6, задаваемая процессу ssh, по значению которой можно узнать, какой механизм аутентификации был использован, идентифицировать клиента и определить набор команд, доступных ему на выполнение в командной оболочке. Для этого стандартная командная оболочка для соответствующего пользователя в ОС была заменена на свою, в которой проводится идентификация пользователя по этой переменной, генерируется и отправляется на стандартный вывод уникальный номер сессии, а в базу данных записываются параметры этой сессии. Основная командная оболочка реализована в виде TCP-сервера, так как это проще в отладке, не требует создания и настройки псевдотерминала и борьбы с особенностями его работы эхо, переносы строк. Клиенты получают к нему доступ через SSH local port forwarding, в посылки включают выданный первичной командной оболочкой номер сессии. Для предотвращения нехватки места на диске записи о старых неактивных сессиях стираются из базы данных. Данные клиентов, хранящиеся в файловой системе, организованы в дерево с путями вида . С такой структурой легко удаляются данные конкретного клиента все сразу или в указанном временном интервале, например, при его удалении через веб-интерфейс или при автоматической очистке старых данных. Очистка запускается по расписанию, и при нехватке места в файловой системе удаляются данные старше заданного возраста. Серверная часть веб-интерфейса была реализована с использованием фреймворка Django, так как автор был с ним частично знаком, в комплекте шли библиотека для ORM и система шаблонов веб-страниц. Этот выбор определил основной язык для реализации остальных компонент сервера Python 3. В качестве веб-сервера был выбран Apache 2 с включенным modwsgi, впоследствии на нем была настроена поддержка HTTPS с самоподписанным сертификатом. Клиентская часть рис. 2 веб-интерфейса была реализована с использованием библиотеки jQuery, упрощающей разработку динамических страниц, и библиотеки стилей Bootstrap. Большинство запросов на сервер отправляются периодически с использованием AJAX. Клиентская часть см. рис. 2 была написана на языке C14, так как библиотека libssh2 для работы с SSH реализована на языке C, и автор был знаком с фреймворком Qt 5 для построения графических пользовательских интерфейсов. Конфигурацию клиента настройки подключения и сервисов было решено не выносить в отдельный текстовый файл, а оставить в исполняемом файле, чтобы избежать случайной порчи рабочих настроек. Клиентское приложение при запуске сворачивается в область уведомлений и переходит на передний план лишь при необходимости ввода одноразового пароля для регистрации. Пара ключей для SSH генерируется один раз и хранится в директории для локальных файлов приложений. Там же находится файл с журналом событий, ограниченный размером 10 МБ, который может быть использован для устранения неполадок в работе данного программного средства. При нормальной работе программного средства у оператора не должна возникать потребность открывать главное окно, однако при возникновении сбоев в работе оно может быть полезно, так как содержит состояния подключения и сервисов, которые можно передать разработчикам и получить указания по дальнейшим действиям. Клиент был скомпилирован и протестирован для ОС Windows 7, 10, Centos 7 Linux, Ubuntu 18.04 Linux. Поскольку требования к программному средству в будущем могут меняться, то может нарушаться совместимость клиентской и серверной частей. Для контроля версии ПО и своевременного его обновления на веб-интерфейсе отображается версия запущенного клиента. Версия присваивается автоматически во время сборки в системе непрерывной интеграции Jenkins. В результате тестирования по описанной выше методике были получены следующие характеристики и выводы 1 минимальная скорость, при которой удалось добиться стабильной работы программного средства, 3 кбитc на прием и передачу данных 2 снимок экрана в формате PNG с максимальной степенью сжатия и 24 битами цвета занимает объем около 200 КБ при типичном для бурения наборе открытых окон и их компоновки 3 в качестве заставки рекомендуется использовать сплошную заливку одним цветом, так как снимок такого рабочего стола лучше сжимается 4 программное средство работает стабильно в течение трех-четырех недель, затем может произойти критический сбой, причина которого пока не выявлена. Представленное программное средство прошло этап внедрения в отдел программного обеспечения НПП ГА Луч. Данное внедрение имело во многом тестовый характер, в его рамках проводились испытания с ограничением скорости приема и передачи данных. Но нашлось и практическое применение для данного средства оно было использовано для учета рабочего времени сотрудников и заполнения табелей и для оказания поддержки в использовании телеметрической системы Луч. Программная часть данной телеметрической системы устанавливается на ПК полевого инженера наклонно направленного бурения. В нее входят сервер баз данных сервис RealDepth5 5, взаимодействующий непосредственно с аппаратной частью телесистемы, регистрирующий параметры бурения и предоставляющий к ним доступ по специальному протоколу графический монитор полевого инженера, взаимодействующий с сервисом и отображающий параметры бурения скважины. В ходе эксплуатации телеметрической системы была обнаружена ошибка в работе программы, вызванная переходом базы данных в несогласованное состояние. С помощью разработанного средства удалось подключиться к СУБД и восстановить работоспособность телеметрической системы. При этом от полевого инженера не требовалось никаких действий по работе с этим сред ством. Кроме того, по запросу осуществляется подключение к сервису RealDepth5 для оказания консультаций по работе комплекса. В ходе данного внедрения был создан образ виртуальной машины с серверной частью разработанного средства с пустым списком зарегистрированных клиентов и отсутствием каких-либо записей об активности. Если возникает необходимость разграничить доступ ведущих инженеров к разным ПК буровых, то это можно осуществить, создав нужное количество копий образа виртуальной машины и изолировав их друг от друга. В настоящее время проводится внедрение в телеметрическую службу ПАО Сургутнефтегаз. В данной организации уже имеется сеть VPN, объединяющая буровые с офисом управления бурением, поэтому возможность удаленного доступа уже была там до внедрения. Предполагается, что разработанное программное средство найдет применение в качестве монитора состояния сервисов на буровых и как единая точка доступа к данным бурения. Кроме того, полезной будет информация об активности пользователей, например, при разборе нештатных ситуаций. Разработано программное средство для прозрачного удаленного доступа к технологическим параметрам бурения и данным скважинной телеметрической системы в условиях нестабильной связи. За основу средства была взята клиент-серверная архитектура с сервером, расположенным в офисе, и клиентами, расположенными на буровой и имеющими прямой доступ к данным бурения. С применением данного средства ведущие инженеры наклонно направленного бурения для доступа к данным бурения могут использовать те же программные средства, что и полевые инженеры. Средство из-за набора технологий получилось универсальным, пригодным не только для удаленного доступа к данным бурения, а к любым данным, доступным по TCPIP на ПК буровой. Реализован сбор снимков экранов и времени активности пользователей ПК буровой как дополнительного источника информации при разборе нештатных ситуаций. Проведены тесты, по результатам которых определена пригодность средства для работы в полевых условиях с использованием спутниковой и мобильной связи буровой и офиса программное средство работает стабильно при скорости приема и передачи данных, равной 3 кбитc, и без сбоев в течение трех-четырех недель. С помощью данного программного средства оперативно устранены неисправности в работе ПО забойной телеметрической системы Луч путем подключения к СУБД на ПК буровой и переведением ее в согласованное состояние. Разработанное программное средство используется для удаленной помощи в эксплуатации данного комплекса. Из недостатков можно отметить возможную необходимость учитывать доступность TCPпортов сервера а следовательно, и клиентских сервисов, предоставляющих доступ к данным бурения из локальной сети офиса и предотвращать несанкционированный доступ к ним. На данный момент этот недостаток устраняется с помощью творческого подхода системных администраторов, например, используются межсетевые экраны. "}
{"title": "ОБОБЩЕННЫЙ АЛГОРИТМ ЗАЩИЩЕННОГО ИНФОРМАЦИОННОГО ОБМЕНА   ДЛЯ БЕСПРОВОДНЫХ СИСТЕМ БЕЗОПАСНОСТИ   С УСЛОЖНЕННОЙ ИМИТОВСТАВКОЙ  ", "absract": "На основании обобщенного алгоритма защищенного информационного обмена для беспроводных систем безопасности и защищенного устройства управления группой роботов разработан обобщенный алгоритм защищенного информационного обмена с усложненной имитовставкой для беспроводных систем безопасности. Данный алгоритм основан на использовании в управляющем блоке контроля программируемого постоянного запоминающего устройства уникальных идентификационных данных, в котором хранится таблица уникальных кодовых последовательностей, присваиваемых каждому контролируемому объекту. Имитозащищенность передаваемых команд обеспечивается за счет добавления к ним суммы по правилу XOR исходного значения первой псевдослучайной последовательности ПСП-1 и уникальных идентификационных данных контролируемого объекта. С помощью разработанного алгоритма (при соответствующей адаптации) можно затруднить стороннему наблюдателю выявление проверяемого в данный момент времени контролируемого объекта, одновременно осуществить индивидуальную проверку требуемого контролируемого объекта на подлинность  и наличие всех контролируемых объектов в радиусе связи. Разработанный алгоритм с усложненной имитовставкой может найти применение в различных областях беспроводных систем безопасности, в которых требуется защита передаваемых по радиоканалу тревожных и служебных сообщений от несанкционированного доступа. ", "text": " Из литературы известно, что для защиты и охраны периметра важных объектов военные объекты, крупные промышленные предприятия и т. д. от незаконных посягательств применяются различные системы безопасности, например технические системы охраны 13. Вместе с тем также известно, что технические системы охраны сами подвержены деструктивным действиями, направленным на нарушение их работоспособности саботаж. Саботажу способствует то, что многие технические системы охраны не могут устанавливаться скрытно 1 3, и их системы передачи служебных и тревожных сообщений частично могут находиться за контролируемой зоной 2 3. В настоящий момент идет активное развитие беспроводных систем безопасности 4 5. Вместе с тем значительное количество реальных случаев умышленного нарушения работоспособности технических систем охраны примерно 45 случаев приходится на беспроводную систему связи систему передачи извещений. Так, среди основных методов нарушения работоспособности беспроводных систем связи выделяют постановку помех, имитацию сигнала оконечного оборудования, подмену объектового оборудования систем связи и т. д. В общей сложности на данные угрозы приходится до 40 случаев нарушения работоспособности беспроводных систем безопасности другая часть на отключение электропитания системы передачи извещений и т. п. 1. Таким образом, защита от несанкционированного доступа НСД информационного обмена в системах безопасности при использовании беспроводного канала связи является актуальной задачей. В настоящее время основными методами защиты информационного обмена при этом выступают криптографические методы и технологии на основе шумоподобных сигналов ШПС. Развитие технологий защиты радиоканала систем безопасности на основе ШПС представляет значительный интерес 4 5. Перспективной технологией повышения защищенности информационного обмена на основе ШПС выступает использование хаотических сигналов ХС 4 68. Их использование в защищенной радиосвязи позволяет добиться повышенной защищенности от НСД за счет повышенной структурной и информационной скрытности по сравнению с другими видами ШПС 68. Исходя из сказанного, важной научной и практической задачей является разработка новых и совершенствование существующих методов и алгоритмов защищенного информационного обмена в беспроводных системах безопасности 9 10. Целью данной статьи является разработка обобщенного алгоритма защищенного информационного обмена с усложненной имитовставкой для беспроводных систем безопасности. Из литературы и списков источников к ней известно достаточное количество алгоритмов защищенного информационного обмена на основе ШПС для различных беспроводных систем безопасности 4 5 10. Однако теория и практика использования алгоритмов информационного обмена на основе ХС для беспроводных систем безопасности развита не достаточно хорошо 4 10. Одним из таких известных алгоритмов на основе ХС является обобщенный алгоритм защищенного информационного обмена в беспроводных системах безопасности 10, основанный на использовании перезаписываемых накопителей хаотических последовательностей НХП, а также на использовании в управляющем блоке и контролируемых объектах одинаковых генераторов второй псевдослучайной последовательности ПСП-2, инициализация которых осуществляется периодически изменяющимся псевдослучайным числом, вырабатываемым генератором первой псевдослучайной последовательности ПСП-1 управляющего блока. Данный алгоритм состоит из следующих шагов 10 1 инициализация генератора ПСП-1 управляющего блока 2 выработка первого псевдослучайного числа генератором ПСП-1 управляющего блока 3 отправка полученного значения одновременно на генератор ПСП-2 управляющего блока и в НХП 4 передача произведения ПСП-1 и ХС из НХП на контролируемый объект 5 декодирование в контролируемом объекте полученного сигнала с помощью накопителя копии хаотической последовательности НКХП, идентичного НХП в управляющем блоке 6 поступление декодированного сигнала в виде последовательности в генератор ПСП-2 контролируемого объекта, функция генерации последовательности которого идентична функции генератора ПСП-2 управляющего блока 7 передача произведения выработанной последовательности ПСП-2 контролируемого объекта с хаотическим сигналом из НХП на управляющий блок 8 декодирование в управляющем блоке полученного сигнала с помощью НКХП, идентичного НХП в контролируемом объекте 9 поступление декодированного сигнала в виде ПСП-2 контролируемого объекта в устройство сравнения УС 10 выработка ПСП-2 управляющего блока и ее поступление в УС 11 сравнение ПСП-2 управляющего блока и ПСП-2 контролируемого объекта 12 если сравнение верно, то отображается сигнал Норма и осуществляется переход к п. 1 алгоритма 13 если сравнение неверно, то отображается сигнал Тревога и осуществляется переход к п. 14 алгоритма 14 вмешательство в работу беспроводной системы безопасности персонала ответственных лиц. На рис. 1 описанный алгоритм приведен в виде упрощенной блок-схемы 10. Данный алгоритм защищенного информационного обмена может найти практическое применение для защиты информационного обмена между блоком контроля и оконечными датчиками в охранно-пожарных системах 11, для защищенной беспроводной системы управления робототехническим комплексом 12, а также для беспроводной защищенной идентификации и контроля доступа транспортных средств на охраняемые объекты 13. Вместе с тем в работе 14 авторами предлагается устройство управления группой роботов с передачей команд по защищенному от несанкционированного доступа беспроводному каналу связи. На рис. 2 приведена структурная схема защищенного устройства управления группой роботов оператором сервером посредством беспроводного канала связи. Устройство, изображенное на рис. 2, состоит из сервера, в состав которого входят система управления СУ, перезаписываемое постоянное запоминающее устройство уникальных идентификационных данных ППЗУ УИД, НКХП, генератор ПСП-1, блок логической операции XOR, НХП, генератор ПСП-2, УС, приемопередающее устройство ППУ и роботов, в состав каждого из которых входят НКХП, ППУ, НХП, блок логической операции XOR, блок УИД, электропривод, ПСП-2, актуаторы, блок формирования сигналов управления, сенсоры. Сервер и роботы имеют одинаковые наборы хаотических последовательностей в перезаписываемых накопителях, что позволяет производить кодирование декодирование передаваемых сообщений и обеспечивает упрощение обслуживания роботов 14. Функционирование осуществляется в широковещательном и индивидуальном режимах 14. Вначале СУ дает команду генератору ПСП-1 на генерацию значения первой ПСП-1, которая, кроме прочего, также отправляется на генератор ПСП-2 и одновременно дает команду ППЗУ УИД на выбор из таблицы одного уникального значения, присвоенного каждому роботу. После этого значение первой ПСП-1 и УИД выбранного робота отправляются в блок логической операции XOR, где происходит их сложение. Далее их сумма через ППУ поступает в НХП, где перемножается с хаотической последовательностью и после вхождения в режим синхронизации широковещательным запросом отправляется всем роботам. Истинное значение первой ПСП-1, сформированное генератором ПСП-1, может декодировать лишь тот робот, чей УИД совпадает с переданным блоком ППЗУ таблицы роботов значением УИД. Несмотря на это, все роботы производят декодирование переданного сообщения с помощью НКХП. Далее декодированный сигнал поступает в блок логической операции XOR, в который одновременно приходит индивидуальное значение УИД каждого робота. Из блока логической операции XOR выходит ПСП. После этого каждый робот вырабатывает свое значение второй ПСП-2 от генератора ПСП-2 и отправляет его в ППУ. Одновременно с этим в ППУ приходит значение УИД робота. Сформированный пакет, состоящий из значения второй ПСП-2 и УИД, отправляется в НХП, где перемножается с хаотической последовательностью и отправляется на сервер. На сервере после вхождения в режим синхронизации каждое принятое сообщение проходит декодирование с помощью НКХП. Декодированные пакеты поступают в ППУ. ППУ выполняет следующие действия подсчитывает количество входящих пакетов, отправляет в ППЗУ УИД уникальные значения роботов, который отмечает их в строке получения и передает в УС значение второй ПСП-2 заранее выбранного робота. Кроме того, после окончания приема всех сообщений, ППУ сравнивает количество пришедших пакетов и количество роботов в ППЗУ УИД. В случае неравенства этих значений выдается сигнал тревоги. В УС сервера происходит сравнение значений второй ПСП-2 сервера и второй ПСП-2 выбранного робота. В случае верного сравнения СУ переходит в индивидуальный режим управления выбранным роботом. В случае неверного сравнения выдается сигнал тревоги, сигнализирующий о компрометации проверяемого робота. Индивидуальный режим управления состоит в следующем 14. СУ осуществляет управление выбранным роботом через ППУ, добавляя в команды управления имитовставку, состоящую из суммы значения первой ПСП-1 и УИД. При обработке входных команд робот отделяет от команд управления имитовставку и вычисляет значение второй ПСП-2, которое добавляется в команды, посылаемые роботом обратно на сервер. Сервер, как и при широковещательном режиме работы, периодически проверяет истинность значения второй ПСП-2 робота для предотвращения несанкционированного доступа к командам управления. Данная технология за счет использования ППЗУ УИД в котором хранится таблица уникальных кодовых последовательностей, присваиваемых каждому роботу, отличается усложненной имитовставкой, добавляемой в передаваемые служебные команды между управляемым роботом и сервером, затруднительностью стороннему наблюдателю по выявлению проверяемого в данный момент времени робота, осуществлением одновременной индивидуальной проверки требуемого робота на подлинность и наличия всех роботов в радиусе связи 14. На основании описанных выше обобщенного алгоритма защищенного информационного обмена см. рис. 1, описанного в 10, и защищенного устройства управления группой роботов см. рис. 2, описанного в 14, разработаем обобщенный алгоритм защищенного информационного обмена с усложненной имитовставкой. Данный алгоритм будет состоять из следующих шагов 1 инициализация генератора ПСП-1 управляющего блока 2 выработка первого псевдослучайного числа генератором ПСП-1 управляющего блока, и его отправка на генератор ПСП-2 блока контроля и в блок логической операции XOR 3 выбор ППЗУ УИД из таблицы одного уникального значения, присвоенного каждому контролируемому объекту 4 сложение по правилу XOR значений первой ПСП-1 блока контроля и УИД выбранного контролируемого объекта 5 отправка полученного значения в НХП, где оно перемножается с ХС, и передача полученного произведения на контролируемый объект 6 декодирование в контролируемом объекте полученного сигнала с помощью НКХП, идентичного НХП в управляющем блоке 7 поступление декодированного сигнала в блок логической операции XOR контролируемого объекта, в который одновременно с этим приходит индивидуальное значение УИД контролируемого объекта 8 получение в блоке логической операции XOR контролируемого объекта значения ПСП-1 блока контроля и его поступление в виде последовательности в генератор ПСП-2 контролируемого объекта, функция генерации последовательности которого идентична функции генератора ПСП-2 управляющего блока 9 выработка в генераторе ПСП-2 контролируемого объекта, функция генерации последовательности которого идентична функции генератора ПСП-2 управляющего блока, последовательности ПСП-2 10 передача произведения выработанной последовательности ПСП-2 контролируемого объекта с ХС из НХП на управляющий блок 11 декодирование в управляющем блоке полученного сигнала с помощью НКХП, идентичного НХП в контролируемом объекте 12 поступление декодированного сигнала в виде ПСП-2 контролируемого объекта в УС 13 выработка ПСП-2 управляющего блока и ее поступление в УС 14 сравнение ПСП-2 управляющего блока и ПСП-2 контролируемого объекта 15 если сравнение верно, то отображается сигнал Норма и осуществляется переход к п. 1 алгоритма 16 если сравнение неверно, то отображается сигнал Тревога и осуществляется переход к п. 14 алгоритма 17 вмешательство в работу беспроводной системы безопасности персонала ответственных лиц. На рис. 3 разработанный обобщенный алгоритм приведен в виде упрощенной блок-схемы. Как видно, разработанный алгоритм имеет общий вид его практические приложения могут быть разнообразными, например, как описано выше, робототехнические комплексы, а также охранно-пожарные сигнализации, системы автомобильной безопасности и другие беспроводные системы безопасности. Отличительной чертой данного алгоритма, в отличие от приведенного на рис. 1, является усложненная имитовставка для передаваемых команд за счет сложения по правилу XOR исходного значения ПСП-1 и УИД контролируемого объекта выделено жирным на рис. 3. Данную сумму можно использовать в качестве имито вставки, затрудняющей стороннему наблюдателю как процесс изучения алгоритма генерации ПСП, так и подмену передаваемых служебных и тревожных команд при передаче от блока управления на контролируемые объекты, а также для проверки имитозащищенности подлинности контролируемых объектов. Кроме того, в дальнейшем, можно предусмотреть, что при передаче служебных и тревожных сообщений от контролируемого объекта на управляющий блок в обратном направлении можно использовать в качестве имитовставки не значение ПСП-2, вырабатываемое на контролируемом объекте, а сумму по правилу XOR значения ПСП-2 контролируемого объекта с его УИД. Восстановление исходной ПСП-2 контролируемого объекта будет осуществляться сложением по правилу XOR в управляющем блоке полученной суммы с УИД проверяемого контролируемого объекта. Защиту передаваемых данных от просмотра, перехвата и подавления помехами обеспечивают, как и в ранее приведенном алгоритме см. рис. 1, перезаписываемые накопители хаотических сигналов, в которые можно записать потенциально бесконечное число различных хаотических реализаций для восстановления исходной ПСП, а также служебной и тревожной информации необходимо иметь точную копию хаотического сигнала. Также с помощью разработанного алгоритма при соответствующей адаптации можно выполнить следующие действия 14 затруднить стороннему наблюдателю выявление проверяемого в данный момент времени контролируемого объекта, одновременно осуществить индивидуальную проверку требуемого контролируемого объекта на подлинность и проверку наличия всех контролируемых объектов в радиусе связи в случае широковещательного запроса. Таким образом, в данной работе на основании обобщенного алгоритма защищенного информационного обмена см. рис. 1, описанного в 10, и защищенного устройства управления группой роботов см. рис. 2, описанного в 14, разработан обобщенный алгоритм защищенного информационного обмена с усложненной имитовставкой. Данный алгоритм защищенного информационного обмена основан на использовании в управляющем блоке контроля программируемого постоянного запоминающего устройства уникальных идентификационных данных, в котором хранится таблица уникальных кодовых последовательностей, присваиваемых каждому контролируемому объекту. Имитозащищенность передаваемых команд обеспечивается за счет сложения по правилу XOR исходного значения ПСП-1 и УИД контролируемого объекта. Также с помощью разработанного алгоритма при соответствующей его адаптации можно затруднить стороннему наблюдателю выявление проверяемого в данный момент времени контролируемого объекта, одновременно осуществить индивидуальную проверку требуемого контролируемого объекта на подлинность и проверку наличия всех контролируемых объектов в радиусе связи при широковещательном запросе. Среди основных преимуществ разработанного подхода следует выделить повышенную защищенность от НСД за счет использования перезаписываемых накопителей хаотических последовательностей и генераторов ПСП 4 1113, а также потенциальную возможность использовать разработанный алгоритм для различных беспроводных систем безопасности. Среди недостатков следует выделить необходимость наличия точной синхронизации между передающей и приемной сторонами. Однако использование перезаписываемых накопителей хаотических последовательностей, содержащих одинаковые копии ХС на передающей и приемной сторонах 1113, позволяет упростить задачу обеспечения точной синхронизации между передающей и приемной сторонами за счет уменьшения времени извлечения ХС из блоков памяти по сравнению с их вычислением 10. "}
{"title": "ПРИМЕНЕНИЕ МЕТОДОВ ГЛУБИННОГО ОБУЧЕНИЯ   ДЛЯ ОБНАРУЖЕНИЯ ВТОРЖЕНИЙ  ", "absract": " Приведены результаты применения глубоких нейронных сетей для детектирования вредоносной активности  в сетевом трафике. В процессе исследования реализованы два вида нейронной сети: рекуррентный автоэнкодер и генеративно-состязательная сеть. Приведены результаты исследования на наборе данных CICIDS2017. ", "text": " Выявление вредоносной активности в сетевом трафике является актуальной задачей, к решению которой существует несколько подходов 1. Классический подход состоит в написании шаблонов, по которым в сетевом трафике детектируется вредоносная активность. Данный подход является высокоэффективным, но не позволяет обнаруживать атаки, для которых отсутствует шаблон. Современные подходы базируются на том, что детектирование вредоносного трафика является частным случаем классической задачи классификации, которая в настоящее время успешно решается с помощью машинного обучения, в частности, нейронных сетей. Однако простые алгоритмы машинного обучения являются эффективными только при правильном ручном извлечении признаков из исходных данных. А извлечение необходимых признаков во многих случаях само по себе является не тривиальной задачей. Применение методов позволяет автоматически выявлять признаки, которые необходимы для дальнейшей классификации. А для выявления высокоуровневых признаков используют методы глубинного обучения 2. Цель работы исследовать возможность построения универсального классификатора сетевого трафика на основе глубокой нейронной сети. Для обучения нейронной сети был сформирован набор данных CICIDS2017, который является публично доступным и предназначен для исследований в области кибербезопасности и обнаружения вторжений. Набор данных CICIDS2017 распространяется в виде файлов 2-х форматов PCAP и CSV. Первые хранят дампы трафика, охватывающие пять дней сетевой активности, вторые содержат описание для каждого сетевого потока статистические признаки и класс, к которому принадлежит поток. Поток это последовательность сетевых пакетов, у которых совпадают следующие поля IP источника, IP получателя, порт источника, порт получателя и протокол. Для каждого потока выделяется более 80 признаков . Общие данные о наборе CICIDS2017 представлены в табл. 1. В качестве глубокой нейронной сети был выбран рекуррентный автоэнкодер 2 как нейронная сеть, предназначенная для обработки последовательностей различной длины. Обучение нейронной сети проходило на TCP пакетах из дампов трафика. Архитектура рекуррентного автоэнкодера представлена в табл. 2. Общие данные о CICIDS2017 General Information about CICIDS2017 Класс Вредоносность Количество потоков Benign 2 358 036 DoS Hulk 231 073 Port Scan 158 930 DDoS 41 835 DoS GoldenEye 10 293 FTPPatator 7 938 SSHPatator 5 897 DoS Slow Loris 5 796 DoS Slow HTTP Test 5 499 Botnet 1 966 Web Attack Brute Force 1 507 Web Attack XSS 652 Infiltration 36 Web Attack SQL Injection 21 Heartbleed 11 Архитектура рекуррентного автоэнкодера Recurrent Autoencoder Architecture Слой Число нейронов Функция активации Dropout Энкодер GRU 128 ReLU 0.2 GRU 64 ReLU 0.2 Декодер GRU 128 ReLU 0.2 GRU 256 Softmax 0 Размерность входного слоя 256 Оптимизатор 10 Функция ошибки MSE Размер пакетов batch size 64 Количество эпох 100 Для более равномерного последующего нормирования входных значений каждому нейрону на вход подается 1 байт пакета. А выбранный размер входного слоя 256 является предположительно оптимальным с точки зрения качества работы сети и сложности вычислений. При обучении рекуррентный автоэнкодер представлял собой модель, в которой ожидаемый вектор устанавливался таким же, как и исходный. А обучение происходило исключительно на легитимном трафике. Идея заключалась в том, что обученный таким образом рекуррентный автоэнкодер должен восстанавливать аномальный трафик с ошибки. рассчитывается как значение близости исходного TCP пакета и восстановленных данных. Для того чтобы определить, является ли пакет вредоносным, необходимо ввести параметр порог ошибки восстановления. Таким образом, корректируя значение порога ошибки восстановления можно настраивать точность выявления вредоносной активности. Однако во время обучения на сконструированном рекуррентном автоэнкодере не удалось получить точность восстановления более 60 . Предметная область изображения, звук, текст в существенной степени влияет на процесс обучения признакам. Например, сверточные нейронные сети в рамках задачи распознавания изображений используют иерархии объектов и базируются на особенностях работы зрительной коры головного мозга 3. Для сетевого трафика такой концепции на данный момент не выработано. Отсутствие концепции обучения признакам и недостаточная мкость модели стали причинами низкой точности восстановления. Сетевой трафик в наборе CICIDS2017 представляет собой совокупность потоков, в свою очередь, поток это совокупность сетевых пакетов. Для обучения нейронной сети в качестве входных данных могут быть использованы сетевые пакеты или потоки в зависимости от того, какие классы атак необходимо детектировать. Достоинства и недостатки двух подходов можно проследить на примере обнаружения конкретных типов атак. Атаки класса Brute Force сложно выявить инспекцией только отдельных сетевых пакетов. Ключевой особенностью таких атак является отправка множества однотипных пакетов за небольшой промежуток времени. Вредоносные и легитимные пакеты в данном случае слабо различимы. Такие атаки, как SQL Injection или XSS, ключевая информация для детектирования которых содержится внутри полезной нагрузки, сложно детектировать на уровне потоков. При работе с сетевыми потоками информация заключенная внутри полезной нагрузки, теряется. Вероятно, статистические признаки сетевого потока не позволяют закодировать достаточно много информации. Один поток может содержать сотни и тысячи сетевых пакетов, каждый из которых имеет собственные уникальные признаки. При агрегировании сетевых пакетов до уровня потоков теряется часть информации. Это то же самое, что взять предложения из некоторого текста и заменить вектором метаданных, который кодирует количество слов и символов в предложении. Таким образом, перспективным можно считать подход, при котором для различных классов атак реализуется свой метод обнаружения, основанный на особенностях представления данных и применимости определенного типа нейронной сети. Это означает, что необходимо отказаться от идеи универсального классификатора и сосредоточить внимание только на определенной группе атак. Например, классы атак, представленные в CICIDS2017, можно разделить на две группы и использовать рекомендуемые типы нейронных сетей в соответствии с табл. 3. Рекомендуемые типы нейронных сетей для CICIDS2017 Recommended Types of Neural Networks for CICIDS2017 Классы атак Типы нейронной сети Данные для обучения DoS, DDoS, Port Scan, FTPPatator, SSHPatator, Bot, Web Attack Brute Force, Infiltration, Heartbleed Автоэнкодер и генеративно-состязательная сеть 4 Сетевые потоки Web Attack SQL Injection и XSS Seq2Seq автоэнкодер Сетевые пакеты На основе предложенного подхода была разработана нейронная сеть, которая объединяет в себе вариационный автоэнкодер Variational Autoencoder, VAE и генеративно-состязатель ную сеть Generative Adversarial Network, GAN. Сети такого типа были предложены в 5 и имеют название VAEGAN. Обучение реализованной нейронной сети происходило без учителя, на легитимных сетевых потоках из набора CICIDS2017. В качестве тестовых данных были выбраны легитимные сетевые потоки, которые не входили в тренировочный набор, и сетевые потоки всех типов вредоносной активности. Общая информация о тестовой выборке представлена в табл. 4, архитектура реализованной VAEGAN сети в табл. 5. Общая информация о тестовой выборке General Information about Test Dataset Класс Вредоносность Количество потоков Benign 1 000 Port Scan 1 000 DDoS 1 000 DoS 1 000 FTPPatator 1 000 SSHPatator 1 000 Botnet 1 000 Web Attack Brute Force 1 000 Web Attack XSS 652 Infiltration 36 Web Attack SQL Injection 21 Heartbleed 11 Архитектура VAEGAN VAEGAN Architecture Слой Число нейронов Функция активации Dropout Энкодер E Dense 64 LeakyReLU 0.2 0.2 Dense 32 LeakyReLU 0.2 0.2 Dense 32 LeakyReLU 0.2 0.2 Декодер G Dense 32 LeakyReLU 0.2 0.2 Dense 32 LeakyReLU 0.2 0.2 Dense 64 LeakyReLU 0.2 0.2 Dense 80 Tanh 0 Дискриминатор D Dense 64 LeakyReLU 0.3 0.2 Dense 64 LeakyReLU 0.3 0.2 Dense 32 LeakyReLU 0.3 0.2 Dense 1 Sigmoid 0 Оптимизатор 0.001, 0.5 Размер пакета batch size 64 Размерность входного слоя энкодера и дискриминатора 80 Размерность кода 20 Начальная инициализация весов Xavier normal В VAEGAN вариационный автоэнкодер получает на вход вектор признаков для сетевого потока и учится восстанавливать максимально похожий вектор на выходе. Дискриминатор принимает на вход восстановленный и исходный векторы и учится предсказывать, какой вектор является настоящим, а какой восстановленным. Выявление вредоносной активности реализовано на основе подхода, представленного в 6. Для того чтобы определить, является ли сетевой поток вредоносным, вычисляется значение аномальности 0.1 0.9, где сетевой поток, восстановленный вариационным автоэнкодером сетевой поток, ошибка на -м слое дискриминатора, ошибка вариационного автоэнкодера. Поток считается вредоносным, если значение превышает установленный порог. Корректировать точность выявления вредоносной активности можно, регулируя значение порога аномальности. Полученные результаты представлены на рисунке. Каждая точка на этом рисунке отображает значение аномальности для сетевого потока. Красная линия установленный порог. В результате полученная точность составила 0,983, полнота 0,889, значение F-меры 0,933. Процент правильной классификации по классам представлен в табл. 6. Результат работы VAEGAN The VAEGAN Results Класс Правильно классифицированные потоки, Benign 88,2 Port Scan 98,3 DDoS 100 DoS 100 FTPPatator 100 SSHPatator 99,7 Botnet 63,9 Web Attack Brute Force 98,6 Web Attack XSS 48,3 Infiltration 100 Web Attack SQL Injection 4,8 Heartbleed 100 В настоящее время многие задачи классификации успешно решаются с помощью глубоких нейронных сетей. В работе был сконструирован рекуррентный автоэнкодер для задачи классификации сетевого трафика. Использование нейронной сети данного типа было обусловлено тем, что исходными данными являлись последовательные сетевые пакеты различной длины. Однако не было заложено никакой концепции обучения признакам. В результате точность восстановления оказалась низкой. При анализе полученных результатов были рассмотрены ключевые особенности сетевого трафика в рамках задачи классификации. Это позволило сделать предположение о неэффективности универсального классификатора и предложить подход, повышающий точность обнаружения вредоносного трафика. На основе сформулированного подхода на легитимных сетевых потоках была обучена VAEGAN сеть. В результате удалось получить высокую точность выявления сетевых потоков для выделенных классов атак. Низкий процент детектирования оказался для атак SQL Injection, XSS и Botnet, для успешного выявления которых требуется инспекция полезной нагрузки и применение рекомендуемого в табл. 3 типа нейронной сети. "}
{"title": "EXPERIENCE IN DEVELOPMENT AND IMPLEMENTATION   OF THE INFORMATION SYSTEM, SUPPORTING STUDENTS ASSIGNMENT   FOR PRACTICE TO NRU MPEI  ", "absract": "Рассмотрен обязательный для высших образовательных учреждений РФ процесс проведения практических занятий студентов, приведены ссылки на нормативные документы, описан подход, устоявшийся в НИУ МЭИ. До начала проведения практики каждый студент должен быть прикреплен к определенной базе практики – учреждению с соответствующей профилю подготовки обучающегося специализацией, которое будет осуществлять проведение и контроль практических занятий. Если база практики внешняя, т. е. не входит в организационную структуру образовательного учреждения, то с ней должен быть заключен договор. В статье представлен опыт разработки и внедрения в НИУ МЭИ информационной системы, автоматизирующей процесс распределения студентов по базам практик и подготовку сопутствующей документации. Программная реализация включает модуль импорта данных из других информационных систем, модуль редактирования календарного графика практик, модуль ведения справочной информации о предприятиях-партнерах, модуль  формирования и согласования заявок с распределением студентов, модуль подготовки печатных форм документов, модуль построения статистической отчетности. Описана работа каждого из модулей, отмечаются их преимущества перед ручной обработкой данных. Раскрыты некоторые технические решения и характеристики программной системы, отдельное внимание уделено разграничению прав доступа. ", "text": " Неотъемлемой частью любых теоретических познаний является их применение на практике. Как бы подробно и детально не был разобран изучаемый вопрос теоретически, человек, успешно прошедший обучение, на практике может столкнуться с совершенно новыми и неизвестными для него трудностями. Это хорошо известный факт, который требует от современных учебных заведений в обязательном порядке включать в учебный процесс мероприятия, предлагающие учащимся на практике применить полученные знания для решения реальных задач. В статьях 1 2 отмечается высокая роль учебной и производственной практик в формировании профессиональных компетенций и трудоустройстве выпускников. Проведение практики положительно оценивается как самими студентами, так и их будущими работодателями 3 4. В контексте высших учебных заведений, в частности НИУ МЭИ, следует упомянуть приказ Министерства образования и науки Российской Федерации ныне Министерство науки и высшего образования Российской Федерации от 27 ноября 2015 г. 1383, утверждающий Положение о практике обучающихся, осваивающих основные профессиональные образовательные программы высшего образования . Положение распространяется на все организации, осуществляющие основные профессиональные образовательные программы высшего образования ОПОП ВО, и накладывает требования на программу практики, дает описание форм проведения практики, регламентирует деятельность лиц, участвующих в процессе направления и прохождения практики обучающимися, и характеризует другие аспекты, связанные с практикой. В свою очередь, федеральные государственные образовательные стандарты высшего образования ФГОС ВО, являющиеся основой для любой программы подготовки, разрабатываемой в вузе, включают в программу блок Практика и требуют проведения различных типов практик в ходе обучения. Например, реализуемые в МЭИ ФГОС ВО для бакалавриата и магистратуры по направлению подготовки 13.03.01 Теплоэнергетика и теплотехника. До 27.01.2018 Положение о практике явно выделяло два вида практики учебную и производственную. Первая, учебная, была ориентирована на приобретение первичных профессиональных умений и навыков и обычно проводилась в стенах вуза являлась стационарной по способу проведения. Вторая, производственная в том числе преддипломная, была направлена для получения углубленных профессиональных умений и опыта профессиональной деятельности и часто связана с направлением обучающихся на работу во внешние организации являлась выездной по способу проведения. Согласно приказу, начиная с 28.01.2018, организациям разрешено самостоятельно устанавливать виды практик и способы их проведения в соответствии с ФГОС ВО, однако многие вузы продолжают считать основными видами практик учебную и производственную . Более сложной, с юридической точки зрения, является практика, которая проводится вне стен учебного заведения на базе внешней организации. В этом случае, помимо внутренних документов вуза, которые готовятся участниками в ходе проведения практики, с внешней организацией должен быть заключен официальный договор, устанавливающий обязанности и ответственность сторон . Для большинства организаций-партнеров подходит некоторый устоявшийся формат договоренностей, и договор готовится по стандартной форме, принятой в вузе. Но в некоторых случаях необходима большая гибкость, и сторонами может быть сформирован особый договор в согласованной форме. Все обучающиеся направляются на практику согласно календарному графику, в котором строго определены даты начала и окончания всех видов учебной деятельности в семестре, в том числе и практик. Все договоры с организациями-партнерами должны быть заключены строго до начала проведения практики. Учитывая тот факт, что у вузов с большим количеством обучающихся, вероятнее всего, имеется и немалое количество организаций-партнеров, а также сжатость сроков для подготовки необходимых документов, естественным образом встает вопрос автоматизации процесса направления студентов на практику. Если в некотором вузе рассмотренная задача и решается вручную, то увеличение размера исходных данных а учебное заведение стремится к увеличению количества обучающихся с большой вероятностью приведет к повышению человеческих трудозатрат, появлению ошибок в документах, нарушению регламентов и, в целом, обнаружит нерентабельность ручной обработки. Федеральное государственное бюджетное образовательное учреждение высшего образования Национальный исследовательский университет МЭИ НИУ МЭИ включает в себя 12 институтов и более 60 кафедр, которые принимают непосредственное участие в обучении более 13 000 студентов по программам бакалавриата, специалитета и магистратуры 5 6. Прохождение практик является неотъемлемой частью учебного процесса для всех студентов МЭИ и регламентируется локальным положением . На различных курсах обучения студенты должны пройти учебную, производственную, преддипломную и научно-производ ственную практики. В качестве базы практики учреждения, к которому прикрепляется студент, могут выступать как подразделения МЭИ на конец 2018 г. в организационной структуре МЭИ насчитывалось более 350 подразделений, так и внешние организациипартнеры. В ходе учебной практики студенты обычно выступают в роли ассистентов преподавателей кафедры и помогают им в проведении занятий. При проведении остальных видов практик студенты, по возможности, направляются для работы во внешние организации и решают поставленные там задачи. Для многих из них это первый опыт работы, а для некоторых еще и успешное начало карьеры. В НИУ МЭИ устоялся определенный процесс направления студентов на практику и подготовки сопроводительной документации. Каждая кафедра выбирает одного или нескольких ответственных за практику сотрудников для взаимодействия со студентами, организациямипартнерами и отделом занятости и практических форм обучения ОЗ и ПФО. На плечи ответственных ложится достижение первоначальных договоренностей о прохождении практики конкретных студентов в конкретных организациях. В одних случаях инициатива исходит от студентов, в других от организаций. Ответственные заносят эти договоренности в заявку на проведение практики и передают ее в ОЗ и ПФО. В заявке содержится информация о виде практике, ее сроках и распределении студентов по базам практик. Получив заявку на практику, сотрудники ОЗ и ПФО готовят договоры для всех студентов, направляемых во внешние организации. Возможны следующие виды документов 1 разовый договор стандартная форма МЭИ для заключения соглашения о разовом прохождении практики студентов на базе внешней организации 2 дополнительное соглашение используется при действующем долгосрочном договоре с организацией, в рамках которого МЭИ может направлять студентов на практику. Все направления фиксируются в дополнительных соглашениях 3 договор по форме предприятия аналог разового договора для случая, когда стандартная форма договора МЭИ не подходит внешней организации. Каждый из подготовленных документов в двух экземплярах со стороны МЭИ подписывается начальником ОЗ и ПФО. Затем ответственный от кафедры забирает подготовленные документы и направляет их для подписания уполномоченным лицам во внешние организации, после чего один экземпляр возвращается в ОЗ и ПФО. Когда все студенты распределены по базам практик и подписаны сопровождающие документы, готовится приказ по МЭИ о направлении студентов на практику. Формально процесс согласования и подготовки документов можно представить с помощью диаграммы деятельности рис. 1. На приведенной диаграмме для компактности изображения использованы узлы, обозначающие элементарные действия, но некоторые из них на самом деле представляют собой более сложные составные шаги. Например, подготовка любого из видов документов разбивается на несколько составляющих перенос из заявки сведений о внешней организации наименование, адрес, подписант и др., сроках и виде практики, направляемых студентах поиск в информационных системах МЭИ дополнительных данных о студентах и включение их в текст документа подготовка сопроводительного письма-направления для организации печать и подпись документа. В случае дополнительного соглашения добавляется поиск и указание ссылки на долгосрочный договор. На практике при подготовке документов не всегда удается соответствовать утвержденному регламенту. У кафедр нет доступа к актуальному списку студентов группы, его приходится поддерживать самостоятельно, из-за чего возможны потери при подготовке заявок. В некоторых случаях ответственные самостоятельно формируют договор, подписывают и передают его вместе с заявкой в ОЗ и ПФО. Это может приводить к юридическим ошибкам и необходимости повторно заключать договор. Кроме этого, в силу объективных и субъективных причин могут затягиваться сроки подписания, изменяться базы прохождения практик, и возникать другие сложности, требующие оперативного решения. С учетом большого количества студентов, кафедр и организаций-партнеров огромная нагрузка ложится на сотрудников ОЗ и ПФО, которым вручную крайне сложно отследить и обработать все поступающие к ним изменения и запросы. В конце 2017 г. было принято решение о необходимости автоматизации процесса подачи заявок на проведение практики кафедрами и их обработки ОЗ и ПФО. Процесс согласования заявок напоминает электронный документооборот и, вероятно, может быть автоматизирован за счет внедрения системы электронного документооборота СЭД. Основной недостаток использования коробочных СЭД высокая стоимость приобретения, внедрения и обслуживания 7. Само внедрение нередко упирается в консерватизм сотрудников и нежелание обучаться новым непривычным для них технологиям 8 9. При этом если СЭД не будет внедрена на всех рабочих местах, то и эффект от ее использования будет минимален 9. Поэтому нередко организации приходят к решению использовать заказное программное обеспечение и, таким образом, разрабатывать решение под себя 10 11. Для принятия окончательного решения в каждом конкретном случае требуется оценить затраты на приобретение и разработку, а также потенциальную выгоду от внедрения нового ПО. Согласно данным аналитического агентства TAdviser, наиболее популярными СЭД на российском рынке являются Directum, Elma, DocsVision, Дело ЭОС, Тезис, 1СДокументо оборот . Но перечисленные решения слабо ориентированы на рассматриваемую задачу и не позволяют решить ее из коробки. Для этого потребуются немалые доработки например, разработка шаблонов документов и реализация интеграционных процессов например, для передачи данных о студентах. Конечно, большинство современных СЭД предоставляют возможности, упрощающие процессы адаптации продукта и внедрения в конкретной организации. Например, в состав СЭД Directum входит предметно-ориентированный инструмент разработки IS-Builder для гибкой настройки системы и Integration Toolset для интеграции с другими решениями. Однако все работы по внедрению должны проводить специалисты, обладающие высокой квалификацией в конкретной СЭД, а для НИУ МЭИ это означало бы привлечение внешних сотрудников, дополнительные затраты и увеличение сроков реализации проекта. Отметим, что у организации уже имеется опыт внедрения коробочного решения платформы Alfresco, которая с 2015 г. используется в МЭИ качестве СЭД. Однако в настоящее время с системой работает лишь малая часть контингента вуза, что не позволяет рассматривать данный продукт для подготовки и согласования заявок на прохождение студентами практик. В контексте автоматизации задач в сфере образования нельзя не упомянуть решения фирмы 1С 1СУниверситет и 1СУниверситет ПРОФ. Системы функционируют в таких вузах, как МЭСИ, МГТУ СТАНКИН и Санкт-Петербургский государственный институт кино и телевидения . Однако, согласно описанию на официальном сайте, текущие возможности по управлению практиками ограничиваются подготовкой графиков распределения, приказов и протоколов распределения. Итерационное согласование несколькими пользователями системы будущих баз практик студентов заявок на практику пока не предусмотрено. Другая проблема готовых решений перегруженность и слабая адаптируемость пользовательского интерфейса. В основном они ориентированы на хорошо подготовленных узкоспециализированных операторов, а в согласовании заявок от кафедр задействованы преподаватели в том числе по нетехническим дисциплинам, которым необходим минимальный, понятный и прозрачный интерфейс решения их задачи. В качестве примера сложного интерфейса можно привести решение 1С, включающее в себя панель разделов, панель открытых, панель инструментов, панель функций текущего раздела, панель избранного, панель истории. Несомненным преимуществом продуктов 1С является возможность настройки интерфейса, что не всегда присуще решениям такого класса. Но, несмотря на это, многим конечным пользователям интуитивно сложно сориентироваться и сразу приступить к выполнению своей задачи. К общим минусам коробочных продуктов были отнесены высокая стоимость некоторых решений, ограничения бесплатных версий, вероятные сложности при интеграции с уже функционирующими системами. В итоге руководством НИУ МЭИ было принято решение о собственной разработке информационной системы под названием Практика ИС Практика. Задача была направлена в отдел разработки и внедрения информационных систем, который взял на себя ответственность решить ее в сжатые сроки. На начальном этапе проекта было утверждено техническое задание, разбивающее систему на несколько модулей. 1. Модуль импорта данных из существующих в МЭИ систем. 2. Модуль График проведения практики, предназначенный для ввода календарного графика практик по каждому институту. 3. Модуль Предприятия, служащий для ведения справочной информации о предприятиях, с которыми взаимодействуют кафедры НИУ МЭИ. 4. Модуль Заявки, предназначенный для формирования и обработки заявок на практику. 5. Модуль подготовки печатных форм. 6. Модуль построения статистической отчетности. Такое разделение позволило вводить в опытную эксплуатацию ИС Практика поэтапно. Рассмотрим модули в порядке их запуска. ИС Практика обеспечивает ежедневный импорт сведений о студентах, учебных группах и организационной структуре МЭИ кафедрах и вышестоящих институтах из функционирующих в МЭИ систем кадрового учета студентов и сотрудников. Импортируемые данные необходимы для начала процесса подготовки любой заявки. Доступ к актуальным спискам учебных групп существенно облегчает работу каждого ответственного от кафедры. позволяет задать связь направления и курса обучения студентов с видом, трудоемкостью и сроками прохождения практики. Данная информация вводится в систему дирекциями институтов и утверждается учебным управлением МЭИ в начале каждого семестра. Выделение в ИС Практика графика проведения практик в отдельный набор таблиц, его утверждение и предоставление доступа к нему в виде справочника при подготовке заявок позволило устранить ошибки в указании сроков и в названии практик. В все внешние организации разделены на две категории партнеры МЭИ и партнеры кафедр. Партнеры МЭИ организации, с которыми заключены долгосрочные договоры. Долгосрочный договор обычно заключается на 5 лет и дает право взаимодействующим с организацией кафедрам направлять в нее студентов на практику по дополнительным соглашениям. Справочник партнеров МЭИ ведет сотрудник ОЗ и ПФО. Партнеры кафедр организации, с которыми заключаются разовые договоры на прохождение практики. У каждой кафедры в ИС Практика собственный справочник партнеров, к которому не имеют доступа другие подразделения. Исключением являются сотрудники ОЗ и ПФО, которые проверяют корректность указанных сведений, а также могут перевести организацию из категории партнер кафедры в категорию партнер МЭИ после заключения долгосрочного договора. Для борьбы с дубликатами, возникающими в случае, если организация одновременно является партнером нескольких кафедр и переходит в категорию партнер МЭИ, предусмотрены функции по слиянию нескольких записей организация и или подписант в одну. Также ИС Практика контролирует появление дублей среди партнеров одной кафедры и партнеров МЭИ по ИНН. Централизованный справочник организаций, с одной стороны, отображает и позволяет актуализировать ОЗ и ПФО сведения более чем о 600 внешних партнерах, а с другой предлагает каждой кафедре личное пространство, не перегружая его чрезмерной информацией. Помимо основных сведений об организации название, ИНН, юридический адрес и др., система позволяет указывать список сотрудников-подписантов, отображает связанные с организацией документы и заявки рис. 2. Внесенные один раз в справочник партнеров данные могут повторно использоваться при распределении новых студентов по базам практик. основная часть ИС Практика. Так как процесс подготовки и обработки заявок тесно связан с появлением изменений, в системе реализована возможность итеративного согласования заявки между кафедрой и ОЗ и ПФО. Для успешной обработки заявка должна преодолеть цепочку из 4 статусов Подготовка на кафедре, Подготовка в ОЗ и ПФО, Обработана в ОЗ и ПФО, Завершена. С каждым статусом ассоциируется определенная информация о состоянии заявки и полномочия различных пользователей. 1. Подготовка на кафедре присваивается новой заявке. В этом статусе с заявкой работает ответственный от кафедры, включая в нее студентов и задавая им базы практики. 2. Подготовка в ОЗ и ПФО. Сотрудник ОЗ и ПФО проверяет корректность данных в заявке и готовит договоры и дополнительные соглашения для подписания. 3. Обработана ОЗ и ПФО сигнал для ответственного от кафедры о том, что распечатанные и подписанные со стороны МЭИ документы можно забирать и направлять для подписи во внешнюю организацию. 4. Завершена. Сотрудник ОЗ и ПФО переводит заявку в этот статус, когда все документы, связанные с заявкой, подготовлены и подписаны заинтересованными сторонами. При выявлении неточностей заявка может быть возвращена в предыдущий статус для доработки. Система позволяет добавлять комментарий при изменении статуса, давая понять, на что именно требуется обратить внимание. Для упрощения процесса согласования было принято организационное решение о возможности разделения одной группы студентов на несколько заявок. Дополнительная сложность заявки вложенность в нее множества документов, которые должны быть подписаны обеими сторонами. В отличие от статуса заявки, которую всегда первым подписывает заведующий кафедрой, для документа в общем случае неизвестна сторона, которая первой его подпишет. Поэтому для документа выделены признаки подписан МЭИ, подписан организацией, аннулирован. Данные характеристики проставляет сотрудник ОЗ и ПФО при получении бумажного подтверждения свершившегося факта. Признак аннулирован может быть использован, например, при изменении базы практики договор с первой организацией расторгается, а студент включается в повторную заявку с новой организацией. Удобства ИС Практика для сотрудников кафедры уже отмечались актуальный список студентов, доступ к утвержденному графику практик, справочник организаций-партнеров. Для сотрудников ОЗ и ПФО помимо указанных удобств реализованы и другие. Например, автоматическое включение в один договор с организацией всех связанных студентов в заявке вручную можно разбить на несколько договоров автоматический выбор внешнего подписанта автоматическая подстановка долгосрочного договора при подготовке дополнительного соглашения автоматическая нумерация заявок кафедр, облегчающая группировку, поиск и сортировку высокоинформативные табличные представления данных рис. 3. Функции понятны из его названия. В ИС Практика утвержден перечень печатных форм, которые могут быть экспортированы в формате Microsoft Word. В перечень входят график проведения практик, заявка на проведение практики рис. 4, долгосрочный договор, дополнительное соглашение, разовый договор, сопроводительное письмо-направление. Для указанных документов генерируется текст, не требующий никаких поправок или изменений. Модуль закрывает все потребности пользователей по подготовке печатных версий документов, начиная с утверждения графика практик и заканчивая подготовкой сопроводительных писем во внешние организации. Обычно совместно с переносом данных в электронный формат решаются задачи аналитики и построения отчетных форм. В ИС Практика для этих целей реализован е . На данный момент разработаны следующие отчеты 1 позволяет отслеживать заявки с учетом заданных критериев, отображает количество заявок в различных статусах с учетом заданных критериев рис. 5 2 в разрезе кафедр предоставляет сведения о количестве студентов, проходящих практику в МЭИ и во внешних организациях 3 позволяет найти документы, соответствующие заданным критериям, например за определенный период, по конкретной кафедре, по типу документа, по курсу учебной группы. Модуль отчетности поддерживает расширение при появлении новых регламентированных периодических запросов разрабатываются отдельные отчетные формы. Ответ на нерегламентированный разовый запрос может подготовить человек, владеющий языком структурированных запросов T-SQL. При разработке любой многопользовательской системы обязательно встает вопрос о разграничении прав доступа. Разграничение прав основывается на идентификации, аутентификации и авторизации. Под первым термином понимается присвоение элементам системы идентификаторов и сопоставление их с определенным ранее перечнем например, присвоение реальному человеку учетной записи пользователя в ИС. Под вторым проверка подлинности элементов системы например, проверка предоставленных пользователем своих учетных данных. Под третьим определение и проверка прав для выполнения конкретных действий в системе например, контроль операций чтения и редактирования пользователей и их прав в ИС. За идентификацию и аутентификацию в ИС Практика отвечает функционирующая в НИУ МЭИ служба каталогов Active Directory. Каждый пользователь имеет пару логин-пароль, которую должен использовать для работы с информационными сервисами НИУ МЭИ. Все необходимые процедуры авторизации ИС Практика обеспечивает самостоятельно. В системе предусмотрено множество разрешений, в том числе параметризуемых, из которых складываются конкретные группы роли пользователей. Параметризуемость означает, что для разрешения можно задать определенную область действия табл. 1. Представленные разрешения могут быть назначены напрямую отдельному пользователю или группе пользователей и уже через нее переданы конкретным пользователям. Из указанных в табл. 1 разрешений складываются основные группы пользователей ИС Практика табл. 2. Разрешения и их возможные области их действия Permissions and Their Possible Scope Разрешение Область действия Р1. Просмотр графика проведения практики Все институты Р2. Редактирование графика проведения практики Конкретный институт Р3. Просмотр предприятия Все подразделения МЭИ в целом и кафедры Р4. Редактирование предприятия Конкретное подразделение Р5. Просмотр заявки в статусе Все статусы Р6. Редактирование заявки в статусе Конкретный статус Р7. Просмотр заявки подразделения Все подразделения Р8. Редактирование заявки подразделения Конкретное подразделение Группы пользователей в ИС Практика User Groups in IS Practice Группа роль ИС Практика Разрешения Сотрудники дирекции института И1 Р1, Р2 для И1 Р5 для Завершена Р7 для кафедр К1, К2, К, входящих в состав И1 Ответственные от кафедры К1, входящий в состав института И1 Р1 для И1 Р3, Р4, Р7, Р8 для К1 Р3 для МЭИ Р5 для Все статусы Р6 для Подготовка на кафедре Сотрудники ОЗ и ПФО Р1 для Все институты Р3, Р4, Р7, Р8 для Все подразделения Р5 для Подготовка в ОЗ и ПФО, Обработана ОЗ и ПФО, Завершена Р6 для Подготовка в ОЗ и ПФО, Обработана ОЗ и ПФО В ИС Практика присутствуют и другие группы пользователей, которые используют как представленные, так и опущенные в данном тексте разрешения. Реализованный механизм разграничения прав, основанный на разрешениях и области их действия, позволяет определять новые группы пользователей и не требует навыков программирования. Другой аспект, связанный с безопасностью программных систем и реализованный в ИС Практика, это протоколирование любых изменений данных и ведение соответствующего журнала аудита. Дополнительно ИС Практика фиксирует дату последнего входа в систему для каждого пользователя. На конец 2018 г. в журнале аудита зафиксировано более 200 000 фактов изменений. Современные программные системы обычно работают согласно клиент-серверной архитектуре и предоставляют своим пользователям веб-интерфейс. Указанный подход имеет множество преимуществ, среди которых снижение аппаратных и программных требований к рабочим машинам конечных пользователей повышение доступности с системой можно работать из любой точки мира, имеющей доступ к глобальной сети Интернет, и с устройств различных видов и размеров упрощение процедуры выпуска новых версий программного продукта. ИС Практика реализована по клиент-серверной архитектуре на стеке технологий компании Microsoft. Сервер работает под управлением операционной системы Microsoft Windows Server 2012 R2 64-разрядная версия и имеет следующие аппаратные характеристики процессор Intel Xeon X5675 3.07GHz, объем оперативной памяти 8 ГБ, жесткий диск 60 ГБ. Помимо ИС Практика, указанный сервер обслуживает и другие информационные системы, функционирующие в НИУ МЭИ. За управление базой данных отвечает SQL Server 2012 SP 2, за обработку веб-запросов Internet Information Services IIS 8.5. Задействованные технологии достаточно давно и успешно используются при решении аналогичных задач, они сопровождаются и активно развиваются компанией Microsoft и по праву занимают немалую долю рынка современных ИТ-решений. При разработке ИС Практика использован фреймворк ASP.NET MVC, реализующий шаблон разделения исходного кода Модель-Представление-Контроллер или Model-ViewController. Для доступа к данным используется объектно-реляционное отображение с помощью технологии ADO.NET Entity Framework. Адаптивный пользовательский интерфейс строится на базе Bootstrap и использует входящие в его состав HTML и CSS шаблоны. Основными компонентами для реализации интерактивности на веб-страницах ИС Практика являются язык JavaScript, библиотека JQuery и ряд плагинов Bootstrap и JQuery. При формировании документов в формате Microsoft Word DOCX задействован набор средств разработки Open XML SDK, позволяющий работать с электронными документами в серии форматов Office Open XML, включающей DOCX. Для разработки сводных отчетов применяется служба SQL Server Reporting Services, являющаяся дополнением к системе управления базами данных SQL Server. Наконец, собрать воедино все перечисленные технологии и многие другие позволяет среда разработки Microsoft Visual Studio MSVS. MSVS, без сомнения, один из самых передовых, современных и мощных инструментов для разработки приложений любой сложности. В отличие от многообразия и сложности технологий разработки ИС Практика для пользователя системы все значительно проще. Работать с ИС можно через любой современный веббраузер Internet Explorer, EDGE, Google Chrome, Firefox и др.. ИС практика запускалась поэтапно начиная с марта 2018 г. На первом этапе ответственные от дирекций институтов внесли и утвердили в системе графики прохождения практик. На втором этапе ответственным от кафедр и сотрудникам ОЗ и ПФО был открыт доступ к справочнику организаций-партнеров. Третьим этапом был запущен модуль подготовки и согласования заявок на проведение практик. Запуск этапов сопровождался публикацией на веб-портале МЭИ информационных писем. Они разъясняли регламент работы с новой системой и обязывали ответственных лиц работать в ИС Практика. В рамках подготовки пользователей к работе в новой системе отделом разработки и внедрения информационных систем была подготовлена инструкция, рассматривающая решение задач различных категорий пользователей. Помимо этого, было проведено обучение ряда пользователей и предложены очные консультации по отдельным вопросам. Большинство пользователей позитивно отнеслись к запуску ИС Практика. Система не была заменой уже функционирующей, а являлась принципиально новым подходом к автоматизации ряда рутинных задач. Возможно, именно поэтому при внедрении практически отсутствовало сопротивление со стороны пользователей. В отдел разработки поступало немало предложений по улучшению функционала системы. В основном пожелания относились к повышению информативности реализованных вебформ. Например, добавить в таблицу заявок отображение связанных документов столбец Документы на рис. 3. Такие доработки оперативно вносились в функционал ИС Практика. Используемые при разработке проекта веб-технологии позволили без труда обновлять функционал, доступный конечным пользователям. Замечаний к реализованному в системе бизнес-процессу направления студентов на практику не было. Конечно, этот процесс имел уже достаточно устоявшийся характер, но всетаки требовал некоторой формализации для воплощения в программной системе. По результатам работы ИС Практика в двух семестрах весеннем 20172018 и осеннем 20182019 можно отметить следующие факты в работе задействованы сотрудники ОЗ и ПФО, 11 институтов и почти 50 кафедр к системе обращается более 110 пользователей заведено более 650 организаций-партнеров сформировано более 3 000 направлений студентов на практику обработано почти 400 заявок кафедр подготовлено более 900 документов. В ходе запуска проекта система получила дополнительный функционал для сбора сведений от выпускающих кафедр о трудоустройстве студентов и была интегрирована с другими системами, функционирующими в МЭИ подготовка приказов на проведение практики в системе учета контингента студентов ИС Студент. Обработка данных в электронном формате позволила повысить скорость и точность подготовки статистических сводок. В современном мире информатизация стала неотъемлемой частью любого процесса, связанного с обработкой данных, а сами данные ценным ресурсом их владельца. ИС Практика частично решает задачи, связанные с документооборотом, возникающим внутри МЭИ и между МЭИ и организациями-партнерами. У решения видны определенные перспективы и варианты развития охват новых участников процесса студенты, руководители практики, представители внешних организаций и др. и автоматизация подготовки прочих документов задание на практику, отчет по практике и др.. Перед разработчиками системы не стояла задача охвата всевозможных процессов в сфере образования, связанных с подготовкой и согласованием документов. С одной стороны, это можно считать недостатком область применения достаточно ограничена, но с другой преимуществом. Специфика присутствует практически всегда, и тяжеловесные продукты широкого профиля зачастую не подходят для решения узконаправленных задач, тогда выбор падает на небольшие специализированные системы. Хотя они и не обладают множеством функций в том числе и слабо востребованных универсальных продуктов, но превосходят их ориентированностью на конкретную задачу и нередко позволяют решить ее наилучшим образом. ИС Практика следует относить к классу именно таких специализированных систем. Современные образовательные учреждения РФ обязаны проводить практику для обучаемых студентов. Многие из них достаточно глубоко изучают и анализируют этот процесс и его особенности 14. Их цель заключается в улучшении результатов проведения практики в целом и в совершенствовании процессов распределения студентов по базам практик и подготовки сопроводительной документации в частности 12 13. Представленный в статье опыт будет, несомненно, им интересен, а описанные технические решения могут быть адаптированы с учетом специфики конкретного образовательного учреждения и применены для автоматизации указанных выше процессов. "}
{"title": "ПЛАТФОРМА КОМПЛЕКСИРОВАНИЯ И ТЕСТИРОВАНИЯ   СРЕДСТВ ТРАНСФОРМАЦИИ ЕСТЕСТВЕННО-ЯЗЫКОВЫХ ЗАПРОСОВ   В SPARQL-ЗАПРОСЫ  ", "absract": "Статья посвящена вопросу поддержки процесса создания средства трансформации естественно-языковых (ЕЯ) запросов в SPARQL-запросы (далее – средство трансформации). Во введении описаны актуальность задачи понимания ЕЯ-запросов информационными системами, а также преимущества использования онтологий как средства представления знаний для решения данной задачи. Обозначена роль средств трансформации в системах с ЕЯ-запросами к реляционным базам данных. На основании анализа проблем, связанных с комплексированием и тестированием существующих средств трансформации,  а также с целью поддержки создания и тестирования собственных модулей трансформации предложена концепция программной платформы, упрощающей эти задачи. Архитектура платформы удовлетворяет требованиям простоты подключения сторонних средств трансформации, переиспользования отдельных модулей,  а также интеграции результирующих средств трансформации в другие системы, в том числе в системы тестирования. Строительными блоками создаваемых систем трансформации служат отдельные модули трансформации, упакованные в Docker-контейнеры. Программный доступ к каждому модулю осуществляется при помощи gRPC. Загруженные в платформу модули могут быть выстроены в конвейер трансформации автоматически или вручную при помощи встроенного стороннего редактора диаграмм потоков данных SciVi. Совместимость отдельных модулей контролируется при помощи автоматического анализа программных интерфейсов. На основании спецификации конвейера в формате, поддерживаемом SciVi, а также gRPC-спецификаций отдельных модулей комплексируется единое многоконтейнерное приложение, которое может быть интегрировано в другие системы, а также протестировано на пополняемом наборе тестов. Ожидаемые и фактические результаты трансформации запроса доступны для просмотра в графическом виде в разработанном ранее средстве визуализации. ", "text": " В современном мире все чаще используются естественно-языковые ЕЯ интерфейсы для взаимодействия с различными информационными системами. Примером этого может служить разговор на естественном языке с роботом-промоутером на выставке или в торговом центре, где любой человек вне зависимости от знаний в области информационных технологий может задать вопрос о товаре, услуге, получить ответ и, возможно, сразу же оформить новый заказ. Те же подходы к человеко-машинному взаимодействию активно применяются и в виртуальных ассистентах, работающих не только в мобильных устройствах Яндекс Алиса, Google Ассистент, Apple Siri, но и в умных колонках, являющихся центральными узлами систем домашней автоматизации Яндекс Станция, Google Home, Apple HomePod. Взаимодействие с такими системами может быть не только устное, но и письменное при помощи приложений обмена мгновенными сообщениями. Для внутренних нужд компаний корпоративного сектора естественно-языковой интерфейс используется при общении с чат-ботами в корпоративных мессенджерах. Традиционным способом реализации таких чат-ботов является сопоставление текста запроса с образцом и выдача результата, полученного предопределенным для сопоставленного шаблона способом. Для предоставления возможности задания более сложных, нерегламентированных запросов следует использовать знания, которые бы определяли процесс вывода ответа на запрос. В качестве средства представления знаний можно использовать онтологии. Онтология это точная спецификация концептуализации 1, ключевыми элементами которой являются понятия и связи между ними. К настоящему моменту существуют стандарт OWL для записи онтологий в машиночитаемом виде, средства программной обработки и вывода на онтологиях. Активно развивается исследовательское направление организации доступа к данным, основанного на онтологиях Ontology-based Data Access, OBDA 2. Существенная часть исследований в области OBDA посвящена предоставлению виртуального доступа к данным, хранящимся в реляционных базах данных, т. е. трансформации запросов на языке SPARQL в запросы на языке SQL. Ранее в работе 3 была предложена концепция обогащения унаследованных информационных систем сервисом запросов на естественном языке . Основными идеями концепции были двухэтапная трансформация ЕЯ-запроса в SQL-запрос с использованием промежуточного представления в виде SPARQL-запроса, а также автоматизация конфигурирования как используемых OBDA-фреймворков, так и всей системы в целом. Reply разрабатывался как сервис для трансформации традиционных информационных систем в интеллектуальные системы с запросами на естественном языке безотносительно предметной области исходной информационной системы, а также к целевому языку запросов русский, английский. В то же время для получения более качественного и полного ответа на запросы пользователей в каждом конкретном случае следует предусмотреть возможность выбора оптимального средства трансформации ЕЯ-запроса в SPARQL-запрос либо сборки нового средства на основе существующих модулей. В данной статье описана разрабо танная платформа комплексирования и тестирования средств трансформации ЕЯ-запросов в SPARQL-запросы для поддержки этого процесса. Под комплексированием в работе понимается процесс объединения системных элементов для производства полной системы . В настоящем разделе описываются экосистема, современные подходы и существующие реализации средств трансформации. Идея, положенная в основу вопросно-ответной системы AskNow 4, заключается в использовании в качестве промежуточного представления особой синтаксической структуры, названной авторами нормализованной структурой запроса Normalized Query Structure NQS. На первом этапе исходный ЕЯ-запрос должен быть преобразован в соответствующую ему NQS. Для этого с помощью модуля Query Processor запрос разбивается на отдельные токены, которые впоследствии помечаются тегами частей речи part-of-speech tag, POS-тег. Модуль Auxiliary Relation Handler выделяет вспомогательное отношение отношение, которое содержит лексические формы выражений is, is kind of, much, might be, does. Модуль Token Merger объединяет токены в сегменты исходя из их POS-тегов и положения в запросе. Выделенные сегменты проходят через модуль NQS Instance Generator, который строит итоговую NQS по определенным правилам. После этого построение SPARQL-запроса по нормализованной структуре запроса происходит также в несколько этапов. Модуль NQS Parser определяет тип запроса по его NQS и сопоставляет с сегментами запроса наиболее подходящие элементы онтологии DBpedia с помощью сервиса DBpedia Spotlight. Для решения проблем с отображением сегментов на онтологию используется электронный тезаурус WordNet. В нем осуществляется поиск синонимов для неопределенных сегментов. Используя результаты предыдущих этапов, модуль SPARQL Generator преобразует NQS в итоговый SPARQLзапрос. Работа вопросно-ответной системы Sina 5 разделяется на четыре этапа. На первом этапе производится предобработка запроса выделяются токены в виде отдельных ключевых слов, удаляются стоп-слова, выполняется лемматизация. На втором этапе ключевые слова различным образом объединяются в сегменты N-граммы, каждый сегмент проверяется на возможность соответствия некоторому элементу онтологии. Далее на третьем этапе для всех подходящих сегментов ведется поиск соответствующего ресурса в онтологии по свойству rdfslabel. На этапе устранения неоднозначностей disambiguation выбирается подграф из базы знаний, наиболее соответствующий исходному запросу. Далее по полученному подграфу строится SPARQL-запрос. Вопросно-ответная система Xser 6 представляет собой конвейер из двух этапов выделение из запроса возможных семантических структур экземпляров, классов, отношений, и отображение выделенных структур на элементы онтологии. На первом этапе происходит разметка исходного запроса с использованием меток начало фразы-отношения, продолжение фразы-экземпляра и т. п. По полученной разметке строится ациклический ориентированный граф зависимостей фраз. На втором этапе полученный граф преобразуется в запрос к онтологии. Так как с каждой фразой, являющейся элементом графа зависимостей, может быть сопоставлено более одного элемента онтологии, все возможные отображения ранжируются, и выбирается наилучшее. В качестве метрики выступает произведение нормированных результатов функции похожести для каждого слова, полученных с помощью Freebase Search API для запросов к базе знаний Freebase. Хотя в описанных системах используются разные методы и средства для преобразования ЕЯ-запросов в SPARQL-запросы, в процессе трансформации можно выделить одинаковые этапы 7. Этап анализа естественно-языкового запроса может включать определение типа запроса, выделение именованных сущностей, определение зависимостей между частями предложения, построение синтаксического дерева запроса и т. д. На этапе отображения сегментов запроса на элементы онтологии происходит поиск подходящих определенной части запроса экземпляров, классов и отношений онтологии. Так как из-за наличия неоднозначностей в естественном языке многозначность, омонимия и т. п. с одним сегментом запроса могли быть сопоставлены несколько ресурсов онтологии, в каждом случае необходимо определить наиболее подходящий к контексту ресурс. Эти проблемы решаются на этапе устранения неоднозначностей. На этапе построения SPARQL-запроса определяется необходимый тип запроса SELECT, ASK, строится основной графовый шаблон запроса. Возможность выделения отдельных этапов при решении задач обработки естественного языка привела к появлению универсальных платформ по анализу и преобразованию текстов. Примерами таких платформ служат NLTK 8 и TAISim 9. Кроме того, существуют платформы, позволяющие конструировать программные средства, решающие более частные задачи данной области знаний, в том числе задачу трансформации ЕЯ-запроса в SPARQLзапрос. Qanary 10 система для комплексирования средств трансформации ЕЯ-запросов из отдельных компонентов. Согласно методологии разработки вопросно-ответных систем, предложенной авторами Qanary, компоненты системы должны взаимодействовать посредством аннотаций, определенных в словаре Qanary, построенном на основе модели аннотаций WADM. Qanary Pipeline центральный компонент системы представляет собой сервер, к которому подключаются остальные компоненты посредством RESTful интерфейса с помощью фреймворка Spring. Qanary Pipeline имеет веб-интерфейс для выбора компонентов для текущего конвейера, определения их порядка и запуска конвейера с некоторым исходным запросом. Пользовательские компоненты также должны быть реализованы в виде сервисов. Разработчики Qanary предоставляют шаблон Maven-приложения на Java для создания компонента. Шаблон включает код для запуска Spring-сервиса и пустую реализацию Qanaryкомпонента. При запуске сервиса отправляется запрос на регистрацию компонента в системе. При вызове компонента из Qanary Pipeline он получает входные данные и сохраняет результат своей работы с помощью извлечения и добавления аннотаций в служебную онтологию посредством выполнения SPARQL-запросов. При необходимости использования других технологий разработчик может вызвать свою реализацию из Java-компонента. Собранная с помощью Qanary-фреймворка система может быть интегрирована в другие системы как Springсервис. В работе 11 представлен фреймворк QALL-ME, предоставляющий переиспользуемую архитектуру для создания мультиязычных вопросно-ответных систем, учитывающих пространственно-временной контекст запроса. Авторы декомпозируют процесс трансформации на этапы и сопоставляют с каждым этапом отдельный тип компонентов, например аннотаторы именованных сущностей для различных языков. В QALL-ME компоненты разделяются на три типа языкозависимые, пространственно-зависимые и общесистемные компоненты, реализация которых одинакова для всех языков и местоположений. Фреймворк поддерживает сервис-ориентированную архитектуру компоненты системы реализуются в виде веб-сер висов, а их программный интерфейс описывается на языке WSDL Web Service Description Language. QALL-ME не является средством комплексирования средств трансформации. Цель создания фреймворка упрощение разработки мультиязычных вопросно-ответных систем. В частности, реализация содержит методы для вызова компонента определенного типа, подходящего для языковых и пространственных характеристик запроса. Архитектура средства трансформации должна быть определена заранее, и последовательный вызов компонент должен быть запрограммирован. QALL-ME позволяет расширять возможности системы посредством написания компонентов для других языков и местоположений и регистрации пользовательских компонентов в QAPlanner ядре системы с помощью отправки запросов. Так как компоненты являются веб-сервисами, они могут быть реализованы с использованием любых языков программирования и технологий. openQA 12 расширяемый вопросно-ответный фреймворк. Он нацелен на улучшение качества ответов на естественно-языковые запросы путем комбинирования результатов работы нескольких систем. Обработка пользовательского запроса происходит в четыре этапа интерпретация запроса в запрос на формальном языке, получение результатов запроса, синтез и представление результатов. На первом этапе ЕЯ-запрос обрабатывается всеми активными модулями интерпретации, например, в качестве таких модулей в openQA присутствуют реализации вопросно-ответных систем Sina и TBSL. Далее из источника извлекаются результаты выполнения полученных запросов на формальных языках SPARQL, SQL. На третьем этапе результаты ранжируются по релевантности, на четвертом представляются пользователю. К openQA можно подключить пользовательские модули для каждого этапа, однако они должны быть реализованы в виде Java-плагинов. Фреймворк не поддерживает возможность комплексирования модуля интерпретации из нескольких компонент. Собранная система представляет собой сервис и доступна через RESTful интерфейс. Основными критериями для сравнения существующих платформ были выбраны 1 предъявляемые требования к степени связывания как непосредственно между модулями, так и между модулями и платформой 2 наличие средств поддержки процесса развертывания создаваемых систем. Основной принцип связывания состоит в уменьшении числа допущений, которые делают друг о друге взаимодействующие стороны 13. Возможность слабого связывания трактуется как преимущество платформы, поскольку упрощается процесс подмены реа лизации, тем самым ускоряется поиск наилучшей комбинации модулей средства трансформации. Среди рассмотренных выше существующих платформ построения средств трансформации системой с сильным связыванием является система openQA, требующая оформления отдельных модулей системы в виде Java-плагинов, тем самым ограничивающая возможности для использования прочих языков программирования. Даже при наличии возможности написания программной обертки на языке Java, разработчику требуется самостоятельно организовывать коммуникацию между программами на языке Java и языке программирования ядра модуля трансформации. Qanary позволяет создавать системы на принципах слабого связывания, однако коммуникация между отдельными модулями осуществляется при помощи модификации глобального состояния множества аннотаций онтологии. Для модулей отсутствует формальное описание того, какие именно категории аннотаций будут добавлены, удалены, изменены в процессе работы. Корректность создаваемого конвейера в случае зависимости одного модуля от результатов работы другого модуля в данной платформе может быть проверена только на этапе исполнения. QALL-ME также позволяет создавать системы на принципах слабого связывания, причем API каждого из сервисов описывается на языке WSDL. Наличие формального описания позволяет генерировать клиентские и или серверные части взаимодействующих компонентов. Недостатком данного подхода является выбор технологий веб-сервисов для взаимодействия компонент. У данной технологии есть проблемы с производительностью, объясняемые использованием XML и HTTP 1.1 для передачи сообщений. Кроме того, в QALL-ME существенно ограничены типы модулей, для которых можно предоставить собственную реализацию. Рассмотренные платформы не ориентированы на поддержку процесса развертывания итогового средства трансформации с учетом требований к среде исполнения отдельных модулей, а также с учетом потенциальной противоречивости этих требований. Например, несколько модулей могут зависеть от разных версий одной программной библиотеки, которая должна располагаться по одному и тому же предопределенному системному пути. В таком случае без дополнительного вмешательства на этапе сборки или запуска средства трансформации использование комбинации этих модулей будет невозможно. Для сравнения средств трансформации необходимо производить их тестирование. На данный момент существуют тестовые наборы запросов и соответствующих эталонных SPARQL-запросов к различным онтологиям. Большинство тестовых наборов 14 15 содержат запросы к обширным базам знаний общего назначения, таким как DBpedia, Freebase, YAGO. Например, с 2011 г. в рамках серии соревнований QALD 16 для оценки вопросноответных систем организаторами было разработано более десяти тестовых наборов запросов к DBpedia, среди которых помимо англоязычных наборов присутствует несколько мульти язычных. Тестовые наборы составляются вручную группой людей и включают в себя запросы различных типов и сложности, поэтому с их помощью можно провести качественную оценку вопросно-ответных систем. Наличие в платформе комплексирования средств трансформации возможности проверки собранных систем на существующих тестовых наборах запросов, а также наглядного просмотра результатов таких тестов существенно упростит процесс разработки. На основании анализа недостатков описанных ранее программных средств было принято решение о разработке собственной платформы комплексирования и тестирования средств трансформации. Основные требования к платформе 1 минимальность предъявляемых ограничений на технологии, используемые модулями трансформации 2 проверка совместимости интерфейсов модулей на этапе комплексирования 3 эффективность технологий межмодульной коммуникации 4 возможность проведения тестирования средств трансформации и визуализации его результатов 5 простота встраивания системы в сторонние интеллектуальные информационные системы. Для удовлетворения этих требований в качестве ключевых технологий были выбраны программная платформа контейнеризации Docker и система удаленного вызова процедур gRPC . Использование технологии контейнеризации позволяет разработчику модуля однократно настроить изолированное воспроизводимое окружение исполнения программного кода. Кроме того, существующие средства согласованного запуска нескольких контейнеров позволяют автоматизировать процесс сборки и запуска созданного при помощи платформы средства трансформации, в том числе как часть сторонних систем. Система удаленного вызова процедур gRPC требует формального описания сервисов на языке описания интерфейсов Protocol Buffers . Использование этого описания позволяет автоматически проверять совместимость интерфейсов сервисов, а также автоматически генерировать программный код по комплексированию отдельных сервисов. Требование реализации gRPC-интерфейса существенно не ограничивает разработчика модулей трансформации. Поддержка gRPC реализована для всех наиболее популярных современных языков программирования, а значительная часть программного кода для сетевого взаимодействия может быть сгенерирована автоматически. Еще одним преимуществом gRPC является эффективность при передаче сообщений за счет жесткости протокола, использования бинарной сериализации и HTTP 2.0 в качестве транспорта. На этапе проектирования были выделены следующие сценарии использования плат формы 1 управление модулями трансформации 2 комплексирование средств трансформации 3 проведение тестирования средств трансформации 4 анализ результатов тестирования средств трансформации 5 выгрузка созданного средства трансформации. В сценарии основной операцией является загрузка новых модулей трансформации в платформу. Для этого пользователь заблаговременно загружает в приватный Docker-репозиторий платформы Docker-образ программного модуля, предоставляющий после запуска gRPC-сервис. В пользовательском интерфейсе платформы пользователь добавляет новый модуль, указывая его имя, категорию, а также формальную спецификацию gRPC-сервиса при помощи proto-файла. Впоследствии пользователь может отредактировать эти параметры. В сценарии пользователь выстраивает конвейер трансформации из загруженных в платформу модулей. Доступные модули отображаются в палитре модулей редактора диаграмм потоков данных системы научной визуализации SciVi 17. Для пополнения этой палитры разработанная платформа на основании загруженного формального описания интерфейса каждого модуля на языке описания сервисов gRPC Protobuf автоматически формирует правила конфигурации в онтологическом формате, используемом редактором. В редакторе пользователь может перетащить необходимые модули из палитры в область редактирования диаграммы, после чего соединить соответствующие сокеты входы и выходы узлов вершин рис. 1. Редактор позволяет отфильтровывать только совместимые с выбранным модули трансформации, а также проверять корректность создаваемых дуг. Построенную диаграмму трансформации можно сохранить в платформе с целью последующего редактирования. После сохранения диаграммы в фоновом режиме запускается процесс комплексирования средства трансформации, соответствующего этой диаграмме. Для этого в копию заранее подготовленного шаблона проекта на языке Scala добавляются proto-файлы с описанием всех сервисов модулей, использованных в диаграмме. Затем автоматически генерируется программный код на языке Scala, который последовательно либо параллельно в зависимости от дуг в диаграмме осуществляет соответствующие gRPC-вызовы. Полученный проект компилируется и упаковывается в Docker-контейнер. После этого автоматически формируется соответствующий диаграмме конфигурационный файл для утилиты Docker Compose, позволяющей установить зависимости между Docker-контейнерами всех использованных модулей трансформации, а также настроить их совместный запуск. В платформе имеется возможность автоматической генерации нескольких средств трансформации по одной диаграмме. В таком случае генерируются альтернативные конвейеры трансформации, в которых отдельные модули заменены на другие совместимые по интерфейсу модули того же класса. В сценарии пользователь выбирает одно или несколько комплексированных ранее средств трансформации и запускает их тестирование на одном или нескольких заранее подготовленных тестовых наборах. В настоящий момент тестовые наборы представляют собой множества из кортежей следующей структуры 1 исходный естественно-языковой запрос 2 ожидаемый результирующий SPARQL-запрос 3 онтология, к которой задается запрос. В сценарии пользователь может просмотреть результаты тестирования в срезах по средствам трансформации и по тестовым наборам. Для каждого тестового случая пользователь может, не выходя из при ложения, просмотреть ожидаемый и фактический результат трансформации ЕЯ-запроса в SPARQL-запрос в наглядном виде с использованием разработанного ранее средства визуального графического представления 18. В сценарии пользователь скачивает созданный на этапе комплексирования файл конфигурации для утилиты Docker Compose docker-compose.yml. Благодаря принятым архитектурным решениям этого файла достаточно для автоматической загрузки и развертывания комплексированного средства трансформации на любом компьютере пользователя при возможности подключения к приватному Docker-репозиторию платформы. При загрузке модуля в платформу пользователь сопровождает его спецификацией сервиса на языке описания интерфейсов Protocol Buffers. Спецификация содержит имя сервиса, названия реализуемых сервисом серверных частей удаленных процедур, форматы входных и выходных сообщений. Встроенный сторонний редактор диаграмм потоков данных SciVi принимает на вход онтологическое описание модулей для добавления их в палитру редактора, отображения входных и выходных параметров модуля и анализа их совместимости. Для разбора файла спецификации и преобразования описания сервиса в требуемое SciVi онтологическое описание были использованы классы FileDescriptorSet, FileDescriptorProto и DescriptorProto из официальной библиотеки Protocol Buffers, позволяющие получить объектное представление спецификации сервисов. В качестве языка программирования для автоматически генерируемого кода конвейера трансформации был выбран язык Scala. Статическая типизация и компилируемость этого языка позволяла на этапе разработки платформы быстрее находить некоторые ошибки в сгенерированном программном коде без необходимости запуска тестов. Кроме того, в системе сборки Scala build tool sbt были использованы релевантные для задачи плагины ScalaPB и sbt Native Packager. ScalaPB позволяет автоматически сгенерировать программный код gRPC-клиента на этапе компиляции без необходимости вызова сторонних программ генерации. sbt Native Packager позволяет автоматически упаковать Scala-приложение в Dockerконтейнер и опубликовать его в задаваемом в параметрах проекта репозитории. Исходя из того, что на данном этапе развития платформы предполагается, что пользователь в редакторе диаграмм потоков данных может строить только направленные ациклические графы, программный код конвейера трансформации генерируется с учетом возможных параллельных дуг графа. В таком случае более эффективным является параллельное выполнение запросов к отдельным модулям трансформации в асинхронном режиме. Для представления результатов асинхронных вызовов удаленных процедур gRPC в Scala используется класс Future, представляющий собой программную обертку над значением, которое в данный момент может быть еще не вычислено. Несмотря на возможное отсутствие значений, экземпляры классов Future можно комбинировать между собой в неблокирующем режиме. Благодаря этому весь генерируемый программный код представляет собой цепочку из неблокирующих вызовов с соответствующим параллельным исполнением запросов см. пример в следующем разделе. Для демонстрации разработанной платформы была рассмотрена задача создания системы для трансформации ЕЯ-запросов в SPARQL-запросы к базе знаний Geobase . База знаний предоставляется в виде фактов на языке Prolog. Для преобразования Prolog-фактов в OWL были использованы правила отображения, представленные в работе 19. В качестве модулей системы были выбраны сторонние компоненты стеммер NLTK Snowball stemmer Python 8, парсер зависимостей Stanford Parser Java 20. Кроме того, были созданы демонстрационные компоненты NER Component Kotlin, Entity Linker Kotlin, Query Constructor Kotlin, решающие задачи отображения токенов запроса на ресурсы онтологии и построения SPARQL-запроса по множеству найденных ресурсов. Для каждого модуля была создана программная обертка, предоставляющая gRPC-сервис. Каждый модуль был загружен в Docker-репозиторий и зарегистрирован в разработанной платформе. Для каждого модуля автоматически сформирован файл с онтологическим описа нием в формате использованного редактора диаграмм потоков данных. На рис. 2 приведен скриншот графического представления фрагмента автоматически сформированной онтологии графическое представление создано при помощи редактора онтологий ОНТОЛИС 2.0 21. После этого при помощи редактора диаграмм потоков данных был построен граф трансформации ЕЯ-запроса в SPARQL-запрос см. рис. 1. На основании этого графа был автоматически сгенерирован и скомпилирован Scala-проект, выполняющий трансформацию запроса посредством удаленного вызова процедур использованных модулей в соответствии со спецификацией пользователя. В листингах 15 приведены результаты работы всех модулей трансформации в виде текстового представления сообщений Protocol Buffers на примере запроса What states does the Mississippi run through. Листинг 1. Результат работы модуля Stanford parser Listing 1. Stanford Parser Modules Result Листинг 2. Результат работы модуля Entity linker Listing 2. Entity Linker Modules Result Листинг 3. Результат работы модуля NLTK Snowball stemmer Listing 3. NLTK Snowball Stemmer Modules Result Листинг 4. Результат работы модуля NER component Listing 4. NER Component Modules Result Листинг 5. Результат работы модуля Query constructor Listing 5. Query Constructor Modules Result Собранный проект был автоматически упакован в Docker-контейнер и загружен в приватный Docker-репозиторий платформы. Листинг 6. Фрагмент автоматически сгенерированного кода вызова модулей трансформации Listing 6. Fragment of Automatically Generated Code which Calls Transformation Modules С целью демонстрации пользовательского интерфейса просмотров результатов тестирования комплексированное средство трансформации было протестировано на наборе из 250 запросов Geoquery. На рис. 3 приведен пример просмотра результата модели на наборе тестов, а на рис. 4 пример просмотра ожидаемых и фактических результатов тестового случая. В работе были рассмотрены некоторые из современных средств трансформации ЕЯ-за просов в SPARQL-запросы. На основании схожести этапов их работы, а также по причине выявленных ограничений существующих платформ создания средств трансформации была сформулирована задача разработки собственной платформы комплексирования и тестирования средств трансформации. Удовлетворение сформулированных к платформе требований было достигнуто при помощи использования двух ключевых технологий программной платформы контейнеризации и системы удаленного вызова процедур . Их использование позволило реализовать поддержку комплексирования переносимой системы из модулей, использующих наиболее подходящие для того или иного этапа программные технологии. Описанная платформа автоматизирует многие процессы разработки средств трансформации созданы средства поддержки связывания отдельных модулей с поддержкой автоматической проверки корректности, создана система автоматического комплексирования средств трансформации на основе графа трансформации, создана система тестирования, интегрированная с разработанной ранее системой визуализации результатов трансформации. В будущем планируется автоматически генерировать средства трансформации произвольной структуры в дополнение к реализованной возможности генерации альтернативных средств заданной структуры, а также отображать различия между ожидаемым и фактическим результатами трансформации в наглядном виде при помощи визуального графического представления онтологии. "}
{"title": "ВОССТАНОВЛЕНИЕ ТРЕХМЕРНОЙ ГЕОМЕТРИИ СОСУДОВ   ПО ДАННЫМ КОМПЬЮТЕРНОЙ ТОМОГРАФИИ ", "absract": "Рассматриваются алгоритмы построения триангуляции внутренней поверхности коронарных артерий сердца по данным компьютерной томографии. Точное определение геометрии сосудов необходимо для построения гидродинамической модели кровоснабжения сердца и расчета параметров кровотока с помощью уравнений Навье – Стокса. Для восстановления трехмерной геометрии применяется комбинация двух основных методов: трехмерного алгоритма роста области из семени и ячеечного метода, использующего разбиение пространства на тетраэдры. При этом используется тетраэдрическая сеть, предложенная в работах S. Chan, E. Purisima (1998) и V. Skala (2000), в которой тетраэдры строятся в кубической решетке на общих гранях смежных кубов. Эта сеть строится не на всем пространстве, а только в окрестности границы множества вокселей, вычисленного на первом этапе как результат применения трехмерного алгоритма роста области. ", "text": " Ишемическая болезнь сердца является одним из самых распространенных заболеваний. Ее основной причиной является нарушение кровоснабжения сердечных мышц, связанное, как правило, с сужением коронарных артерий стеноз. В настоящее время имеются достаточно эффективные методы ее лечения, главным из которых является установка расширителей сосудов стентов. Для этого в коронарную артерию вводится катетер. Перед проведением подобной операции необходимо вначале убедиться в ее необходимости. Одним из основных критериев является так называемая величина FFR fraction flow reserve, показывающая, насколько уменьшается кровоток в месте сужения артерии. FFR определяется как отношение давления крови в точках до и после сужения. В медицине используется так называемый золотой стандарт измерения FFR, использующий инвазивный метод введение катетера с датчиком давления в артерию. Несмотря на то, что в настоящее время эта процедура хорошо отработана и может быть совмещена с установкой стента, желательно все-таки иметь возможность определить FFR каким-либо неинвазивным методом, например, используя данные компьютерной томографии области сердца. Это поможет избежать введения катетера в коронарную артерию в случаях, когда нет необходимости в установке стента. При исследовании кровеносных сосудов с помощью компьютерной томографии в кровь пациента через вену вводится контрастное вещество, резко увеличивающее степень поглощения рентгеновских лучей кровью. Томографические срезы, полученные компьютерным томографом, представляют собой матрицы размером 512 512, содержащие двухбайтовые целые числа со знаком. Их величины обозначаются через HU housfield units, они отражают степень поглощения рентгеновских лучей тканью пациента в данной точке среза. Величина HU воздуха равна 1 024, воды 0, крови без контрастного вещества около 4050. При введении контрастного вещества в кровь ее HU резко возрастает до нескольких сотен, и кровеносные сосуды становятся хорошо различимыми на фоне окружающих тканей. Данная работа является частью проекта создания компьютерной модели кровоснабжения сердца для конкретного пациента. Основная идея состоит в том, чтобы определить всевозможные параметры кровотока методами гидродинамики, применяя численные методы решения уравнений течения жидкости уравнения Навье Стокса, уравнение состояния и др. Эти численные методы предполагают построение геометрии расчетной области в виде задания ее триангуляции, затем вычисление расчетной сетки и численное решение по этой сетке дифференциальных уравнений в частных производных. Предполагается использовать систему FlowVision 1 2, успешно применяемую в расчетах, необходимых для кораблей, турбин, летательных аппаратов и т. п. Для ее применения в области медицинской диагностики при изучении системы кровообращения требуется на первом шаге точно воссоздать трехмерную геометрию кровеносных сосудов, в нашем случае аорты и коронарных артерий. В данной работе рассматривается именно эта задача. Томографические срезы представляют собой последовательность параллельных сечений тела пациента. Современный томограф позволяет за очень короткое время около 0,35 с получить серию срезов с очень высоким разрешением обычно сканируется область размером 16 см по оси вертикальной оси тела пациента с шагом 0,25 мм по вертикали, при этом горизонтальные размеры пикселя по осям и равны 0,5 мм. Компьютерный томограф практически мгновенно выдает серию из 640 срезов в области сердца. Эти срезы определяют функцию рентгеновской плотности ткани человеческого тела в трехмерном пространстве, в промежутках между срезами она вычисляется с помощью интерполяции. Стандарт DICOM digital imaging and communication in medicine определяет следующие направления координатных осей ось направлена от правой части тела пациента к левой Right Left, ось от передней стороны тела к задней Anterior Posterior, ось от ног к голове Feet Head. Задачу трехмерной реконструкции в самом простом случае можно сформулировать как построение триангуляции поверхности, заданной уравнением, где, функция плотности, пороговое значение threshold. В зависимости от выбора значения мы восстанавливаем разные структуры человеческого тела например, при 200 получается поверхность не очень твердых костей, при 1 000 зубов, при 200 опухолей в легких и т. п. При восстановлении внутренней поверхности кровеносных сосудов в случае использования контрастного вещества применяется пороговое значение в пределах HU от 150 до 400. Отметим также, что практически всегда восстановление такой поверхности выполняется не во всем пространстве, а только в интересуемой области, в медицине для этого используется термин ROI region of interect или, реже, VOI volume of interest. ROI обычно задается либо наборами контуров на каждом срезе, либо наборами битовых маск чаще всего используются оба метода одновременно. Существует два основных класса алгоритмов трехмерной реконструкции. Первый класс состоит из так называемых ячеечных методов, среди них наиболее известен метод марширующих кубов 3, 1987. В таких методах пространство разбивается на многогранники маленького размера в несколько пикселей на томографических срезах, например, на маленькие кубики в методе марширующие кубы или тетраэдры в методах типа марширующие тетраэдры методы МТ5, MT6 и др.. Под словом тетраэдр всюду в этой статье подразумевается любая треугольная пирамида, не обязательно правильный тетраэдр. Значение функции, вычисляется в вершинах этих многогранников. Рассматриваются ребра каждого многогранника. Если в вершинах ребра функция принимает значения разных знаков, то при допущении, что в точках ребра функция меняется линейно, вычисляется точка на ребре, в которой функция принимает значение 0. Полученные точки на ребрах соединяются одним или несколькими треугольниками внутри рассматриваемого многогранника. Объединяя полученные таким образом точки и треугольники, получаем триангуляцию всей поверхности см. далее, рис. 4 для случая тетраэдрических ячеек. Второй класс алгоритмов состоит из так называемых методов роста области из семени seeded region grow, мы рассматриваем их трехмерные варианты. Алгоритм роста области из семени строит множество вокселей внутри интересуемой области, которая может задаваться пороговым значением функции, в трехмерном пространстве область состоит из вокселей, значения функции в которых не ниже порогового, а также какими-либо другими признаками. В интересуемой области выбирается начальный воксель семя, он добавляется к множеству . Затем программа в цикле добавляет к множеству воксели, соседние с уже содержащимся в и удовлетворяющие критерию принадлежности к области. В процессе работы алгоритм использует какую-либо динамическую структуру, содержащую воксели, которые уже были добавлены к множеству, но соседи которых еще не были рассмотрены. Алгоритм заканчивается, когда становится пустой. В качестве можно использовать очередь, стек, список, но наиболее удобной структурой такого рода является структура Deque double ended queue двусторонняя очередь, содержащаяся в стандартной библиотеке языка C stddeque. Вот запись трехмерного алгоритма роста области из семени на псевдокоде множество вокселей очередь вокселей deque 0 начальный воксель семя .добавить 0 .добавить в конец 0 цикл пока не пуста выполнять .начало .удалить начало цикл для каждого соседа вокселя выполнить если не принадлежит множеству и удовлетворяет критерию принадлежности к области, то .добавить .добавить в конец конец если конец цикла конец цикла В качестве соседей вокселя в трехмерном пространстве берутся либо 6 соседей, одна из координат которых отличается ровно на единицу от соответствующей координаты, либо 26 соседей, представляющих собой все воксели куба размером 3 3 с центром, отлич ные от . Метод роста области из семени имеет совсем простую программную реализацию. Но главным достоинством этого метода является то, что он вычисляет связную область, содержащую начальный воксель. Он хорошо подходит для построения множества вокселей внутри кровеносных сосудов, поскольку такое множество невозможно задать только на основе порогового значения. Например, костная ткань плотность которой варьируется в очень широких пределах может иметь такие же значения плотности HU, как и кровь при использовании контрастного вещества, поэтому ячеечными методами отделить кровеносную систему от костной ткани невозможно. Но алгоритм роста области добавляет к трехмерной модели лишь те воксели, которые связаны с начальным вокселем семенем. Если начальный воксель находится внутри кровеносного сосуда, то и все добавленные воксели будут находиться внутри кровеносной системы учитывая, что кровеносная система замкнута алгоритм роста не должен протекать в пространство вне сосудов. Таким образом, костная ткань автоматически исключается из трехмерной модели. После построения множества вокселей остается вычислить триангуляцию его поверхности. Эта процедура также несложная рассматриваются те грани внешних вокселей из множества, к которым не примыкают другие воксели из . Каждая такая прямоугольная грань разбивается диагональю на 2 треугольника, и получаем требуемую триангуляцию поверхности множества . Еще одно достоинство алгоритма роста области состоит в том, что несложно ограничить рост области, заполнив контуры на некоторых срезах и запустив алгоритм роста повторно . На рис. 1 изображены результаты восстановления области сердца, полученные трехмерным алгоритмом роста области. Левая модель получена ростом из начального вокселя, расположенного внутри аорты. В правой модели используется задание области интереса ROI, которая отделяет часть аорты и коронарные артерии от остальной части кровеносной системы правая модель представляет собой часть модели, изображенной слева. Но у алгоритма роста области из семени есть и недостатки. Первым из них является большее время работы, чем у ячеечных алгоритмов, поскольку рассматриваются все воксели трехмерной модели, которая строится, а их число может быть очень большим. В ячеечных алгоритмах можно выбирать размер шага т. е. размер многогранников, на которые разбивается пространство, но в алгоритме роста области шаг всегда минимально возможный он равен размеру одного вокселя. Кроме того, ячеечные алгоритмы добавляют к модели лишь треугольники, расположенные на поверхности модели, а алгоритм роста области проходит по всему ее объему. Однако для наших целей этот недостаток не столь существенен, поскольку в любом случае шаг нужно выбирать минимально возможным, чтобы достичь наилучшего разрешения, так как коронарные артерии могут иметь очень небольшой поперечный размер. К тому же современные компьютеры позволяют достичь очень высокой скорости, и вдобавок отсутствуют существенные ограничения на объем оперативной памяти. Отметим, что второй недостаток алгоритма роста области, увы, не позволяет напрямую его использовать при построении триангуляции для последующего гидродинамического расчета. Дело в том, что поверхность построенной модели получается негладкой, она составлена из поверхностей кубиков, представляющих собой воксели полученного множества рис. 2, 3. Если бы цель состояла только в том, чтобы получить изображение поверхности, то эта проблема была бы не столь существенна трехмерный алгоритм Фонга с использованием нормалей в вершинах триангуляции позволяет визуально сгладить изображаемую поверхность см. рис. 2. Но при гидродинамическом расчете поверхность нуждается в реальном, а не только визуальном сглаживании. Алгоритмы сглаживания из класса Subdivision Surface дробление поверхности, такие как алгоритм Лупа 4 или Кетмулла Кларка 5, также мало подходят для нашей цели, поскольку они, лишь сглаживая углы, в целом не меняют форму поверхности, к тому же в медицинской диагностике желательно избежать даже минимального изменения формы вычисляемой поверхности. Отметим, что ячеечные алгоритмы строят более гладкую поверхность, поскольку по строенные в них треугольники получаются приблизительно перпендикулярными вектору градиента функции плотности, в отличие от метода роста области, в котором плоскости треугольников параллельны координатным плоскостям. Решение проблемы состоит в последовательном применении двух алгоритмов. Сначала с помощью алгоритма роста области из семени вычисляется множество вокселей, составляющее трехмерную модель интересующего участка кровеносной системы . На втором этапе используется ячеечный алгоритм вычисления триангуляции, причем он применяется не ко всему пространству, а только к окрестности поверхности модели, вычисленной на первом этапе. Самым первым ячеечным алгоритмом построения триангуляции изоповерхности был метод марширующих кубов 3. Он неплох, если речь идет только об изображении трехмерного объекта. Однако быстро выяснился его серьезный недостаток в некоторых случаях вершины триангуляции на ребрах куба можно соединить треугольниками разными способами. При несогласованном выборе треугольников внутри смежных кубов в построенной триангуляции сплошного объекта могут образоваться дыры. Всего с точностью до симметрии имеется 14 вариантов расположения вершин триангуляции на ребрах куба, неоднозначность возможна в 5 случаях. Вероятность этих ситуаций мала, и они почти не влияют на визуальное восприятие объекта, но если речь идет о точном воспроизведении топологии, то подобное недопустимо. Этого недостатка лишены ячеечные методы, в которых пространство разбивается на тетраэдры. С точностью до симметрии имеется лишь 2 варианта расположения вершин триангуляции на ребрах тетраэдра. В случае трех точек они соединяются одним треугольником, в случае четырех двумя рис. 4, других случаев не бывает. При использовании тетраэдрических ячеек возникает проблема как выбрать наилучшую тетраэдрическую сеть Дело в том, что разбить трехмерное пространство на правильные тетраэдры невозможно в отличие от плоскости, которая разбивается на правильные треугольники. Это означает, что априори самой лучшей тетраэдрической сети не существует. Обычно под качеством сети понимают средний аспект входящих в нее тетраэдров. Аспектом тетраэдра называется отношение радиусов описанной и вписанной сфер. Аспект правильного тетраэдра в точности равен 3, у любого тетраэдра, отличного от правильного, аспект стро го больше трех, так что аспект может служить мерой того, насколько тетраэдр отличается от правильного. Также желательными свойствами тетраэдрической сети являются равенство входящих в нее тетраэдров, инвариантность сети относительно сдвигов в трех независимых направлениях, удобство программирования и т. п. Самым простым методом построения тетраэдрической сети является разбиение пространства сначала на кубы, а затем разбиение каждого куба на тетраэдры. Не добавляя дополнительных вершин, куб можно разбить на тетраэдры 6 способами. В методе MT5 см. 6 куб разбивается на 5 тетраэдров, из которых один правильный с объемом, он образован скрещивающимися диагоналями граней куба остальные 4 тетраэдра имеют объем, каждый из них образован тремя перпендикулярными ребрами куба, выходящими из одной вершины. Это разбиение изображено слева на рис. 5. В методе MT6 см. 7 куб разбивается на 6 равных тетраэдров см. рис. 5, в центре. Сеть MT6 удобна тем, что она инвариантна относительно сдвигов на вектор любого ребра куба. Однако для нашей цели лучше всего подходит сеть, предложенная в работе S. L. Chan, E. O. Purisima 8 она стала широко известна также и благодаря статье V. Skala 9, в литературе ее часто называют сетью Скала. Тетраэдры этой сети изображены на рис. 5, справа, они строятся на границах смежных кубов кубической решетки. В сети Скала все тетраэдры равны между собой это тетраэдры Кокстера, сеть инвариантна при отражениях пространства относительно любых граней тетраэдров. Сеть Скала имеет наилучший аспект 3.162 среди всех известных на данный момент тетраэдрических сетей. Для сравнения аспект сети MT6 равен 4.182, средний аспект сети MT5 равен 3.878., Помимо остальных прекрасных свойств сети Chan Purisima Skala равенство входящих в нее тетраэдров, наилучший аспект среди всех известных сетей, инвариантность относительно сдвигов и отражений, она обладает свойством, крайне ценным для нашей задачи в ней тетраэдры строятся на гранях смежных кубов кубической решетки. Справа на рис. 5 изображены 4 тетраэдра, построенные на общей грани двух смежных кубов, расположенных горизонтально, аналогично строятся тетраэдры на общей грани соседних кубов, расположенных вертикально и во всех трех независимых направлениях. Вершины построенных тетраэдров находятся в вершинах исходной кубической решетки, а также в центрах кубов. Если размер ребра куба равен 1, то длины ребер тетраэдров равны 1 два ребра, совпадающие с ребрами куба и 32 0,866 остальные 4 ребра, равные половине большой диагонали куба. Если каждый куб решетки представляет воксель в пространстве, то построенная на этих кубах тетраэдрическая сеть Скала позволяет достичь субпиксельной точности, которая необходима для точного восстановления геометрии кровеносных сосудов. Ключевой момент состоит в том, что тетраэдрическая сеть строится не во всем пространстве, а только в окрестности границы трехмерной воксельной модели, полученной алгоритмом роста области из семени. Благодаря этому при последующем применении ячеечного метода трехмерного восстановления мы не добавляем нежелательных объектов к модели, а лишь уточняем форму ее поверхности. Точный алгоритм построения уточняющей тетраэдрической сети следующий. Обозначим через исходную модель, полученную трехмерным алгоритмом роста области из семени, она состоит из кубических вокселей. Каждый воксель пространства это куб с 8 вершинами. Какие-то вершины вокселей из могут лежать на поверхности модели, какие-то нет. Построим множество вокселей следующим образом произвольный воксель трехмерного пространства добавляется к, если хотя бы одна из его вершин лежит на поверхности модели . Таким образом, множество будет содержать как некоторые воксели из модели, так и некоторые воксели, не входящие в, но касающиеся ее границы. После определения множества вокселей строится уточняющая тетраэдрическая сеть для любых двух соседних вокселей из, имеющих общую грань, строятся 4 тетраэдра сети см. рис. 5, справа. Схематично процесс построения сети изображен на рис. 6 в двумерной проекции трехмерный рисунок получился бы слишком громоздким. На рис. 6 темными квадратами показаны воксели исходной модели множество, светлыми воксели из построенного множества, не принадлежащие, но имеющие вершину на границе . Каждые 2 соседних вокселя из множества определяют 4 тетраэдра, которые строятся на их общей грани, проекции этих тетраэдров нарисованы тонкими линиями. После построения уточняющей тетраэдрической сети запускается алгоритм трехмерного восстановления изоповерхности ячеечного типа. Результат применения алгоритма для модели тора показан на рис. 7. В правой части рис. 7 специально используется плоский режим закрашивания треугольников, чтобы они были лучше видны на изображении. Если применить алгоритм Фонга, использующий нормали в вершинах триангуляции для сглаживания изображения, то результат получается визуально совершенно гладким. На рис. 8 уточненная модель изображена слева как проволочный каркас Wireframe, справа используется алгоритм Фонга. На рис. 9. показан результат применения уточняющего алгоритма для компьютерной модели кровеносного сосуда. Отметим, что толщина сосуда в этом примере минимальна 34 вокселя, а исходная воксельная модель имеет форму, далекую от цилиндрической, однако уточненная триангуляция получается достаточно гладкой. На рис. 10 и 11 показан результат применения алгоритма к реальным данным. Слева изображена воксельная модель, в центре и справа триангуляция, полученная уточняющим алгоритмом используется плоское и гладкое закрашивание граней. Рисунок 11 крупно показывает небольшой фрагмент модели, представленной на рис. 10. Все алгоритмы, описанные в данной работе, реализованы на языке C с использованием библиотеки классов Qt и системы разработки приложений QtCreator. Для получения изображений использовалась библиотека трехмерной графики OpenGL. Был реализован как трехмерный алгоритм роста области из семени, так и ячеечный алгоритм восстановления изоповерхности, использующий тетраэдрическую сеть Chan Purisima Skala. Последний алгоритм реализован в двух вариантах классический вариант строит сеть во всем пространстве, в варианте уточнения границы сеть строится только в окрестности границы воксельной модели, как описано выше. Отметим, что алгоритм уточнения границы воксельной модели работает чрезвычайно быстро, поскольку он проходит не по всему пространству, а только по границе модели, до этого вычисленной алгоритмом роста области. Тетраэдры сети имеют размеры, не превышающие размера вокселя, и строятся очень естественно по вокселям исходной модели. Это позволяет достичь необходимой гладкости и субпиксельной точности результирующей модели. Причем в модель не вносятся никакие искажения формы при сглаживании, неизбежные, к примеру, в методах Лупа или Кетмулла Кларка 4 5, поскольку все вычисления используют только исходную функцию плотности объекта в трехмерном пространстве, полученную как результат томографического обследования пациента. Таким образом, комбинация этих двух алгоритмов позволяет точно и эффективно воссоздать сглаженную трехмерную модель сосудов кровеносной системы, необходимую для программ гидродинамических расчетов. "}
{"title": "ЛОКАЛИЗАЦИЯ ИСТОЧНИКОВ АКТИВНОСТИ МОЗГА  НА ЕГО ТРЕХМЕРНОЙ МОДЕЛИ ПРИ ПОМОЩИ СОВМЕСТНОГО АНАЛИЗА   ДАННЫХ ЭЭГ/CМРТ   ", "absract": "Несмотря на большое количество существующих методов диагностики головного мозга, он остается наименее изученной частью человеческого организма. Электроэнцефалография (ЭЭГ) – один из наиболее популярных методов исследования мозговой активности. Это обусловлено относительной дешевизной, безвредностью  и мобильностью оборудования. При анализе данных ЭЭГ возникает проблема решения обратной задачи электроэнцефалографии – локализации источников электрической активности мозга. Ее можно сформулировать следующим образом: по сигналам, регистрируемым на поверхности головы, необходимо определить, в какой области мозга расположены источники этих сигналов. Целью исследования является разработка программной системы для локализации источников мозговой активности на основе совместного анализа данных ЭЭГ и сМРТ. Существуют различные подходы к решению обратной задачи ЭЭГ. Для получения наиболее точных результатов некоторые из них предполагают использование данных сМРТ (изображений структурной магнитнорезонансной томографии), описывающих индивидуальную анатомию головы человека. В этой работе используется один из таких подходов – EMSICA (Electromagnetic Spatiotemporal Independent Component Analysis), предложенный A. Tsai. В статье рассмотрены основные этапы работы системы, такие как предварительная обработка исходных данных; расчет специальной матрицы подхода EMSICA, значения которой показывают уровень активности определенного участка мозга; визуализация источников активности мозга на его трехмерной модели.  ", "text": ", Мозг выполняет огромное количество жизненно важных функций человека, поэтому точная и своевременная диагностика состояния головного мозга одна из ключевых задач современной медицины. Мозг человека активно исследуют посредством измерения и анализа его анатомии, биоэлектрической активности и т. п. Один из наиболее популярных методов исследования мозговой активности электроэнцефалография ЭЭГ метод оценки функционального состояния головного мозга при помощи регистрации и анализа электрических сигналов на поверхности головы. Электроэнцефалография занимает важное место среди методов функциональной диагностики состояния мозга. Несмотря на появление таких диагностических методов, как магнитно-резонансная томография МРТ, функциональная магнитно-резонансная томография, позитронно-эмис сионная томография ПЭТ и др., интерес врачей и исследователей к электроэнцефалографии и методам ее анализа в последнее время возрастает. Популярность ЭЭГ связана со сравнительно низкой стоимостью оборудования и его мобильностью, безвредностью ввиду отсутствия вредных для мозга излучений. Также стоит отметить, что ЭЭГ чувствительный метод исследования, он отражает малейшие изменения состояния коры головного мозга и глубинных мозговых структур, обеспечивая миллисекундное временное разрешение, недоступное другим методам исследования мозговой активности. При анализе ЭЭГ-данных возникает проблема решения обратной задачи электроэнцефалографии локализации источников электрической активности мозга. Ее можно сформулировать следующим образом по ЭЭГ сигналам, регистрируемым на поверхности головы, необходимо определить, в какой области мозга расположены источники этих сигналов. Целью данной работы является разработка программной системы для локализации источников мозговой активности на основе совместного анализа данных ЭЭГ и сМРТ. Локализация источников ЭЭГ основана на широком спектре методов обработки сигналов, включающих цифровую фильтрацию, анализ трехмерных изображений, обработку массивов сигналов, моделирование и реконструкцию изображений, слепое разделение источников 1. Наиболее распространенным подходом к решению обратной задачи ЭЭГ является определение пространственных характеристик и силы токовых диполей для компонент, вычисленных при помощи анализа независимых компонент Independent Component Analysis ICA. Данный алгоритм был разработан Aapo Hyvrinen и Erkki Oja 2. Его основное преимущество использование только ЭЭГ-данных для нахождения источников сигналов, кроме того данный метод включен в распространенный программный пакет EEGLAB. Но такой подход не учитывает индивидуальную анатомию человеческого мозга, что ведет к ошибкам в определении расположения источников активности. Еще одним распространенным методом локализации источников мозговой активности является электромагнитная томография низкого разрешения LORETA 3. Для получения наиболее точных результатов некоторые подходы предполагают использование данных МРТ, которые дают высокоточную информацию об индивидуальной анатомии головы человека. МРТ способ получения томографических медицинских изображений для исследования внутренних органов и тканей с использованием явления ядерного магнитного резонанса. Изображения структурной МРТ сМРТ мозга предоставляют данные об анатомических структурах мозга с высоким пространственным разрешением. Одним из подходов, использующих МРТ для решения обратной задачи ЭЭГ, является метод одновременной регистрации данных ЭЭГ и МРТ, описанный K. J. Mullinger и др. 4. Данный способ точно локализует источники сигнала в головном мозге, но он крайне затратен по временным и денежным ресурсам. В этой работе предполагается использование подхода, который также использует МРТданные электромагнитный пространственно-временной анализ независимых компонент Electromagnetic Spatiotemporal Independent Component Analysis EMSICA, предложенного A. Tsai 5 6. Данный метод является модификацией анализа независимых компонент, в то же время он использует МРТ-данные. Его преимущество перед одновременной регистрацией данных ЭЭГ и МРТ использование одних данных МРТ для разных ЭЭГ-экспериментов одного и того же обследуемого. В статье подробно описана математическая модель электромагнитного пространственновременного анализа независимых компонент, оригинальный алгоритм, а также предложенная модификация этого алгоритма. Также описан процесс предварительной обработки данных ЭЭГ и МРТ для использования алгоритмом. Представлена архитектура разработанной системы, этапы ее работы, пользовательский интерфейс, а также некоторые детали реализации. Особое внимание уделено подходу к визуализации источников мозговой активности. Электромагнитный пространственно-временной анализ независимых компонент, предложенный A. Tsai 5, основан на совместном анализе данных ЭЭГ и МРТ. Этот метод является модификацией ICA, и его основное преимущество использование информации об индивидуальной анатомии головы обследуемого. Стоит отметить, что данные сМРТ регистрируются один раз независимо от регистрации ЭЭГ-данных. Иначе говоря, можно получать источники мозговой активности для каждого нового ЭЭГ-обследования без повторного МРТ-обследо вания. В данном подходе расположение источников мозговой активности будет определяться на поверхности коры головного мозга. Для этого предполагается разделить поверхность головного мозга на тесселяционных элементов здесь под тесселяционным элементом подразумевается небольшой участок на поверхности коры головного мозга. Математическая модель данного метода 5 выглядит следующим образом 1 известная векторная функция от времени, содержащая данные ЭЭГ-сигналов, в реальном наборе данных представляется как . неизвестная векторная функция от времени, описывающая искомые разделенные сигналы, в реальном наборе данных представляется как . известная матрица потенциальных полей, содержащая информацию о геометрии и проводимости модели. неизвестная матрица весов с элементами, которые задают уровень активности -го источника в -м тесселяционном элементе на коре. Таким образом, по значениям столбца можно определить активные участки коры мозга, соответствующие -й компоненте. Задача заключается в поиске матрицы по известным и для последующей визуализации активных участков мозга в виде компонент EMSICA. Предполагается, что, чтобы гарантировать существование матрицы . Также в 5 утверждается, что матрица в 1 может быть интерпретирована аналогично матрице смешивания подхода анализа независимых компонент. В байесовском подходе 1 обратную задачу можно сформулировать как оценку распределения источников на коре, а также соответствующих им сигналов по данным, записанным с электродов. Расположение источников, т. е., можно оценить, максимизируя следующую апостериорную вероятность 11 2 Здесь обозначает пропорциональность, т. е. то же самое, что . Если предположить независимость расположения источников на поверхности коры и независимость сигналов во времени, справедливо . Тогда Чтобы избавиться от неудобного параметра по правилам байесовского подхода уравнение 2 можно преобразовать к 3 Поскольку исходные компоненты считаются независимо распределенными, априорную вероятность можно представить в виде произведения априорных вероятностей отдельных источников, т. е. . Тогда на основе подхода алгоритма Infomax ICA 7, также использующего байесовский подход, интеграл в правой части уравнения 3 можно преобразовать следующим образом . Элементы -го столбца матрицы могут рассматриваться как случайный вектор, и предполагается, что эти векторы имеют независимое распределение в пространстве, тогда их распределение . На основе изложенного апостериорная вероятность имеет следующий вид 4 В работе A. Tsai 6 выдвинуто предположение, что и имеют следующий вид 5 6 На основе представленных в статье 6 формул приведем подробное описание используемых величин функций и диагональная матрица, каждое значение которой имеет вид гиперболический секанс, т. е. скалярный квадрат вектора . Скаляр является гиперпараметром. Из-за того, что временной интервал ЭЭГ-обследования временных единиц может быть достаточно большим, в подходе EMSICA предлагается разбить его на интервалы по единиц времени. Другими словами вектор-функция в реальном наборе данных представляет собой матрицу, тогда разобьем ее на блоков . Учитывая это, в работе A. Tsai было установлено, что апостериорная логарифмическая вероятность, соответствующая апостериорной вероятности в 4, имеет следующий вид На основе вышеизложенного для нахождения матрицы необходимо решить следующую задачу безусловной оптимизации 7 где A. Tsai предлагает найти максимум логарифмической вероятности с помощью метода градиентного спуска. Для этого берется ее градиент по здесь подразумевается взятие частной производной по каждому элементу матрицы где, матрицы со значениями и соответственно. На основании 5 и 6 нами были выведены следующие формулы где элемент матрицы Умножим правую часть уравнения 7 на 5 Тогда на каждой итерации градиентного спуска 8 В качестве правила окончания цикла было выбрано правило . Здесь возникает проблема поиска параметра в уравнении 8. Принятие параметра за константное значение и его эмпирический подбор не показали хорошего результата. Поэтому поиск параметра был произведен на основе модификации алгоритма Нелдера Мида 8. В результате эмпирических исследований нами были выбраны следующие значения гиперпараметров алгоритма, . Такие значения обеспечили наименьшее количество общего числа итераций оптимизационного алгоритма для предоставленного набора тестовых данных. Для исследования Научно-исследовательским институтом физиологии и фундаментальной медицины были предоставлены очищенные от шума ЭЭГ-данные в формате EEGLAB с расширением .set и данные структурной МРТ с расширением .nii. Алгоритм EMSICA в качестве входных данных принимает матрицу потенциальных полей, полученную на основе обработки данных МРТ и ЭЭГ, а также вектор-функцию или матрицу в дискретном виде, извлеченную из ЭЭГданных Исходя из предоставленных данных размерности . Количество тесселяционных элементов в этом исследовании . Программная система включает в себя модуль по обработке данных. После того, как пользователь загрузит файл с ЭЭГ-данными с расширением .set, а также файл с матрицей потенциальных полей с расширением .mat, запускается реализованный на языке MATLAB скрипт для извлечения необходимых данных. Далее описывается способ получения файла с матрицей потенциальных полей, примененный в результате подготовки данных для нашей программной системы. Решение обратной задачи ЭЭГ с использованием данных об анатомии мозга предполагает предварительное моделирование тканей головы и характеристик электродов. Матрица потенциальных полей матрица усиления, используемая в 1, содержит информацию о том, как электрический ток, протекающий в мозге, создает различия в электрических потенциалах на внешних датчиках ЭЭГ электродах, учитывая различные ткани головы. На основании подхода EMSICA для каждого обследуемого матрица рассчитывается на основе высококачественной реалистичной модели головы методом граничного элемента BEM boundary element method 9. В настоящее время существует несколько программных продуктов, выполняющих подобные вычисления. В этой работе для вычисления матрицы усиления было решено использовать программный пакет Brainstorm, который задокументирован и предназначен для скачивания онлайн под общедоступной лицензией GNU 10. Для расчета матрицы этому программному пакету необходимы данные модели головы, которые могут быть получены с помощью разных средств. Мы решили остановиться на программе BrainSuite. Выбор данных продуктов был обусловлен прежде всего удобством и простотой в использовании, а также наличием подробного руководства. Итак, сначала необходимо построить реалистичную модель головы в программном пакете BrainSuite. BrainSuite создает индивидуальные модели структур мозга на основе T1-взве шенной МРТ головы человека, в том числе модели внутренних и внешних границ коры головного мозга. Данные этой модели также будут использованы для визуализации активных участков мозга на его трехмерной модели. Предоставленные данные МРТ имеют высокое пространственное разрешение, и при построении модели головы в программе BrainSuite возникает сбой из-за превышения максимального размера стека памяти. Для решения этой проблемы был реализован скрипт OVERRIDEMRI для сжатия МРТ-данных на языке MATLAB на основе метода библиотеки Tools for NIfTI and ANALYZE image. После использования скрипта для сжатия нужно загрузить полученный файл в приложение BrainSuite и выбрать опцию для выполнения всех шагов извлечения поверхности коры головного мозга. В результате выполнения программы будут созданы файлы с моделями анатомических структур мозга. Теперь на основе полученных данных можно вычислить матрицу с помощью программного пакета Brainstorm. Сначала нужно импортировать данные анатомии мозга и файл с ЭЭГданными. В программном обеспечении Brainstorm по умолчанию считается, что электрическая активность, которая регистрируется датчиками, создается в основном набором электрических диполей, расположенных на поверхности коры 9. Используемая сетка источников диполей определяется поверхностью коры, каждая вершина этой поверхности рассматривается как диполь. Анализ данных в этой работе был проведен на основе 15 000 вершин значение, выставленное в Brainstorm по умолчанию. Использование меньшего количества вершин просто снизит разрешение результатов использование большего количества приводит к чрезмерному увеличению объема данных и может привести к проблемам с памятью. Для вычисления матрицы Brainstorm предлагает несколько методов. Основываясь на работах 5 6, нужно использовать OpenMEEG BEM метод граничного элемента из программного обеспечения с открытым исходным кодом OpenMEEG 11. В результате создается файл с расширением .mat, содержащий матрицу, а также координаты вершин сетки. Для извлечения этих данных из полученного файла был реализован скрипт на языке MATLAB, который включается в модуль по обработке данных нашей программной системы. Кортикальная карта, или изображение коры головного мозга -й компоненты EMSICA, может быть описана на основе значений соответствующего столбца матрицы, т. е., содержащего одно значение для каждого тесселяционного элемента. Чтобы найти и отобразить вершины, сильно активные в определенной карте компонент EMSICA, столбцы матрицы нормализуются по стандартному отклонению. Нормализованные значения матрицы обозначим . Участки мозга, для которых соответствующие абсолютные значения превышают некоторый порог, считаются сильно активными 5 и выделяются цветом на трехмерной модели головного мозга. Именно таким образом отображаются компоненты EMSICA в нашей системе. Здесь стоит отметить, что интерпретировать физический смысл ненормализованных значений довольно сложно, так как единицей измерения значений матрицы по СИ является 1 . Эта величина выведена из уравнения 1 на основе единиц измерения матрицы потенциальных полей 1 и матрицы ЭЭГ-данных именно такие единицы измерения имели извлеченные из файлов данные. Нормализованное значение отображает степень отклонения состояния соответствующего участка коры. При реализации модуля для визуализации компонент EMSICA возникла проблема совмещения сетки мозга, полученной в программном пакете Brainstorm, с реалистичной моделью мозга BrainSuite. Как уже отмечалось, наша программная система использует эти промежуточные данные для визуализации трехмерной модели головного мозга. На основе подхода EMSICA нам известен уровень активности вершин модели Brainstorm. Но так как мы визуализируем компоненты EMSICA на модели мозга BrainSuite, для каждой вершины этой модели необходимо найти ближайшую вершину модели Brainstorm. Для решения возникшей проблемы был разработан следующий подход. Сначала осуществляется поиск центров моделей мозга. Мы предполагаем, что центр это точка, имеющая минимальное среднее расстояние до вершин сетки. Формально это можно представить следующим образом вектор координат -й вершины сетки модели мозга искомый центр сетки модели мозга. Тогда поиск центра модели будет состоять в решении задачи оптимизации В качестве начального приближения центра модели мы выбрали центр масс . Будем считать что вершины модели Brainstorm вершины модели BrainSuite центр модели Brainstorm, центр модели BrainSuite, полученные на основе приведенного выше алгоритма. Тогда если вершина активная вершина, то все вершины такие, что угол между векторами и меньше, будем считать активными. Таким образом мы совмещаем центры моделей друг с другом. Стоит отметить, что приведение базисов не требуется, так как системы координат обеих моделей уже имеют один и тот же базис. Поэтому мы можем интерпретировать векторы и как радиусвекторы вершин соответствующих моделей в одной системе координат, при этом центры моделей будут совпадать с началом координат. Теперь поясним роль угла в нашем подходе. Предположим, что мы спроецировали вершины обеих моделей на сферу с центром в начале координат. Тогда будем считать, что для некоторой активной вершины модели Brainstorm, все вершины, проекции которых находятся в малой окрестности проекции вершины, являются активными. Очевидно, что при такой постановке, явное проецирование не требуется, так как такая окрестность может быть задана с помощью угла угла между радиус-векторами вершин обеих моделей. Разработанная система для локализации источников мозговой активности имеет три основных модуля. 1. Модуль предварительной обработки данных. 2. Модуль для вычисления компонент EMSICA. Данный модуль находит решение оптимизационной задачи 7. 3. Модуль для визуализации источников мозговой активности Модуль для обработки данных был реализован на языке MATLAB. Выбор языка определен прежде всего тем, что файл с матрицей потенциальных полей имеет формат данных программной системы MATLAB, поэтому здесь имеется богатый функционал для обработки подобных данных. Второй модуль также реализован на языке MATLAB и реализует алгоритм максимизации апостериорной логарифмической вероятности. После вычисления матрицы он осуществляет экспорт этой матрицы и набор координат модели Brainstorm для использования модулем визуализации. Модуль для визуализации компонент EMSICA разработан с помощью фреймворка Qt на языке C и предоставляет пользовательский интерфейс для работы со всей системой. Основной опцией нашей программной системы является визуализация кортикальных карт компонент EMSICA с заданным порогом, который характеризует уровень активности участков коры мозга. Также для осуществления дополнительного анализа компонент на основе программного комплекса EEGLAB предоставляется опция для создания и сохранения файла с расширением .set, который содержит данные о компонентах EMSICA, подобно данным о компонентах ICA матрицу смешивания, поэтому все механизмы анализа независимых компонент применимы и к новым компонентам. Программная система опробована на данных 10 человек, и, по экспертной оценке сотрудников НИИФФМ, было подтверждено, что полученные компоненты действительно локализуют наиболее активные участки мозга, а также имеют тенденцию к разделению коры мозга на стандартные анатомические области. Кроме того, отображение новых компонент с помощью программного пакета EEGLAB соответствует изображениям на трехмерной модели мозга для всех тестовых данных, что подтверждает выбранный для визуализации подход. На рис. 1 представлена визуализация компоненты EMSICA на трехмерной модели мозга нашей программной системы слева, а также двумерное изображение этой же компоненты, полученное в программном пакете EEGLAB справа. На рис. 2 изображена информация о частотной характеристике сигнала источника, соответствующей этой компоненте. Данные также получены в программном пакете EEGLAB. По частотному анализу видно, что найденный источник действительно проявляет активность в момент начала ЭЭГ-эксперимента выраженный пик в момент времени 0. Подход EMSICA для решения обратной задачи ЭЭГ объединяет сильные стороны существующих подходов, поэтому нами был выбран этот подход для разработки программной системы локализации источников мозговой активности. Во время исследования данного подхода были внесены некоторые уточнения и модификации, необходимые с точки зрения реализации. Также был разработан подход к визуализации компонент EMSICA на трехмерной модели головного мозга, полученной с помощью приложения BrainSuite. Результатом работы является программная система, которая позволяет визуализировать кортикальные карты компонент EMSICA, а также активные участки мозга в определенный момент времени. Кроме того, для получения большей информации о компонентах предусмотрена опция сохранения данных в файл с расширением .set, в результате чего может быть проведен дополнительный анализ полученных результатов в программном пакете EEGLAB. На данный момент разработанная система проходит апробацию в Научно-исследователь ском институте физиологии и фундаментальной медицины. "}
{"title": "РАЗРАБОТКА МЕТОДОВ ИНТЕГРАЦИИ   АВТОМАТИЧЕСКИХ СРЕДСТВ ЛОГИЧЕСКОГО ВЫВОДА   ДЛЯ ПОРОЖДЕНИЯ ЗНАНИЙ В ОНТОЛОГИЧЕСКОЙ МОДЕЛИ  ", "absract": "  Статья посвящена разработке методов порождения новых знаний на основе анализа текстов естественного языка. Для извлечения знаний из текстов на естественном языке используется метод представления предложений в виде двухместных предикатов с введенной константой ситуацией. Для представления знаний в формальном виде используются бескванторные предложения логики предикатов, а также язык OWL DL. Порождение новых знаний реализуется при помощи автоматических средств логического вывода с использованием заранее заданных шаблонов правил вывода. Разработана программная система, которая дает возможность пользователям получать ответы на определенные вопросы, относящиеся к данным текстам естественного  языка. Ответы строятся на естественном языке, при этом используются не только явно содержащиеся в обрабатываемом документе знания, но и знания, порожденные при помощи автоматических средств логического вывода. ", "text": " Данная работа посвящена разработке и программной реализации методов порождения новых знаний по текстам естественного языка. Порождение новых знаний происходит при помощи автоматических средств логического вывода с использованием шаблонов, предварительно созданных для заданной предметной области. Знания, извлеченные из текстов, представляются в виде фрагмента атомарной диаграммы модели в сигнатуре, состоящей из символов двухместных предикатов и констант. Далее атомарные предложения транслируются в язык OWL DL, благодаря чему мы можем использовать автоматические средства логического вывода ризонеры. Корректность порожденных знаний контролируется пользователями с помощью запросов к программной системе на естественном языке. В своей жизни мы сталкиваемся с большим количеством разных документов. Очень часто документы имеют большие объемы, и при этом информация в документах может быть не структурирована. Ключевые моменты могут находиться в разных местах документа одна часть важной информации может быть в начале документа, а другая часть в конце. Для точного определения содержания документа нужно выяснять смысл каждого предложения в отдельности, а также семантическое влияние одних предложений на другие. Сходные проблемы возникают, когда для решения какой-либо задачи нужно извлечь знания из нескольких связанных между собой документов и затем сопоставить знания, содержащиеся в разных документах. Так, например, для определения порядка действий студента ФИТ в течение ряда лет его обучения, нужно изучить следующие регламентирующие документы Образовательная программа по направлению 09.04.01 информатика и вычислительная техника, 09.04.01 Программа государственной итоговой аттестации по образовательной программе высшего образования программе магистратуры, Приложения к программе государственной итоговой аттестации по образовательной программе высшего образования программе магистратуры, Приказы о проведении сессий и другие связанные документы. В одних документах описывается порядок действий студентов, в других описаны сроки и т. п. Поэтому, чтобы извлечь правильную информацию из таких текстов естественного языка, нужно изучить все связанные между собой документы. Учитывая количество и объемы таких документов, сделать это может быть крайне затруднительным. Целью разработки программной системы, описываемой в данной статье, является автоматизация извлечения знаний из текстовых документов с возможностью порождения новых знаний на естественном языке за счет сопоставления и комбинации извлеченных знаний и осуществления логического вывода. Программная система должна решать следующие задачи извлекать знания из текстовых документов на естественном языке и представлять их в формальном виде на языке логики предикатов и OWL DL осуществлять логический вывод с использованием ризонеров для OWL DL и таким образом порождать новые знания предоставлять пользователям возможность задавать вопросы на естественном языке, относящиеся к рассматриваемым текстам документов. В результате применения разработанных методов была создана программная система, предназначенная для порождения новых знаний по текстам на естественном языке, основанная на представлении извлеченных из текстов знаний в виде онтологической модели. Созданная программная система позволяет получать знания, которые явно не содержатся в документах, но логически следуют из них. При создании онтологических моделей различных предметных областей мы основываемся на четырехуровневой модели представления знаний 1 2. В рамках этого подхода разработка онтологической модели предметной области включает в себя создание онтологии предметной области, т. е. задание набора ключевых понятий сигнатуры онтологической модели и спецификация смысла этих ключевых понятий, задание взаимосвязей, отношений между понятиями и т. д. формальное представление общих знаний универсальных утверждений и регламентов, истинных для каждого прецедента данной предметной области формальное представление набора прецедентов предметной области формальное представление вероятностных, оценочных и экспертных знаний в виде предложений, имеющих нечеткие значения истинности 1 2. При этом происходит настройка взаимосвязи со сторонними программными системами, описание взаимодействия с другими онтологиями и др. 35. В рамках нашего подхода создание онтологической модели можно представить как разработку модульной системы 6. Модулями этой системы, в частности, являются ядро, модуль пополнения онтологической модели, модуль взаимодействия с онтологической моделью. Ядро системы позволяет создавать онтологии на языке OWL DL . Создавать онтологию можно как посредством доступных редакторов онтологий с графическим интерфейсом, например Protg, так и напрямую на языке OWL DL. Для ядра системы построения используется описанная выше четырехуровневая модель представления знаний 1 2 1 онтология, 2 общие знания, 3 прецеденты, 4 вероятностные и оценочные знания. Ядро системы, в частности, позволяет проверять созданные онтологические модели на непротиворечивость при помощи автоматических средств логического вывода. Модуль пополнения онтологической модели позволяет пополнять онтологическую модель новыми знаниями как извлеченными из текстов естественного языка, так и полученными в результате логического вывода. Пополнение онтологической модели можно сделать несколькими способами. Первый способ это объединение онтологий. Для создания онтологических моделей существует несколько языков, основными из которых являются RDF, RDF Schema, OWL, логика описаний. Данный модуль позволяет объединять онтологии, написанные на разных языках. Для этого существуют программы для перевода с одного языка на другой. Второй способ это использование правил вывода. Правила вывода могут быть написаны на разных языках. Для получения знаний с помощью правил вывода используются машины логического вывода. Модуль взаимодействия с онтологической моделью позволяет с помощью языков запросов SQWRL и SPARQL и правил вывода SWRL выполнять запросы к онтологической модели. Также есть возможность взаимодействовать со сторонними программными системами, такими как Ontograf визуализация онтологии в виде графа, Logic Text представление текста в виде атомарных диаграмм и др. Схема работы с онтологической моделью представлена на рис. 1. Семантический механизм рассуждений 7 это часть программного обеспечения, способная вывести логические умозаключения новые знания из набора формализованных базовых понятий и представленных аксиом. Понятие семантического механизма рассуждений обобщает понятие машины логического вывода. Семантический механизм рассуждений предоставляет богатый набор механизмов для работы. Правила вывода обычно определяются с помощью языка описания онтологий. Многие семантические механизмы рассуждений используют логику предикатов первого порядка для выполнения рассуждений. Для работы с онтологиями на языке OWL DL существует несколько основных машин логического вывода. Некоторые из них являются коммерческими программными продуктами Bossam, RacerPro, OntoBroker 8. Некоторые свободными в использовании, но с закрытым исходным кодом KAON2, Internet Business Logic, Cyc inference engine 9, а другие бесплатным программным обеспечением с открытым исходным кодом Drools, OpenRules, Pellet 10, Jena, Fact 11. Для данной работы была выбрана машина логического вывода Pellet, так как она предоставляет наиболее полную поддержку OWL DL, а также имеет понятный программный интерфейс. Применение машин логического вывода для онтологий можно осуществлять и без использования правил вывода. В таком случае машины логического вывода могут определять иерархию классов, принадлежность экземпляров к определенным классам, а также эквивалентность классов. Но новые знания в такой ситуации получить невозможно. Для этого нужно использовать правила вывода 12. Для использования правил вывода при работе с онтологиями существуют различные инструменты SWRL, DLP Grosof, dl-programs Eiter, DLsafe rules, Conceptual Logic Programs CLP, AL-Log, DLlog 13. Выделяют два основных подхода применения правил вывода в онтологиях однородный гомогенный и гибридный 14. Однородный подход также называют семантической интеграцией. В однородном подходе онтологии и правила вывода используются на одинаковых условиях, т. е. создается единый язык. Одни и те же предикаты используются как для формулировки онтологических утверждений, так и для формулировки правил вывода. Правила в таком подходе можно использовать для определения классов и свойств. В данном подходе нет проблемы совместимости. Недостатками данного подхода является то, что совмещение в одном языке разных средств и для описания правил вывода, и для описания онтологии сильно затрудняет реализацию. Также однородный подход часто может быть неприменим в работе из-за того, что онтология и правила вывода могут разрабатываться разными специалистами независимо друг от друга. Примерами такого подхода являются SWRL и DLP 15. Гибридный подход отличается от гомогенного строгим семантическим разделением. Предикаты, используемые в онтологиях, и предикаты, используемые в правилах вывода, строго различаются. Вывод производится только с помощью отдельно реализуемых программ. Могут разрабатываться независимо от онтологий. К недостаткам относится то, что правила не могут определять новых классов и свойств онтологий, за исключением некоторых специальных отношений. Хоть гибридный подход и позволяет разрабатывать правила вывода независимо от онтологий, это вносит ряд ограничений, для того чтобы гарантировать разрешимость. Примерами такого подхода являются RIF 16 и Answer Set Programming ASP 17. В настоящее время существует ряд программных систем, предназначенных для анализа текстов естественного языка при помощи онтологий. Такими системами являются FRED 18, Apache Stanbol и Text2Onto 19. Рассмотрим особенности этих систем. это анализатор текста, основанный на технологиях Semantic Web. Способен обрабатывать тексты естественного языка на 48 различных языках и преобразовывать его в связанные данные. Он разработан на языке Python, а также реализован в виде REST API и в виде набора библиотек языка Python. Для анализа текста FRED использует комбинаторную категориальную грамматику CC, теорию репрезентационного представления DRT, семантику фреймов и шаблоны проектирования онтологий. Для определения именованного объекта анализатор FRED использует Apache Stanbol, TagMe, для устранения неоднозначности Boxer и IMS. Результат обработки может представлять в формате RDFOWL. Также FRED генерирует графы знаний, которые могут быть интерпретированы машинами в соответствии с общей формальной семантикой. В основе работы лежат фреймы Frame Semantic. Фрейм обычно выражается глаголами или другими лингвистическими конструкциями, которые могут распознаваться во входном тексте как -арное отношение. Все -арные отношения записываются как подклассы класса Предикаты представляются в виде классов, в названии которых есть сам объект. Пример такого именования Вывод может быть представлен в виде графа рис. 2. программный продукт для пополнения онтологии из текстовых ресурсов. В основе его лежит вероятностная онтологическая модель POM Probabilistic Ontology Model. POM, используемая Text2Onto, представляет собой набор созданных примитивов моделирования, которые не зависят от конкретного языка представления онтологии. Фактически Text2Onto включает в себя библиотеку примитивов моделирования MPL, которая определяет эти примитивы декларативным способом. Добавление новых примитивов происходит без изменения структуры онтологии. Это делает онтологию гибкой и расширяемой. Также созданные примитивы могут быть переведены на любой язык представления знаний, например RDFS3, OWL4 и F-Logic. Text2Onto сочетает в себе машинное обучение и базовую лингвистическую обработку токенизацию и разбор на предложения. Программа определяет в тексте некоторые виды отношений, такие как класс-подкласс, эквивалентность, экземпляры классов. Например, для выявления отношения подкласса в Text2Onto были реализованы различные алгоритмы, в частности реализовали алгоритм сопоставления шаблонов с использованием структуры WordNet. Целью разрабатываемой программной системы является получение новых знаний на основе уже имеющихся знаний, содержащихся в текстах естественного языка, а также получения ответов на вопросы, относящиеся к этим текстам. В рамках работы в качестве примеров были взяты локальные нормативные документы факультета информационных технологий. На вход программная система получает текстовый документ, который она преобразовывает в бескванторные предложения логики предикатов. Для преобразования текстов в логику предикатов используется программа Logic Text 20. С помощью данной программы можно получить фрагменты атомарных диаграмм по предложениям естественного языка. Далее происходит преобразование многоместных предикатов в двухместные. Для того чтобы не потерять смысл предложений, вводятся константы, обозначающие ситуации. После этого полученные предложения, записанные в сигнатуре двухместных предикатов, транслируется в язык OWL. На следующем шаге порождаются правила вывода по заранее созданным шаблонам. Шаблоны строятся для каждой предметной области отдельно. Для построения шаблонов используется логика предикатов рассматриваемой сигнатуры. С помощью машины логического вывода и созданных правил вывода в онтологическую модель добавляются новые знания. Для работы с онтологией на языке OWL и с правилами вывода, написанными на SWRL, используется машина логического вывода Pellet. Шаблоны для запросов к онтологической модели также строятся на языке логики предикатов. Как и шаблоны для правил вывода, шаблоны для запросов строятся под конкретную предметную область. Заранее подготовленные шаблоны для запросов к онтологической модели заполняются с помощью пользовательского интерфейса, после чего происходит запрос к онтологической модели. Учитывая новые выведенные знания, мы получаем ответ на запрос с помощью языка SQWRL, затем формулируем ответ на понятном для пользователя языке. В итоге программная система может отвечать на вопросы пользователей по текстам на естественном языке. Схема работы программной системы представлена на рис. 3. В схеме работы можно выделить следующие основные этапы преобразование текстовых документов выбранной предметной области в наборы атомарных предложений конвертация фрагментов атомарных диаграмм в онтологическую модель порождение правил вывода для построенной онтологической модели вывод новых знаний проверка полученных результатов. Рассмотрим подробно каждый из этапов. Для построения по текстам естественного языка фрагмента атомарной диаграммы используется программная система LogicText 21. Знания, представленные в тексте, формализуются на языке многоместных предикатов. Однако многоместные предикаты нельзя представить на языке OWL, так как OWL поддерживает только двухместные предикаты. Поэтому нужно преобразовать многоместные предикаты в двухместные. . Онтологическая модель строится на основе четырехуровневой модели представления знаний 1 2 это онтология, общие знания, прецеденты, оценочные знания. В данном случае нам потребуются только первые три уровня. Рассмотрим уровни онтологической модели на примере нормативных документов факультета. Первый уровень это онтология 22. Онтология представляет собой формальное описание языка предметной области, цель которого в явном виде определить смысл терминов, используемых в данной предметной области. Ключевые термины это понятия, смысл которых, во-первых, является специфичным для данной предметной области и, во-вторых, одинаково понимается всеми экспертами предметной области. Примерами таких знаний о смысле понятий являются . Второй уровень это общие, универсальные знания о предметной области, которые считаются полностью истинными на данный момент времени. В рамках формального описания учебного процесса это знания, извлеченные из различных нормативных документов. Общие знания извлекаются из текстов и содержат общую информацию о предметной области. Например . Третий уровень онтологической модели прецеденты или частные знания. Это знания, которые истины в конкретной ситуации, т. е. для определенного экземпляра предметной области. Например . Для пополнения онтологической модели знаниями, извлеченными из текстов естественного языка, происходит преобразование многоместных предикатов в двухместные. Для этого используется алгоритм, представленный в 23. Преобразование многоместных предикатов в двухместные происходит с помощью введения сигнатуры дополнительных констант-си туаций. Для пополнения онтологической модели новыми знаниями необходимо создавать правила вывода. Чтобы не строить каждый раз правила вывода вручную, используются шаблоны правил вывода. Заполнение шаблонов правил вывода происходит в момент создания онтологической модели. Шаблоны строятся для конкретной предметной области. При переводе -местных предикатов в двухместные вводятся специальные отношения между константами-ситуациями 23. Например отношение, обозначающее, что ситуация является частью более общей ситуации отношение, обозначающее, что ситуации и эквивалентны. Для отношения справедливы, например, следующие правила вывода А для отношения справедливы правила вывода Эти правила вывода являются примерами шаблонов. Вместо мы можем подставить любой предикат из сигнатуры онтологической модели. и тоже могут быть любыми ситуациями, которые связанны предикатами или соответственно. Шаблоны правил вывода могут заполняться автоматически и добавляться в онтологическую модель уже как готовые правила вывода. Для получения по онтологической модели новых знаний используются правила вывода, построенные на предыдущем этапе, и машина логического вывода Pellet. Сначала машина логического вывода проверяет, что созданная онтологическая модель не является противоречивой. Если мы выявили, что какие-либо знания противоречат друг другу, то специальная утилита для редактора онтологий Protg подскажет, какие утверждения вступают в противоречие. Разрешить такие противоречия в рамках разрабатываемой системы можно только вручную. После того как машина логического вывода подтвердила, что онтологическая модель является непротиворечивой, мы переходим к порождению новых знаний. Система Pellet использует порожденные ранее правила вывода и добавляет новые знания в онтологическую модель. . Чтобы проверить, получилось ли вывести новые знания, используются запросы к онтологической модели, которые также строятся по шаблонам. Шаблоны запросов порождаются для конкретной предметной области аналогично шаблонам правил вывода. Редактирование шаблона происходит пользователем через графический интерфейс. Шаблон имеет вид какого-либо вопроса. Например Вместо может быть подставлен любой класс из онтологической модели, который связан с ситуацией свойством или . При этом можно выбрать любой вопрос, который заполнился по шаблону. Если заполнение шаблона не может произойти однозначно, то пользователю предоставляется возможность самому выбрать правильный вопрос. Например, если вместо можно подставить несколько слов, и т. д., то на экране появится выпадающий список со всеми этими словами. Пользователь сам выберет нужное и задаст вопрос. Также пользователь может задать несколько вопросов, по очереди выбирая нужное слово. После того как пользователь сформировал вопрос, он представляется в виде SQWRL запроса к онтологической модели. Так как SQWRL имеет доступ и к тем знаниям, которые были выведены с помощью машины логического вывода, то в ответ пользователю попадет не только та информация, которая в явном виде содержится в текстах, но и та, которая была выведена с помощью правил вывода. SQWRL возвращает ответ в виде таблицы. По данным из таблицы, учитывая ситуацию, с которой связано это слово, мы строим текстовый ответ пользователю и отображаем его на экране. Чтобы проверить, какие знания получилось вывести, можно, например, задать следующие вопросы Рассмотрим ответ на вопрос . По этому вопросу составится SQWRL запрос вида Это основной запрос, по нему получим информацию о том, что должен сделать рецензент. В данном случае это будет и Чтобы ответ получился полным, нужно сделать запросы, уже используя полученную информацию. В итоге получим ответ Далее пользователю предлагаются уточняющие вопросы. Например, В ответ получим Была разработана программная система на языке Java, работающая посредством OWL API с онтологической моделью, представленной на языке OWL 2 DL. Шаблоны правил вывода создаются индивидуально для каждой предметной области. Выше были рассмотрены примеры шаблонов, в частности Помимо шаблонов правил вывода со специальными отношениями, мы рассматриваем шаблоны, которые не связаны со специальными отношениями Подставляя в шаблоны конкретные константы-ситуации и конкретные предикаты, программа порождает правила вывода. Это происходит автоматически через OWL API. Запросы к онтологической модели строятся с помощью SQWRL. Для данной предметной области можно определить основные шаблоны запросов Пользователю выводятся данные шаблоны, вместо или предлагаются на выбор слова. Слова берутся из онтологической модели. Например, для первого вопроса для того, чтобы заполнить возможными значениями переменную, в онтологическую модель делается запрос Переменная не содержится в потому, что нам не важно в данном случае, к какой ситуации относятся выведенные константы. Аналогичные запросы выполняются для всех переменных. После того как пользователь сделает выбор по поводу заполнения переменных, создаются запросы к онтологии. Ответы пользователям на естественном языке также строятся по шаблонам. Шаблоны ответов строятся аналогично шаблонам вопросов. Так, например, к шаблону вопроса троится шаблон ответа . Здесь это ответ, полученный с помощью SQWRL-запроса. В общем виде из онтологической модели с помощью SQWRL-запроса может быть получено несколько действий объекта . Обобщая шаблон на такой случай, получаем X должен Y иили Z, иили S, иили . Рассмотрим примеры вопросов и их представление на SQWRL. Ответы представим сразу в читаемом для пользователя виде на естественном языке. Когда должен На такой запрос мы не сможем получить ответ, так как промежутка времени не задано в предложении. Поэтому нужно сделать два других запроса до какой даты или какой даты Получим ответ по шаблону X должен Y до Z. Сколько времени есть у для выполнения задачи В запросах, начинающихся на, в ответ пользователю выдаем просто значение, полученное с помощью SQWRL. Получим ответ Тестирование программной системы проходило на документах ФИТ НГУ, а именно 09.04.01 Программа государственной итоговой аттестации по образовательной программе высшего образования программе магистратуры, Приказы о проведении сессий. Было обработано 30 предложений, содержащих информацию о сроках проведения этапов обучения, представления документов на кафедру и порядке проведения защиты квалификационной работы. По каждому предложению было составлено порядка 10 двухместных предикатов. По подготовленным предикатам составлена онтологическая модель, содержащая 367 аксиом. Автоматически были созданы 50 правил вывода. Программный продукт может отвечать на 6 видов вопросов, а именно Статья посвящена разработке методов извлечения знаний из текстов на естественном языке и порождения новых знаний, явно не содержащихся в текстах. Была создана программная система, предназначенная для порождения новых знаний на основе обработки текстов естественного языка. Разработанная программная система позволяет извлекать знания из текстов и представлять их в формальном виде в онтологической модели. Онтологическая модель строится на основе четырехуровневой модели представления знаний. Использование онтологической модели позволяет порождать новые знания с помощью добавления новых правил вывода, а также проверять полученные знания на непротиворечивость с помощью машины логического вывода. Программная система дает возможность пользователям задавать вопросы на естественном языке, относящиеся к рассматриваемым документам. Ответы на вопросы строятся динамически, исходя из знаний, содержащихся в онтологической модели. При составлении ответа на вопрос используются как знания, явно содержащиеся в текстах, так и новые знания, порожденные в онтологической модели. "}
{"title": "РАЗРАБОТКА МУЗЫКАЛЬНОЙ РЕКОМЕНДАТЕЛЬНОЙ СИСТЕМЫ  НА ОСНОВЕ ОБРАБОТКИ МЕТАДАННЫХ КОНТЕНТА  ", "absract": "Музыкальная рекомендательная система (МРС) помогает пользователям музыкальных стриминговых сервисов находить интересующий их музыкальный контент. Разреженность пользовательских оценок – одна  из главных проблем исследования МРС. Она вызвана тем, что пользователь оценивает лишь малую долю объектов музыкального каталога. В результате МРС часто не обладает достаточным набором данных для составления рекомендаций.  В статье предложен подход для решения проблемы разреженности пользовательских оценок на основе использования оценок связанных объектов. Описана гибридная МРС, использующая как нормализованные пользовательские оценки треков, альбомов, артистов, жанров, так и информацию о связях между объектами разных типов. Произведена оценка эффективности разработанной МРС, а также произведен сравнительный анализ предложенного подхода с коллаборативным методом предсказания пользовательских предпочтений. ", "text": " Рекомендательные системы это программные инструменты и методики, которые предлагают пользователям объекты, наиболее интересные для них 1. Музыкальная рекомендательная система МРС предлагает пользователям музыкального сервиса объекты музыкального каталога. Основными задачами и направлениями исследований МРС являются 1 предсказание пользовательских оценок треков, альбомов, артистов, жанров и др. 2 автоматическое тегирование 3 автоматическое составление продолжение плейлиста 4 контекстно-ориентированные системы. Задача предсказания пользовательских оценок решается для составления рекомендаций 25 и для восполнения пропусков в разреженной матрице пользовательских оценок 6. Семантические дескрипторы теги позволяют описать объекты музыкального каталога в терминах, понятных для пользователя 7 8, поэтому они удобны для поиска музыки. Этим вызван интерес к задачам автоматического тегирования, например, классификации жанров и распознавания эмоций 9. Так как пользователь обычно слушает треки в составе последовательности 10, задача автоматического составления продолжения плейлиста 8 11 также представляет интерес. Она связана с выбором треков, соответствующих предопределенным характеристикам например, семантическим дескрипторам 8, порядком выбранных треков и др. 10. Контекст пользователя локация, время, деятельность и др. значительно влияет на его ситуативные предпочтения 10, поэтому разработка контекстно-ориентированных систем 8 является перспективным направлением. Для решения задач исследований МРС используются три вида данных 1 контентные данные 2 музыкальный контекст 3 пользовательские данные. Контентные данные 12 это значения акустических признаков, полученные в результате обработки аудиосигнала 2 3 8 13. Музыкальный контекст 14 это данные, которые описывают музыкальные объекты, но не являются результатом обработки аудиосигнала. Например, текстовые описания объектов, информация о связях между объектами разных типов, теги, поставленные экспертной группой, и др. Пользовательские данные 15 включают в себя персональные данные 3 5, историю воспроизведений 4 11 16, историю сессий повторные воспроизведения треков, пропуски треков и др. 4 6, контекст пользователя 6 8, поставленные оценки 2 3 5 6, присвоенные теги 11 13 и др. Также используются данные о взаимодействии пользователей с другими видами контента 5. При решении задач исследований МРС возникают следующие проблемы 1 холодный старт новый пользователь, новый объект 2 разреженность пользовательских оценок. Проблема холодного старта 10 является обобщением проблемы нового пользователя и проблемы нового объекта. Проблема нового пользователя возникает, когда пользователь регистрируется в музыкальном сервисе, и МРС не обладает данными об этом пользователе, чтобы составить для него рекомендацию. Для решения этой проблемы применяются опрос пользователя при регистрации и кросс-доменный подход 5. Проблема нового объекта возникает, когда объект добавляется в каталог, и МРС не обладает данными об этом объекте, чтобы включить его в рекомендацию. Для решения этой проблемы применяются контентноориентированный подход 2 и контентные гибридные системы 13 16. Проблема разреженности пользовательских оценок 10 возникает, когда число поставленных оценок значительно меньше числа возможных. Разреженность определяется согласно формуле 1 где число пользователей, число объектов, число пользовательских оценок пользователь может поставить только одну оценку объекту. Эта проблема особенно актуальна для исследований МРС. Из-за того, что музыкальные каталоги содержат огромное число объектов десятки миллионов треков 10, пользователь обычно взаимодействует лишь с малой их долей. Также пользователь обычно слушает треки в составе последовательности и не прерывает воспроизведение, чтобы оценить их. Более того, пользователь нередко не концентрируется на воспроизводимых треках и не оценивает их. В результате доля объектов, оцененных пользователем, обычно близка к нулю. Значение разреженности одного из наибольших наборов данных C15 Yahoo Music user ratings of musical tracks, albums, artists and genres, v 1.0 составляет 99,96 набор данных содержит пользовательские оценки треков, альбомов, артистов, жанров. Для сравнения разреженность набора данных от Netflix составляет 98,82 набор данных содержит пользовательские оценки фильмов и сериалов 10. Разница более чем в процент существенна. Для решения этой проблемы применяются контентные гибридные системы и методы, в которых вычисляются неявные пользовательские оценки. В контентных гибридных системах 2 обычно для предсказания пользовательской оценки трека используются оценки треков похожих по значениям акустических признаков. Также может быть обучена модель 3, которая использует значения акустических признаков совместно с персональными данными. В методах, основанных на неявных оценках 4 6 для треков, с которыми пользователь взаимодействовал, но которые не оценивал, вычисляются неявные оценки, которые восполняют пропуски в разреженной матрице пользовательских оценок. Для решения проблемы разреженности пользовательских оценок предлагается использовать оценки связанных согласно метаданным контента объектов музыкального каталога как похожих. В статье описана гибридная МРС, в которой применен предложенный подход. Этапы работы МРС 1 определение похожих альбомов, артистов, жанров 2 предварительный выбор треков 3 определение похожих пользователей 4 вычисление значений признаков 5 обучение модели для предсказания пользовательских оценок треков 6 предсказание пользовательских оценок треков 7 составление рекомендации. На этапах 12 для пользователя предварительно выбираются треки. Для этого определяются альбомы, артисты, жанры, которые предположительно нравятся ему, и выбираются треки, связанные с ними. На этапах 36 для каждого выбранного трека предсказывается оценка. Для этого используются оценки, поставленные похожими пользователями как этому треку, так и связанным с ним объектам. На этапе 7 выбираются треки с наибольшими предсказанными оценками. Объекты представлены в виде целочисленных идентификаторов. Множество объектов определено согласно формуле где число объектов. Метаданные контента содержат информацию о типах объектов и о связях между объектами разных типов. В результате обработки метаданных контента определены 1, разбиение множества на множества треков, альбомов, артистов, жанров 2 отображение, которое сопоставляет с треком связанный альбом. Если трек не связан ни с одним альбомом, то сопоставляется 3 отображение, которое сопоставляет с треком связанного артиста. Если трек не связан ни с одним артистом, то сопоставляется 4 отображение, которое сопоставляет с треком множество связанных жанров 5 отображение, которое сопоставляет с альбомом связанного артиста. Если альбом не связан ни с одним артистом, то сопоставляется 6 отображение, которое сопоставляет с альбомом множество связанных жанров. Также определены вспомогательные отображения 1 отображение, которое сопоставляет с альбомом множество связанных треков 2 отображение, которое сопоставляет с артистом множество связанных треков 3 отображение, которое сопоставляет с артистом множество связанных альбомов 4 отображение, которое сопоставляет с жанром множество связанных треков 5 отображение, которое сопоставляет с жанром множество связанных альбомов. Пользователи представлены в виде целочисленных идентификаторов. Множество пользователей определено согласно формуле где число пользователей. МРС использует пользовательские оценки объектов 1 отображение, которое сопоставляет с пользователем и объектом нормализованную оценку. Если пользователь не оценивал объект, то сопоставляется 2 отображение, которое сопоставляет с пользователем и объектом бинарную оценку. Определено согласно формуле где пороговое значение. Если достигает, то считается, что пользователю нравится объект . Если пользователь не оценивал объект, то сопоставляется . Рассмотрим на примере альбомов. В первую очередь по формуле определяется множество альбомов, связанных хотя бы с одним треком, . Для каждого альбома согласно формуле строится вектор . Компонента соответствует пользователю и содержит значение из множества в зависимости от того, оценивал ли пользователь альбом, и если оценивал, то понравился ли альбом ему. Далее, для каждой пары альбомов на основе векторов и вычисляется значение коэффициента схожести Чем ближе значение к, тем больше альбомы, похожи. Чем ближе значение к, тем более они различны. Если значение близко к, то схожесть не определена. Если хотя бы один альбом не оценен ни одним пользователем, то считается, что . Далее, для каждого альбома на основе значений определяется множество похожих альбомов где пороговое значение. Для артистов, жанров, связанных хотя бы с одним треком, аналогично. Также при построении вектора для альбома, если пользователь не оценивал альбом, но оценивал хотя бы один связанный трек, предлагается вычислять среднее значение нормализованных оценок пользователя, поставленных связанным трекам, и в зависимости от того, достигает ли это значение, восполнять компоненту значением из множества . В результате восполнения нулевых компонент векторов строятся векторы, которые могут быть использованы вместо векторов при вычислении значений . Аналогично для артистов, жанров используются оценки связанных треков и альбомов. Для пользователя выбираются треки, которые в дальнейшем могут быть включены в рекомендацию. В первую очередь согласно формулам, определяются множества альбомов, связанных хотя бы с одним треком, которые нравятся пользователю, не нравятся и которые он не оценивал, соответственно. Для каждого альбома определяется число похожих альбомов, которые нравятся пользователю и не нравятся, соответственно, . На основе этих чисел предсказывается бинарная оценка . Если оба эти числа равны нулю, то оценка не предсказывается. Для артистов, жанров, связанных хотя бы с одним треком, аналогично. Для пользователя случайно выбираются треков, связанных с альбомами, артистами, жанрами, которые предположительно нравятся ему согласно или . В первую очередь для каждого пользователя строится вектор . Компонента соответствует объекту и содержит значение из множества в зависимости от того, оценивал ли пользователь объект, и если оценивал, то понравился ли объект ему. Далее, для каждой пары пользователей на основе векторов и вычисляется значение коэффициента схожести Чем ближе значение к, тем больше пользователи, похожи. Чем ближе значение к, тем больше они различны. Если значение близко к, то схожесть не определена. Если хотя бы один пользователь не оценивал ни один объект, то считается, что . Далее, для каждого пользователя на основе значений определяется множество похожих пользователей . Для этого выбираются пользователей с наибольшими положительными значениями . Для пары пользователь, трек вычисляются значения признаков . В качестве признаков выбраны средние взвешенные значения нормализованных оценок, поставленных похожими пользователями из множества объектам из множеств табл. 1. Признаки и соответствующие множества объектов Features and Corresponding Sets of Items Признак Множество Объекты множества Трек Альбом, связанный с треком Треки, связанные с альбомом Артист, связанный с треком Треки и альбомы, связанные с артистом Жанры, связанные с треком Треки и альбомы, связанные с жанрами Идея заключается в том, что если похожие пользователи не оценивали трек это вероятно из-за проблемы разреженности пользовательских оценок, то, возможно, они оценивали связанные альбом, артиста, жанры. В этом случае значение не определено, но хотя бы одно из значений, можно вычислить. Если похожие пользователи не оценивали и связанный альбом, то, возможно, они оценивали другие треки, связанные с ним. В этом случае значение не определено, но значение можно вычислить. Аналогично для связанных артиста, жанров. Более того, когда значение можно вычислить, использование значений может способствовать увеличению эффективности предсказания оценок треков. Множества объектов см. табл. 1 определены согласно формулам, Значения признаков вычисляются по формулам, Если, то значение не определено. В этом случае считается, что . На этапах определения похожих пользователей и вычисления значений признаков подготавливаются тренировочное, валидационное для выбора модели и тестовое множества. Эти множества содержат кортежи пользователь, трек, значения признаков, оценка или . Важно, чтобы при подготовке этих множеств используемые оценки не пересекались. С использованием тренировочного множества обучается модель модели для предсказания оценок треков или . В качестве входных данных модель использует предварительно обработанные значения . Обученная модель предсказывает оценки для предварительно выбранных треков. Для пользователя составляется список треков, которые, предположительно, нравятся ему. Для этого из предварительно выбранных треков выбираются треков с наибольшими предсказанными нормализованными оценкам, достигающими в порядке убывания предсказанной нормализованной оценки. Если предсказываются бинарные оценки, то трек включается в рекомендацию, если предсказанная бинарная оценка . Для реализации МРС выбран набор данных C15 Yahoo Music user ratings of musical tracks, albums, artists and genres, v 1.0 тренировочное подмножество большого поднабора данных, табл. 2. Пользователи и объекты треки, альбомы, артисты, жанры представлены в виде целочисленных идентификаторов. Для треков опционально определены связанные альбом, артист, жанры для альбомов связанные артист, жанры. Пользовательские оценки представлены в виде целочисленных значений из множества, хотя 97,69 оценок кратны 10. Основные характеристики используемой части набора данных Characteristics of the Datasets Applied Part Показатель Значение Число пользователей 1000990 Число объектов 624961 Число треков 507172 Число альбомов 88909 Число артистов 27888 Число жанров 992 Число пользовательских оценок 252800275 Разреженность согласно формуле 1 99,96 Оценки при помощи деления на 100 приведены к значениям из отрезка . Выбрано пороговое значение нормализованной оценки . Это наибольшее значение, которое достигается как минимум половиной нормализованных оценок 58,67, при 47,44 . Недостатком набора данных является то, что не все альбомы, артисты, жанры связаны с треками. Поэтому на этапах определения похожих альбомов, артистов, жанров и предварительного выбора треков рассматривались 52 187 альбомов 58,7 от числа всех альбомов, 19 691 артист 70,61, 205 жанров 20,67 . На основе оценок пользователей из множества определены множества похожих альбомов, артистов, жанров. Для этого использовались значения, вычисленные на основе векторов, и пороговые значения 0.01, 0.05, 0.1, 0.15, 0.2, 0.25 12 подходов, для каждого подхода множества определены по отдельности. Для альбомов выбирается подход, при котором достигается наибольшая точность предсказания бинарных оценок. Для артистов, жанров аналогично. Для пользователя с применением выбранных подходов предварительно выбираются треков. Для каждого пользователя из множества оценки треков разделены на тренировочные, валидационные и тестовые в долях 75, 12,5, 12,5 соответственно. Все оценки альбомов, артистов, жанров использовались как тренировочные. Для построения векторов и вычисления значений использовались только тренировочные оценки. Для пользователей из множества хотя бы с одной оценкой трека 123 пользователя вычислены значения относительно пользователей из множества . Для определения множеств похожих пользователей выбирались пользователей с наибольшими положительными значениями . В результате для 119 из 123 пользователей определена 1 000 похожих пользователей для остальных 4 пользователей меньшее число. В среднем по 123 множествам среднее значение составило 0,1481, а среднее квадратичное отклонение значений внутри множества 0,03. Для оценок треков, поставленных пользователями из множества, вычислены значения признаков . В результате подготовлены тренировочное, валидационное и тестовое множества с мощностями 16769, 2797, 2787 соответственно табл. 3. Доли пропусков значений признаков, Features Missing Parts, Множество Признак Тренировочное 32,55 20,6 17,87 13,71 13,36 4,94 2,17 Валидационное 33,25 20,38 17,73 14,48 13,55 4,83 2,32 Тестовое 32,15 19,27 17,19 13,17 12,67 5,06 1,94 В тестовом множестве значение признака среднее взвешенное значение нормализованных оценок трека, поставленных похожими пользователями не определено в 32,15 случаев. Доли пропусков значений признаков значительно меньше. Отметим, что в используемой части набора данных 8,33 треков не связаны ни с одним альбом, 12,52 ни с одним артистом, 6,15 ни с одним жанром в коммерческих музыкальных каталогах эта проблема отсутствует. Для реализации модели выбран метод машинного обучения случайный лес 17. Метод применен со значениями параметров число деревьев 10, 20, 30, 40, 50, 60, 70 минимальное число элементов в листе 1, 5, 10, 15, 20 35 вариантов. Пропуски в значениях признаков заменяются средним значением признака в тренировочном множестве для признаков эти значения равны 0,5747, 0,5593, 0,547, 0,6021, 0,5579, 0,6243, 0,573 соответственно. С использованием тренировочного множества обучены модели для предсказания нормализованных и бинарных пользовательских оценок треков. С использованием валидационного множества выбираются модели с наибольшей эффективностью предсказания оценок. С использованием выбранной для нормализованных или бинарных оценок модели выбираются треков для рекомендации. Для оценки эффективности предсказания бинарных оценок альбомов, артистов, жанров использовались оценки пользователей из множества . На основе оценок пользователей из множества выявлено, что в случаев, когда пользователь оценивал как альбом, так и хотя бы один связанный трек, бинарная оценка альбома совпадает с приведенным к бинарному значению с использованием порогового значения средним значением нормализованных оценок связанных треков. Для артистов, жанров совпадения выявлены в и случаев соответственно. Это означает, что если пользователю нравится альбом, артист или жанр, то с большой вероятностью с меньшей для жанра ему нравятся связанные треки. Таким образом, при высокой точности предсказания бинарных оценок альбомов, артистов, жанров предварительный выбор треков является эффективным. Для каждого пользователя из множества с двумя и более оценками альбомов 4 652 пользователя оценки альбомов случайно разделены пополам на оценки, которые предсказываются и которые используются для предсказания. Всего предсказывалось 223 639 оценок, значение 0 принимают 46,3, значение 1 53,7 . Для каждого подхода получены точность по формуле 2 и доля не предсказанных оценок табл. 4. Результаты предсказания бинарных оценок альбомов все подходы Albums Binary Ratings Prediction All Approaches ACC, Доля, 0,01 78,51 78,62 0,85 0,47 0,05 79,57 1,61 1,33 0,1 76,96 76,61 6,47 7,25 0,15 66,1 63,39 20,55 24,16 0,2 49,49 44,15 41,32 48,13 0,25 34,91 28,17 59,27 67,47 Выбран подход с использованием векторов и значения . По сравнению с аналогичным подходом на основе векторов доля альбомов с хотя бы одним значением, достигающим, увеличилась с 93 до 95,86 для этих альбомов потенциально может быть предсказана бинарная оценка. Для выбранного подхода получены доли, в которых для бинарных оценок со значениями 0 и 1 предсказаны значения 0, 1 и табл. 5. Результаты предсказания бинарных оценок альбомов со значениями 0 и 1 выбранный подход Albums Binary Ratings Equal to 0 and 1 Prediction Selected Approach Для артистов аналогично табл. 6. Всего предсказывалось 359 378 оценок 9 831 пользователь, значение 0 принимают 39,39, значение 1 60,61 . Результаты предсказания бинарных оценок артистов все подходы Artists Binary Ratings Prediction 31,5 33,61 Выбран подход с использованием векторов и значения . По сравнению с аналогичным подходом на основе векторов доля артистов с хотя бы одним значением, достигающим, увеличилась с 91,13 до 94,57 . Для выбранного подхода получены доли, в которых для бинарных оценок со значениями 0 и 1 предсказаны значения 0, 1 и табл. 7. Результаты предсказания бинарных оценок артистов со значениями 0 и 1 выбранный подход Artists Binary Ratings Equal to 0 and 1 Prediction Selected Approach, 75,46 23,42 1,12 9,39 89,8 0,81 Для жанров аналогично табл. 8. Всего предсказывалось 32 596 оценок 6 498 пользователей, среди которых значение 0 принимают 38,92, значение 1 61,08 . Результаты предсказания бинарных оценок жанров все подходы Genres Binary Ratings Prediction All Approaches ACC, Доля, 0,01 84,35 83,91 0,01 0 0,05 84,95 84,17 0,05 0 0,1 85,89 84,85 0,23 0,05 0,15 86,09 0,85 0,52 0,2 86,09 86,03 1,93 1,94 0,25 84,62 84,9 4,08 3,82 Выбран подход на основе векторов и значения . Доля жанров с хотя бы одним значением, достигающим, составляет 100 . Для выбранного подхода получены доли, в которых для бинарных оценок со значениями 0 и 1 предсказаны значения 0, 1 и табл. 9. Результаты предсказания бинарных оценок жанров со значениями 0 и 1 выбранный подход Genres Binary Ratings Equal to 0 and 1 Prediction Selected Approach, 86,02 13,53 0,44 12,26 86,63 1,11 На основе оценок пользователей из множества с хотя бы одной оценкой трека 123 пользователя и похожих пользователей из множества подготовлены валидационное и тестовое множества с мощностями 2 797, 2 787 соответственно табл. 10. Доли оценок кратных 0,1 в валидационном и тестовом множествах, Parts of Ratings that Are Multiples of 0.1 in the Validation and the Test Sets. Метод случайный лес применен со значениями параметров число деревьев 10, 20, 30, 40, 50, 60, 70 минимальное число элементов в листе 1, 5, 10, 15, 20. Для обученных моделей с использованием валидационного множества получены значения RMSE табл. 11 RMSE предсказания нормализованных оценок треков из валидационного множества все модели Tracks Normalized Ratings Prediction RMSE for the Validation Set All Models Ч. д. Минимальное число элементов в листе 1 5 10 15 20 10 0,3133 0,3071 0,309 0,3107 0,3119 20 0,3065 0,3035 0,3048 0,3095 0,3106 30 0,3043 0,3028 0,3059 0,3083 0,311 40 0,3026 0,3014 0,3049 0,3084 0,3097 50 0,303 0,3018 0,3049 0,3075 0,3103 60 0,3036 0,30101 0,3048 0,3075 0,3099 70 0,3018 0,3042 0,3079 0,3104 Выбрана модель, для которой метод случайный лес применен со значениями параметров число деревьев 70, минимальное число элементов в листе 5. Также рассмотрен коллаборативный метод, в котором значение признака среднее взвешенное значение нормализованных оценок трека, поставленных похожими пользователями используется в качестве предсказания. В тех случаях, когда значение не определено для тестового множества в 32,15 случаев, используется среднее значение в тренировочном множестве. Для выбранной модели и коллаборативного метода с использованием тестового множества получены значения RMSE и MAE табл. 12 Результаты предсказания нормализованных оценок треков из тестового множества Tracks Normalized Ratings Prediction for the Test Set RMSE MAE Выбранная модель 0,3037 0,2354 Зн. пр. или ср. зн. 0,3946 0,3177 Выбранная модель превосходит коллаборативный метод. Также значения RMSE и MAE получены для подмножества тестового множества, для которого значения определены табл. 13. Результаты предсказания нормализованных оценок треков из подмножества тестового множества, для которого значения определены Tracks Normalized Ratings Prediction for the Part of the Test Set where Is Calculated RMSE MAE Выбранная модель 0,3093 0,2419 Зн. пр. 0,374 0,2808 Даже в тех случаях, когда коллаборативный метод предсказывает нормализованную оценку значение определено, выбранная модель предсказывает ее с меньшими значениями ошибок RMSE и MAE. Для выбранной модели получены значения важности признаков табл. 14. Для этого для каждого дерева вычисляется среднее взвешенное значение уменьшения неопределенности англ. impurity в вершинах, где используется признак. В качестве весов используются доли элементов тренировочного множества, достигающих вершины. Важность признака это среднее этих значений, вычисленных для каждого дерева. При обучении моделей в качестве меры неопределенности используется среднеквадратичная ошибка MSE. Важность признаков для предсказания нормализованных оценок треков выбранная модель Features Importance for the Normalized Ratings Prediction Selected Model 0,0986 0,0655 0,1166 0,1168 0,1106 Наиболее важными являются признаки и средние взвешенные значения нормализованных оценок, поставленных похожими пользователями трекам и альбомам артиста трекам и альбомам жанров соответственно. Аналогично обучены модели для предсказания бинарных оценок. Среди бинарных оценок из валидационного множества значение 0 принимают 43,15, значение 1 56,85 . Среди бинарных оценок из тестового множества значение 0 принимают 43,09, значение 1 56,91 . Для обученных моделей с использованием валидационного множества получены значения точности согласно формуле 2, табл. 15. Точность предсказания бинарных оценок треков из валидационного множества все модели, Tracks Binary Ratings Prediction Accuracy for the Validation Set All Models, Ч. д. Минимальное число элементов в листе 1 5 10 15 20 10 76,87 76,83 76,69 76,94 76,08 20 77,55 77,51 77,08 76,51 75,94 30 77,4 77,51 77,26 77,05 76,22 40 77,51 77,69 77,08 76,62 76,44 50 78,01 77,69 77,08 76,73 76,51 60 77,94 77,65 77,01 76,76 76,44 70 77,87 77,37 77,15 76,51 Выбрана модель, для которой метод случайный лес применен со значениями параметров число деревьев 70, минимальное число элементов в листе 1. Аналогично рассмотрен коллаборативный метод, в котором приведенное к бинарному значение признака используется в качестве предсказания. В тех случаях, когда значение не определено для тестового множества в 32,15 случаев, используется предопределенное значение бинарной оценки 0 или 1. Для выбранной модели и коллаборативного метода с использованием тестового множества получены значения точности и TPR, TNR, PPV, NPV табл. 16, . Результаты предсказания бинарных оценок треков из тестового множества Tracks Binary Ratings Prediction for the Test Set ACC, TPR TNR PPV NPV Выбранная модель 0,8045 0,7252 0,7945 0,7375 Зн. пр. или 0 64,08 0,8815 0,3231 0,6323 0,6736 Зн. пр. или 1 65,81 0,6141 0,7161 0,7407 0,5842 Выбранная модель превосходит коллаборативный метод. Также значения точности и TPR, TNR, PPV, NPV получены для подмножества тестового множества, для которого значения определены табл. 17. Результаты предсказания бинарных оценок треков из подмножества тестового множества, для которого значения определены Tracks Binary Ratings Prediction for the Part of the Test Set where Is Calculated ACC, TPR TNR PPV NPV Выбранная модель 76,04 0,8124 0,6776 0,8007 0,6938 Зн. пр. 72,03 0,8382 0,5322 0,7407 0,6736 Даже в тех случаях, когда коллаборативный метод предсказывает бинарную оценку, выбранная модель предсказывает ее с большей точностью и значениями TNR, PPV, NPV. Для выбранной модели аналогично получены значения важности признаков при обучении моделей используется неопределенность Джини, табл. 18. Важность признаков для предсказания бинарных оценок треков выбранная модель Features Importance for the Binary Ratings Prediction Selected Model 0,0971 0,1132 0,1258 Наиболее важными являются признаки, среднее взвешенное значение нормализованных оценок, поставленных похожими пользователями трекам и альбомам артиста трекам и альбомам жанров трекам альбома треку соответственно. В статье предложен подход для решения проблемы разреженности пользовательских оценок в исследованиях МРС. Он заключается в использовании оценок связанных согласно метаданным контента объектов как похожих. На основе предложенного подхода разработана и реализована МРС. Выполнена оценка реализованной МРС. Выявлено, что если пользователю нравится альбом, артист или жанр, то с большой вероятностью в меньшей степени для жанра ему нравятся и треки, связанные с ним. При этом получена точность предсказания бинарных пользовательских оценок альбомов, артистов, жанров 79,99, 84,15 и 86,39 соответственно. Это означает, что предварительный выбор треков, реализованный в МРС, является эффективным. Метод предсказания пользовательских оценок треков, реализованный в МРС, превосходит коллаборативный метод использующий оценки похожих пользователей, поставленные треку как на всем тестовом множестве в тех 32,15 случаев, когда коллаборативный метод не может предсказать оценку, используется предопределенное значение, так и на его подмножестве, для которого коллаборативный метод может предсказать оценку. При этом наиболее важными являются признаки, значения которых вычислены на основе оценок похожих пользователей, поставленных объектам, связанным с артистом и жанрами трека. Это означает, что использование оценок связанных объектов в реализованной МРС действительно способствует решению проблемы разреженности пользовательских оценок. "}
{"title": "РАЗРАБОТКА АВТОМАТИЗИРОВАННЫХ МЕТОДОВ ПРЕДСТАВЛЕНИЯ ЗНАНИЙ   О ДЕЙСТВИЯХ И СИТУАЦИЯХ  ", "absract": "  Статья посвящена разработке автоматизированных методов интеграции знаний, извлеченных из текстов естественного языка. Для решения этой задачи используются методы преобразования предложений естественного языка во фрагменты атомарных диаграмм. Знания, извлеченные из текстов, формализуются при помощи атомарных предложений сигнатуры, состоящей из символов констант, двухместных предикатов и дополнительных констант-ситуаций. Разработаны методы интеграции знаний, содержащихся в нескольких предложениях естественного языка, позволяющие учитывать их семантические контексты. ", "text": " Существует огромное количество текстовых документов, представленных в цифровом виде. С каждым днем их объем стремительно растет. Когда перед человеком встает задача обработки информации, заключенной в этих документах, справиться вручную уже практически невозможно. Таким образом, возникает потребность в программном обеспечении, способном обрабатывать тексты естественного языка, извлекать из них необходимую информацию и объединять полученные знания. При работе с документами, представленными на естественном языке, крайне важно учитывать смысл текста, определения и смысл входящих в него понятий, иначе говоря, семантику текста. Проблема формального представления семантики текста исследовалась многими специалистами. Существенный вклад в решение этой проблемы внес И. А. Мельчук, разработав теорию Смысл Текст 1 2. В рамках разработки этой теории был создан толковокомбинаторный словарь, позволяющий учитывать возможность слов вступать в семантические и синтаксические связи с остальными словами предложения. Кроме того, И. А. Мельчук предложил рассматривать глаголы в качестве многоместных предикатов. Теория Смысл Текст была применена в 3 при разработке теоретико-модельного подхода к извлечению знаний из текстов естественного языка. Подход был реализован в программной системе LogicText 4, позволяющей строить атомарные предложения логики предикатов по предложениям русского языка. Для построения фрагментов атомарных диаграмм моделей используются словари номинализаций и валентностей глаголов. Дальнейшее развитие теоретико-модельного подхода предложено в 5, где описан подход к формализации знаний при помощи двухместных предикатов и констант-ситуаций, а также методы заполнения пустых валентностей предикатов-глаголов для выявления недостающих в тексте знаний и для пополнения этих знаний. При анализе и обработке текстов естественного языка крайне важно учитывать контекст. Для корректного понимания семантики необходимо обрабатывать несколько предложений текста одновременно, поэтому целью данного исследования стала разработка методов интеграции знаний, заключенных в разных предложениях естественного языка. Особое внимание в данной работе уделяется выявлению связей между предложениями текста. При обработке, формализации и интеграции извлеченных из текста знаний мы используем четырехуровневую модель представления знаний, предложенную ранее 6 7. Данная модель включает в себя 1 онтологию 2 общие знания 3 эмпирические прецедентные знания 4 оценочные и вероятностные знания. Онтология это спецификация смысла, определения полные или неполные ключевых понятий, которыми описывается данная предметная область. Общие знания это утверждения, принципы и закономерности, являющиеся универсальными для всей предметной области. Они считаются истинными в каждом конкретном экземпляре, прецеденте данной предметной области на текущий момент. Эмпирические знания иначе говоря, прецеденты это описания конкретных ситуаций, экземпляров предметной области. Оценочные и вероятностные знания это знания, истинность которых не является точной, это приближенные, нечеткие, гипотетические или субъективные знания. В рамках четырехуровневой онтологической модели оценочные и вероятностные знания могут порождаться на основе онтологических, общих и эмпирических знаний о предметной области. Одной из задач данного исследования является разработка методов формализации и интеграции знаний, соответствующих разным уровням описанной модели. Введем некоторые определения. В работе рассматриваются модели вида сигнатуры, где универсум модели, предикатные символы, а константные символы. Множество предложений сигнатуры обозначается как . Предложение называется атомарным, если или где Множество предложений мы называем атомарной диаграммой модели . Подмножество атомарной диаграммы модели мы называем фрагментом атомарной диаграммы модели, конечное подмножество конечным фрагментом. В данной работе рассматриваются только конечные фрагменты атомарных диаграмм. Сведения по теоретикомодельному подходу к извлечению и представлению знаний можно найти в 3 5 8. И. А. Мельчук предложил рассматривать глаголы в качестве многоместных предикатов. Основанием этому послужила способность глаголов вступать в связи с другими словами предложения. Это свойство было названо валентностью. Подход И. А. Мельчука был применен в 3 для извлечения и формализации знаний, содержащихся в предложениях естественного языка. В 3 разрабатывался теоретико-модельный подход к извлечению и формализации знаний они представляются в виде наборов атомарных предложений логики предикатов. Глаголы, причастия и деепричастия представляются в виде -местных предикатов. Разработанные методы были реализованы в программе Logic Text 4. Она осуществляет построение фрагментов атомарных диаграмм моделей по предложениям естественного языка, используя словари номинализаций и валентностей глаголов. Пример работы программы представлен на рис. 1. Одной из главных задач данного исследования является формализация знаний, извлеченных из текстов естественного языка, в виде двухместных предикатов. В первую очередь, подобный подход решает проблемы изменения валентности предикатов. -местные предикаты, предложенные в 3 имеют фиксированный набор аргументов и не всегда полностью соответствуют составу слов в предложении, особенно когда речь идет об однородных членах предложения. С помощью двухместных предикатов мы можем обрабатывать слова, отвечающие на один и тот же вопрос. Кроме того, выбор двухместных предикатов в качестве базовой конструкции связан с тем, что для дальнейшей обработки знаний целесообразно использовать технологии семантической паутины Semantic Web 913. Одним из основных инструментов Semantic Web является язык описания онтологий OWL 14. Он, в свою очередь, основан на модели представления данных RDF. RDF-утверждения имеют вид триплетов субъект предикат объект. Двухместные предикаты подходят под структуру триплетов, а значит, могут транслироваться в RDF-утверждения. Благодаря этому мы можем в дальнейшем использовать технологии Semantic Web, в частности применять ризонеры автоматические средства логического вывода 13 15 к наборам двухместных предикатов, построенных по текстам естественного языка. Это позволит нам выявлять противоречия, а также обрабатывать полученные знания и порождать новые. Другим важным аспектом работы стало использование констант-ситуаций в качестве первого аргумента двухместного предиката. Как было сказано ранее, в данном исследовании используются различные уровни представления знаний. В текстах естественного языка объекты и сущности могут иметь различные смысл и свойства в зависимости от контекста и происходящей ситуации. Для корректной обработки текстов естественного языка необходимо учитывать, о каком объекте и о каких свойствах объекта в данном предложении идет речь. Таким образом, константы-ситуации могут быть применены для решения проблемы неполноты и неточности извлекаемой информации. Например, рассмотрим предложения Вчера Вася купил хлеб за 30 рублей. Сегодня Вася купил хлеб за 35 рублей Несмотря на внешнюю схожесть объектов один и тот же глагол, объект, понятно, что эти предложения относятся к разным ситуациям, при этом Вася в обоих предложениях один, а хлеб разный. Такие моменты необходимо учитывать при обработке текстов естественного языка. В данной работе мы продолжаем исследование проблемы формализации и интеграции знаний, извлеченных из текстов естественного языка, с применением двухместных предикатов и констант-ситуаций, начатое в 5. Кратко изложим те аспекты подхода, предложенного в 5, которые потребуются нам в данной работе. Как уже было отмечено, в качестве базовой конструкции для построения модели знаний по тексту естественного языка нами выбраны двухместные предикаты и константы-ситуации. Для обработки текста на естественном языке и извлечения из него знаний на первом этапе производится преобразование текста с помощью программной системы LogicText. В результате мы получаем набор фрагментов атомарных диаграмм моделей, иначе говоря, набор многоместных предикатов, построенных по тексту. Например, предложение Рецензент предоставляет в НГУ рецензию до 31 мая программной системой LogicText будет преобразовано в предикат, . является константой-дей ствием. Задача следующего этапа преобразование -местных предикатов в двухместные. В рамках Semantic Web известен подход, когда -местный предикат преобразуется в набор из двухместных предикатов 16. Мы же осуществляем преобразование из каждого -мест ного предиката в набор из двухместного предиката. Перед преобразованием необходимо привести полученные на первом этапе наборы атомарных диаграмм к специальному виду, а затем заменить вспомогательные константы-действия на константы-ситуации. Более подробно преобразование предикатов описано в 5. В результате мы имеем набор из двухместного предиката. Так, приведенный выше многоместный предикат преобразуется в следующий набор Здесь новая константа-ситуация, введенная специально для формального представления данного предложения. На третьем этапе необходимо определить связи между предложениями, точнее, между константами-ситуациями. Этот шаг является ключевым для понимания общего контекста. Важно определить, являются ли ситуации тождественными, т. е. идет ли в них речь об одном и том же действии. Кроме того, в одних случаях одна константа относится к одним и тем же объектам, а в других к совершенно разным. Таким образом, на третьем этапе выявляются эквивалентные ситуации, а также тождественные объекты. После прохождения всех трех этапов работы мы имеем набор двухместных предикатов, построенных по фрагменту текста естественного языка, а также знаем об эквивалентности некоторых констант-ситуаций. Теперь основная задача объединить извлеченные знания. Рассмотрим данный этап подробнее. Предположим, у нас есть ситуации, которые являются эквивалентными. Эквивалентность ситуаций и задается с помощью отношения . Для каждой из этих ситуаций описаны фрагменты атомарных диаграмм. В таком случае для интеграции знаний создается новая ситуация . К ней добавляются все знания, которые соответствуют ситуациям, при этом сами фрагменты диаграмм, не изменяются. Такой подход позволяет нам объединять знания и при этом сохранять исходные ситуации и данные для дальнейшего отслеживания изменений и обработки ризонерами 12 17. В результате мы получаем новую ситуацию, включающую в себя знания из нескольких предложений текста естественного языка. Помимо отношения тождественности, между ситуациями может возникать связь . Такое отношение мы используем, когда ситуация является частью более общей ситуации . В этом случае при объединении знаний идет уточнение информации. Например, мы имеем два предложения Студент находится в новом корпусе НГУ и Новый корпус НГУ находится в Академгородке. Первое предложение имеет меньшую продолжительность по времени и общность, чем второе предложение. Значит, ситуация, связанная с первым предложением, включается в ситуацию, связанную со вторым предложением. В результате объединения знаний и логического вывода мы получим предложение Студент находится в Академгородке. Формально представить описанные выше связи между ситуациями можно следующим образом ситуация тождественна ситуации . Аксиомы отношения эквивалентности, . Аксиома конгруэнции ., частное, общее. Аксиомы частичного порядка, . Аксиома наследования . В ходе исследований было выявлено, что введение констант-ситуаций, а также отношений тождественности и включения между ними недостаточно для полноценной и семантически верной интеграции знаний. Объекты могут менять свои свойства, в том числе и с течением времени. Нам важно учитывать, что какие-то события происходят одновременно, какие-то последовательно или параллельно. Во избежание противоречий нужно понимать, какое событие произошло раньше, а также какой временной объем оно имело сколько длилось, с какими событиями пересеклось. Для каждого такого события необходимо описывать набор ситуаций. По этой причине нам необходимо ввести модель, в которую, помимо прочего, будут введены временные отношения между ситуациями. Такая модель должна включать в себя двухместные предикаты, первым аргументом которых является определенная ситуация, набор используемых ситуаций и отношения между ситуациями например, раньше, позже, часть по времени, часть по протяженности и т. д. Вероятно, для определения временных отношений между ситуациями потребуется обработка дат каким-либо внешним источником например, чтобы выявить, какая ситуация произошла раньше. Для этого можно использовать оракулы веб-сервисы, объекты из внешнего мира. Отдельно стоит отметить, что при интеграции знаний мы рассматриваем множество тех ситуаций, которые относятся к определенному событию, обстоятельству. Объем или протяженность каждой ситуации включает протяженность рассматриваемого события. Итак, для того чтобы учитывать связи между ситуациями относительно времени, введены дополнительные отношения. Для определения связей между ситуациями, которые выполняются последовательно, мы используем двухместное отношение или . отношение между ситуациями, когда ситуация происходит раньше ситуации . Мы можем понять, что ситуации происходят последовательно, если в предложении четко указано время или присутствуют специальные слова, указывающие на это, например этим, этого, и подобные. Обратный случай можно обозначить двухместным отношением отношение между ситуациями, когда ситуация происходит позже ситуации . Таким образом, Рассмотрим данную связь между ситуациями на примере. Возьмем предложения Комплект документов собирается на факультете и После комплект документов хранится в деле Обучающегося. Обратим внимание, что сущности комплект документов и дело Обучающегося будут рассматриваться как целые константы, а не как отдельные слова. После выполнения первого шага описанного выше алгоритма и приведения многоместных предикатов к специальному виду получим следующее 1 2 Этому соответствуют следующие наборы двухместных предикатов 1 2 Схематично это можно представить следующим образом рис. 2. Две полученных ситуации мы можем объединить согласно общему алгоритму интеграции. Его описание представлено ниже. 1. На первом шаге мы создаем общую ситуацию, включающую в себя подситуации и подситуаций может быть неограниченное количество. Другими словами, имеем отношения и . 2. Проверяем тождественность ситуаций для трех и более подситуаций делаем это последовательно, поскольку для отношения соблюдается транзитивность. Если удается выявить объекты, которые совпадают по смыслу, выносим их в общую ситуацию т. е. для этих объектов меняем текущую ситуацию на общую ситуацию. 3. Остальные объекты остаются в своих подситуациях, подситуации связываем соответствующим отношением. 4. Объединяем все полученные предикаты и отношения, строим по ним окончательное объединенное предложение. Применим алгоритм к нашему примеру. 1. Создаем общую ситуацию, включающую в себя ситуации и, получаем связи между ситуациями и . Схематично это можно представить следующим образом рис. 3. 2. Проверяем тождественность и и выносим эквивалентные объекты в общую ситуацию В нашем случае такими объектами являются константы комплект документов и, соответственно, предикаты и Выносим тождественные объекты в общую ситуацию путем замены первого аргумента в соответствующих двухместных предикатах, получаем предикат Остальные предикаты остаются прежними Стоит отметить следующий момент чтобы отнести тождественные объекты к общей ситуации, нужно их объединить в один. Если слова одинаковые, проблем при объединении не возникает. Но бывают случаи, когда встречаются слова, синонимичные, эквивалентные по смыслу или находящиеся в отношении общее частное. Например, если в одном предложении используется слово, а в другом . Сейчас для простоты будем приводить объекты к тому виду, в котором они встретились нам впервые. Если сначала мы рассмотрели предложение, где объектом был студент, потом предложение, где объектом был бакалавр, то, объединив эти слова, получим студент и вынесем его в общую ситуацию. В дальнейшем такие случаи нужно обрабатывать отдельно, возможно, в полуавтоматическом режиме привлекая пользователя или эксперта. Результат второго шага схематично представлен на рис. 4. 3. Далее необходимо связать подситуации и каким-либо отношением. Поскольку в предложении встречается ключевое слово, будем связывать их временным отношением . 4. Выписываем все полученные предикаты и отношения . Для составления конечного предложения сначала выписываются общие объекты из общей ситуации, потом к ним добавляются объекты из подситуаций. Поскольку подситуации связаны временным отношением, выписываем их в соответствующем порядке рис. 5. Мы рассмотрели пример интеграции знаний для ситуаций, которые происходят последовательно. Для определения связей между ситуациями, которые происходят одновременно, предлагается использовать двухместное отношение или . В данном случае ключевыми словами могут быть в то же время, одновременно и подобные. Если в предложениях явно не указано время действия или отсутствуют ключевые слова, применяется принцип пресуппозиции. Другими словами, сначала выявляется пресуппозиция, что две ситуации и связаны отношением, затем задается вопрос пользователю о верности данной пресуппозиции. Если возможности общения с пользователем нет, формируется условное утверждение фрагмент атомарной диаграммы верен, если верна данная пресуппозиция. В противном случае формируется другой фрагмент атомарной диаграммы, поскольку нам важно рассмотреть все возможные варианты интеграции знаний. Для ситуаций, связанных отношением, объединение знаний происходит по описанному выше алгоритму. Так, из предложений Для поступления поступающий подает заявление о приеме и Для поступления поступающий подает документ, удостоверяющий образование соответствующего уровня мы получим Для поступления поступающий подает заявление о приеме и документ, удостоверяющий образование соответствующего уровня. Некоторые ситуации могут иметь условия, меняющиеся во времени, т. е. в момент времени утверждение является истинным, а в момент времени, отличный от, это же утверждение ложно. Поэтому кроме временных отношений между ситуациями следует вводить аргумент время. Если в утверждение добавлять момент времени, то оно становится абсолютно истинным или ложным, т. е. не зависящим от ситуации и времени. В рамках данного подхода предложена конструкция, позволяющая добавить время в многоместный предикат и преобразовать его в набор двухместных. Сначала многоместные предикаты вида, как это описано выше, преобразуются в набор атомарных предложений, где соответствующая константа-ситуация. Выше были рассмотрены примеры предикатов, . Эти двуместные предикаты, типы аргументов предиката, они соответствуют вопросам к действию ситуации, задаваемым предикатом . Таким образом, при преобразовании многоместного предиката в набор двухместных происходит добавление символов предикатов в качестве новых элементов и добавление констант в качестве новых элементов. Для того чтобы не добавлять имена предикатов в качестве новых элементов модели, мы рассматриваем также следующий способ преобразования многоместных предикатов в двухместные. Многоместный предикат вида преобразуется в набор атомарных предложений Пример предиката . При таком способе преобразования многоместных предикатов в двухместные, происходит добавление только констант в качестве новых элементов модели и, соответственно, новых сигнатурных символов. Символы предикатов в качестве новых элементов модели не добавляются. В элементарную теорию полученной модели добавляются универсальные предложения . В работе предложен подход к формализации и интеграции знаний, извлеченных из текстов естественного языка. В его основу легли теория Смысл Текст И. А. Мельчука, а также теоретико-модельный подход к извлечению и представлению знаний, разработанный авторами ранее. Разработаны методы интеграции знаний, содержащихся в нескольких предложениях естественного языка, основанные на использовании двухместных предикатов и констант-ситуа ций. Предложенные методы могут быть применены для решения проблемы неполноты и неточности знаний. Также они дают возможность интегрировать как знания об объектах с неизменными свойствами, так и знания об изменяющихся во времени свойствах объектов. В дальнейшем предложенный подход может быть дополнен использованием технологий Semantic Web, в том числе автоматических средств логического вывода, для выявления противоречий в документах естественного языка и для порождения новых знаний. "}
{"title": "РАЗРАБОТКА МОБИЛЬНОГО ПРИЛОЖЕНИЯ ВИЗУАЛИЗАЦИИ   ТЕХНИЧЕСКИХ ХАРАКТЕРИСТИК УСТРОЙСТВ ПОД OC ANDROID   НА БАЗЕ ТЕХНОЛОГИЙ ДОПОЛНЕННОЙ РЕАЛЬНОСТИ   И МЕТОДОВ МАШИННОГО ОБУЧЕНИЯ  ", "absract": "В последнее время увеличивается количество окружающих нас электронных приборов, возрастает и их техническая сложность. В то же время инструкции к данным приборам читает только малая часть людей. Также возможны ситуации, когда инструкции или специалиста нет рядом с устройством. Поэтому часто встречаются случаи неправильного использования техники. В связи с этим закономерно встает задача быстрого распознавания типа устройства с последующим выводом информации о данном устройстве. В работе описывается процесс реализации системы распознавания типа устройства с использованием методов машинного обучения, с последующим выводом на экран его основных заранее отобранных характеристик и отображением пользователю набора вероятных инструкций для данного типа устройств.  Поскольку направлением данной работы является нахождение похожих объектов, а также их классификация на основе информации о внешнем представлении объекта, то рассматриваются алгоритмы получения признаков объекта из его изображения. В статье предлагается подход получения определяющих признаков объекта на основе его внешнего представления (контуров). ", "text": " В последнее время увеличивается количество окружающих нас электронных приборов, возрастает и их техническая сложность. В то же время инструкции к данным приборам читает только малая часть людей. Возможны ситуации, когда инструкции или специалиста нет рядом с устройством, поэтому часто встречаются случаи неправильного использования техники. В связи с этим закономерно встает задача быстрого распознавания типа устройства с последующим выводом информации о данном устройстве. Но для реализации системы, хранящей информацию обо всех устройствах, требуется огромный объем данных, который обработать вручную не представляется возможным. Поиск объекта по шаблону в данной задаче является нерациональным, так как любой такой алгоритм составляется вручную с использованием перебора большого количества вариантов классификации объектов. Сложности возникают при распознавании объектов с разных ракурсов, при различном освещении и при деформации. Методы машинного обучения позволяют обучить модель с использованием различных видов входных данных, что дает высокий уровень распознавания объектов. Поэтому решением данной проблемы является использование технологий машинного обучения. В работе описывается процесс реализации системы распознавания типа устройства, с последующим выводом на экран его основных заранее отобранных характеристик и отображением пользователю набора вероятных инструкций для данного типа устройств. Поскольку направлением данной работы является нахождение похожих объектов, а также их классификация на основе информации о внешнем представлении объекта, то рассматриваются алгоритмы получения признаков объекта из его изображения. В статье предлагается подход к получению определяющих признаков объекта на основе его внешнего представления. При этом должна иметься возможность корректировки признаков, влияющих на результат распознавания объекта, и корректировка вклада отдельно взятых признаков. Одним из наиболее популярных методов выделения признаков объекта на основе его внешнего представления является метод SURF. Этот метод основан на поиске ключевых точек изображения. Ключевая точка это точка, имеющая определенные признаки, существенно отличающие ее от остальных точек изображения. Имея информацию о ключевых точках объекта, можно выполнять сравнение двух объектов или классифицировать объект, имея информацию о том, какой набор особых точек характерен для того или иного типа объектов. После получения ключевых точек изображения для каждой из них высчитывается ее дескриптор. Дескриптор это вектор, характеризующий особую точку. Данный алгоритм не подходит к решению задачи, поскольку, имея только ключевые точки рис. 1, которые являются более характеристикой изображения, нежели объекта, нельзя предсказать признаки устройств. Поэтому в данной работе используется метод, основанный на использовании контурного анализа 1. С. 224. Контурный анализ представляет собой совокупность методов описания, преобразования, выделения контуров объекта на изображении. Контур в данном контексте это граница объектов, т. е. совокупность точек пикселей. Контуры изображения являются областями, которые хранят большое количество информации об объекте и не зависят при этом от уровня освещенности и яркости. Контурный анализ требует минимизацию количества шумов на изображении, поэтому до выделения контуров обычно применяются операции, которые уменьшают количество шумов размытие, анализ гистограммы и т. д.. Одними из наиболее распространенных алгоритмов выделения контуров являются алгоритмы Adaptive Thres holding и Canny. Рассмотрим их подробнее. Adaptive Thresholding часто применяют в задаче сегментации изображений. Подход является пороговым методом, при котором выбирается определенное значение яркости, обычно полученное из анализа гистограммы изображения, затем каждый пиксель поочередно сравнивают с выбранным значением, и получившиеся два разбиения соответствуют либо принадлежности точки фону, либо объекту . В алгоритме, использующем адаптивный порог, пороговое значение каждого пикселя зависит от соседних. Берется либо среднее значение окружающих пикселей, либо значение, в которое пиксели, лежащие ближе к исходному пикселю, дают больший вклад, а более удаленные меньший. Затем для каждого пикселя из получившегося значения для области вычитают заранее заданную константу. Получившееся число является пороговым значением для области. Исходя из того, что данный алгоритм опирается на значения яркости изображения, итоговый результат становится чувствительным к перепадам яркости, теням и другим световым артефактам. Алгоритм Canny состоит из пяти шагов. 1. Сглаживание. На данном этапе происходит фильтрация шума изображения с помощью фильтра Гаусса размером 5 5. Влияние пикселей при использовании фильтра Гаусса друг на друга обратно пропорционально квадрату расстояния между ними. 2. Нахождение градиентов для каждого пикселя изображения. На данном этапе для вычисления приближенного значения градиентов применяется оператор Собеля. 3. Подавление немаксимумов Non-maximum suppression. Пикселями границ становятся точки, в которых в направлении вектора градиента наблюдается локальный максимум. 4. Выполнение двойной пороговой фильтрации. На данном шаге потенциальные границы определяются пороговыми значениями. 5. Трассировка области неоднозначности. Происходит подавление границ, не связанных с выделенными на шаге 4. В результате анализа описанных подходов предложен алгоритм выделения признаков устройств на основе его контуров, а также их связи с техническими характеристиками устройств. Реализованный алгоритм является более гибким и прозрачным, так как поддерживает настройку вклада каждого контура в получение его признаков и удаление ненужных контуров. Поскольку не существует отдельного набора данных, подходящего под начальные условия задачи, было решено воспользоваться платформой Open Image Dataset. Вторым способом получения данных является использование поискового робота так называемый скрапер для обхода сайта производителя или поставщика техники. Полученные данные представляют собой таблицу в виде списка URL-адресов для загрузки данных, а также таблицу соответствий адресов классам изображений. Но в дальнейшем данные, полученные таким способом, не использовались, поскольку невозможно подобрать инструкции к моделям, представленным на изображениях. Поэтому в работе используется скрапер для обхода сайта реселлера техники, который получает изображения техники вместе с его инструкцией в формате PDF. Для того чтобы получить технические характеристики объекта, используется поисковый скрапер Web Scraper, который обходит сайт-реселлер, получая с каждой страницы товара нужную информацию. Для обхода сайта строится граф переходов между страницами, пагинацией сайта. Также задаются поля веб-страницы, откуда берутся параметры объекта, а также ссылка на его изображение рис. 2. Результат обхода сайта сохраняется в таблице в формате CSV для последующего использования при кластеризации. Пример полученных данных показан на рис. 3. Чтобы выделить контуры из исходного изображения, необходимы предварительные преобразования. Сначала изображение переводится из цветного в монохромное, соответственно значение каждого пикселя становится равным числу из множества 0, ..., 255. Далее необходимо выделить объект на исходном изображении, но поскольку изображения взяты из каталога сайта-реселлера, объекты зачастую находятся по центру на белом фоне, без лишних объектов, поэтому задача распознавания объекта на изображении на данном этапе не рассматривается. На следующем шаге необходимо выделить границы объекта. Для решения задачи выделения границ объекта применяются алгоритмы Canny или Adaptive Thresholding адаптивная пороговая обработка. Проанализируем их применимость к задаче. В данной задаче перед алгоритмом Canny также было выполнено размытие по Гауссу с размером окна, равным 5. Данное значение обусловлено тем, что при больших значениях наблюдается снижение уровня шума, но также и потеря значимых контуров. Алгоритм Adaptive Thresholiding реализуется методом из библиотеки OpenCV. Размер фильтра составляет 5 пикселей. Для того чтобы избавиться от шумов, перед выполнением алгоритма изображение обрабатывается с помощью медианного фильтра. Алгоритм его работы заключается в выборке среднего значения пикселей, попавших в окно фильтра на текущей итерации. Получившееся значение и будет выходным для рассматриваемого пикселя. Чтобы сузить толщину линий контура и восстановить разрывы в контуре, на бинарном изображении применяются морфологические преобразования. В программной реализации, использующей алгоритм Canny, применяются операции Erosion и Closing 2. Р. 137. Erosion позволяет сузить контур. Принцип работы заключается в последовательном скольжении ядра по изображению если все пиксели в окне равны единице, то и результирующий пиксель приравнивается к 1, иначе к 0. Операция Closing является последовательным расширением и сужением до исходного состояния контура, что позволяет избавиться от пробелов внутри контура. Программно это реализуется функцией из библиотеки OpenCV. В реализации, использующей алгоритм Adaptive Thresholding, применяется операция Opening, которая помогает избавиться от мелких шумов на изображении, что, в свою очередь, минимизирует появление разрывных мелких контуров. Поскольку сравнение двух объектов будет производиться в том числе и на основании иерархии контуров и их моментов, даже незначительные изменения положения на фотографии или уровня освещенности может снизить процент распознавания, а также повлиять на классификацию устройства. К тому же, поскольку внешний вид в пределах типа распознаваемого устройства может варьироваться, необходимо сохранить только значимые детали. Для решения этой задачи был написан метод, который выполняет аппроксимацию контура. Аппроксимация контура достигается путем удаления из контура компонент, находящихся на расстоянии меньше заданного. Также контуры, состоящие из количества точек меньше заданного, не включаются в получившийся список. Иерархия контуров при этом перестраивается с учетом удаленных контуров. Результат выполнения можно видеть на рис. 4, где справа находится объект с оптимизированным списком контуров, а слева без оптимизации. На различных изображениях при использовании данного алгоритма количество контуров уменьшается в 25 раз, существенно не меняя представление объекта. При использовании алгоритма Adaptive Thresholding наблюдается более сильное акцентирование мелких деталей, но также большие разрывы контуров рис. 5. Границы объектов распознаются как отдельные контуры. С учетом этого в конечной реализации используется выделение контуров на основе алгоритма Canny. Сравнение схожести объектов, полученных с фотографии пользователя, и исходной выборки, опирается на сравнение контуров. Для того чтобы определить положение контуров относительно друг друга, используется иерархия контуров. Библиотека OpenCV имеет встроенный интерфейс для выделения контуров из предварительно обработанных изображений, реализующийся с помощью метода, где 1 исходное черно-белое изображение 2 режим поиска контура. В данном случае используется извлечение контуров вместе c полной иерархией RETRTREE 3 метод контурной аппроксимации. Используется метод, при котором каждый контур хранит только угловые точки CHAINAPPROXSIMPLE. Использование такого метода обусловлено тем, что слишком большое количество точек может увеличить скорость сравнения и привести к снижению результатов. Для каждого контура существует родительский контур и дочерние контуры. Структура контуров, которую предоставляет библиотека OpenCV, выглядит следующим образом, где индекс следующего контура на текущем слое индекс предыдущего контура на текущем слое индекс первого дочернего контура индекс родительского контура. Таким образом, иерархией контуров является граф рис. 6. Для оптимизации времени сравнения и для большей прозрачности самой операции сравнения, рассматривание контуров происходит от большего к меньшему, т. е. от родительского к дочернему. Соответственно при больших отклонениях мер родительских контуров операция завершается неудачей, и дочерние контуры сравниваться уже не будут. Чтобы сравнивать контуры между собой, необходимо выделить количественные коэффициенты контуров, а также задать сами правила сравнения. В условиях текущей задачи точное соответствие контуров при сравнении не требуется, поскольку тогда даже небольшие различия, возникающие из-за разных ракурсов, уровня освещения и большей предметности, например, моделей техники, может приводить к ухудшению качества распознавания. Сравнение получившихся контуров происходит с помощью сравнения их моментов, что позволяет не учитывать их размер и угол поворота в пространстве. Момент это численная характеристика контура, момент контура складывается из моментов его точек. Различают центральные, нормализованные и инвариантные моменты. Момент точки, порядка определяется как, где, интенсивность пикселя с координатой, порядок порядок . Порядок степень, в которую возводят компоненты суммы. В случае с контурами момент, в котором 0, равен числу точек в контуре поскольку рассматриваемое на данном шаге изображение бинарное, то интенсивность для точек контура равна 1. Но моменты, вычисленные по такой формуле, зависят от положения в пространстве, поэтому используются центральные моменты, которые лишены этого недостатка, а также являются инвариантными относительно масштабирования. В вычислении центральных моментов применяются центроиды, где, . В таком случае формула принимает вид . Для независимости моментов от масштабирования моменты нормализуются . Данный тип моментов не применяется при сравнении моментов, так как он не является инвариантным относительно поворотов. Поэтому для этих целей применяются Hu-моменты 3. Инвариантный момент является линейной комбинацией центральных моментов. Hu-момен ты это набор из семи моментов, первые шесть инвариантны относительно сдвига, масштабирования и поворота, последний момент меняет знак при зеркальном отражении, . В работах 4 5 приводится метод сравнения контуров на основе встроенных функций сравнения контуров которые используют Hu-моменты из библиотеки OpenCV, но неприменимость этого подхода в данной задаче обусловливается тем, что получаемый объект сравнивается не с одним объектом, а участвует в классификации, из чего следует необходимость хранения множества характеристик для каждого объекта выборки. Hu-моменты вычисляются функцией из библиотеки OpenCV. Для сравнения меры схожести моментов применяется несколько метрик. Зачастую применяется метрика вида, где H логарифм Hu-момента по основанию 10, взятый со знаком этого момента. Использование данной метрики обусловлено также тем, что при составлении таблицы признаков для кластеризации необходимо хранить данные о каждом контуре, используя которые можно сравнивать контуры между собой. Таким образом, для каждого контура хранится алгебраическая сумма его моментов, имея которые и используя свойства суммы, можно вычислить меру сходства между контурами. Поскольку категории, извлеченные с сайта, находятся в разном представлении текстовая, численная информация, то необходимо нормализовать признаки, т. е. привести их к одному виду, в одну форму. Рассмотрим признаки, полученные с сайта, для выборки аудиоколонок 1 тип колонок напольные и т. д. 2 материал корпуса дерево, металл и т. д.. 3 мощность 4 частотный диапазон 5 габариты 6 вес 7 диаметр высокочастотных излучателей 8 диаметр низкочастотных излучателей. Выбор признаков обусловлен наличием связи между внешним видом устройства и его характеристиками. Например, имея данные о габаритах устройства и информацию о габаритах, полученную из анализа изображения, можно предсказать габариты объекта, полученного с камеры смартфона при распознавании. Поскольку в полученной в результате обхода сайта таблице данные представления в столбцах в текстовой и числовой информации, необходимо привести данные в столбцах только к одному виду, опустив единицы изменения, предлоги, а также разбить столбцы, содержащие интервалы на два минимальные и максимальные значения рис. 7. Также в таблицу вносится информация о контурах, расположенная в порядке уменьшения периметра контуров. Поскольку в дальнейшем данные будут использоваться в алгоритме классификации, а в большинстве методов классификации используются евклидово или метрические пространства, то данные представляются в виде векторов. Метрикой является евклидова метрика, где,...,..., векторы размерностью . Категориальные данные преобразуются в числовые. В таких случаях можно сопоставить с каждой категорией числовое представление, например catagoriaa 1, catagoriab 2 и т. д. Но проблема данного подхода заключается в том, что числовое представление категорий создает евклидовое представление. На нем становятся доступны операции, не имеющие смысла в категориальных признаках, такие как вычитание, умножение и т. д. Для того чтобы избежать этого, используется подход, в котором каждая категория заменяется на отдельный признак. На позиции, соответствующие численному значению, ставится 1, иначе 0 рис. 8. В выборке встречаются недостающие данные, которые заменяются средним значением признака. Поскольку значения признаков могут сильно варьироваться от пары десятков до нескольких десятков тысяч например, в столбцах, отвечающих за моменты, разные признаки дают разный вклад при определении объекта. Данная проблема решается нормализацией значений признаков. В результате нормализации значение каждого признака принимает значение в интервале 1, 1. Поскольку для каждого класса в условиях задачи классов техники существует свое число внешних определяющих признаков которое может не совпадать между классами, в качестве проверки работоспособности алгоритма решается задача бинарной классификации аудиоколонок. Для того чтобы выделить признаки из контуров, необходимо их проанализировать. Для каждого класса коэффициенты, описанные ниже, могут отличаться и настраиваться исходя из выборки. Рассмотрим изображение из полученной выборки и его контуры рис. 9. На изображении присутствуют незначительные контуры либо помехи, которые при дальнейшей кластеризации и сравнении объектов могут вносить погрешности. Для того чтобы минимизировать эти эффекты, применяется фильтрация по периметру, а также по площади контура. Поскольку площадь объекта может меняться, данная фильтрация нужна прежде всего, чтобы явно выделить внешние грани объектов, а также большие ограниченные области внутри самих объектов. Рассмотрим распределение контуров по площади и периметру. Общее количество контуров рассматриваемого объекта 134. Преобладают контуры, площадь которых близка к 0 рис. 10, такие контуры не являются определяющими для объекта и, скорее всего, являются шумом. Но поскольку это может быть площадь незамкнутых контуров, то также следует рассмотреть периметр контуров объекта. Больше всего контуров, периметры которых близки к 0 рис. 11. Также есть контуры, длина которых больше тысячи. Можно предположить, что это грани объекта и грани динамиков определяющие признаки. В данном случае из набора контуров удаляются контуры, длина которых меньше 50 и площадь которых меньше 1 000. Данные числа получены экспериментально. На рис. 12 показаны оставшиеся контуры, по моментам которых будет происходить последующее сравнение объектов. Примем гипотезу, что наиболее точно определяют объект его наибольшие компоненты. Для того чтобы построить таблицу признаков, выделим первые контуров на основе их периметра, в таблицу признаков записываются соответствующие им моменты. В качестве обоснования состоятельности подхода связи внешнего представления изображения с его характеристиками решается задача бинарной кластеризации. Набор данных включает в себя объекты двух типов напольные и полочные аудиоколонки. В качестве алгоритма кластеризации используется алгоритм K-means рис. 13. Принцип работы данного алгоритма заключается в перерасчете центров масс кластеров, изначально заданных произвольным образом, до тех пор, пока с каждой итерацией внутрикластерное расстояние не перестанет изменяться. В качестве метрики используется евклидово расстояние. Точность кластеризации составила 0,95. Алгоритм работы распознавания характеристик объекта состоит из следующих шагов 1 по полученной выборке с отсутствующими данными строится таблица признаков 2 таблица признаков нормализуется все признаки приводятся к одному виду 3 происходит заполнение недостающих данных исходя из значений данного признака для других объектов класса 4 при получении объекта с неполными данными заполняются отсутствующие данные, и объект классифицируется. Как уже было сказано, обучающая выборка состоит из объектов, принадлежащих двум классам напольные и полочные аудиоколонки. Поскольку при фотографировании объекта модели на вход подается вектор, имеющий только часть, полученную из анализа изображения, требуется предсказать первую часть вектора, включающую в себя характеристики устройства. Вычисление всего вектора неизвестных признаков целиком одной моделью является нетривиальной задачей и может давать плохой результат, поэтому для каждого вычисляемого признака создается своя модель. Соответственно, количество моделей равно количеству неизвестных признаков. Результатом же выполнения будет класс численная характеристика неизвестного параметра. Например, известно, что мощность устройства может быть одним значением из множества 50Вт, 100Вт, 300Вт. В таком случае каждое значение является отдельным классом, и результатом классификации будет одно из этих значений. Такой подход также позволяет выбирать только определенные известные признаки для получения значения неизвестного признака и предугадывать значения, используя заранее вычисленные значения. В рассматриваемой выборке создается 10 моделей для получения неизвестных десяти характеристик. Но, поскольку данный подход является операцией над категориальными признаками, возможные значения которых должны быть заранее известны, он не подходит под признаки конечного вида, например габариты и т. д. Для того чтобы вычислить значения таких признаков, решается задача регрессии 6. C. 18. Для решения данной задачи при классификации были использованы следующие алгоритмы 1 дерево решений, точность 0,96 2 ближайших соседей, точность составила 0,79 3 метод опорных векторов, точность 0,67. Точность рассчитывается следующей формулой . В данном случае TP, TN количество верно распознанных объектов первого или второго класса, FP, FN количество неверно распознанных объектов первого или второго класса. Для того чтобы узнать точность предсказания каждого класса в отдельности, нужно использовать понятия полноты recall доля объектов класса, из всех объектов класса, которую нашел алгоритм, и точности precision доля объектов, которую алгоритм назвал положительными и которые действительно таковыми являются, поэтому используется -метрика . -метрика является средним гармоническим величин precision и recall, где 1. С использованием данной метрики распознавание напольных колонок составило 0,92, а полочных 0,93. При распознавании массы колонок выборка была разбита на классы до 10 кг, от 10 до 20 и выше 20 кг. Такое разбиение обосновывается на частоте встречаемости данных масс. При данном разбиении доля распознавания составила 0,74. Как уже было сказано, для предсказания некатегориальных признаков таких как длина и т. д. используется регрессия. Поскольку данные в разных классах могут сильно отличаться, для предсказания параметра используются выборки, включающие только свой класс в данном случае, например, отдельно класс напольных колонок и отдельно полочных. В качестве алгоритмов регрессии выбраны алгоритмы линейной регрессии, регрессия на основе случайного леса ближайших соседей. Для вычисления каждого из неизвестных признаков из исходного списка признаков выбираются те, которые имеют зависимость от искомого признака. Например, при поиске габаритов такими данными являются те признаки, которые задают моменты первых контуров, вес, высота отдельных известных компонентов объекта. После первого прогона алгоритмов результаты выглядят следующим образом 1 линейная регрессия 0,6 2 случайный лес 150 деревьев 0,76 3 ближайших соседей 6 соседей 0,36. В данной задаче в качестве метрики используется коэффициент детерминации -квад рат . Данная метрика показывает, насколько условная дисперсия модели отличается от реальной дисперсии модели. Поскольку второй алгоритм дал наиболее точный результат, модель, его реализующая, была выбрана в качестве основной для дальнейшего обучения. Также остальные алгоритмы при изменении параметров давали не сильно отличающиеся результаты. После преобразований наилучший полученный результат стал равен 0,82. Данный результат достигнут на конфигурации, состоящей из 200 деревьев количество выделяемых признаков, равное количеству выбранных заранее максимальная глубина дерева 20 так как в данных возможны шумовые выбросы, что при большой глубине давало бы ненужные взаимосвязи. Рассмотрим применение алгоритма к другим обучающим выборкам. Для этого была извлечена выборка, состоящая из обычных и двухстворчатых холодильников рис. 14. Характеристиками объекта были выбраны 1 тип 2 вес 3 количество камер от 2 до 4 4 ширина 5 высота 6 глубина. В качестве пороговых значений для минимальной площади конура было выбрано значение 1 000, для периметра 500. Точность классификации объекта составила 1 дерево решений, точность 0,94 2 ближайших соседей, точность 0,73 3 метод опорных векторов, точность 0,68. Результат распознавания количества камер 0,75. Для получения результата брались характеристики, отвечающие за ширину объекта, а также значения первых пяти контуров данное количество получено опытным путем. Из полученных результатов видно, что алгоритм показывает хорошие результаты распознавания характеристик для различных выборок объектов. Качество зависит от анализа признаков контуров, таких как значения коэффициентов при выделении контуров, выбор минимальных значений для площади и периметра контуров. Алгоритм работы системы состоит из следующих шагов рис. 15 1 пользователь открывает приложение 2 при фотографировании объекта изображение отсылается на сервер 3 сервер классифицирует объект 4 клиенту возвращается класс устройства, данные о нем и список возможных для загрузки инструкций 5 на экране телефона показывается информация о найденном объекте с применением дополненной реальности 6 при нажатии на список инструкций на сервер передается запрос, результатом которого является выбранная инструкция в формате PDF 7 при получении мобильным приложением инструкции она отображается на экране смартфона. Так как распознавание непосредственно на устройстве является ресурсоемким, то было принято решение реализовать архитектуру тонкий клиент, когда устройство ответственно только за получение и отправку данных. При старте приложения открывается экран, где показывается изображение с камеры устройства. При наведении смартфона на объект серверу передается текущее изображение. Для того чтобы не учитывать контуры фона, изображение обрезается выделяется квадрат со стороной, равной трети исходного изображения. Затем клиентское приложение получает список вероятных характеристик устройства, а также идентификаторы, присущие инструкциям устройств данного класса. При выборе одной из инструкций на сервер передается запрос, результатом которого является выбранная инструкция. Мобильное приложение написано под OS Android на языке Kotlin. При написании приложения используются принципы ООП. Приложение спроектировано с использованием подхода Clean Architecture 7. Этот подход является одним из популярных архитектурных решений на данный момент при проектировании мобильных приложений из-за простоты обучения, четкой интерпретации и большого количества обучающих источников. Также множество современных библиотек приспособлены для использования именно данного решения. Clean Architecture позволяет добиться таких важных моментов 1 масштабируемость 2 независимость от фреймворков 3 хорошая тестируемость 4 независимость от реализации пользовательского интерфейса UI 5 независимость от выбора базы данных. Подход заключается в разбиении приложения по следующим уровням рис. 16. 1. Слой представления. На данном слое логика связывается с интерфейсом приложения. Фрагменты и Активности, которые поставляет фреймворк Android, не имеют собственной логики, а ответственны только за отображение данных, полученных от презентера, компоненты приложения, связывающей логику отображения информации с бизнес-логикой приложения, и передачи команд, таких как ввод текста пользователем или нажатие на кнопки презентеру. Презентеры на этом слое связываются с интеракторами из слоя бизнес-логики. Интерактор это логика, разбитая на пользовательские сценарии, например интерактор для авторизации на сервере, интерактор для отправления данных и т. д. Зачастую в этом месте происходит смена потока выполнения с интерфейсного на фоновый. 2. Слой бизнес-логики. Данный слой является модулем, лишенным зависимостей от фреймворка Android. На данном слое находится вся логика приложения. Логика разбита на интеракторы. Интеракторы связаны со слоем данных Data-слой. 3. Слой данных. На этом слое находятся источники данных база данных, кэш и т. д., также на данном слое происходит соединение с сервером. При включении приложения происходит регистрация клиента на сервере клиентское приложение получает токен, по которому в дальнейшем происходит его аутентификация на сервере. Взаимодействие с сервером происходит по технологии REST, для соединения с сервером используется библиотека Retrofit. На главном экране приложения отображается полученное с камеры устройства изображение. При наведении камеры на распознаваемый объект полученное изображение отсылается на сервер для дальнейшей классификации. После того как сервер вычислил значение признаков для классифицируемого объекта, клиентское приложение извлекает их из полученного файла в формате JSON и отображает на экране устройства. Также во всплывающем окне появляется список инструкций, связанный с данным кластером устройств. При выборе нужной инструкции на сервер посылается GETзапрос с ее идентификатором. Результатом выполнения запроса является инструкция в формате PDF, которая по окончании загрузки сохраняется в память устройства и отображается на экране. Для отображения информации на экране используется библиотека ARCore. Когда фреймворк ARCore распознал поверхность вертикальную или горизонтальную, через заранее заданный промежуток времени выполняется отправка на сервер изображения с камеры. Если серверное приложение распознало один из типов устройств, то клиентское приложение получает информацию об этом устройстве, которая показывается поверх распознанного устройства рис. 17 в виде списка. Сервер хранит заранее обученную модель, на вход которой при запросе передается информация, полученная из анализа переданного клиентом изображения. Поскольку полученное изображение цветное, то сначала оно переводится в черно-белое, затем из него выделяются контуры и их моменты по алгоритму Canny, описанному ранее. После успешной классификации и вычисления характеристик входящего устройства в базе данных инструкций ищутся все ассоциированные с данным классом устройств инструкции. Затем идентификаторы инструкций передаются клиентскому приложению. При получении запроса от клиента на скачивание определенной инструкции в базе данных ищется искомая инструкция по идентификатору и отсылается клиенту. Серверная компонента приложения связывается с приложением-клиентом с помощью архитектурного подхода REST API. Запрос, реализующий данный подход, выглядит следующим образом 1 маршрут отправки адрес, по которому направляется запрос 2 тип метода GET, POST, PUT 3 заголовки запроса 4 тело запроса данные. Метод GET используется для получения с сервера определенных данных, результат на запрос данных отправляется приложению-клиенту рис. 18. Запрос отвечает за вычисление класса устройства, изображение которого присылает клиент в теле запроса. Результатом выполнения запроса является класс девайса. Запрос возвращает характеристики устройства. Запрос запускает поиск инструкций краткой инструкции и списка доступных для загрузки инструкций для конкретного типа устройств. Загрузка определенной инструкции производится по запросу . Разработанный подход получения признаков объекта показал хорошую точность на исходной выборке. Данный подход позволяет связывать отдельные части объекта ограниченные контуром с каким-либо набором его признаков, что позволяет рассматривать изображение объекта как набор составляющих его частей, что в дальнейшем можно использовать задаче кластеризации объектов, зная характеристики отдельных компонент объектов. "}
{"title": "МЕТОДИКА АВТОМАТИЧЕСКОГО ТЕСТИРОВАНИЯ   РАЗВИВАЮЩЕГОСЯ ВЕБ-ПРИЛОЖЕНИЯ  ", "absract": " Статья посвящена методике автоматизированного тестирования системы автоматической оценки заданий  по программированию NSUts. При разработке методики главным приоритетом было параллельное тестирование старой и новой версий приложения так, чтобы одни и те же или минимально модифицированные тесты проходили на двух версиях системы с различными архитектурами. Мы надеемся, что наш опыт будет полезен при выстраивании процесса разработки других приложений с длительным жизненным циклом. Чтобы тестировать не только серверную, но и клиентскую часть веб-приложения, мы предлагаем использовать инструменты типа Selenium WebDriver для симуляции действий пользователей, посылая команды настоящим браузерам. В методике применяется известный шаблон проектирования Page Object и рассматривается ряд приемов, позволяющих снизить хрупкость разрабатываемых тестов и упростить их адаптацию для работы с новой версией системы. В статье также описано применение данной методики для организации тестирования системы NSUts и проведен анализ ее эффективности. Анализ показал, что оценочное покрытие кода данными тестами достаточно высоко, и потому методику можно считать эффективной и применять на схожих веб-приложениях. ", "text": " При разработке системы автоматической оценки заданий по программированию NSUts авторы столкнулись с необходимостью улучшить процедуры контроля качества. Необходимость была связана, главным образом, с планом перевода системы на новую архитектуру и стек технологий. При этом у заказчиков и пользователей возникал резонный вопрос можно ли доверять новому коду в той же степени, что и старой системе, у которой был накоплен большой и преимущественно позитивный опыт эксплуатации Чтобы снять этот вопрос, было принято решение организовать автоматизированное тестирование старой и новой систем. Методике организации этого тестирования и посвящена данная работа. Мы надеемся, что сама методика и соображения, исходя из которых мы ее создавали, могут быть полезны при решении аналогичных задач, в первую очередь при построении систем поддержки образовательного процесса. Разработку программного обеспечения можно описать как формализацию требований. В начальный момент требования заказчика доступны лишь в виде неформального описания, даже не всегда в виде единого документа на естественном языке. На основе этих описаний разрабатывается описание системы на машинно-читаемом языке или языках. Машинночитаемость сама по себе налагает достаточно высокие требования на уровень формализации. В свете этого рассуждения контроль качества программного обеспечения можно описать как повторную формализацию тех же требований, как правило, на другом машинно-читаемом языке например, на входном языке разрабатываемой системы в надежде на то, что вероятность дважды совершить одну и ту ошибку существенно ниже. В зависимости от характера задач формализацию целесообразно выполнять на разных этапах и в разных видах. В некоторых приложениях требования просты и стабильны, а стоимость возможной ошибки очень велика, поэтому целесообразно вложиться в формализацию самих требований, после чего можно применять инструменты для автоматической генерации кода и тестов к нему, а иногда и автоматической верификации. В других ситуациях требования сложны или просто велики по объему и меняются часто, так что формализация на раннем этапе оказывается экономически нецелесообразной. В этом случае часто прибегают к ручному тестированию, когда формализацию требований в итоге выполняет тестировщик. В нашем случае занимать студентов ручным тестированием было политически невозможно, поэтому автоматическое тестирование было сочтено наиболее приемлемым вариантом. Для системы NSUts уже были разработаны комплекты автоматизированных тестов на основе Selenium, но попытки применить их для тестирования новой системы выявили их хрупкость, в первую очередь чувствительность к изменениям верстки HTML. Поскольку новый стек технологий генерация HTML на стороне клиента при помощи фреймворка React предполагал полное изменение верстки, это делало старые тесты практически непригодными. Поэтому было решено разработать методику, позволяющую составить автоматические тесты таким образом, чтобы они работали как с новой, так и со старой версией системы, и требовали при этом минимальных изменений для запуска после внесения модификаций. В НГУ давно существует, активно развивается и используется система для автоматической оценки заданий по программированию NSUts. Она используется в учебном процессе, для проведения школьных и вузовских олимпиад по программированию и тренировок сборной НГУ. Система достаточно сложна по сравнению с типичными студенческими проектами 1 406 файлов, 148 115 строк кода и содержит около двадцати крупных функциональных модулей собственно оценка заданий, построение рейтинга по различным правилам, возможность задавать вопросы и т. д. В 2010 г. для системы было разработано техническое задание в соответствии с требованиями ГОСТ 19.201-78, которое заняло 49 страниц. Поскольку система развивается, появляются новые требования, и этот документ потерял актуальность. Ему на замену в 2018 г. было составлено новое описание функциональности, которое содержит 37 пунктов, соответствующих отдельным страницам системы. Для каждой из этих страниц описано в среднем по 5 функций. Сам документ занимает более 50 страниц понятного человеку текста рис. 1. Ежегодно в системе проводится несколько различных олимпиад. Кроме того, на протяжении всего учебного года она используется преподавателями и студентами для сдачи заданий по курсам Программирование на языке высокого уровня и для тренировки олимпиадных команд НГУ. Каждый год на Открытой Всесибирской олимпиаде им. И. В. Поттосина представляется тур со специальной задачей с уникальными правилами. Правила проведения некоторых олимпиад например, регионального этапа Всероссийской олимпиады по информатике РОИ меняются за несколько месяцев до их проведения, что требует оперативного внесения изменений в код системы. Иногда это требует существенной доработки, поскольку изменения затрагивают множество модулей сразу. Например, обновление правил РОИ в 2019 г. привело к изменению 972 строк в 14 файлах. Изначально требования заказчика выражены неформально даже если они подробно описаны в документах типа технического задания, они все еще описаны на естественном языке, по которому невозможно сгенерировать конечный продукт. Потому при контроле качества, как и при разработке, эти требования рано или поздно формализуются в программный код или в действия, которые выполняет тестировщик. В зависимости от того, насколько сложны требования и как часто они изменяются, экономически выгодно формализовать их так или иначе рис. 2. Рассмотрим основные применяемые на практике подходы к контролю качества ручное тестирование формализация в ходе выполнения описанных неформально сценариев формальная верификация требования описываются на формальном языке, что позволяет затем автоматически генерировать тесты или верифицировать саму программу на соответствие этим требованиям автоматическое тестирование формализация требований в виде программного кода тестовых сценариев. Если требования достаточно сложны или меняются часто, может оказаться очень эффективным простой подход ручного тестирования человек, который достаточно хорошо знаком с неформально выраженными требованиями иногда не в исходной их форме, а в форме плана тестирования, по сути формализует их в процессе выполнения различных сценариев в приложении либо может записать их в виде последовательности действий, которую должен выполнить другой специально обученный человек. Данная технология широко используется при разработке приложений поддержки бизнеса, учебного процесса, веб-приложений и др. В процессе отладки нового кода, разработчики в той или иной форме выполняют отдельные операции по ручному тестированию. Но при этом ошибка в коде и пропуск ее при тестировании могут быть причинно связанными и не могут считаться независимыми в теоретиковероятностном смысле. Поэтому главный принцип, изложенный во введении, что при самом программировании и при контроле качества мы выполняем формализацию требований, по возможности независимо, не выполняется. Поэтому полагаться на тестирование самими разработчиками для контроля качества невозможно. В промышленности тестированием обычно занимаются другие люди. При этом ручное тестирование составляет значительную долю общих трудозатрат проекта, и во многих случаях эту долю воспринимают как проблему и так или иначе стараются снизить 1 2. Одно из усовершенствований идеи ручного тестирования привело к созданию подхода Capture and Replay, при котором компьютер записывает действия пользователя и затем может их воспроизводить. Этот подход особенно популярен при тестировании приложений с графическим и веб-интерфейсом. Построенные таким образом тесты довольно хрупки, т. е. перестают работать при незначительных изменениях в приложении. Во многих случаях даже небольшие изменения функциональности или визуального дизайна требуют полной перестройки всего набора тестов. Встречаются также попытки генерации тестов по журналам доступа реальных пользователей 3 4. При обсуждении данного подхода обычно не рассматривают вопрос, насколько правомерна генерация тестов не на основе требований. Ключевым недостатком Capture and Replay является сам принцип работы записывающих действия пользователей продуктов. Человек выполняет некоторые действия осмысленно, а программа механически записывает его действия. При взаимодействии с различными элементами на странице программа запоминает какие-то отличительные свойства этих элементов, чтобы в дальнейшем найти эти же самые элементы снова. Такими свойствами могут быть, например, текстовые надписи, значение атрибута id или XPath-выражение. id это уникальная строковая метка, привязанная разработчиками веб-приложения, а язык XPath позволяет указать на конкретный элемент в иерархии элементов, описанных на языке разметки HTML. В листинге 1 представлен пример рис. 3. Для этого примера автоматические инструменты могли бы записать id элемента header, при нажатии на ссылки их текст, например, Выйти. Поскольку далеко не каждый элемент может иметь id, а текст может повторяться по несколько раз, многие инструменты просто записывают соответствующее XPath-выражение. Ссылке Профиль соответствует следующее выражение divdiv2divdiva1. Однако к приложениям со сложным внутренним состоянием, в которых выполнение одной и той же последовательности действий приводит к разным результатам, данный подход оказывается неприменим. Например, при создании в NSUts олимпиады в базе появляется новая запись, и пользователь в списке видит новый пункт. При записи сценария человек нажимает на такой пункт, и инструмент запомнит какое-то его свойство. Если создать новую олимпиаду, эти свойства уже будут другими, а записанный сценарий будет обращаться к старым. С другой стороны, если у олимпиады будет такое же название, то неизвестно, старую или новую выберет инструмент. Получается, что для приложений подобного рода невозможно составить адекватный сценарий, не описывая некоторую логику приложения, чего запись действий пользователя не предполагает. На другой стороне спектра находится формальная верификация. Формализация требований происходит в процессе их описания на специальном языке, по которому в дальнейшем можно сгенерировать код или верифицировать, что написанный код соответствует описанным требованиям. Этот подход больше соответствует предметным областям, в которых требования к функциональности могут быть относительно простыми, но требование к надежности и безопасности стоит во главе угла. Примерами таких областей могут быть авионика 5 6, медицина 7, автомобильная промышленность 8, разработка распределенных вычислительных программ 9 и аппаратного оборудования в соответствии с индустриальными стандартами 10. Для решения таких задач ведется разработка специальных технологий и инструментов, но эти инструменты приспособлены именно к языкам, операционным системам, протоколам и др., которые применяются именно в соответствующих областях например, к языку Ada. В нашей же задаче требования сложны и нестабильны, и потому данный подход является неприменимым. Поэтому даже перевод проекта на технологии и языки, для которых есть средства формальной верификации, не мог бы решить стоящую перед нами проблему. С учетом изложенных ранее соображений для нашей задачи наиболее разумным подходом представляется автоматическое тестирование, при котором формализация происходит при написании программного кода тестовых сценариев. По оценкам 1 2, начальное написание тестирующих скриптов занимает больше времени по сравнению с Capture and Replay, но дальнейшая их доработка после внесения изменений в тестируемую систему оказывается дешевле, и уже после 23 обновлений общие трудозатраты на поддержку Capture and Replay становятся выше. Часто встречаются различные попытки генерации тестов по различным графам, соответствующим приложению 11, или с помощью автоматических инструментов по самому приложению 12 13. Идея тестирования в принципе заключается в независимой проверке тех же требований, а генерация тестов по коду приложения сводит эту идею на нет. Кроме того, поддерживать автоматически сгенерированный код, как правило, гораздо сложнее, нежели написанный людьми. Поэтому можно предположить, что по мере развития системы также окажется, что поддержка написанных вручную скриптов наиболее выгодный по трудозатратам вариант. Также в рассмотренной литературе встречается описание генерации тестов по модели в виде конечного автомата 14. В этом случае страницы описываются группами состояний, а функциональность переходами между этими состояниями. Система автоматически обходит все возможные пути в данном автомате, проверяя, что все требования выполняются после каждого перехода. По сути, это иной способ записать требования формально не в виде программного кода, а в виде диаграммы состояний конечного автомата. Дискуссия о сравнительных достоинствах разработки программ в виде текстов и в виде диаграмм состояний продолжается уже много десятилетий. На взгляд авторов, ограниченный успех CASE-инструментов, ориентированных на диаграммы, свидетельствует о том, что все-таки писать и поддерживать программы в форме текста людям почему-то удобнее. Кроме того, авторы работ по данной технологии тестирования предлагают инструменты только для языка Java, но не для языков, используемых в нашем проекте. Как было показано ранее, наиболее подходящим подходом для нашего проекта является формализация требований в виде тестирующих скриптов. Для того чтобы упростить эту формализацию, можно собрать и систематизировать имеющиеся требования в виде некоторого документа. Таким документом может быть, например, техническое задание, но в целом достаточно будет и простого, но подробного описания функциональности. Инструменты для тестирования веб-приложений можно разбить на две категории те, что притворяются браузерами и отправляют только HTTP-запросы настоящие браузеры или их эмуляторы, исполняющие также клиентский Javascript-код. Первые применимы для тестирования серверной части веб-приложения, но если на клиентской стороне также присутствует нетривиальная логика, которую мы хотим проверить, то нужно использовать вторые. В нашем случае даже старая версия системы реализовала ряд нетривиальных функций например, вопросы и ответы, новости при помощи Javascript, а новая версия системы полностью основана на генерации страниц средствами Javascript, что делает тестирование на уровне запросов HTTP полностью неприменимым. Ко второй категории можно отнести headless-браузеры которые не отрисовывают страницу при работе и другие инструменты, предоставляющие API для работы с каким-то конкретным браузерным движком. Такие версии браузеров, а тем более сторонние инструменты на их основе, имеют ряд отличий иногда недокументированных от обычных браузеров, и их использование может привести к неожиданным результатам при тестировании. Кроме того, headless-браузеры предоставляют API, несовместимые между собой. В NSUts заявлена поддержка Firefox и Chrome Chromium, поэтому разработка тестов при помощи headless-браузера потребовала бы работы с двумя разными API. Наиболее популярный инструмент, решающий эти проблемы это Selenium он позволяет обращаться к реальным браузерам и имеет при этом общий для них всех API, что упрощает написание тестирующих скриптов. В прошлом в нашем проекте уже предпринимались попытки разработать тестовые сценарии с использованием инструмента Selenium WebDriver, который будет подробнее рассматриваться далее. Сценарии были разработаны на языке Perl, для унификации с основным кодом системы. Как отмечено в работе 2, поддержка тестов является трудоемкой и дорогостоящей задачей, поскольку должна выполняться вручную 15. Из-за нехватки ресурсов и некоторых специфических проблем, которые будут обсуждаться далее, поддержка этих скриптов проводилась в недостаточном объеме, поэтому они отстали от реальной системы и оказались неприменимы. Кроме того, продолжали развиваться браузеры и Selenium, и получилось так, что библиотека, использованная для реализации скриптов в нашем проекте, была снята с поддержки, а доступные для новой версии Selenium библиотеки для Perl неофициальны и несовместимы со старыми . Поскольку в новой архитектуре системы мы также отказываемся от Perl, было решено было решено писать новые тесты на Python. Предполагается, что применение методики позволит сделать процесс более системным, а тесты более поддерживаемыми. Проведенное командой разработчиков NSUts исследование 16 показало, что прототипы системы, использующие технологии AJAX AJAJ, создают гораздо меньшую нагрузку на сервер, что критично при большой нагрузке. Например, во время интернет-тура Открытой Всесибирской олимпиады по программированию количество одновременно активных пользователей превосходило тысячу. При этом активность многих этих пользователей заключалась в частом иногда раз в несколько секунд обновлении страницы рейтинга, что приближало систему к исчерпанию мощности процессоров и ряда других параметров. Поэтому в настоящее время система находится в процессе поэтапного перехода на новую архитектуру. Системой постоянно пользуются студенты и преподаватели, и потому необходимо избежать негативных последствий при внесении изменений нужно осуществить этот переход так, чтобы с точки зрения пользователей система продолжила работать как прежде. Таким образом, перед нами стоит следующая задача написать тесты так, чтобы они не только поддерживались в будущем, но и позволяли убедиться, что модули, разработанные на замену оригинальным, имеют ту же функциональность. Для этого хотелось бы составить тесты так, чтобы их можно было запускать на обеих версиях системы, т. е. тестировать именно функциональность системы, а не ее реализацию. Понятно, что тесту в любом случае придется учитывать различия из-за особенностей реализации, поэтому в ходе применения методики нужно было придумать способ, с помощью которого адаптация написанного для исходной системы теста к работе с новой версией будет требовать минимального написания нового кода. Selenium WebDriver позволяет взаимодействовать со страницей передавать нажатия мыши и клавиш клавиатуры элементам страницы. Для этого нужно иметь возможность указать, с каким элементом например, ссылкой или кнопкой надо взаимодействовать. В Selenium есть 8 способов найти элемент по HTML-атрибуту id по HTML-атрибуту name, который обычно имеют только различные поля ввода по XPath-выражению, соответствующему элементу по тексту ссылки по частичному тексту ссылки по имени HTML-тега по классу элемента по CSS-селектору. XPath это место элемента в структуре HTML-документа, поэтому он, по определению, существует у любого элемента страницы. Но при малейших изменениях в верстке структура документа меняется, и XPath может перестать соответствовать тому элементу, которому он соответствовал раньше. Остальные способы применимы не для всех элементов например, не все элементы являются ссылками или являются недостаточно точными например, на странице может быть много элементов с одинаковым именем HTML-тега. Поиск элементов по id метке, которую привязывают сами разработчики, оказывается наиболее точным и наименее хрупким из доступных способов указать конкретный элемент. Атрибут id можно оставить прежним даже после полного изменения верстки страницы. Это позволяет устранить целый класс различий между двумя реализациями системы можно семантически связывать элементы, которые выполняют одну и ту же функцию в разных реализациях, просто указав для них одинаковый id. Главный недостаток этого способа в нашей ситуации заключается в том, что при разработке старого кода не было действующих соглашений по стилю кодирования, требовавших расставлять эти метки. Поэтому большинство элементов, с которыми нужно взаимодействовать тестирующим скриптам, этих меток не имели. Внесение изменений в старый код, особенно при отсутствии тестов, является нежелательным, поскольку может привести к созданию ошибок. Однако использование id имеет значительные преимущества и вдобавок является достаточно безопасным изменением, поскольку добавление атрибута id не влияет на функциональность. Первоначально ставилось требование, чтобы тесты проходили на старом коде системы без каких-либо изменений этого кода. Преимущества, которые давала расстановка id, были сочтены настолько существенными, что это требование было ослаблено. Другая проблема состоит в том, что в системах типа NSUts содержимое страниц в основном состоит из списков различных сущностей олимпиады, задачи, решения. Из-за этого на странице присутствует множество однотипных элементов, и потому в id элементов добавляется переменное значение чаще всего, первичный ключ сущности, рис. 4 Тестирующему скрипту нужно взаимодействовать с конкретным элементом, а для этого необходимо выяснить, какое переменное значение ему соответствует. Предлагается при создании сущностей генерировать уникальные значения например, при отправке текста программы на проверку в системе NSUts можно добавить комментарий с текущим временем и случайно сгенерированной строкой. Затем придется перебрать все доступные сущности в поисках этого значения и таким образом вычислить искомый id. Чтобы минимизировать изменения, необходимые для адаптации тестов к новым версиям старых модулей, был разработан промежуточный программный интерфейс для взаимодействия с приложением. Для разработки этого интерфейса использован шаблон проектирования, известный как Page Object. Он состоит в том, что каждой странице приложения в соответствие ставится класс в нашем случае класс языка Python, а доступная на странице функциональность описывается методами этого класса. Это позволяет описывать в тестовых сценариях логику взаимодействия в терминах высокоуровневого функционального описания системы, а не дублировать множество команд, например, нажатия мыши по конкретным элементам страницы. Код, использующий библиотеки для управления браузером, скрыт внутри классов наследников описания страницы. Исследования 17 показывают, что ввиду указанных причин применение этого шаблона упрощает поддержку тестовых скриптов. Поскольку функциональность старой и новой версий модулей должна совпадать, можно сделать классы страниц абстрактными и предоставлять для них по две реализации. Применение полиморфизма позволит передавать экземпляры классов для разных реализаций в код тестовых сценариев, написанный для работы с интерфейсом их базового класса. Код самих тестовых сценариев при этом может вообще остаться без изменений. С тех пор, как систему начали переводить на новую архитектуру, прошло уже несколько лет, и за это время появились новые требования. Было решено реализовывать новую функциональность только в новых версиях модулей, чтобы способствовать переходу на них. Влияние новой функциональности нужно учитывать наравне с различиями в реализации модулей. Это делается путем написания разной реализации одних и тех же методов в соответствующих Page Object. Совпадающую функциональность можно описывать в базовом классе. Как было сказано, во многих простых случаях достаточно использовать одинаковые id элементов, чтобы устранить различия для тестирующих скриптов. В системе может быть множество параметров, которые влияют на функциональность отдельных ее элементов. Например, в NSUts бывают разные правила олимпиад, настройки тура, различный набор привилегий у пользователей. При этом необязательно писать разные тесты помимо разных реализаций для страниц тест может и принимать другие параметры, и учитывать их. Это, однако, может привести к комбинаторному взрыву, при котором из-за различных комбинаций значений всех параметров получается слишком большое число возможных вариантов, и потому сильно возрастает время прохождения тестов. Были обнаружены исследования 18, в которых описаны методики сокращения числа тестов, обеспечивающие при этом приемлемый уровень кодового покрытия. В настоящий момент наши тестовые скрипты работают с небольшим числом параметров, но в дальнейшем рассматривается возможность добавления новых и применения указанной методики для эффективного управления временем прохождения тестов. Для запуска тестов и проверки написанных разработчиками новых версий страниц был подготовлен тестовый стенд. Разработчики могут запускать тесты и на собственных машинах, однако можно сэкономить их время, проделав настройку один раз. В стенде используются Selenium Server, последние версии Google Chrome и Mozilla Firefox, соответствующие им Selenium-драйвера и библиотека для работы с Selenium. Все эти компоненты периодически обновляются, и чтобы тесты работали, необходимо использовать согласованный набор компонент. На машинах разработчиков может не быть всех браузеров или установлены старые версии компонент, из-за чего тесты, которые запускаются в одном месте, перестают работать в другом. Чтобы этого избежать, можно использовать стенд, который поддерживается в актуальном состоянии одним из разработчиков. В тестовый стенд должны входить экземпляр тестируемой системы одна или несколько машин, на которых запускаются браузеры и Selenium Server машина, на которой запускаются тестирующие скрипты, управляющие браузерами через Selenium Server. Все эти компоненты могут располагаться на разных компьютерах. В нашем случае тестируемая система NSUts состоит из двух частей веб-сервера, работающего на Debian, и набора тестирующих клиентов, работающих на Windows. На последних установлены компиляторы разных версий, и запущен процесс, который общается с вебсервером NSUts, получает решения участников, компилирует и запускает их проверку на наборах входных данных, после чего сообщает веб-серверу, успешно ли решение прошло проверку. Схема работы изображена на рис. 8. В целях верификации работы веб-сервера NSUts не обязательно разворачивать полноценные тестирующие клиенты достаточно, чтобы сервер получил запрос на выдачу решения, а затем получил отчет о его проверке. Поэтому в наших тестирующих скриптах реализованы поддельные тестирующие клиенты, которые скачивают решение и выдают заранее согласованный ответ. Также это сокращает время, необходимое для тестирования веб-сервера, поскольку поддельные клиенты могут сообщить о результатах проверки мгновенно, а при использовании настоящих клиентов приходилось бы ожидать, пока этот процесс действительно произойдет. Запуск браузеров на разных машинах позволяет сократить время выполнения тестов, запуская их параллельно. Пока что нам это не потребовалось, и потому для тестового стенда достаточно одной машины, на которой установлены все необходимые браузеры. Поскольку большинство пользователей NSUts пользуются ОС Microsoft Windows, необходимо запускать браузеры именно в этой ОС. Веб-сервер NSUts работает на Debian, и его можно развернуть либо на отдельной машине, либо внутри виртуальной машины. Нами был выбран второй вариант виртуальная машина работает на той же машине, на которой запускаются браузеры. Таким образом, тестовый стенд представлен всего одним компьютером. Запуск тестирующих скриптов происходит на машине разработчика. Для этого ему требуется установить дистрибутив языка, на котором реализованы скрипты в нашем случае Python и библиотеку для работы с Selenium на этом языке. Данный подход сопряжен с серьезной проблемой в Selenium Server не реализована аутентификация, поэтому размещение его на публичном или даже локальном в рамках сети НГУ IP-адресе привело бы к тому, что скрипты не обязательно разработанные нами мог бы запускать кто угодно. Для решения этой проблемы, удаленный доступ к Selenium Server осуществляется через ssh-туннель. Тестовый стенд подразумевает однократную первоначальную настройку, т. е. развертывание тестируемой системы и установку браузеров, Selenium и драйверов, а затем многократный запуск тестов, перед которым выполняется обновление тестируемой системы. По ряду причин часть из которых описана ниже очистка от результатов предыдущих тестов осуществляется как отдельная операция и должна активироваться вручную. Для удобства развертывания системы как для тестирования, так и для разработки, был создан набор скриптов, упрощающий данный процесс. Пользователю нужно загрузить эти скрипты из специального репозитория, и по мере их работы указывать желаемые настройки. Скрипты сами устанавливают необходимые пакеты с помощью менеджера пакетов, создают необходимые директории и файлы например, конфигурацию для веб-сервера apache, создают и заполняют таблицы в базе данных, загружают код веб-приложения из отдельного репозитория. Поскольку развертывание системы проводится один раз при создании стенда, необходимость пользовательского ввода считается некритическим недостатком. Боевая система также не переразвертывается каждый раз как минимум в том смысле, что данные учетные записи пользователей, олимпиады, задачи, сданные решения и т. д. должны сохраняться, даже когда вносятся изменения в схему базы данных. Поэтому в репозиторий добавляются специальные скрипты, которые инкрементально обновляют развернутую систему, например SQL-запросы для изменения схемы БД. Тестируемая система обновляется точно так же перед очередным запуском тестов из репозитория загружаются изменения и запускаются все новые скрипты. В отличие от набора скриптов для развертывания системы данные скрипты не требуют пользовательского ввода, поэтому процедура обновления происходит полностью автоматически. Чтобы запустить тестирующие скрипты, разработчики получают их из отдельного репозитория и указывают в конфигурационном файле, по какому адресу доступны Selenium Server и веб-сервер NSUts. Наличие конфигурационного файла позволяет легко использовать машину с Selenium Server и браузерами для тестирования реальной системы. Схема работы стенда показана на рис. 9. В настоящее время по указанной методике разработаны тесты для четырех модулей системы NSUts, и два из этих модулей были успешно переведены на новую архитектуру. После минимальных изменений в коде классов страниц новые модули были протестированы. В одном случае изменения не потребовались вовсе, несмотря на значительные различия во внешнем виде пользовательского интерфейса и в структуре HTML табл. 1. Сейчас указанные модули уже используются вместо их старых аналогов, и готовятся новые версии модулей, для которых уже написаны тесты. Объем кода тестов для страниц системы и изменений для адаптации тестов к новой версии системы Amount of Tests Code for System Pages and Changes to Adapt Tests to Work with the New Version of the System Страница Число строк общего кода добавленных Новости 399 Отправить 315 Печать 241 95 Результаты 392 0 Изменения не потребовались на странице со статической информацией результаты отправленных на тестирование решений, т. е. новым представлением тех же данных, и нескольким доступным действиям, не ведущим к их изменениям например, просмотр текста отправленного решения или ошибки компиляции. Здесь очень сильно пригодилось использование совпадающих значений атрибута id. Однако на странице с возможностью отправки информации печать текста на принтере потребовалось сделать отдельные, хотя и очень схожие, реализации класса страницы для разных модулей. Дело в том, что страницы работают по-разному, хотя для пользователя поведение системы выглядит практически неотличимым. Так, в одном случае при отправке формы происходит несколько перенаправлений, а в другом асинхронный запрос, и это различие необходимо отразить в коде соответствующих странице классов. Одной из самых популярных метрик, используемых для оценки качества тестов, является процент покрытия ими исходного кода. К сожалению, данную метрику сложно измерить без специализированных инструментов. В нашем случае используется Perl в старой архитектуре и PHP Javascript в новой, и не было обнаружено инструмента, который поддерживал бы все три языка. Поэтому для оценки покрытия был использован метод Монте-Карло, заключающийся в следующем в файле выбирается случайная строка, она изменяется с целью изменить логику программы, и запускаются тесты. Изменения в строку вносятся вручную, чтобы новая строка была корректна синтаксически, но некорректна семантически например, замена условия на противоположное. Если тесты проходят успешно, то строка считается непокрытой, и наоборот. Не все строки в файле влияют на логику программы например, комментарии, пустые строки или строки с различными скобками, и потому такие строки не учитываются. Номера строк генерируются псевдослучайным образом. Если генератор выдает номер строки, которая уже была протестирована, она все равно учитывается в выборке. По полученной выборке можно построить график, показывающий, как изменяется процент покрытия с увеличением размера выборки. То, что процент покрытия прекращает существенно изменяться, говорит о том, что этот метод действительно позволяет оценить реальный процент покрытия. Подсчет был совершен для двух модулей, имеющих реализацию на обеих архитектурах. Далее представлены графики сходимости покрытия рис. 10 и приведены получившиеся результаты табл. 2. Оценка покрытия кода модулей тестами, Evaluated Code Coverage, Страница Perl PHP Javascript Печать 60,88 79,1 Результаты 56,05 75,2 Из табл. 2 видно, что тест покрывает код на новой архитектуре даже лучше, чем на старой. Это позволяет предположить, что в старой системе существует значительная доля мертвого кода. Покрытие неполное, поскольку на страницах присутствуют элементы, которые не влияют на функциональность, например заголовки и другой текст, предназначенный для пользователя. Некоторые элементы просто не обладают функциональностью например, дата отправки в таблицах на указанных страницах, и потому тесты на них написаны не были. Соответствующие им строки действительно не покрыты тестами, ведь их изменение или отсутствие не отражается на прохождении тестов. Строки, изменение которых привело к провалу тестов, реально соответствуют тестируемой функциональности, поэтому методику можно считать применимой и, учитывая достаточно высокий процент покрытия, эффективной. При необходимости после получения оценки покрытия тесты можно доработать, и протестировать изменения в менее важных или недостающих, если таковые имеются, элементах и функциональности. В работе представлена методика автоматического тестирования развивающихся веб-при ложений. Поскольку мы разрабатывали методику для приложения со сложными и часто меняющимися требованиями, она основывается на написании тестирующих сценариев. А так как мы разрабатывали ее для веб-приложения, она предлагает использование Selenium WebDriver. Важной особенностью методики является применение полиморфизма при разработке скриптов, позволяющее написать тест так, чтобы он мог проверять несколько разных реализаций одной и той же функциональности. Адаптация скрипта к новой реализации может вообще не потребовать написания нового кода, если приложение соответствующим образом адаптировано к тестированию. В нашем случае главным методом адаптации является расстановка HTML-тегов id у управляющих элементов интерфейса приложения. Методика используется при организации тестирования системы NSUts, и спроектированные по ней тесты существенно упрощают задачу разработчиков, позволяя быстро и надежно убедиться, что переводимые ими на новую архитектуру модули имеют ту же функциональность, что и их старые аналоги. Показано, что оценочное покрытие кода данными тестами достаточно высоко. "}
{"title": "РАЗРАБОТКА СИСТЕМЫ ОЦЕНКИ ПАРАМЕТРОВ ЦУНАМИ   У ПРИБРЕЖНЫХ ТЕРРИТОРИЙ  ", "absract": "Проблема своевременного предупреждения населения об опасности цунами всё еще является актуальной  на прибрежных территориях всего мира. Несмотря на то что цунами довольно редкое явление, его последствия могут быть катастрофическими. В Академгородке многие годы занимаются разработкой и реализацией алгоритмов численного моделирования цунами, используемых для расчета параметров цунами у береговой линии. Целью данной работы является объединение существующих реализаций алгоритмов, написанных  на разных языках программирования (С++, Си, Python, Kotlin, Fortran и т. д.), в единую систему. Разработанная система позволит, принимая на вход данные о сейсмическом событии, рассчитывать параметры цунами  у защищаемой береговой линии. В статье рассмотрены основные этапы работы системы, такие как мониторинг сейсмической активности, извлечение данных с DART станций, фильтрация приливной компоненты, расчет времени добегания волны и непосредственно моделирование, и промежуточные шаги, связанные  с предобработкой и трансформацией данных. Особое внимание уделяется разработке архитектуры системы, взаимодействие между модулями построено таким образом, чтобы в дальнейшем реализации алгоритмов могли дорабатываться и беспрепятственно встраиваться в систему. ", "text": " В настоящее время единственный метод защиты от цунами и его последствий своевременное предупреждение населения прибрежных территорий о надвигающейся опасности. Для оценки масштаба возможных разрушений необходимо обладать данными о высоте и скорости волны у береговой линии. Для решения этой задачи применяются методы математического моделирования. При прогнозировании такого рода событий критическую важность имеет время, которое необходимо затратить для моделирования цунами с момента получения первых данных о землетрясении. В новосибирском Академгородке, и в частности в НГУ, давно занимаются решением этой задачи. На данный момент реализовано множество алгоритмов, каждый из которых решает одну из подзадач. Данные алгоритмы постоянно совершенствуются, увеличивается скорость работы 1. При этом эффективность того или иного алгоритма оценивается на основании тестирования на синтетических и или исторических данных. Полный путь от сырых данных об эпицентре землетрясения до получения параметров волны у побережья состоит из 4 основных шагов извлечение данных о профиле волны, которая проходит через некоторый регистратор, фильтрация приливной компоненты, расчет начальной деформации водной поверхности в зоне источника цунами, моделирование распространения волны по открытой воде. Помимо этого, существуют промежуточные шаги, связанные с обработкой и трансформацией данных для передачи на вход следующему алгоритму. В такой ситуации ручное тестирование любого из основных алгоритмов является довольно трудоемким в плане подготовки тестовых данных. Также все шаги не тестируются в совокупности. Решением этой проблемы является создание системы по предупреждению опасности цунами, объединяющей разработанные алгоритмы. Такая система позволит в автономном режиме следить за сейсмической активностью и выдавать предупреждение в случае возникновения опасности цунами для прибрежной территории, а также проводить сквозное тестирование новых алгоритмов. Цель данной работы разработать систему, которая позволит в автоматическом режиме, принимая на вход данные о некотором сейсмическом событии, рассчитывать параметры цунами у прибрежных территорий. Дополнительным условием является то, что разные этапы алгоритма должны быть изолированы и могут реализовываться на разных языках программирования. Алгоритмы будут совершенствоваться, и система должна уметь реагировать на эти изменения. Рассмотрим основные шаги моделирования цунами. Причинами возникновения цунами могут стать подводные землетрясения вулканическая активность подводные оползни падение в воду обломков скал и т. д. Согласно глобальной исторической базе данных о цунами, с 1900 г. более 80 вероятных цунами были вызваны землетрясениями. Но далеко не каждое подводное землетрясение сопровождается цунами. Цунамигенным т. е. порождающим катастрофическую волну может быть лишь землетрясение с большой энергией магнитуда более 7,8. Если же магнитуда меньше 6, то вероятность цунами близка к нулю 2. В связи с этим начало деятельности по предупреждения населения об опасности цунами начинается с отслеживания сейсмической активности. На данный момент существует множество сервисов, которые представляют информацию о сейсмических событиях в реальном времени. Примером такого сервиса является сайт Геологической службы США United States Geological Survey, USGS. У каждого государства, которое подвержено опасности цунами, существуют программы по минимизации последствий от такого рода опасности. Наиболее интенсивно такие программы развиваются в США и Японии. В рамках Национальной программы США по предотвращению опасности цунами была построена сеть из DART Deep-ocean Assessment and Reporting of Tsunamis станций, расположенных вблизи цунамигенных регионов рис. 1. В данной работе для рассмотрения была выбрана именно программа США, так как она наиболее активно развивается и предоставляет открытые данные со станций в реальном времени на сайте Национального управления океанических и атмосферных исследований National Oceanic and Atmospheric Administration, NOAA . DART станция состоит из двух основных частей датчика давления, который крепится к морскому дну, и поверхностного буя. Датчик давления измеряет изменение высоты водяного столба и с помощью телеметрии сообщает поверхностному бую данные 3, которые через спутник передаются в центр обработки данных рис. 2. Система имеет два режима стандарт и событие. В обычном режиме датчик регулярно собирает информацию об уровне моря и сообщает результаты измерения при относительно низких частотах передачи каждые 15 минут. Это экономит электроэнергию и, следовательно, время автономной работы и продлевает срок службы. Система переходит в режим события, когда датчик давления фиксирует волну Релея, поверхностную сейсмическую волну. Затем он начинает сообщать информацию об уровне моря с частотой измерения 15 секунд, а затем с частотой в 1 минуту. Система возвращается в стандартный режим через 4 часа, если дальнейшие сейсмические события не обнаружены. Профиль волны, поступающий с DART станции, является суперпозицией волны от источника цунами и приливной компоненты и не может быть использован для дальнейших шагов. Ветровые волны станция не фиксирует, поскольку они не оказывают давления на датчик, который расположен на дне. Чтобы получить доступ к реальному профилю волны цунами, необходимо отфильтровать приливную компоненту. Для фильтрации приливной компоненты в рамках стажировок иностранных студентов на ФИТ НГУ Jessy Bogalho разработал скрипт на Python. На вход данный алгоритм принимает начало и конец временного интервала для извлечения данных и номер DART станции. Данные с DART станции в реальном времени размещаются на сайте Национального управление океанических и атмосферных исследований США . Для получения данных о профиле волны необходимо обладать информаций о номере станции и времени прохождения волны через нее. Специализированного API для получения данных с DART станции не предусмотрено, поэтому необходимо производить ручной разбор HTML страницы. Для этого используется библиотека Beautiful Soup . Алгоритм фильтрации приливной компоненты волны использует данные с датчика DART за несколько дней до события и во время прохождения волны цунами через станцию включительно. Этапы работы алгоритма 1 предобработка данных удаление дубликатов, восстановление пропусков в данных, исправление некорректных значений, удаление данных после прохождение цунами после возврата к 15 минутной частоте измерения 2 интерполяция данных о высоте волны для приведения к одному шагу измерения 3 построение функции экстраполяции по данным до события и применение ее на интервале прохождения цунами 4 на интервале прохождения цунами вычитаем из реальной функции экстраполированную, тем самым получая чистый сигнал, без приливной компоненты. Результатом работы алгоритма являются 2 набора чисел первый содержит данные о времени измерения, а второй соответствующую этому времени высоту волны в точке расположения DART станции. Для извлечения данных о профиле волны цунами с DART станции необходимо понимать, когда начинать снимать сигнал, т. е. когда волна достигнет станции. Время движения волны в океане неравномерно, поскольку зависит от профиля дна. Это ставит перед нами дополнительную задачу. Для расчета времени добегания волны используется алгоритм, описанный А. Г. Марчуком 4. В качестве шаблона соседних вершин используется шаблон, состоящий из 16 точек рис. 3, описанный в 5. Расчет времени добегания волны до рассматриваемой вершины строится путем минимизации суммы времени добегания волны от очага до соседних вершин в которые волна уже дошла и от этой соседней вершины до рассматриваемого узла 4. Скорость распространения волны зависит только от глубины воды и вычисляется по формуле Лагранжа, где ускорение силы тяжести, а глубина. Время движения волны цунами между соседними узлами расчетной сетки равно расстоянию между ними, деленному на среднее арифметическое скоростей цунами в этих точках 4, т. е. 2, где расстояние между узлами сетки, а и значение глубины в соответствующих точках. Пакет MOST, который используется для моделирования цунами, может работать в двух режимах принимая на вход параметры землетрясения например, длину и ширину разлома, угол разлома и т. д. или деформацию водной поверхности после сейсмического события . С практической точки зрения больше применим второй вариант, так как узнать вышеперечисленные характеристики в момент, когда произошло землетрясение не представляется возможным сейсмические наблюдения позволяют определить лишь координаты эпицентра землетрясения и оценить магнитуду количество выделившейся энергии. Для восстановления формы первоначального возмущения водной поверхности используется метод предварительных вычислений. Запись с DART станции аппроксимируется линейной комбинацией синтетических расчетных мареограмм 6. Для получения этих расчетных мареограмм наиболее сейсмогенные районы океана были покрыты системой эталонных единичных источников прямоугольников размером 50 100 км рис. 4. Затем в каждый единичный источник была помещена предварительно выбранная характерная форма возмущения морского дна и численно определены параметры волны от такого возмущения. В работах В. Титова было показано, что сигнал от неизвестного источника цунами можно с удовлетворительной точностью приблизить линейной комбинацией синтетических сигналов, вычисленных заранее, от эталонных источников 6. Далее по полученным коэффициентам в разложении реального сигнала необходимо сформировать деформацию для рассматриваемого события и передать его на вход алгоритму расчета распространения волны цунами, который по сути тот же самый, что и для расчетов профилей волны от единичных источников. Для моделирования используется пакет MOST Method of Splitting Tsunami, который представляет собой набор программ численного моделирования, способных имитировать три процесса эволюции цунами землетрясение, распространение волны и расчет наката волны на берег. Вышеперечисленные шаги составляют каркас системы моделирования цунами, однако для полной работы системы как единого целого необходимы еще и промежуточные этапы, которые будут решать задачи предобработки данных и обеспечивать интеграцию между различными реализациями основных алгоритмов. Полный алгоритм работы системы можно рассмотреть на схеме рис. 5. Основной целью работы является объединение существующих алгоритмов в единую систему. Так как существующие алгоритмы реализованы на разных языках программирования Fortran, C, C, Python и в будущем будут изменяться, необходимо обеспечить легкое внедрение нового алгоритма в общую систему. Для этого предлагается изолировать все элементы системы друг от друга, но четко зафиксировать контракт общения между ними рис. 6. Для такого рода взаимодействия хорошо подходит микросервисная архитектура. Каждый отдельный алгоритм инкапсулирован в микросервисе, общение происходит через REST API. Для удобства поставки модули упакованы в docker-контейнеры, а для запуска всех контейнеров как единой системы используется docker-compose . Это решение позволяет не задумываться о подготовке среды для запуска приложения на новом сервере, так как каждый контейнер уже включает в себя вс необходимое для работы приложения библиотеки, системные инструменты, код и среду исполнения 7. Рассмотрим подробнее назначение каждого модуля и общий алгоритм работы системы. 1. . Компонентом системы, инициирующим начало основной работы, является подмодуль отслеживания сейсмической активности в океане. Данный подмодуль периодически опрашивает систему мониторинга сейсмической активности. В настоящий момент используются данные с сайта Геологической службы США United States Geological Survey, USGS . В дальнейшем возможно использование других источников. При старте приложения запускается периодическая задача, которая опрашивает сервис USGS для получения данных о новых сейсмических событиях. Данная информация представлена в формате ATOM с использованием стандарта GeoRSS, для разбора используется библиотека Rome . Полученные данные фильтруются по локации землетрясения для моделирования цунами имеет смысл рассматривать только те события, которые произошли в море или океане. Также не имеет смысла обрабатывать события с низкой магнитудой. 2. . При обнаружении релевантного события для начала моделирования необходимо получить данные с DART станции в дальнейшем можно использовать несколько источников, например, кабельные системы, GPS буи. Для ускорения поиска ближайшей станции данные о расположении DART станций были извлечены из сети Интернет и сохранены в локальной базе данных. Для расчета времени добегания волны используется алгоритм описанный А. Г. Марчуком в статье Минимизация погрешностей при численных расчетах волновых лучей и фронтов цунами 4. На начало работы над системой уже существовала реализация данного алгоритма на C. Однако она не вполне подходила для применения в работе алгоритм был рассчитан для работы с батиметрической картой картой, изображающей подводный рельеф по равномерной сетке в формате GBR98. Батиметрия, которая используется для основного алгоритма системы MOST, построена на прямоугольной, но не квадратной сетке. На данный момент алгоритм портирован на язык Kotlin и доработан для работы с прямоугольной сеткой, протестирован и отлажен на исторических событиях. 3. . Профиль волны, полученный с DART станции, не может быть использован в чистом виде для выполнения дальнейших шагов, так как он содержит приливную компоненту. Существующая реализация алгоритма фильтрации приливной компоненты на Python, выдавала неплохой результат, однако в процессе обработки сигнала изменялся временной интервал измерений. Таким образом, на выходе программа выдавала корректные результаты в плане высоты волны, но неверные соответствия времени измерения рис. 7. На данный момент программа доработана и протестирована на нескольких исторических событиях. Для поднятия веб-сервера на Python был использован фреймворк Flask . 4. . Для разложения реального сигнала как линейной комбинации сигналов от синтетических источников П. Татаринцевым был реализован алгоритм на C 8. Данный алгоритм принимает на вход два текстовых файла, которые содержат реальный профиль волны и расчетные мареограммы от нескольких ближайших эталонных источников в месте расположения DART станции. Результатом работы алгоритма является текстовый файл, в котором каждому эталонному источнику соответствует коэффициент в разложении реального сигнала. Такой вариант входных и выходных файлов прост в разработке, но является неподходящим для интеграции с другой системой. В связи с этим данная реализация была изменена на общение с модулем координации через REST API. На вход алгоритм принимает отфильтрованный сигнал с DART станции без приливной компоненты и данные синтетических расчетных мареограмм от базисных источников. Результатом работы алгоритма являются коэффициенты, соответствующие базисным источникам, линейная комбинация которых приближает реальный сигнал с определенной точностью. Для обработки событий в реальном времени необходимо иметь базу данных синтетических мареограмм. Получение расчетных мареограмм производится с использованием пакета MOST для моделирования волны цунами от эталонного источника. Результатом рабо ты MOST является файл формата NetCDF Network Common Data Form, содержащий информацию о высоте волны и скорости по направлениям и для каждого узла батиметрии в зависимости от времени. NetCDF это бинарный формат файлов, предназначенный для создания, доступа и публикации научных данных. NetCDF является самоописательным форматом, это значит, что в файл входит информация о содержащихся в нем данных, включая указание на единицы измерения. Для работы с файлами формата NetCDF используется библиотека NetCDF Java . Полный расчет деформации водной поверхности океана от одного эталонного источника занимает на дисковом пространстве порядка 2 Гб данных. Это ставит перед нами дополнительную задачу обеспечить оптимальное хранение расчетных мареограмм. Если тщательно проанализировать задачу, становится ясно, что хранение данных о профиле волны для всех точек океана совсем не обязательно. Для подсчета коэффициента интересны только данные в точках расположения DART станций. Таким образом, проделав предварительную работу по извлечению из NetCDF файлов расчетных мареограмм данных о профиле волны в точках расположения DART станций, можно уменьшить объем хранимой информации на диске и увеличить скорость обработки сейсмического события. Но следует учитывать, что такого рода база данных требует периодического обновления для поддержания ее в актуальном состоянии, так как DART станции могут менять место своего расположения например, после поднятия на поверхность для сервисного обслуживания. 5. . По полученным на предыдущем этапе коэффициентам формируем деформацию для рассматриваемого события и передаем ее на вход пакету MOST. Результатом работы пакета MOST является файл в формате NetCDF, для просмотра результатов моделирования может быть использована утилита ncview рис. 8. В дальнейшем можно доработать систему таким образом, чтобы визуализировать сравнение результатов моделирования с реальными данными о профиле волны с DART станции. 6. . Модуль, контролирующий взаимодействие всех частей системы, разработан на языке Kotlin. Это статически типизированный язык программирования, работающий поверх JVM. Данный модуль отвечает за все промежуточные шаги между основными этапами моделирования цунами, такие как поиск ближайших к эпицентру сейсмического события DART станций и единичных источников, разбор NetCDF файла для извлечения профиля волны в точках расположения DART станций, формирование композитной деформации водной поверхности из деформаций от единичных источников по коэффициентам в разложении реального сигнала и т.д. Результатом работы является программное средство для оценки параметров цунами. Данная система позволит в автоматическом режиме анализировать волну цунами от получения данных о сейсмическом событии до моделирования поведения волны у прибрежной территории. Все этапы работы системы изолированы в отдельные модули, что позволяет легко тестировать и отлаживать новые реализации этапов алгоритма, отслеживая, как те или иные изменения повлияют на весь алгоритм моделирования. Работа над данным проектом еще не закончена, в дальнейшем планируется закончить интеграцию всех модулей системы, а также разработать пользовательский интерфейс для работы с системой. "}
{"title": "РАЗРАБОТКА МЕТОДОВ СЕМАНТИЧЕСКОГО ПОИСКА В ИНТЕРНЕТЕ ", "absract": "Статья посвящена разработке методов поиска информации в Интернете. В настоящее время задача быстрого автоматизированного извлечения данных из различных источников является чрезвычайно актуальной. Цель данной работы – создание инструментария для решения этой задачи. Идея подхода заключается в разработке полуавтоматических методов составления лингвистических шаблонов для заданного фрагмента атомарной диаграммы. Процесс построения шаблонов по данному фрагменту атомарной диаграммы выполняется  в 2 этапа: 1) порождение простых шаблонов; 2) с помощью полученных простых шаблонов создание более сложных или реже встречающихся шаблонов. С помощью полученных шаблонов можно находить необходимую информацию, обрабатывая тексты естественного языка, представленные в Интернете. ", "text": " В современном мире задача быстрого и автоматизированного извлечения данных является очень актуальной. Например, когда возникает необходимость найти некоторую информацию в Интернете, нужно просмотреть множество страниц, попробовать несколько вариантов запросов, проанализировать большое количество информации и выбрать что-то действительно удовлетворяющее требованиям. Для некоторых запросов подобный процесс может потребовать очень много времени и усилий. Поэтому было бы крайне полезным наличие программного инструмента, который мог бы предложить пользователю не огромное количество различных Интернет-ресурсов, а несколько, например 35, в которых содержалась бы нужная ему информация. Разработка такой программной системы является целью данной работы. Предлагаемый подход основан на разработке полуавтоматических методов порождения лингвистических шаблонов для поискового запроса, формально представленного в виде некоторого фрагмента атомарной диаграммы алгебраической системы. Построение лингвистического шаблона для конкретного фрагмента атомарной диаграммы выполняется в два этапа. На первом этапе происходит поиск простых шаблонов. На втором этапе на основе построенных простых шаблонов выполняется поиск более сложных вариантов шаблонов или редко встречающихся в текстах. С помощью полученных шаблонов происходит поиск и извлечение необходимой информации путем проверки соответствия текста естественного языка лингвистическому шаблону. В настоящее время существует множество систем, решающих подобные задачи 14. Самые популярные среди них поисковые системы, такие как Гугл, Яндекс и др. Они основаны на поиске по ключевым словам с применением различных эвристик и способны выдать нужную информацию для простых запросов, однако возникают проблемы с более сложными поисковыми запросами. Также задачу поиска информации призваны решать различные вопросно-ответные системы 5 6. Их важным преимуществом является то, что они используют различные методы извлечения знаний, способны уточнять запрос, учитывать контекст, также могут использовать методы машинного обучения. Таким образом, подобные системы способны лучше отвечать на вопросы пользователя, однако у них также есть недостатки. Существует два вида вопросно-ответных систем системы, отвечающие на вопросы пользователя, используя внутреннюю базу данных, и системы, порождающие ответы при помощи знаний, содержащихся в Интернете 5. В первом случае нужной информации может просто не быть в базе, либо она может быть устаревшей, а пользователю обычно не предоставляется возможность каким-либо образом расширить базу. С системами второго типа все немного сложнее. Поскольку они извлекают информацию из Интернета, они обычно пытаются различными способами свести сложные запросы к последовательности простых и далее раскручивать запрос по цепочке. При этом ответы на простые запросы получаются с помощью все тех же поисковых систем. Таким образом, ответ на запрос находится по ключевым словам. Однако одна и та же информация с семантической точки зрения может быть представлена совершенно по-разному. Это справедливо даже для самых простых запросов. Например, для запроса Где родился Эйнштейн ответ может быть представлен как Эйнштейн родился в городе Ульм либо, например, как Город Ульм подарил миру Эйнштейна. Таким образом, поиск по ключевым словам Эйнштейн и родился не обнаружит второй вариант. Для сложных запросов подобные наблюдения еще более существенны. Таким образом, цель данной работы разработать программный инструмент, который будет выполнять поиск требуемой информации без необходимости представлять поисковый запрос в виде последовательности нескольких ключевых слов. Определенные методы и технологии семантического поиска были описаны в ряде работ 18. Идея разрабатываемого подхода заключается в автоматизированном построении лингвистических шаблонов для конкретного поискового запроса пользователя. При этом пользователь может описать свой поисковый запрос т. е. поставить в соответствие запросу множество лингвистических шаблонов, если готовый лингвистический шаблон, полностью соответствующий поисковой потребности, отсутствует в базе. Пользователь может контролировать процесс извлечения и порождения шаблонов, для того чтобы избежать построения ошибочных вариантов поисковых запросов. При создании лингвистических шаблонов можно рассматривать параметризованные фрагменты атомарных диаграмм 6 и для них строить семантически параметризованные лингвистические шаблоны. Методы, используемые в данной работе, основаны на понятиях фрагмента атомарной диаграммы 9 10, параметризованного фрагмента атомарной диаграммы 6 и лингвистического шаблона 8 11 12. Атомарной диаграммой модели называется множество истинных на ней атомарных предложений и отрицаний атомарных предложений 9 10. Атомарным предложением называется бескванторное предложение вида, где символ -местного предиката, а, символы констант. Фрагмент атомарной диаграммы может быть параметризован, в таком случае часть предикатов, входящих в данный фрагмент атомарной диаграммы, являются заранее не определенными при реализации информационного поиска предикаты-параметры оснащаются конкретными предикатами 6. Каждому поисковому запросу пользователя ставится в соответствие конечный фрагмент атомарной диаграммы. Каждому конечному фрагменту атомарной диаграммы соответствует один или несколько лингвистических шаблонов. Таким образом, каждый поисковый запрос пользователя формально определяется множеством лингвистических шаблонов. Лингвистический шаблон это параметрический набор условий на искомую структуру текста 8 11. Он может быть представлен несколькими способами. Один из возможных вариантов представление лингвистического шаблона в виде аналога регулярного выражения над множеством слов 8 11. Рассмотрим, например, шаблон вида Данный шаблон описывает последовательность из двух существительных, где первое находится в именительном падеже, а второе в родительном. Данному шаблону удовлетворяют такие словосочетания, как отец ребенка, стены дома и др. В данном шаблоне параметрически задано значение падежа таким образом, слова в словосочетании, найденном при помощи данного шаблона, должны удовлетворять условиям, наложенным на падеж. При этом могут варьироваться другие параметры слов, такие как род, число и пр. Один шаблон может содержать несколько параметризаций. Недостатком подобных шаблонов является то, что они неустойчивы к порядку слов. Например, фраза ребенка отец уже не удовлетворяет данному шаблону, хотя с семантической точки зрения фразы отец ребенка и ребенка отец эквивалентны. Другой вариант шаблона так называемый древовидный шаблон. Древовидный шаблон это дерево, в вершинах которого находятся слова, а ребро между вершинами обозначает, что между словами, находящимися в данных вершинах, существует связь. Пример такого шаблона для запроса Где родился человек представлен на рис. 1. Древовидные шаблоны устойчивы к порядку слов, поскольку они учитывают лишь типы связей между словами, но не порядок их в предложении. Например, шаблону с рис. 1 удовлетворяют предложения Эйнштейн родился в Ульме, Эйнштейн в Ульме родился, В Ульме родился Эйнштейн и т. д. В работе используются именно древовидные шаблоны. Для того чтобы сформировать запрос к поисковой системе, необходимо расположить слова из шаблона в том порядке, в котором они были в изначальном предложении можно выбрать любой, если вариантов несколько, поскольку поисковые системы не учитывают порядок, а также подставить в запрос конкретный субъект и исключить объект. Для конкретного человека запрос может выглядеть, например, так Пушкин родился в. Сначала опишем общий алгоритм порождения шаблонов 1 поиск предложений, содержащих необходимую информацию 2 извлечение шаблонов из найденных предложений 3 расширение множества предложений и возвращение к шагу 2. Рассмотрим подробно каждый из этих этапов., На первом этапе необходимо найти предложения, в которых содержится информация о текущем запросе. Мы используем два основных метода получения таких предложений. 1. Национальный корпус русского языка 13 14 это информационно-справочная система, основанная на собрании русских текстов в электронной форме. Корпус насчитывает около 30 млн предложений различной тематики, таких как художественные тексты, газетная публицистика, технические тексты, научные тексты, тексты личной переписки и др. Корпус позволяет быстро выполнять лексико-грамматический поиск, используя различные морфологические, грамматические и семантические признаки. Также корпус позволяет получить результаты поиска в удобном для машинной обработки формате. Однако, поскольку корпус вручную обрабатывается и поддерживается, объем текстов в нем значительно меньше, чем в Интернете. Поэтому данный метод используется в основном на первом этапе, где выполняется поиск более простых предложений. 2. Поисковая система Гугл . Всем известная система выполняет поиск по всей сети и предоставляет результаты в удобочитаемом для человека формате. Для автоматического извлечения предложений необходимо потратить больше ресурсов, чем для извлечения с помощью корпуса русского языка, однако множество извлеченных предложений гораздо больше по объему и разнообразию. На первом этапе необходимо найти наиболее простые предложения, отвечающие требованиям. В основном поиск производится по ключевым словам без учета морфологических признаков. Например, для запроса Где родился человек можно выполнить поиск по ключевому слову родиться. Очевидно, что не все предложения, содержащие слово родиться, будут содержать информацию о месте рождения человека. Поэтому полученные данные необходимо обработать вручную, чтобы отсеять ненужные варианты. Далее, по найденным предложениям нужно построить лингвистические шаблоны. Для получения шаблонов используются синтаксические деревья предложений, извлеченных на первом шаге. Синтаксическое дерево дерево разбора структура в виде ориентированного дерева, представляющая синтаксическую структуру предложения. Пример синтаксического дерева для предложения Дельта Волги является восьмым чудом света приведен на рис. 2. Корректно построенное дерево разбора обладает следующими свойствами 1 слова, находящиеся на разных вершинах одного ребра, связаны в исходном предложении. Причем слово, находящееся на нижнем уровне, является зависимым. Слово, находящееся в корне дерева, не имеет зависимого. 2 слова, находящиеся в разных ветках, не имеют прямой связи друг с другом и связаны только через зависимые слова. Например, слова восьмым и света не связаны напрямую, но они оба являются характеристиками слова чудо. Таким образом, можно сделать следующие выводы. Если мы хотим выяснить, как два слова связаны в исходном предложении, нам достаточно найти минимальное поддерево, которое содержит в себе искомые слова. В данное дерево не попадут следующие категории вершин 1 вершины, располагающиеся на более нижних уровнях, чем вершины, содержащие искомые слова. Очевидно, что данные вершины не имеет смысла включать в дерево, так как искомые слова никак даже транзитивно от них не зависят 2 вершины, не являющиеся непосредственными предками искомых, но находящиеся на том же уровне или выше. Данные вершины не имеют прямой связи с искомыми, а значит, их также не имеет смысла включать в итоговое дерево 3 вершины, находящиеся выше, чем наименьший общий предок искомых вершин. С семантической точки зрения, слова, находящиеся в таких вершинах, несут более глобальный смысл, чем исходные слова. Такая ситуация может возникнуть, если оба исходных слова находятся в придаточной части предложения, которая сама по себе зависит от других частей предложения. Очевидно, что вершины из данной категории также не нужно включать в искомое дерево. Возвращаясь к лингвистическим шаблонам, можно заметить, что итоговое дерево и есть искомый шаблон, если в качестве искомых слов использовать и исходного предложения. В качестве примера рассмотрим предложение Великолепный Коля внезапно родился в поистине огромной Москве, где его семья жила 10 лет. На рис. 3 можно увидеть дерево разбора данного предложения. В данном дереве субъектом является слово Коля, а объектом Москва. Причем предложение имеет достаточно сложную структуру с большим количеством дополнений. Однако если попытаться найти связь между словами Коля и Москва, то в результате получится очень простой шаблон, аналогичный представленному на рис. 1. Приведем еще два определения, которые понадобятся нам в текущей работе. Синтаксический анализ это процесс сопоставления линейной последовательности лексем естественного языка с его формальной грамматикой. Результатом синтаксического анализа обычно является синтаксическое дерево. Синтаксический анализатор или парсер инструмент, выполняющий синтаксический анализ 15 16. Теперь рассмотрим способы построения синтаксических деревьев. Всего существует два основных подхода. 1. Машинное обучение с учителем. Подход заключается в обучении парсера на предварительно размеченной выборке. Размеченные корпуса текстов можно получить с помощью корпуса русского языка. Этот подход достаточно прост в реализации, однако его точность оставляет желать лучшего. Модель, обученная на корпуса и протестированная на оставшейся части, показывает точность в 79,6 . К тому же, перед тем как отдавать предложения на анализ, необходимо провести их лексический и морфологический анализ, что требует дополнительных ресурсов. 2. Метод, основанный на правилах. Основная идея заключается в создании набора правил, которые определяют, как проставлять связи в предложении. Данный подход дает наибольшую точность и строит корректные деревья разбора, если грамматика корректно описывает данное предложение. Однако данный подход очень ресурсоемок, поскольку он требует описания буквально всего русского языка. Оба метода имеют свои плюсы и свои минусы. В своей работе мы использую парсер Solarix 17. Это парсер с общедоступной лицензией, основанный на правилах. Грамматика языка была описана авторами парсера, поэтому данную задачу в этой работе мне решать не придется. Парсер решает следующие задачи 1 лексический анализ разбивка текста на предложения и слова 2 морфологический анализ определение морфологических признаков с учетом контекста 3 лемматизация приведение слов к начальной форме 4 синтаксический анализ определение синтаксических связей слов в предложении, построение дерева разбора. Таким образом, парсер решает все необходимые задачи, и для построения шаблонов необходимо ввести в парсер множество полученных предложений. Существует два режима работы парсера. 1. Восходящий анализ. Идея метода заключается в разборе сначала конкретных слов, затем в связывании слов в пары, далее связывание пар с другими словами и парами и т. д., пока все слова предложения не окажутся связанными в одну структуру. Такой метод работает достаточно быстро, однако, если грамматика не полностью описывает данное предложение, либо предложение содержит неоднозначности, парсер может сделать ошибочные предположения о связи слов и в результате получить неточный результат. В целом полученные результаты достаточно корректны, и выбросы результаты, сильно отличающиеся от среднего встречаются довольно редко. 2. Нисходящий анализ. Идея метода заключается в выдвижении гипотез о крупномасштабной структуре предложения, далее эта структура уточняется, рекурсивно спускаясь до уровня отдельных слов. Данный метод работает очень медленно, поскольку, сделав ошибочное предположение на ранних этапах и опровергнув его на более поздних, алгоритм выполняет большое количество лишних действий. Однако данный подход может выдать все возможные варианты парсинга предложения в случае наличия неоднозначностей. Поскольку быстрый восходящий анализ работает корректно в большинстве случаев, целесообразно использовать именно его для выполнения первичной обработки предложений. Переключаться на нисходящий анализ разумно только в случае, если восходящий анализ покажет неудовлетворительные результаты. На выборке из 50 предложений восходящий анализ показывает результат 3 секунды, тогда как нисходящий анализ требует 1,5 минуты. В результате анализа полученных шаблонов были выявлены две категории шаблонов, которые должны быть исключены из итоговых результатов. 1. Шаблоны, содержащие только слова ОБЪЕКТ и СУБЪЕКТ. Подобные шаблоны могут возникнуть, если в полученном дереве разбора субъект и объект находятся в соседних узлах. В целом такая ситуация является корректной, но очевидно, что данные шаблоны невозможно использовать для дальнейшего поиска, следовательно, они должны быть отсеяны. 2. Шаблоны, встречающиеся менее чем в 0,5 случаев. Поскольку парсер показывает не 100 верные результаты, необходимо сделать его более устойчивым к ошибкам. Один из способов отсеять шаблоны, которые встречаются очень редко, поскольку они, скорее всего, были получены в результате ошибочного анализа. Величина 0,5 была получена чисто эвристически. Стоит также отметить, что в полученном шаблоне на месте субъекта и объекта могут находиться не только отдельные слова, но также и словосочетания, см. пример на рис. 4. Однако весь анализ для таких случаев остается неизменным, данное предложение также удовлетворяет шаблону из рис. 1. После того как полученные предложения проанализированы и получен набор шаблонов, необходимо выявить более редкие предложения, которые были упущены на первом этапе, и также извлечь из них шаблоны. Для выявления более редких предложений мы используем поисковую систему Гугл ввиду наличия большего объема и разнообразия данных. Например, на первом этапе для предиката Где родился человек используются все предложения, содержащие слово родиться. Очевидно, что большое количество предложений при этом теряется, поскольку в предложении, где идет речь о месте рождения, наличие слова родиться совсем необязательно. Для того чтобы получить больше предложений, необходимо из существующих выбрать несколько таких, в которых субъект и объект широко представлены в текстах, находящихся в Интернете. Далее, сделав запрос вида СУБЪЕКТ ОБЪЕКТ в поисковой системе, мы получим множество различных вариантов того, как субъект и объект могут быть связаны в исходном предложении. Конечно, данные предложения могут содержать информацию, которая не относится к текущему предикату, поэтому полученные предложения также должны быть обработаны вручную. Далее из полученных предложений извлекаются лингвистические шаблоны аналогично тому, как это было сделано на первом этапе. При желании можно повторить второй и третий этапы для получения большего количества шаблонов. В качестве примера рассмотрим процесс получения шаблонов для вопроса Где родился человек. На первом этапе с помощью корпуса русского языка извлекаются около 300 шаблонов, содержащих слово родиться. При этом поиск проводится без учета морфологических признаков, т. е. варианты со словами родился, родилась и т. д. также представлены в итоговых результатах. Из полученных предложений примерно 50 содержат информацию о месте рождения человека. В результате проведенного анализа был получен набор новых лингвистических шаблонов. Вот самые популярные из них 1 СУБЪЕКТ родился в ОБЪЕКТ 19 вхождений в исходное множество 2 ОБЪЕКТ СУБЪЕКТ родился 4 вхождения 3 СУБЪЕКТ родилась в году в ОБЪЕКТ 3 вхождения. Далее мы выбираем следующие пары субъект объект для последующего анализа Эйнштейн Ульм, Ньютон Вулсторп, Чехов Таганрог. Проанализировав около 120 результатов запросов, мы получаем около 40 различных предложений, удовлетворяющих предикату. В результате дальнейшего анализа, помимо шаблонов, аналогичных полученным на первом этапе, также были получены принципиально новые варианты, такие как, и др. Другой пример более сложного предиката Кто является президентом страны. Самые популярные шаблоны, полученные на первом этапе по ключевому слову президент 1 Президент СУБЪЕКТ ОБЪЕКТ 2 ОБЪЕКТ, президент СУБЪЕКТ 3 ОБЪЕКТ является президентом СУБЪЕКТ. Шаблоны второго этапа, не найденные на первом 1 Глава СУБЪЕКТ ОБЪЕКТ 2 ОБЪЕКТ на посту главы СУБЪЕКТ. Разработана программная система, реализующая описанный выше алгоритм. Для проверки корректности работы алгоритма была проведена серия тестов. В программную систему были введены 3 запроса, . Для каждого запроса протестировано 10 возможных субъектов, результаты работы оценивались экспертом. Оценка ставилась из множества 01, где 1 ставилась в случае, если на найденной странице действительно содержалась искомая информация, и 0 в противном случае. В ходе анализа полученных результатов выявлены 3 типа ошибок, т. е. все полученные ошибочные результаты можно разделить на 3 категории. 1. Ошибка первой категории возникает в случае, если предложение удовлетворяет шаблону, однако в более глобальном контексте было сказано, что это предложение ошибочно. Пример, . Стоит отметить, что во всех случаях на этой же странице содержалась информация о реальном положении вещей, поэтому такие страницы были отмечены как успешный результат. 2. Ошибки второй категории возникали в случае, если предложение удовлетворяет шаблону, но все равно не отвечает на запрос. Пример такой ошибки для предиката . Чтобы избежать данной ошибки, необходимо учесть более широкий контекст, чем предложение. Ведь теоретически, дворянская семья вполне может быть названием населенного пункта. Стоит отметить, что подобные ошибки встречались достаточно редко, хотя, несомненно, они являются наиболее опасными. 3. Ошибки третьей категории появляются в случае, если в момент последнего редактирования страницы информация была еще действительна, но на текущий момент она устарела. Или у автора была некорректная информация, или же он намеренно вводит читателя в заблуждение. Пример . Подобные ошибки даже сложно считать ошибкой, ведь в таком случае даже человек не сможет удостовериться, что информация действительно верная. Однако они имеют место, поэтому также были отмечены в текущей работе. Всего для каждого запроса программа выдает 5 результатов с предполагаемым ответом. Таким образом, для каждого предиката было получено 50 результатов. Далее приведена таблица с количеством ошибок каждого типа для каждого запроса. Количество ошибок, Number of Errors, Запрос Категория ошибок первая вторая третья Место рождения 0 10 10 Автор изобретения 0 0 4 Президент страны 0 8 14 Можно заметить, что ошибок первой категории в данном случае не было, хотя они и были обнаружены в процессе тестирования. Можно предположить, что такие ошибки аналогичны ошибкам третьей категории, однако между ними есть существенная разница. В первом случае в тексте явно сказано, что данная информация не верна, в третьем же случае информация представляется корректной. Ну и логично, что в первом случае сразу же приводится корректная информация. Что касается ошибок второй категории, можно понять, что количество таких ошибок зависит от запроса. Например, для запроса алгоритм не допустил подобных ошибок. Ну, действительно, сложно придумать предложение, удовлетворяющее, например, шаблону и имеющее какой-то посторонний смысл. Всего было получено 150 результатов работы программы, из которых 127 были корректными. Таким образом, можно сказать, что на тестовой выборке точность алгоритма составляет 84,6, причем для каждой пары субъект запрос как минимум 3 из 5 результатов были корректными. В целом полученные результаты можно считать успешными. В работе предложен алгоритм автоматизированного извлечения лингвистических шаблонов из текстов естественного языка. Были использованы древовидные лингвистические шаблоны в силу того, что они являются более устойчивыми к порядку слов в предложении. Разработаны и протестированы методы построения синтаксических деревьев по предложениям естественного языка. Предложены критерии определения валидности различных лингвистических шаблонов. Разработана и реализована программная система, позволяющая осуществлять семантический поиск и извлекать требуемые знания в текстах естественного языка, представленных в Интернете. Разработанная программная система протестирована, полученная точность 84,6 представляется достаточно хорошей для решения рассмотренных задач и достижения поставленных целей. "}
{"title": "ОБЗОР ОБЪЕКТНО-ОРИЕНТИРОВАННОЙ ПАРАДИГМЫ   В ПРИЛОЖЕНИИ К РАЗРАБОТКЕ БАЗ ДАННЫХ  ", "absract": " В статье приводится обзор проектов, технологий, программных продуктов, разрабатываемых для реализации идей объектно-ориентированного подхода к проектированию баз данных. В 1980-е гг. велось множество проектов, посвященных идее ООБД, многие специалисты ожидали, что в ближайшее время реляционные базы данных будут вытеснены объектно-ориентированными. Несмотря на впечатляющее количество проектов, проводимых как коллективами ученых, так и коммерческими компаниями, ориентированными на практическое внедрение, не появилось четкой формулировки объектно-ориентированной модели данных, каждый коллектив представлял свое видение применения принципов ООП к проектированию баз данных. Отсутствие универсальной модели данных с проработанным математическим аппаратом (как в случае реляционных баз данных) и сегодня является основной проблемой распространения ООСУБД. Однако применение реляционных СУБД порождает ряд проблем, которые наиболее остро ощущаются в таких областях, как системы автоматизированного проектирования, автоматизированное производство, системы, основанные на знаниях,  и др. ООБД позволяют объединить программный код и данные, избежать различий между представлениями информации в базе и прикладной программе, вследствие чего интерес к ним проявляют современные разработчики. Современный рынок программного инструментария представлен рядом ООСУБД, но ни одна из них не может конкурировать с крупнейшими поставщиками СУБД. ", "text": " Объектно-ориентированная база данных ООБД база данных, данные в которой структурированы в соответствии с моделью данных, основанной на понятиях и принципах объектно-ориентированного проектирования ООП. В 1980-е гг. велось множество проектов, посвященных идее ООБД, многие специалисты были уверены, что в ближайшие 23 года реляционные базы данных будут вытеснены объектно-ориентированными. Сергей Дмитриевич Кузнецов среди проектов, оказавших наибольшее влияние на развитие ООБД, называет Encore 1 Брауновский университет, Провиденс, Род-Айленд, США Cactis 2 Университет Колорадо, США, Thor 3 Массачусетский технологический институт, США Exodus 4 Висконсинский университет, США Pisa 5 университеты Глазго и Сент-Эндрюсм, Шотландия. Большой вклад в развитие объектно-ориентированной парадигмы сделала группа исследовательского института OGI Oregon Graduate Institute. OGI был уникальным, частным, последипломным исследовательским университетом в округе Вашингтон, штат Орегон, в западной части Портленда, с 1963 по 2001 г., с 1989 г. именовался Орегонским институтом высших учебных заведений. Результатом деятельности OGI в области объектно-ориентиро ванных баз данных стала ООСУБД Gemstone 6 7. В качестве базового языка GemStone использовался Smalltalk 8 9. Данный язык разработан в 1970-х гг. на основе уже существовавших в то время концепций, в нем была введена новая терминология, являющаяся наиболее характерной для современных языков программирования. Smalltalk основан на идее посылки сообщений, реализует возможность программирования с динамической типизацией, оказал большое влияние на развитие таких объектно-ориентированных языков, как Java, Ruby, Objective-C. Многие революционные идеи появились в сообществе Smalltalk. К ним можно отнести рефакторинг, шаблоны проектирования применительно к ПО, карты класс обязанности взаимодействие и экстремальное программирование в целом. GemStone была одной из первых коммерчески доступных ООСУБД. Проект корпорации MCC Microelectronics and Computer Technology Corporation ознаменован появлением таких СУБД, как Itasca 10 и UniSQL 11 12. Во французском исследовательском центре INRIA осуществлялся проект Altair, в рамках которого была создана O2. Компанией Hewlett Packard была разработана IRIS, DEC выпустили систему Trellis. В виде завершенных коммерческих систем появились G-Base, упомянутая ранее, Gemstone, Statice, Vbase. К первым СУБД, реализующим принципы объектно-ориентированного подхода, Сергей Дмитриевич Кузнецов сформулировал два основных замечания. Первое сводится к невозможности практического применения указанного спектра систем ввиду таких характеристик, как ненадежность, отсутствие поддержки безопасности данных, низкая производительность и др. Второе замечание касается отсутствия единого языка, коим, по мнению Сергея Дмитриевича, должен был быть С. Необходимость изучать новый язык, а у каждой такой СУБД он был свой, понижала коммерческий интерес 5. Дальнейшее развитие методологии проектирования баз данных находило отражение в так называемых Манифестах. Первый манифест был издан в 1989 г. Его авторами были преимущественно ученые 13, это была первая попытка собрать имеющиеся разноплановые наработки в области применения ОО-подхода к проектированию БД в единое определение ООСУБД. Был приведен перечень основных характеристик, которыми должна обладать СУБД, чтобы быть классифицированной как ООСУБД. Характеристики подразделялись на три группы обязательные, необязательные и открытые. Обязательными характеристиками должна обладать любая СУБД, относящаяся к классу объектно-ориентированных, необязательные характеристики могут быть как присущи данным системам, так и нет. Открытые характеристики реализуются разработчиком в соответствии с его собственными соображениями, унификация на этом уровне не предполагается. К обязательным, например, были отнесены такие характеристики, как идентифицируемость объектов, инкапсуляция, классы множественное наследование это уже пример необязательной характеристики, к открытым относится, например, парадигма программирования. Будущее развитие СУБД авторы манифеста видели в ООСУБД, поддерживающей традиционные возможности. Второй манифест появился в 1990 г. 14. В противовес первому авторы второго манифеста инженеры разработчики баз данных, ориентированных на применение языка SQL. В данном документе дается классификация СУБД по поколениям ранее созданные реляционные, иерархические и сетевые СУБД первое поколение, используемые на текущий момент реляционные СУБД второе, СУБД третьего поколения те, что соответствуют предложенным в документе требованиям. Требования включают три принципа и 13 предложений. В соответствии с первым принципом СУБД третьего поколения должны предоставлять средства хранения и манипулирования объектами, структура которых может включать более широкий спектр типов данных, таких как тексты, например, а также средства создания правил для элементов данных, как ссылочная целостность в реляционных БД и более сложные. Второй принцип состоит в необходимости поддержки возможностей СУБД второго поколения. Третий принцип гласит об открытости СУБД, т. е. о поддержке интеграции с прикладными программами, разработанными на различных платформах. Летом 1991 г. была задумана и впоследствии образована Object Database Management Group ODMG 13 15, в 1998 г. была переименована в Object Data Management Group, чтобы отобразить распространение своей деятельности не только на объектно-ориентированные базы данных, но и технологии ORM Object-Relational Mapping . ORM объектно-реля ционное отображение, или преобразование, технология программирования, которая связывает базы данных с концепциями объектно-ориентированных языков программирования, создавая виртуальную объектную базу данных. Основной целью ODMG было разработать комплекс спецификаций, которые позволят разрабатывать портируемые приложения для объектной базы данных и ORM-приложений. В период с 1993 по 2001 г. ODMG опубликовал пять изменений в своей спецификации. Последней была ODMG версии 3.0, после чего группа распалась. Предлагаемая ODMG архитектура показана на рис. 1. В этой архитектуре определяются способ хранения данных и разные виды пользовательского доступа к этому хранилищу данных. Единое хранилище данных доступно из языка определения данных, языка запросов и ряда языков манипулирования данными. На рис. 1 ODL означает Object Definition Language язык определения объектов, OQL Object Query Language язык объектных запросов 16 и OML Object Manipulation Language язык манипулирования объектами. После публикации второго манифеста на рынок вышел целый новый класс СУБД, именуемый объектно-реляционными СУБД, среди них Informix Universal Server 17, Oracle 8, DB 2 Universal Database. В марте 1995 г. была впервые официально опубликована статья Хью Дарвена и Кристофера Дейта, названная авторами Третьим манифестом 18. Авторы статьи ищут прочные основы для будущего управления данными. При этом Хью Дарвен и Кристофер Дейт считают, во-первых, что такие основы не способен обеспечить язык баз данных SQL, во-вторых, любые такие основы должны твердо корениться в реляционной модели данных, впервые представленной миру Э. Ф. Коддом в 1969 г. При этом авторы сознают ценность поддержки горячо обсуждаемых возможностей объектно-ориентированного подхода, называя их ортогональными реляционной модели. И в силу этого реляционная модель не нуждается в каких-либо расширениях, коррекции или категоризации, а самое главное, в каких-либо искажениях, для того чтобы внедрить указанные возможности в какой-либо язык баз данных, способный представлять те основы, которые мы ищем. Основу Манифеста представляет описание такого языка Допустим, что такой язык имеется и называется D. Авторы приводят предписания и запреты языка D. Некоторые из этих предписаний проистекают из реляционной модели данных и названы РМ-предписаниями. Предписания, которые не происходят из реляционной модели, названы остальными ортогональными предписаниями ОО-пред писаниями. Подобным же образом категоризованы и запреты для языка D. Несмотря на впечатляющее количество проектов, проводимых как коллективами ученых, так и коммерческими компаниями, ориентированными на практическое внедрение, не появилось четкой формулировки объектно-ориентированной модели данных, каждый коллектив представлял свое видение применения принципов ООП к проектированию баз данных. Отсутствие универсальной модели данных, с проработанным математическим аппаратом как в случае реляционных баз данных и сегодня является основной проблемой распространения ООСУБД. А. М. Эльдарханов предлагает рассматривать проблематику разработки ООСУБД с позиции разделения по трем уровням представления данных. Так же, как и в классической модели структуры базы данных ANSI SPARC 19 20, представлены три уровня описания данных. В обеих названных иерархиях уровни располагаются в порядке убывания степени абстракции. Самый нижний уровень, наиболее приближенный к физическим процессам, реализующим задачи хранения и управления данными, в обеих моделях является физический уровень. Над физическим уровнем А. М. Эльдарханов разместил уровень модели данных, далее следует уровень формальной математической модели 21. Для создания формальной математической модели существуют два подхода. Первый подход предполагает последовательное исполнение ряда действий с целью получения заданного результата аналогично функциональному программированию и называется функциональным. В литературе представлены два метода данного подхода алгебра select-project-join SPJ и многосортное исчисление предикатов высшего порядка 22. Язык SQL реализует алгебру SPJ 23. Второй подход создания формальной математической модели дедуктивный. Дедуктивный подход основан на использовании логического вывода, запросы к базам данных формулируются в виде аксиом и правил. Кристофер Дейт в своем фундаментальном труде приводил следующий пример листинг 1, 2 GOODSUPPLIER s, st, sc S s, sn, st, sc AND st 15 На листинге 1 представлено определение предиката GOODSUPPLIER на языке Data log. На листинге 2 приведены примеры запросов к предикату GOODSUPPLIER. 1. Определить всех добросовестных поставщиков. GOODSUPPLIER s, st, sc 2. Определить всех добросовестных поставщиков из Парижа. GOODSUPPLIER s, st, Paris 3. Является ли поставщик si добросовестным GOODSUPPLIER S1, st, sc Средний уровень представления данных уровень модели данных, представлен двумя аспектами поведенческим и структурным. Структурный аспект представляет два уровня описания уровень данных рис. 2 и уровень схемы рис. 3. Важнейшим понятием объектной модели данных, характерным для любой ООСУБД, является идентификатор объекта. В нашем примере на рис. 1. ИО1 и ИО2 идентификаторы двух объектов, моделирующих 2-х студентов ИО4 идентификатор объекта, моделирующего вуз. Над объектами в объектной модели данных определяются составные операции. На нашей схеме составные операции именованы русскоязычными аналогами обозначений функций в англоязычной литературе и языках программирования. Операция домен set создает множество однотипных объектов, как в нашем примере, результатом операции домен является новый объект с идентификатором ИО3, являющийся набором двух студентов с идентификаторами ИО1 и ИО2. Операция кортеж tuple создает кортеж в общем случае разнородных объектов, номер в обозначениях на схеме, следующий за словом кортеж означает, какой это по счету операнд операции составления кортежа. База данных на рис. 1 представлена графом, вершины которого объекты, а ребра отношения вида быть i-м операндом операции с данным результатом. На рис. 3. Представлен граф уровня схемы для тех же объектов, что и на рис. 2. В ходе анализа текущего уровня развития ООБД, Эльдарханов приходит к выводам Ограничения на корректность объектов теории являются внешними средствами по отношению к теории, в основном выраженными в форме указания конкретных классов некорректных объектов с обозначением пути разрешения проблемы важной является также проблема реализации в данной модели сочетания функционального и логического программирования Полной формализации включения функций и отношений в объектную модель пока не создано 21. Несмотря на наличие проблем применения объектно-ориентированного подхода к проектированию баз данных, объектно-ориентированные СУБД являются альтернативными средствами при решении такого класса задач, где применение реляционных СУБД обнаруживает ограниченность модели. В англоязычной литературе встречается термин The object-relational impedance mis match, данный термин применяется для обозначения концептуальных и технических трудностей, возникающих при взаимодействии прикладных программ или комплексов прикладных программ, разработанных на объектно-ориентированных языках, с реляционными базами данных. К одному из ряда подобных осложнений относится отсутствие возможности в реляционных СУБД работы с агрегатом значений атрибутов сущности как с единым целым экземпляром сущности, моделирующим объект предметной области. Например, информацию об экземпляре сущности Книга можно получить из базы данных, схема которой представлена на рис. 4, не обратившись к целостному объекту, а собрав необходимые сведения из соответствующих таблиц посредством конструкции запросов на языке SQL с применением оператора JOIN. Конструкция запроса, которая может быть применена, представлена на листинге 3. SELECT Авторы.Фамилия, Авторы.Имя, Авторы.Отчество, Книги.Название, Справочник жанров.Название жанра, Издательства.Название, Справочник городов.Название города FROM Справочник жанров INNER JOIN Справочник городов INNER JOIN Издательства ON Справочник городов.Кодгорода Издательства.Кодгорода INNER JOIN Книги ON Издательства.Кодиздательства Книги.Кодиздательства INNER JOIN Авторы INNER JOIN Авторы книг ON Авторы.Кодавтора Авторы книг.Кодавтора ON Книги.Кодкниги Авторы книг.Кодкниги ON Справочник жанров.Коджанра Книги.Коджанра Проблемы применения реляционных СУБД наиболее остро ощущаются в таких областях, как системы автоматизированного проектирования, автоматизированное производство, системы автоматизированного управления предприятием, системы, основанные на знаниях, мультимедийные системы. ООБД позволяют объединить программный код и данные, избежать различий между представлениями информации в базе и прикладной программе, вследствие чего интерес к ним проявляют современные разработчики. Среди современных объектно-ориентированных СУБД в первую очередь следует упомянуть о Cach, продукте компании InterSystems, существует и успешно развивается на протяжении 21-го года. ООСУБД Cache используется при проектировании автоматизированных систем управления здравоохранением, банковских и финансовых услуг, государственного управления и других секторов. Вызывает интерес ConceptBase дедуктивная и объектно-ориентированная система управ ления базами данных, разработанная в Университете Аахена и Университете Скуве. ConceptBase используется для концептуального моделирования и метамоделирования в области разработки программного обеспечения 24. В связи с активным развитием глобальных сетей и как следствие технологий разработки кросс-платформенных приложений возрос интерес к системе GemStone, в частности языку Smalltalk как инструменту создания JavaScript, реализующих задачи коммерческих приложений и веб-страниц. GemStoneS на сегодняшний день является одним из лучших примеров ООСУБД, которая хорошо подходит для масштабируемых, высокопроизводительных, многоуровневых распределенных систем 25. Примером современной встраиваемой ООСУБД является ObjectDatabase ODBPP, разработчик Ekky Software . В данной системе для хранения информации об экземпляре книги будет использоваться одна запись в противопоставление рассмотренному выше примеру структурирования данной информации в реляционной СУБД. Такой способ представления данных позволяет оперировать целым объектом и уменьшает необходимость объедине ния данных из разных таблиц сокращает количество требуемых операций блокировки, чтения и записи, что способствует эффективной работоспособности системы при больших объемах данных. ObjectDB это объектная СУБД для Java. Она может использоваться в режиме клиентсервер и во встроенном в процессе режиме. В то время как основные СУБД, представленные на рынке, предоставляют API application program interface. Например, в состав MySQL входит библиотека, написанная на языке С, позволяющая обращаться к данным из любой программы, разработанной на этом языке 26. ObjectDB не предоставляет собственный, для работы с этой СУБД используется один из двух стандартных API Java Java Persistence API JPA или Java Data Objects JDO. Спецификация JPA предоставляет возможность сохранять в удобном виде Java-объекты в базе данных . Объекты данных Java JDO 27 представляют собой классы языка программирования Java для них нет необходимости реализовывать определенные интерфейсы или расширяться из специальных классов. Оба API-интерфейса встроены в ObjectDB, поэтому промежуточное программное обеспечение ORM не требуется 28. ObjectDB является кросс-платформенной и может использоваться в различных операционных системах с Java SE 5 или выше. Он может быть интегрирован в веб-приложения Java EE и Spring и развернут в контейнерах сервлетов Tomcat, Jetty, а также на серверах приложений Java EE GlassFish, JBoss 29. Она была протестирована на различных JVM, включая HotSpot, JRockit и IBM J9 . Максимальный размер базы данных составляет 128 ТБ 131 072 ГБ. Количество объектов в базе данных неограниченно кроме размера базы данных. Все устойчивые типы JPA и JDO поддерживаются ObjectDB, включая определяемые пользователем классы сущностей, определяемые пользователем встраиваемые классы, стандартные коллекции Java, базовые типы данных примитивные значения, значения обертки, String, Date, Time, Timestamp и любые другие сериализуемые классы. Каждый объект в базе данных имеет уникальный идентификатор. ObjectDB поддерживает как традиционные идентификаторы базы данных объектов, так и механизмы реляционных баз данных, такие как первичные ключи, включая составные первичные ключи и создание и присвоение автоматического значения как часть поддержки JPA, которая в основном представляет собой API для РСУБД. Поддерживаются два языка запросов. Язык запросов JDO JDOQL, основанный на синтаксисе Java, и язык запросов JPA JPQL, основанный на синтаксисе SQL. Также поддерживаются запросы по критериям JPA 2. Автоматическая эволюция схемы ObjectDB обрабатывает большинство изменений классов прозрачно, включая добавление и удаление постоянных полей, изменение типов постоянных полей и изменение иерархии классов. Также поддерживается переименование устойчивых классов и постоянных полей. Современный рынок программного инструментария представлен рядом ООСУБД, но, если посмотреть на рейтинги используемых СУБД, как, например, результаты ежегодного опроса, проводимого сайтом Stack Overflow, где в 2018 г. приняли участие свыше 100 000 разработчиков программного обеспечения см. таблицу, ни одну ООСУБД мы не встретим. Самые популярные СУБД, по версии опроса Stack Overflow The most popular DBMSs, according to the Stack Overflow survey пп Название системы организации хранения данных Количество опрошенных, применяющих данный инструментарий, 1 MySQL 58,7 2 SQL Server 41,2 3 PostgreSQL 32,9 4 MongoDB 25,9 5 SQLite 19,7 6 Redis 18,0 7 Elasticsearch 14,1 8 MariaDB 13,4 9 Oracle 11,1 10 Microsoft Azure Tables, CosmosDB, SQL, etc 7,9 11 Google Cloud Storage 5,5 12 Memcached 5,5 В качестве итога можно привести слова Ричарда Энга Хотя ООСУБД и не получили широкого распространения, вс же объектные базы данных имеют свои нишевые рынки 25. "}
{"title": "МОДЕЛИРОВАНИЕ УПРУГИХ ВОЛН   В СРЕДАХ СО СЛОЖНОЙ ТОПОГРАФИЕЙ СВОБОДНОЙ ПОВЕРХНОСТИ", "absract": "Моделирование – неотъемлемая часть исследования процессов распространения сейсмических волн в различных  средах. Широко используемый способ разбиения области на прямоугольные ячейки обладает недостатком: при  сложном строении свободной поверхности (например, гора) возникают эффекты при отражении волны от этой  поверхности, связанные с тем, что граница аппроксимируется ступенчатой функцией для численного решения  задачи. В данной работе предложен иной подход к дискретизации области: построение криволинейной сетки,  хорошо согласующейся с геометрией свободной поверхности. Предложен алгоритм численного моделирования  на основе численного решения линейной 2D-системы теории упругости, записанной в смещениях, с использова нием криволинейной сетки и пошагового метода Лагерра. Представлены результаты моделирования. Также были  реализованы две параллельные версии алгоритма, проведены расчеты на различных многоядерных системах  (на классической многопроцессорной архитектуре, а также архитектуре с использованием сопроцессоров Intel  Xeon Phi – РСК ПетаСтрим). Представлены сравнительные тесты ускорений на разных архитектурах, а также  описаны особенности распараллеливания алгоритма.  : теория упругости, упругие волны, криволинейная поверхность, криволинейные сетки, метод  Лагерра, Intel Xeon Phi, PetaStream.  Работа выполнена в рамках государственного задания ИВМиМГ СО РАН (проект № 0315-2016-0009), а также при поддержке грантов РФФИ № 16-07-00434 и № 16-01-00455 А. ", "text": "Эффективным инструментом исследования процессов распространения волн в различных моделях сложно построенных сред является математическое моделирование. Одним из из вестных методов численного моделирования распространения упругих волн в случае сложно построенных 2D-сред является разностный метод. При использовании данного метода не изменно сталкиваются с проблемой возникновения дифракционных волн при отражении волны от свободной поверхности. Связано это с тем, что для применения данного метода необходимо разбиение физической области на квадратные или прямоугольные ячейки, вследствие чего свободная поверхность заменяется ступенчатой функцией. Пример исполь зования разностного метода приведен на рис. 1 и 2. Подобные дифракционные волны вносят погрешность в решение. Таким образом, была поставлена задача об избавлении от дифракционных волн. Для этого в работе предлагается использовать криволинейные сетки. В последнее время все большую популярность приобре тает моделирование с использованием криволинейных сеток. Это гибкий инструментарии, нашедший применение в численном решении сингулярно-возмущенных задач, моделирова нии потоков плазмы в камере Токомака и др. Способы построения сеток, а также их при менение для решения упомянутых задач приведены в 1. Данная работа особенно важна для дальнейшей разработки 3D-алгоритма, нацеленного на развитие методов исследования областей, характерной особенностью которых является сложное строение топографии свободной поверхности. К таковым можно отнести магма тические вулканы, а также территории арктического шельфа и Сибири Баженовская свита, богатые залежами углеводородов. Существующие методы работы с такого рода задачами не позволяют получить желаемую точность моделирования ввиду большой трудозатратности и особенностей применяемых методов, таких как метод конечных элементов МКЭ. Существует много методов построения криволинейной сетки. Нкоторые из них описаны в работах 112. Криволинейная сетка в физической области получается в результате взаимно-однозначного отображения равномерной сетки расчетной области. Таким обра зом, необходимо установить взаимно-однозначное соответствие между физической и рас четной областью. Физическая область находится в пространстве переменных, а расчетная в пространстве переменных, . Для этого был использован метод трансфинитной интерполяции 1, с. 53. Автором были подобраны управляющие функции, позволяющие определять свойства криволинейной сетки. В данной работе важным моментом построения сетки является ее ортогональность к свободной поверхности, что накладывает ограничение на форму свободных поверхностей, с которыми можно работать при помощи данного метода построения сетки, а именно поверхность должна быть гладкой функцией первого порядка на промежутке, на котором она построена для данной области, а также для любых двух разных и не су ществует, такого что и . Пример на рис. 3. Таким образом, задачу, поставленную в переменных, можно переписать в пере менных, . Моделирование проводится на основе численного решения полной линейной системы теории упругости, записанной в смещениях. В физической области в переменных, линейная система уравнений в смещениях принимает вид 2 0, 2 0. 1 Граничные условия на и начальные условия 0, 0. 2 Условия на свободной поверхности 2 0, 2 0, 3 где, смещения вдоль координатных осей OX и OY, параметры Ламэ, плотность граница области, не включающей свободную поверхность свободная поверхность, единичный вектор нормали к сво бодой поверхности, правая часть, отвечает за работу источника возмущений в среде. В данной работе используется источник типа центр давления, работает в течение 2-х секунд., sin 1 0,8sin2 1 0,2sin3 1, 0 2, 0, 2, sin 1 0,8sin2 1 0,2sin3 1, 0 2, 0, 2. Аналогично работе 13 после преобразования системы 13 получаем задачу вида 2 2, 2 2, . 4 Начальные и граничные условия 0, 0. 5 На свободной границе 2 0, 2 0, 6 где, Якобиан проебразования. Впервые данный метод был применен в работе 14. В отличие от классических пре образований Фурье и Лапласа применение преобразования Лагерра приводит к решению за дачи для системы дифференциальных уравнений, не зависящей от параметра разделения, роль которого в данном случае играет номер проекции Лагерра. В результате примене ния этого преобразования получается задача для проекций Лагерра с правой частью, ре куррентно зависящей от проекций меньших номеров. После применения конечно-разностных аппроксимаций по пространственным переменным, решение исходной задачи сводится к решению системы линейных алгебраических уравнений со многими правыми частями, для решения которых можно использовать различные современные подходы к решению ли нейных систем. В работе рассматривается модификация метода, а именно преобразование Лагерра ис пользуется на последовательности конечных интервалов по времени. Полученное решение в конце одного временного отрезка используется в качестве начальных данных для реше ния задачи на следующем временном отрезке и т. д. Связано это с тем, что для получения решения с хорошей точностью через длительный промежуток времени необходимо очень большое количество проекций Лагерра, что критично скажется во время численной реали зации. Подробно пошаговый метод преобразования Лагерра описан в работе 15. При использовании данного подхода появляется необходимость выбора 4-х параметров количество проекций Лагерра масштабного множителя, необходимого для аппроксимации решения функциями Лагерра, экспоненциального коэффициента весовой функции, использующейся для нахождения решения на конечном временном интервале, и дли тельности этого интервала . Способ выбора этих параметров предложен в работе 15. Мы же ограничимся лишь основными терминами и непосредственно видом задачи после примененного к ней преобразования Лагерра. Полиномы Лагерра имеют вид 1, 7 1, 8 1 2 1, 1, 1 9, 1. 10 Функции Лагерра, 0, 11 образуют полную ортонормированную систему в 0, . Преобразование 12 называется прямым преобразованием Лагерра, а проекциями Лагерра функции . Обратное преобразование Лагерра . 13 Идея метода состоит в получении приближенного значения 14 и значения, 15 выбираем в качестве начальных данных для решения задачи при . Иначе говоря, теперь вместо нахождения неизвестной функции мы ищем значения проекций Лагерра для этой функции. Учитывая уравнения 715, задача 36 сводится к решению линейной системы уравнений 2, 2 2 3 2 2, 2 2 2 2 2, 2 2. 16 На 0, 0, . 17 На 2 18 0, 2 0. В 16 вместо подставляются, -е проекции Лагерра для и соответственно. Вместо оператора подставляются для и для соответственно. число проекций Лагерра, параметры преобразования Лагерра. Таким образом вместо из начальной системы из 2-х уравнений, записанной в смещениях, получаем систему из 2 1 уравнений, записанную в проекциях Лагерра. Далее для полученной системы строится разностный аналог на равномерной сетке раз мером ячеек. Разностная схема для, описана в работе 13, уравнения 3.3, 3.4, за исключением дискретных граничных условий на свободной по верхности и на, которые предложены автором данной работы. Упростив 18, получим на 0, 0. 19 Из 19 получаем разностный аналог 12 32 12 12 32 12, 12 32 12 12 32 12 . Здесь используются так называемые фиктивные узлы. На из 17 получаем разностный аналог 0, 0, 0, . В итоге получаем разностный аналог системы 1618 со вторым порядком аппрокси мации по пространственным и временной переменным. Для численного решения был задействован метод простой итерации. Подробно суть ме тода изложена в 16. Выбор этого метода обусловлен тем, что система для численного решения из 2 1 уравнений, переписанная в матричном виде, будет обладать матрицей с большим диаго нальным преобладанием, что обеспечит быструю сходимость метода. Далее, на примере вместо него подставляются и опишем общий алгоритм действий. 0. На интервале 0, начальные данные выглядят так 0, 0. 0 и 0 берутся из начальных данных задачи. 1. Получив все значения при помощи метода простой итерации, находим . 2. Отсюда, используя формулы, 0, 2, 2 1,2, найдем . 3. Затем, и, наконец, значения, берутся в качестве начальных данных для следующего временного интервала. Присваиваем, . 4. и будут начальными данными для следующего временного интерва ла. Далее, аналогично находим 2, 2 и т. д. При помощи языка Fortran и пакета MPI было создано 2 варианта параллельной программы и проведены численные расчеты на кластере ССКЦ НКС-30Т на узле G7 2 процессора Intel Xeon E5670 и 24 ГБ оперативной памяти. httpwww.sscc.icmmg. nsc.ruhardware.html с классической многопроцессорной архитектурой, а также на кластере МВС-10П МП с архитектурой РСК ПетаСтрим 8 модулей по 8 сопроцессоров Intel Xeon Phi 7120D, 61 ядеро, 244 потока, RAM 16 Gb DDR5. На каждом модуле также стоит процессор Intel Xeon E5-2667 v2. Твердотельные накопители Intel SSD DC S3500. http www.jscc.ruresourceshpc. Декомпозиция области для реализации на CPU и на Intel Xeon Phi представлена на рис. 4. Особенностью архитектуры РСК ПетаСтрим является то, что пользователю доступны для работы только сопроцессоры Intel Xeon Phi. Между собой они обмениваются при помощи MPI-пересылок, а внутри каждого Phi также осуществляется распараллеливание по потокам при помощи OpenMP. Подробнее с особенностями программирования для Intel Xeon Phi можно ознакомиться в работах 1721. Далее будут приведены сравнительные тесты ускорений на примере конкретной модели среды. Для решения системы линейных уравнений используется метод простых итераций, что позволяет прореживать обмены между процессами, так как это не влияет на сам факт схо димости итерационного процесса, а только на ее скорость. В ходе расчетов для модели, описаной далее, выяснилось, что относительно временных затрат на расчеты выгоднее сделать суммарно вдвое большее число итераций и вдвое меньшее число обменов. Другими словами, соседние процессы обмениваются раз в четыре итерации. Это ускорило работу программы в среднем в 1,5 раза, при этом точность решения пострадала незначительно в тестовых расчетах расхождение решений по амплитуде, полученных с прореживанием обменов и без прореживания, составило порядка 0,001 . Область однородная среда с горой на поверхности рис. 5. а б Параметры среды 1, 0,5, 0,25. На рис. 6 размеры области даны в километрах. Соответствующая ей расчетная область прямоугольник размером 64 32 км, дискрети зация области 5 120 2 060 ячеек. Источник типа центр давления работает в течение 2-х секунд. В уравнениях он представлен двумя компонентами, sin 1 0,8sin2 1 0,2sin3 1, 0 2, 0, 2, sin 1 0,8sin2 1 0,2sin3 1, 0 2, 0, 2. Важным свойством криволинейной сетки яляется ее ортогональность к свободой по верхности рис. 6. Следует также упомянуть, что для двух разных форм поверхности не всегда можно использовать один и тот же алгоритм построения сетки. Зачастую возникает необходимость подбирать параметры управляющих функций занова, чтобы не допустить перехлеста ячеек криволинейной сетки. Аналитический метод построения позволяет делать это быстро. Программный генератор сетки написан на языке Fortran и также предложен автором. На рис. 7 можно наблюдать отсутствие дифракций при отражении волны от поверхности, что подтверждает эффективность подхода, предложенного в данной работе. Далее приведены сравнительные тесты для разных архитектур рис. 8. Модель описана в разделе Математическая модель. Тесты для CPU выполнены на сервере G7 2 6ядерных Intel Xeon E5670 и 24 Гб оперативной памяти на узле кластера ССКЦ НКС-30Т, при этом технология hyperthreading отключена. Для Intel Xeon Phi на кластере МВС-10П. В случае Xeon Phi не проводилось никаких дополнительных процедур оптимизации вроде выравнива ния массивов или изменения числа потоков на ядро по умолчанию их 4. В тесте на мас штабируемость алгоритма на каждый сопроцессор Phi приходился объем вычислений, соот ветствующий нашей модели 5 120 2 060 ячеек. Как видно из результатов, даже один узел с 12 ядрами CPU на 1 ядро 1 MPI-поток справляется быстрее, чем один Intel Xeon Phi. При этом заметно, что в случае PetaStream алгоритм быстро уходит в насыщение, что может свидетельствовать о недостаточной оптимизации MPI-обменов между соседними Phi на уровне программного обеспечения кластера. В работе представлен алгоритм и результаты численного моделирования с использо ванием этого алгоритма. Также непосредственно автором создано 2 параллельных реали зации алгоритма, программно реализован генератор криволинейной сетки. Проведены сравнительные тесты для разных архитектур на примере конкретной модели. Новизна работы заключаются в следующем предложен новый способ аппроксимации граничных условий, впервые моделирование сейсмических полей проводилось с использо ванием локально-ортогональной криволинейной сетки, построенной аналитическим спо собом. Проведенные тесты показали отсутствие дифракции при отражении от криволинейной свободной поверхности. В дальнейшем эта работа послужит основой для полноценной 3Dзадачи, результаты которой могут быть применены для решения реальных задач. Автор выражает благодарность В. Н. Мартынову за консультации в ходе выполнения ра боты, а также ССКЦ РАН и МСЦ РАН за предоставленное оборудование для численных расчетов. "}
{"title": "АВТОМАТИЧЕСКОЕ ИЗВЛЕЧЕНИЕ РЕШЕТОК ПОНЯТИЙ   ИЗ МЕДИЦИНСКИХ ТЕКСТОВ НА ОСНОВЕ КОМБИНАЦИИ АНАЛИЗА   ФОРМАЛЬНЫХ ПОНЯТИЙ И ТЕХНОЛОГИЙ БУТСТРАППИНГА ", "absract": "Рассматривается новый способ извлечения понятий из текстов предметной области на основе комбинации анализа формальных понятий и бутстрап-технологии информационного поиска. Анализ формальных понятий представляет собой мощный аппарат автоматического вывода понятий предметной области, однако он рассчитан на высокое качество входных данных, без пропусков и неточностей. Получение таких наборов данных напрямую из текстов затруднено в силу сильной разреженности текстовых корпусов. Соответственно, представляется перспективным улучшение качества входных данных за счет применения бутстраппинга – технологии, обеспечивающей интеллектуальный поиск фрагментированной информации в сети Интернет. Цель данной работы – показать, что при правильном выборе исходных шаблонов поиска бутстраппинг, основанный на использовании открытых ресурсов Интернета как ценных источников знаний, превращается в эффективный инструмент поддержки концептуального моделирования.  анализ формальных понятий, бутстраппинг, извлечение информации, поверхностный лингвистический анализ, информационный поиск.  Работа выполнена при частичной поддержке РФФИ ", "text": "В данной работе мы предлагаем новый способ автоматического извлечения понятий из текстов медицинской тематики, основанный на заполнении пропусков в сильно разреженных матрицах совместной встречаемости терминов. Наш подход опирается на строгие и изящные формулировки анализа формальных понятий метода, который, как отмечается в работе 1, использует язык алгебры для описания понятий и их иерархий. Входные данные для анализа формальных понятий представляются в виде объектнопризнаковой таблицы, отражающей распределение признаков по объектам предметной области. Таблица является бинарной если объект, указанный в строке таблицы, обладает признаком, указанном в столбце таблицы, то на пересечении соответствующих строки и столбца ставится 1, иначе 0. Математический аппарат анализа формальных понятий позволяет выделить в этой таблице множества объектов, обладающих одинаковыми наборами признаков. Считается, что каждое такое множество объектов и их признаков образует одно формальное понятие. Объекты этого множества называются объемом понятия экстенсионалом, а признаки этого множества содержанием понятия интенсионалом. Особенность нашей работы заключается в том, что в качестве входной объектно-при знаковой таблицы мы используем матрицу совместной встречаемости терминов. Термины, образующие строки и столбцы матрицы, мы получаем, извлекая из текстов медицинской тематики конструкции, удовлетворяющие лексико-синтаксическим шаблонам вида Существительное Существительное. Один из самых результативных шаблонов этого вида представляет собой пару Существительное Существительное в родительном падеже. Так, например, при помощи этого шаблона мы извлекаем такие словосочетания, как приступ холецистита, приступ панкреатита, воспаление нерва, нарушение кровоснабжения, обострение гайморита, осложнение гайморита и т. д. Термины, стоящие в указанных парах на первом месте, мы записываем в столбцы матрицы признаки, а термины, стоящие на втором месте, в строки объекты. Также возможна работа и с транспонированной матрицей, тогда термины, стоящие на первом месте, мы записываем в строки, а термины, стоящие на втором месте, в столбцы. К сожалению, полученную таким способом входную матрицу невозможно напрямую использовать для извлечения формальных понятий, так как для этого она слишком неоднородная и разреженная. Дело в том, что строки этой матрицы отражают весь гетерогенный набор объектов, встречающихся в текстах медицинской тематики названия заболеваний, лекарств, методов лечения, органов человеческого тела и т. д. Соответственно и столбцы этой матрицы отражают весь спектр разнородных признаков, каждый из которых присущ только одной своей группе объектов например, признаками обострение и осложнение описываются заболевания, но не органы, а признаками воспаление и отек описываются органы, но не заболевания. Как следствие, увеличивается и без того сильная разреженность, изначально присущая текстовому корпусу. Для устранения неоднородности мы подвергаем исходную матрицу кластеризации, в результате чего из нее получаются более однородные и менее разреженные матрицы меньшего размера кластеры, представляющие собой группы объектов со сходными признаками. Эти матрицы мы используем как отправные шаблоны для бутстраппинга технологии, позволяющей находить недостающую информацию по ее начальным фрагментам. В частности, мы извлекаем из указанных матриц все нулевые пары объект признак и для каждой такой пары формируем поисковый запрос к Интернету как к более репрезентативному корпусу текстов. Таким образом, для каждой нулевой пары объект признак мы проверяем, существует ли устойчивый контекст употребления данного объекта с данным признаком в таком сверхбольшом текстовом корпусе, как Интернет. Если такой контекст существует и является устойчивым, то мы заменяем соответствующий нулевой элемент в матрице на единичный. Только после восстановления пропусков и увеличения количества значимой информации в матрицах мы используем их для извлечения понятий. Как отмечалось выше, для этого мы применяем аппарат анализа формальных понятий, который позволяет не только автоматически выводить понятия предметной области, но и формировать их иерархии. Цель нашей работы заключается в том, чтобы продемонстрировать на конкретном корпусе текстов, как работает предлагаемый подход и насколько эффективно он решает задачу автоматического извлечения понятий. В соответствии с поставленной целью дальнейшее изложение работы ведется следующим образом. Сначала мы приводим основные положения анализа формальных понятий. В последующих разделах мы описываем 4 основных этапа предлагаемого подхода. Этап 1 построение исходной объектно-признаковой матрицы на основе поверхностного лингвистического анализа. Этап 2 разбиение исходной объектно-признаковой матрицы на ряд однородных матриц посредством кластеризации. Этап 3 восстановление пропусков в полученных однородных матрицах методом бутстраппинга. Этап 4 извлечение из восстановленных матриц понятий предметной области и построение их иерархий на основе анализа формальных понятий. В заключение мы излагаем основные выводы и приводим план будущей работы. Входными данными для анализа формальных понятий АФП служит информация о распределении признаков среди объектов предметной области 2. Указанная информация записывается в виде так называемого формального контекста, который представляет собой тройку, где это множество объектов, множество признаков, соответствие между и означает, что объект обладает признаком . Оставим пока в стороне вопрос, каким образом из предметной области выбираются объекты и их признаки для формирования формального контекста. Предположим, что формальный контекст уже задан, и покажем, как в заданном контексте выделяются формальные понятия. Пусть в формальном контексте, выбраны произвольные подмножества объектов и признаков . Операторы Галуа для указанных подмножеств определяются следующим образом, т. е. это множество признаков, которыми обладают все объекты из, т. е. это множество признаков, которыми обладают все объекты из . Тогда формальным понятием контекста называется пара вида, и, такая что и . Множества и называются соответственно объемом и содержанием формального понятия, . Между содержанием и объемом понятия существует обратная зависимость чем больше содержание, тем меньше объем. Другими словами, чем больше признаков содержит данное понятие, тем меньше объектов оно охватывает, и наоборот. Два понятия, и, называют частично упорядоченными, если объем первого понятия входит вложен в объем второго . Множество всех понятий контекста, упорядоченных по вложению их объемов, называется решеткой понятий. Для визуального представления решеток применяются диаграммы Хассе, где сверху показаны наименьшие по объему понятия, а снизу наибольшие 1 3. Поясним основные положения АФП на конкретном примере. На рис. 1 представлен фрагмент формального контекста, сформированного на основе автоматической обработки корпуса медицинских текстов. Контекст задан обычным для АФП способом в виде объектно-признаковой таблицы. В табл. 1 перечислены все четыре формальных понятия, выведенных из рассматриваемого формального контекста. Первое формальное понятие самое широкое по объему, оно включает в себя все 7 объектов, поскольку все они описываются такими общими признаками, как уровень, количество, содержание, активность и концентрация. Утрируя, можно сказать, что в реальности этому формальному понятию соответствует понятие вещества. Второе формальное понятие включает в себя 3 объекта, которые обладают такими дополнительными признаками, как раствор и добавление. Аналогично можно сказать, что в реальности этому формальному понятию соответствует понятие растворимого вещества. Самым узким по объему формальным понятием является четвертое, оно содержит всего 2 объекта глюкоза и лактат. Этому формальному понятию соответствует понятие вещества, которое можно употреблять в пищу. Формальные понятия, выведенные из формального контекста на рис. 1 Понятие Объем понятия Содержание понятия 1, амилаза, аминотрансфераза, глюкоза, креатинин, лактат, мочевина, трансфераза уровень, количество, содержание, активность, концентрация 2, амилаза, глюкоза, лактат раствор, добавление 3, глюкоза, креатинин, лактат, мочевина утилизация, накопление, наличие 4, глюкоза, лактат потребление На рис. 2 изображена диаграмма Хассе, состоящая из двух решеток понятий, построенных на основе рассматриваемого формального контекста. Однако, анализируя полученные иерар хии и классы объектов, эксперт предметной области мог бы заметить, что они не корректны. Например, креатинин и мочевина несправедливо исключены из понятия растворимое веще ство, они тоже могут растворяться. В этом и состоит ключевая проблема анализа формальных понятий если контекст является разреженным и ограниченным, то выходные понятия и их иерархии будут формироваться некорректно. Для автоматического построения входной объектно-признаковой матрицы на основе кор пуса текстов мы используем поверхностный лингвистический анализ shallow linguistic analysis. Поверхностный лингвистический анализ это весьма популярный подход к обработке ес тественного языка, когда речь идет о создании практических приложений в области анализа текстов, ориентированных на конкретные инте ресы пользователей 4. Как следует из его названия, подход не фо кусируется на глубоком многоуровневом и многоаспектном разборе текстов, его цель быстрое выделение и анализ только тех текстовых фрагментов, которые содержат релевант ную с точки зрения пользователя информацию 5. Благодаря этому подход демонстрирует высокую производительность и устойчивость на сколь угодно больших корпусах текстов. Вместе с тем он требует обязательной спецификации того, что считать релевантной инфор мацией, поскольку для выделения такой информации из текста необходима настройка шаб лонов, определяющих соответствие между естественно-языковыми высказываниями и зна ниями предметной области. В этом и заключается основной недостаток поверхностных лингвистических методов. Во-первых, как отмечается в 5, подобная тонкая настройка методов под конкретную предметную область препятствует их переносу на другие предметные области или задачи. Во-вторых, даже внутри исходной предметной области остается неохваченным большой пласт релевантной информации, так как живая структура естественного языка плохо поддается шаблонизации. Применительно к нашей задаче релевантной является информация о медицинских объектах и их признаках. Под медицинскими объектами мы понимаем объекты и явления, которые описываются в текстах медицинской тематики это заболевания, диагнозы, способы лечения, лекарственные препараты, тело человека и т. д. Новизна нашего подхода заключается в том, что указанные объекты и их признаки мы ищем в текстах корпуса на основе поверхностных лингвистических шаблонов вида Существительное Существительное в родительном падеже. Другими словами, мы формируем некоторое начальное множество объектов и их признаков путем извлечения из текстов пар слов, удовлетворяющих заданному шаблону. В качестве признаков мы рассматриваем слова, стоящие в парах на первом месте, а в качестве объектов слова, стоящие на втором месте. Однако предлагаемый нами способ поиска объектов и признаков наследует недостатки, присущие поверхностным лингвистическим методам. Во-первых, он плохо адаптируется к изменениям параметров исходной задачи. Во-вторых, если использовать предлагаемый шаблон напрямую, без дополнительного разбора предложения, то он не покрывает всего множества релевантных объектов и их признаков. Например, объекты и их признаки, разделенные определениями, будут потеряны, т. е. конструкции вида воспаление нерва, осложнение отита и т. п. будет извлечены, в то время как конструкции вида воспаление зрительного нерва, осложнение гнойного отита и т. п. будут пропущены. Поэтому нам приходится расширять данный шаблон. Для практической реализации предлагаемого способа извлечения объектов и их свойств мы используем программный пакет PullEnti свободно распространяемый набор средств разработки SDK для создания приложений по анализу текстов 6 7. Мы подключаем указанные средства разработки в наш проект, реализуемый на языке С, как внешнюю DLLбиблиотеку. На рис. 3 представлен пример работы SDK PullEnti по извлечению объектов и их признаков из текстового фрагмента, описывающего симптомы гайморита Обычно гайморит это следствие осложнений после инфекционного заболевания, например, скарлатины, гриппа, простуды. Основные симптомы гайморита затрудненное дыхание, постоянный насморк, заложенность носа и головная боль. Из данного фрагмента были извлечены такие пары объектов и их признаков, как симптом гайморита, заложенность носа, следствие осложнения, следствие заболевания. На рис. 4 представлен еще один пример работы SDK PullEnti. Здесь объекты и их признаки извлекаются из текстового фрагмента, описывающего осложнение гнойной ангины Синдром Лемьера редкое, но серьезное осложнение гнойной ангины, иногда ее называют постангинальным сепсисом. Из данного фрагмента были извлечены пары синдром Лемьера и осложнение ангины. Как мы видим, несмотря на то что в этом фрагменте объекту ангина предшествует определение гнойная, а признаку осложнение предшествует определение серьезное, это не мешает программе правильно установить объект и его признак. Извлеченные таким образом пары объект признак служат исходным материалом для заполнения объектно-признаковой матрицы все названия объектов без повторений записываются в строках матрицы, а все названия признаков тоже без повторений записываются в столбцах. Для каждой извлеченной пары объект признак на пересечении соответствующих ей строки и столбца матрицы ставится 1. Все остальные элементы матрицы, для которых нет соответствий, обнуляются. Ранее на рис. 1 был представлен фрагмент одной из построенных таким образом объектно-признаковых матриц. На рис. 5 приведен фрагмент формального контекста, сформированного на основе текстов медицинской направленности при помощи программного пакета Pullenti и предложенного нами шаблона. Анализируя фрагмент, можно заметить, что признаки, стоящие в парах с объектами, обозначающими болезни, не используются в паре с объектами, обозначающими органы, и наоборот. Например, можно сказать осложнение гайморита или осложнение гриппа, но нельзя сказать осложнение мозга, и наоборот, можно сказать отек пазухи или отек мозга, но нельзя сказать отек гриппа. Благодаря наличию таких отличительных признаков мы можем выделить во входной объектно-признаковой матрице группы кластеры родственных объектов. Если теперь в каждом кластере убрать нулевые признаки и оставить только те, которые присутствуют хотя бы у одного члена кластера, то мы получим на основе этих кластеров новые менее разреженные объектно-признаковые матрицы меньших размеров. На рис. 6 показаны результаты иерархической кластеризации объектно-признаковой матрицы, построенной на основе рассмотренного выше формального контекста. Первый кластер, как и ожидалось, содержит названия болезней, а второй названия органов. Внутри второго кластера в отдельный подкластер выделены объекты гайморова пазуха и печень, которые в формальном контексте встречались вместе с признаком лечение. Лечение это пример гибридного признака, который употребляется как с болезнями, так и с органами сравните лечение гепатита и лечение печени. В данной работе в качестве метода кластеризации мы используем аггломеративную кластеризацию по Уорду. При использовании метода Уорда на каждом шаге алгоритма происходит слияние кластеров, которое приводит к минимальному увеличению дисперсии внутри объединенного кластера, где, это кластеры до слияния, и объекты кластеров и их центроиды, целевая функция, которая называется ценой слияния. На рис. 7 представлена типичная диаграмма распределения объектов по кластерам. Типичной ее делает наличие одного гигантского кластера на фоне множества мелких. Эксперименты показывают, что мелкие кластеры, как правило, достаточно устойчивы и действительно состоят из однородных объектов, в то время как гигантский кластер, как правило, представляет собой собрание всех неясных объектов, не отнесенных ни к одному из устойчивых кластеров. Как указывал один из основоположников статистической обработки естественного языка Дж. Ципф, разреженность это извечная проблема при работе с текстовыми корпусами 8. Разреженность негативно влияет на результаты кластеризации, искажает их, так что определенная часть терминов в результате такой кластеризации оказывается не в своей категории. Для борьбы с разреженностью данных в этом проекте мы используем подходы на основе слабого машинного обучения. Термин слабое обучение возник сравнительно недавно для обозначения методов, в которых обучение, называемое бутстраппингом англ. bootstrapping применительно к информационным технологиям самозагрузка, ведется на небольшом множестве позитивных примеров 9 10. Например, системе, извлекающей из текстов названия болезней, может потребоваться предоставить небольшое количество примеров названий. После этого система ищет в текстах вхождения этих названий, и пытается определить некоторые общие контексты их появления шаблоны. Затем система по выявленным шаблонам пытается отыскать новые названия болезней, например, в сети Интернет. Процесс обучения является итеративным, что позволяет обнаруживать вс новые шаблоны и новые экземпляры названий. В итоге многократные повторения этого процесса позволят собрать большое количество названий болезней и большое количество шаблонов их употребления в текстах. В нашем случае в качестве обучающих примеров мы используем самые сильные близко расположенные к центроиду объекты кластера и определяем контексты их появления в текстах коллекции. В обнаруженном контексте мы заменяем сильный объект кластера на слабый, например на объект, категория которого вызывает у нас сомнение, и пытаемся отыскать вхождения слабого объекта в рамках заданного контекста в сети Интернет. Для этой цели в нашей системе разработан поисковый робот, который осуществляет просмотр тематических веб-страниц и ищет вхождения слабого объекта. Мы формируем задания этому роботу по сбору веб-страниц из сети Интернет, описывая схемы, позволяющие произвести правильный парсинг страниц. Описание схем производится в полуавтоматическом режиме основная структура веб-страницы загружается в систему, и необходимо настроить только некоторые параметры разметки страниц, например указать контейнер основного текста, последовательность страниц для обхода и т. д. Таким образом, вслед за авторами работы 11 мы используем Интернет как сверхбольшой и сверхценный корпус текстов и оцениваем вероятность использования слабого объекта в контексте, опираясь на количество откликов hits поисковой машины на запрос, . В табл. 2 представлены кластеры, которые получились после уменьшения разреженности в исходном наборе данных, состоящем из 119 строк объектов и 616 столбцов признаков. Жирным шрифтом выделены слова, которые, с точки зрения эксперта, являются релевантными основному содержанию кластера, подчеркнуты слова, ошибочно включенные в данный кластер. Не все кластеры, с точки зрения эксперта, объединяют однородные объекты, тем не менее эти результаты демонстрируют принципиальную возможность использования предлагаемого подхода. Ошибочное появление слов в том или ином кластере можно объяснить, во-первых, разреженностью полученной матрицы, во-вторых, неполнотой исходных корпусов текстов, в-третьих, тем, что решение задачи кластеризации неоднозначно и существенно зависит от выбора метода кластеризации и критерия оценки качества. Кластеры, полученные после уменьшения разреженности Номер кластера и тематика Термины 1 симптомы, признаки, проявления активность период фаза 2 действия общего характера, методы 3 препараты и воздействующие факторы 4 методы медицинского контроля и лечения диагностик фон 5 группирующие слова 6 структурные элементы организма боль человек 7 характеристики, проявления симптомов и болезней день дифтерия зависимость заражение смерть употребление 8 количественные, измеряемые характеристики возможность локализация место особенность результат способность этиология 9 слова, обозначающие заболевание 10 области кожа лицо организм На рис. 8, 9 представлены результаты иерархической кластеризации объектов, при мененной соответственно к кластерам 2 и 8. Как видно из рисунка, объекты внутри кластера можно, в свою очередь, также разделить на семантические подгруппы в соответствии с дифференцирующими признаками. На рис. 10 представлена решетка понятий, сформированная на основе кластера 6. Как видно из этой решетки, лейкоциты, эритроциты и бактерии это клетки. Причем, отличие эритроцитов и лейкоцитов от бактерий заключается в том, что они могут оседать, у них есть ядро, и они подвержены анизоцитозу, а отличие бактерий в том, что они могут быть патогенными. Клетка, орган и ткань согласно диаграмме Хассе это понятия одного уровня. Хотя на самом деле и органы, и ткани состоят из клеток, поэтому клетка должна стоять уровнем ниже, предлагаемый подход позволяет выделять только отношения иерархии is-a и не позволяет выделять отношения вида part-of. Предложенный в статье новый способ извлечения понятий из текстов предметной об ласти, основанный на комбинации анализа формальных понятий и бутстрап-технологии информационного поиска с использованием данных сети Интернет продемонстрировал вы сокую эффективность при работе с корпусами текстов, в которых специальная терминология сильно разрежена. Таким образом, при правильном выборе исходных шаблонов поиска бутстраппинг, основанный на использовании открытых ресурсов Интернета как ценных ис точников знаний, превращается в эффективный инструмент поддержки концептуального моделирования. В своих будущих исследованиях мы планируем апробировать данный подход на текстах других тематик, а также попробовать формировать формальный контекст на основе новых шаблонов, например шаблонов существительное существительное, но с использованием предлогов. По-прежнему остается актуальным вопрос определения количества кластеров пока мы решаем эту задачу эмпирическим путем. "}
{"title": "ТРЕХМЕРНОЕ МОДЕЛИРОВАНИЕ И ИНВЕРСИЯ ДАННЫХ   КОМПЛЕКСА МЕТОДОВ ЭЛЕКТРОКАРОТАЖА В МОДЕЛЯХ СРЕД   С НАКЛОНОМ ГЛАВНЫХ ОСЕЙ ТЕНЗОРА ЭЛЕКТРИЧЕСКОЙ АНИЗОТРОПИИ  ", "absract": "  Впервые формулируются прямая и обратная задачи электрического каротажа об определении компонент тензора электрической анизотропии горных пород по комплексу измерений методами бокового каротажного зондирования и бокового каротажа в нефтегазовых скважинах. Рассматриваются особенности конечно элементной аппроксимации прямой задачи, использующей базисные функции большого порядка. Исследуется возможность восстановления горизонтальной и вертикальной составляющих удельного электрического сопротивления, а также угла наклона главных осей тензора электрической анизотропии. : метод конечных элементов, многоуровневый метод, прямая и обратная задачи, электрический каротаж, тензор удельного электрического сопротивления.  Исследование выполнено при финансовой поддержке РФФИ и Правительства Новосибирской области  в рамках научного проекта № 17-45-540530. ", "text": "Начиная от поиска перспективных объектов, определения их запасов и заканчивая контролем за разработкой месторождений активно используются современные геофизические методы, позволяющие получить исчерпывающую информацию о нефтяных и газовых резервуарах. При изучении геологической среды большую роль играет реконструкция удельного электрического сопротивления УЭС горных пород по данным электрокаротажных зондирований 14. Оценка содержания углеводородов в резервуарах выполняется по значениям УЭС горных пород на основе измерений в скважине методами электрического каротажа. Существуют геологические среды, интерпретация данных измерений в которых требует специализированного математического описания и соответствующих вычислительных алгоритмов. К таким относятся слоистые осадочные породы, представленные переслаиванием тонких прослоев разного вещественного состава и электрофизических свойств, например сильно электропроводящих глинистых отложений и слабо электропроводящих нефтесодержащих песчаников. Такая среда является электрически анизотропной, поскольку значения УЭС в плоскости напластования и в вертикальном направлении существенно отличаются. Если не учитывать электрическую анизотропию при интерпретации данных электрического каротажа, это будет приводить к существенным ошибкам при определении оценки нефтесодержания. Эффект электрической анизотропии слабо изучен при исследовании трещиноватых карбонатных коллекторов, в которых наличие электрической анизотропии обусловлено системой субвертикальных трещин. Таким типом анизотропии обладают палеозойские сложнопостроенные коллекторы. Поэтому решение задачи об определении электрической анизотропии горных пород по данным электрического каротажа является чрезвычайно актуальной и имеет большое прикладное значение в промысловой геофизике. Требуется создание новых эффективных алгоритмов и реализация программных средств, адаптированных под традиционные комплексы методов каротажа скважин. Начиная с 1990-х гг. задачу определения параметров макроанизотропного коллектора решают, применяя индукционные зонды, где генерация токов и измерения выполняется в трехкомпонентных ортогональных катушках 511. Необходимость использования таких сложных систем, а также применения соответствующих ресурсоемких вычислительных схем и процедур интерпретации заметно снижает эффективность их применения. В настоящее время ведутся разработки принципиально новых каротажных систем, предназначенных для определения характеристик макроанизотропных коллекторов 1215. В представленной работе изучение электрической анизотропии геологических объектов базируется на интерпретации данных широко используемых методов электрического каротажа, исходно не предназначенных для изучения макроанизотропных сред. В рамках настоящей работы изучение эффекта электрической анизотропии выполняется по комплексу электрических каротажных методов бокового каротажного зондирования БКЗ и бокового каротажа БК. Необходимость их комплексирования обусловлена различной чувствительностью к компонентам электрической анизотропии. Особенности этих методов таковы, что сигналы зондов БКЗ имеют достаточную чувствительность к вертикальной компоненте анизотропии, а БК к радиальной. Таким образом, по комплексу данных БКЗ и БК становится возможным определение элементов диагонального тензора электрической анизотропии, а также оценки наклона его главных осей. Геофизическую модель рассматриваемой среды будем описывать при помощи функции, задающей зависимость УЭС от пространственных координат и вектора параметров . Последний будет содержать значения параметров геоэлектрической модели. В данной работе будут рассматриваться простые модели, состоящие из однородного пласта, скважины и корпуса зонда. Диаметр и УЭС скважины, а также геометрические характеристики корпуса каротажного зонда будем полагать фиксированными. В дальнейших обозначениях как один, так и оба параметра функции УЭС могут опускаться. УЭС будет полагаться анизотропным имеющим горизонтальную и вертикальную составляющие. Тензор УЭС будет характеризовать угол наклона локальной системы координат относительно оси скважины, в которой он является диагональным. Необходимо отметить, что наклон локальной системы координат описывается тремя углами. Но в рассматриваемом случае каротажные зонды являются симметричными относительно вертикальной оси координат, а также диагональный тензор имеет только две независимые компоненты горизонтальную и компоненты и вертикальную компонента составляющие. Таким образом, тензор УЭС будет иметь только три независимых параметра и выглядеть следующим образом 0 0 0 coscos sinsin cossin sincos, 0 cossin sincos coscos sinsin где и горизонтальная и вертикальная компоненты тензора УЭС соответственно, угол наклона оси зонда относительно локальной системы координат, в которой тензор УЭС является диагональным. В настоящей работе рассматриваются повсеместно используемые на практике при изучении геологических разрезов, вскрытых бурением, два метода электрокаротажа БКЗ и БК. Результатом измерения зондов БКЗ является кажущееся УЭС, которое вычисляется по формуле, где кажущееся сопротивление, коэффициент зонда, потенциал, измеренный на электроде, потенциал, измеренный на электроде, сила тока, протекающего через токовый электрод . В БКЗ используются трехэлектродные зонды, которые имеют следующее обозначение A2.0M0.5N. Здесь расстояние между электродами и составляет 2,0 м, а между и 0,5 м. Результатом измерения зонда БК также является кажущееся УЭС, вычисленное по той же формуле. Но в этом случае потенциал, измеренный на токовом электроде, а потенциал поверхности Земли или потенциал, измеренный на достаточном удалении от токового электрода, соответственно. В отличие от зондов БКЗ токовый электрод зонда БК окружен экранирующими электродами. Их главной задачей является фокусировка тока, достигаемая устранением части токов, протекающих вдоль зонда в окрестности токового электрода. Значение тока, протекающего через токовый электрод, можно получить при помощи следующей формулы I grad, где плотность тока, протекающего через поверхность электрода, удельная электрическая проводимость, напряженность электрического поля, электрический потенциал на электроде, поверхность электрода. Величину коэффициента зонда выбирают таким образом, чтобы кажущееся УЭС, измеренное зондом, совпадало с УЭС однородной среды. Таким образом, результатом измерений являются каротажные диаграммы значений кажущегося УЭС в зависимости от глубины расстояния по скважине, описываемые вектором . Под прямой задачей моделирования процесса каротажа при помощи зондов БКЗ и БК будем понимать определение измеренного кажущегося УЭС по заданной функции распределения УЭС с фиксированным вектором модельных параметров. Как следует из определения кажущегося УЭС, для нахождения его значения необходимо знать значение электрического потенциала на измерительных и токовых электродах. Далее при решении прямых задач БКЗ и БК будут учитываться не только особенности геоэлектрического строения околоскважинного пространства, но конструктивные особенности зондов диаметр корпуса, геометрические размеры электродов и их взаимное расположение. Распределение электрического потенциала в области моделирования описывается следующей краевой задачей div grad 0, 1 0, 2 0, 3, 4, 5 где потенциал напряженности электрического поля, grad, удельная электрическая проводимость, внешняя граница области, на которой электрический потенциал считается равным нулю расстояние от токового электрода до внешней границы выбирается таким образом, чтобы оно существенно не влияло на значение электрического потенциала на измерительных электродах, диэлектрическая поверхность зонда, поверхность токового электрода, поверхность экранирующих электродов зонда БК в случае зонда БКЗ соответствующее краевое условие опускается, напряжение на токовом электроде, напряжение на экранирующих электродах. Представим искомый электрический потенциал в виде суммы неизвестной функции, равной нулю на поверхностях токового и экранирующих электродов и границе, и некоторой функции . Данная функция должна удовлетворять краевым условиям исходной задачи и обладать достаточной гладкостью, 0, 0, 0, 6 Конкретный вид функции выбирается во время дискретизации задачи. Подставим выражение 6 в задачу 15 и сформулируем новую краевую задачу относительно неизвестной функции div grad, 7 0, 8 0, 9 где div grad, а . Для решения краевой задачи 79 будем использовать метод конечных элементов 16. Пусть трехмерная, возможно, неоднородная по физическим свойствам область с липщицнепрерывной границей. Введем следующие функциональные пространства H L grad L, H H 0, где L пространство Лебега, для элементов которого, определим следующее скалярное произведение, . . Для краевой задачи 79 сформулируем следующую вариационную постановку. H H grad grad . 10 Краевые условия 8 и 9 учитываются в данной постановке естественным образом 16. Приближенное решение вариационной постановки 10 будем искать в виде разложения по некоторому множеству базисных функций, образовывающему конечномерное подпространство H пространства 16, 11 где -я базисная функция, вес -й базисной функции в разложении. Дискретная вариационная постановка тогда будет иметь следующей вид. H H grad grad . 12 Поскольку данная постановка должна выполняться для всех функций из подпространства H, а любую такую функцию можно представить при помощи разложения по базису этого подпространства, нам достаточно потребовать, чтобы равенство 12 выполнялось только для всех базисных функций . В результате искомое приближенное решение должно удовлетворять следующим равенствам grad grad, 1,2,..., . В результате приближенное решение полностью определяется вектором весов,..., найти который можно, решив систему линейных алгебраических уравнений СЛАУ, 13 где элементы матрицы и вектора правой части можно вычислить следующим образом grad grad, . В качестве базисных функций будем использовать полиномы высоких порядков, определенных на тетраэдральной сетке, построенной в расчетной области 17. Далее под порядком базисных функций будем понимать максимальный порядок полиномов, использовавшихся при определении базиса. Для улучшения спектральных свойств матриц, получаемых после дискретизации исходной задачи, можно ортогонализовать базисные функции. Полная ортогонализация привела бы к резкому увеличению количества ненулевых элементов матрицы. В 17 предлагается проводить частичную ортогонализацию, т. е. разбить базисные функции на множество групп, а затем выполнить ортогонализацию только внутри каждой группы. Базисные функции высоких порядков могут быть ассоциированы с узлом, ребром, гранью или с самим тетраэдром. Это зависит от того, как определяется степень свободы конкретной базисной функции. Поскольку одно ребро, грань или элемент для базисов высоких порядков ассоциированы с несколькими функциями, будем использовать это свойство в качестве разделителя на группы. Определение групп ортогонализации подобным образом не приводит к увеличению количества ненулевых элементов матрицы, а также к изменению ее портрета. В 17 для ортогонализации используется стандартное скалярное произведение. В этой работе базисные функции внутри одной группы ортогонализуются относительно билинейной формы, которая используется для построения вариационной постановки. Таким образом, процесс ортогонализации будет эквивалентен использованию некоторой блочнодиагональной матрицы. Матрица A СЛАУ 13 является положительно определенной и может быть легко приведена к симметричному виду 16. Исходя из этого для нахождения решения 13 воспользуемся методом сопряженных градиентов. Поскольку решаемая задача является трехмерной, то время решения СЛАУ 13 будет существенным. Это особенно важно при решении обратной задачи, когда основные временные затраты будут приходиться на нахождение решений множества прямых задач. Для уменьшения требуемых вычислительных ресурсов воспользуемся многоуровневым алгоритмом 18. Это полный аналог многосеточного метода 16, но в отличие от него для нахождения решения прямой задачи используется не последовательность вложенных друг в друга сеток, а последовательность вложенных функциональных подпространств. Для формирования данной последовательности вложенных подпространств воспользуемся свойством иерархичности используемых для построения дискретной вариационной постановки базисных функций 16. А именно, множество базисных функций порядка 1 является подмножеством множества базисных функций порядка . Таким образом, операции интерполяции и проектирования между двумя пространствами базисных функций разного порядка вводятся естественным образом. Также существенным является вопрос выбора порядка базисных функций, используемых для построения дискретной задачи. С одной стороны, повышение порядка базисных функций ведет к увеличению порядка аппроксимации получаемого приближенного решения и, следовательно, к возможности использования для моделирования более грубых сеток обладающих существенно меньшим количеством узлов. С другой стороны, при увеличении порядка используемых базисных функций также увеличивается количество степеней свободы, связанных с различными геометрическими примитивами расчетной сетки. Например, для базиса первого порядка с каждым узлом сетки связана одна степень свободы, и размерность результирующей СЛАУ будет равна количеству узлов расчетной сетки. В то же время для базиса второго порядка, помимо степеней свободы, связанных с узлами сетки, возникают степени свободы, связанные с ребрами сетки. Таким образом, размерность СЛАУ будет равна количеству узлов сетки плюс количество ребер сетки. При этом необходимо отметить, что переход к базису второго порядка на одной и той же сетке не только увеличивает размерность СЛАУ, но также увеличивает и заполненность матрицы не нулевыми элементами, что также приводит к дополнительным вычислительным затратам. Поэтому встает вопрос оптимального выбора порядка базисных функций, обеспечивающий получение приближенного решения с заданной точностью за минимальное вычислительное время. В табл. 1 представлена зависимость времени вычисления приближенного решения прямой задачи БКЗ модель зонд скважина пласт. Для каждого выбранного порядка базисных функций подбиралась такая тетраэдральная сетка, что относительная погрешность нахождения кажущегося УЭС была не более двух процентов. В этой таблице используются следующие обозначения порядок полиномов, используемых для построения базисных функций время в секундах, необходимое для уменьшения относительной нормы невязки СЛАУ до 10 при помощи метода сопряженных градиентов время в секундах, необходимое для уменьшения относительной нормы невязки СЛАУ до 10 при помощи многоуровневого метода. Метод сопряженных градиентов использовался с блочно-диагональным предобуславливанием, или, иными словами, использовалась частичная ортогонализация базисных функций, описанная раннее. Как следует из табл. 1, использование базисных функций высоких порядков существенно уменьшает вычислительные затраты при решении прямой задачи БКЗ. В свою очередь, использование базисных функций больших порядков позволяет применять для решения СЛАУ многоуровневый алгоритм при использовании базиса первого порядка он вырождается в простой метод сопряженных градиентов, что также повышает вычислительную эффективность разработанных методов моделирования каротажа. Два этих подхода дают суммарное ускорения в 10 раз. Время вычисления приближенного решения прямой задачи БКЗ, 1 1567 1567 2 575 297 3 320 202 4 378 155 Используемые методы решения СЛАУ не исключают использования других способов предобуславливания, что также может дополнительно ускорить нахождение решения. Но это ускорение будет пропорциональным для всех рассмотренных вариантов расчетов, и не сможет нивелировать выигрыш именно от использования базиса высокого порядка и многоуровневого алгоритма. Необходимо сказать о способе повышения быстродействия вычислений с использованием графических процессоров GPU 19 20. Так, в работе 21 22 разработан и программно реализован алгоритм моделирования данных БКЗ на основе метода конечных элементов и высокопроизводительных гетерогенных вычислений на центральном процессоре CPU и GPU. Численное решение этой прямой задачи сводится к решению СЛАУ, для которого используется разложение Холецкого с последующим решением двух вспомогательных СЛАУ с треугольными матрицами. Особенностью реализации рассматриваемой задачи является то, что необходимо решать много СЛАУ с одной и той же матрицей, но с разными правыми частями, поэтому вычислительные затраты на решение двух СЛАУ с треугольными матрицами значительно превышают затраты на разложение матрицы основной СЛАУ. В работе показано, что это приводит к низкой эффективности использования только GPU и требует разработки гетерогенного метода CPU-GPU вычислений, который позволит повысить быстродействие. Сформулируем обратную задачу каротажа как задачу поиска вектора параметров геоэлектрической модели, минимизирующего функцию 23, min arg где количество измеренных кажущихся УЭС, полученных при каротаже измеренное кажущееся УЭС смоделированное кажущееся УЭС, рассчитанное для модели околоскважинного пространства, заданной вектором параметров решение обратной задачи. Для решения поставленной обратной задачи воспользуемся методом покоординатного спуска 24. Определим следующий вспомогательный алгоритм минимизации функции вдоль направления из точки с начальным шагом, 0 10, 2 Результатом работы данного алгоритма является шаг, на который необходимо сместиться из точки вдоль направления, чтобы получить новое приближенное решение задачи минимизации. Величина шага выбирается так, чтобы новое приближение находилось как можно дальше от текущего, а не как обеспечивающая наибольшее уменьшение целевой функции. Тогда -я итерация алгоритма покоординатного спуска примет следующий вид 1,2,..., 0 1, 0 0,5 где приближенное решение задачи минимизации на -й итерации вектор, параллельный -й оси координат в начальный момент времени -я ось координат, шаг поиска нового приближенного решения вдоль -й оси координат. Эффективность использования алгоритма минимизации для решения обратных задач рассматривается в 24. С использованием разработанного алгоритма трехмерной численной инверсии данных методов электрокаротажа проведено тестирование в типичных моделях сред, учитывающих наклон главных осей тензора анизотропии. В приведенных тестах для решения прямой задачи использовались базисные функции 4-го порядка. Анализ точности восстановления горизонтальной и вертикальной компонент УЭС, а также угла наклона оси скважины относительно локальной системы координат, в которой тензор УЭС является диагональным, выполнен в следующих модельных задачах. Первая включает скважину радиусом 0,108 м с УЭС бурового раствора 1 Омм и пласт с горизонтальной компонентой УЭС 4 Омм, вертикальной 9 Омм, а также различные углы наклона осей тензора УЭС относительно скважины 0, 15, 30, 45, 60, 75 и 90. Во второй горизонтальная и вертикальная компоненты УЭС пласта имеют значения 15 и 75 Омм соответственно, и те же углы наклона главных осей тензора УЭС. Для получения вектора измеренных кажущихся УЭС выполнено моделирование процесса каротажа с использованием четырех зондов БКЗ A0.4M0.1N, A1.0M0.1N, A2.0M0.5N, A4.0M0.5N, и зонда БК. При решении обратных задач использовались измерения с одной глубины. К полученным синтетическим каротажным данным предварительно были добавлены нормально распределенные случайные величины, пропорциональные начальным данным. Так, в табл. 2 приведены результаты решения обратной задачи для первой и второй моделей с дисперсией шума 0,025. В таблице используются следующие обозначения угол наклона осей тензора к оси скважины у исходной модели, восстановленная горизонтальная компонента УЭС, восстановленная вертикальная компонента УЭС, восстановленный угол наклона главных осей тензора к оси скважины. Результаты решения обратной задачи Для модели пласт с горизонтальной компонентой УЭС 4 Омм, вертикальной компонентой УЭС 9 Омм, дисперсия шума Для модели пласт с горизонтальной компонентой УЭС 15 Омм, вертикальной компонентой УЭС 75 Омм, дисперсия шума На основании результатов, приведенных в табл. 2, можно сделать следующие выводы точнее всего удается восстановить горизонтальную составляющую УЭС пласта, восстановленная вертикальная составляющая имеет несколько большую погрешность по сравнению с горизонтальной, при этом погрешность восстановления угла наклона в некоторых случаях может составлять до 20. С одной стороны, такая погрешность восстановления угла наклона является значительной, но с другой стороны, она постулирует саму возможность восстановления угла при помощи зондов, изначально не рассчитанных на решение подобных задач. При решении практических задач теперь появляется возможность такой оценки, что дает дополнительную существенную информацию о строении околоскважинного пространства. На основании проведенных вычислительных экспериментов можно сделать вывод, что совместное использование в конечноэлементной аппроксимации базисных функций больших порядков и многоуровневого алгоритма решения СЛАУ позволят существенно ускорить решение прямых и обратных задач каротажа. Использование комплекса данных БКЗ и БК при решении совместной обратной задачи позволяет восстанавливать значения элементов диагонального тензора удельного электрического сопротивления, а также проводить оценку угла наклона главных осей тензора электрической анизотропии. Относительная погрешность идентификации угла наклона обусловлена тем, что изначально каротажные методы БКЗ и БК не были предназначены для решения задач, связанных с изучением электрической анизотропии. Однако полученные результаты по определению компонент тензора электрической анизотропии и оценке угла наклона его главных осей пусть и с некоторой погрешностью открывают принципиально новые возможности при интерпретации повсеместно применяющихся методов БКЗ и БК для изучения геологических разрезов в Западной и Восточной Сибири. В завершение отметим, что с использованием разработанного алгоритма впервые становится возможным изучение эффекта электрической анизотропии при исследовании трещиноватых карбонатных коллекторов, в которых наличие электрической анизотропии обусловлено системой наклонных трещин. Именно этим типом анизотропии обладают глубокопрогруженные коллекторы в доюрском фундаменте, которые являются чрезвычайно перспективными. Информация о наклоне трещин и их преимущественном направлении играет существенную роль при проектировании наклонно-горизонтальных скважин, достоверная оценка которой возможна методами электрокаротажа. "}
{"title": "РАЗРАБОТКА ИНФОРМАЦИОННОЙ СИСТЕМЫ ПО КЛЕЩЕВОЙ ОПАСНОСТИ  НА ОСНОВЕ ОНТОЛОГИИ ПРЕДМЕТНОЙ ОБЛАСТИ ", "absract": " Предложен подход к разработке состава и структуры Интернет-ресурса на основе онтологии предметной области. Описана предметная область, связанная с распространением клещей и переносимыми ими заболеваниями, представлена ее семантическая структура, выделены основные разделы информационного наполнения и показаны способы навигации по ресурсу. : иксодовый клещ, инфекционные агенты, онтологический подход, информационная система.  Исследования выполнены при частичной поддержке гранта РФФИ № 18-07-01457, Интеграционного проекта СО РАН № АААА-А18-118022190008-8 (№ 0316-2018-0002) и темы госзадания № АААА-А17-117120670141-7 (№ 0316-2018-0009). ", "text": "Развитие научной деятельности в современном обществе приводит к росту роли компьютерных технологий. Возрос поток информации, что обусловило необходимость использования новых способов ее хранения, представления, формализации, систематизации и автоматической обработки. Появились способы создания баз знаний, позволяющих использовать их для различных практических целей. Появления технологий Semantic Web привело к появлению систем, способных без участия человека извлекать нужную информацию из текста. Гипертекстовые страницы Semantic Web имеют дополнительную разметку, которая содержит сведения о семантике элементов страницы. Важным компонентом Semantic Web является понятие онтологии, описывающее смысл семантической разметки. Как правило, под онтологией понимают систему понятий некоторой предметной области, которая представляется как набор сущностей, соединенных различными отношениями 1. Создание основанного на развитой онтологической структуре интеллектуального научного Интернет-ресурса ИНИР или портала по определенным тематикам позволит обеспечить эффективный доступ к информации и ее последующую обработку. Онтология как основа ресурса позволяет, помимо структуризации данных, производить первоначальную верификацию данных, исходя из заданных в ней правил 2 3. Это помогает улучшить качество вносимой информации и в ряде случаев исключить противоречивые факты. Социально значимой информацией являются данные об инфекционных заболеваниях, переносимых иксодовыми клещами, вызванных их разнообразием и сложной структурой природных очагов этих заболеваний. Интеграцию сведений в виде информационного ресурса, или информационной системы ИС, ориентированной на анализ клещевой опасности на основе данных полевых и лабораторных работ, полученных разными группами исследователей, обеспечит использование подхода, основанного на онтологии. Этот ресурс позволит не только осветить проблему заражения трудноизлечимыми заболеваниями, передаваемыми через укус клеща, но и предоставить площадку для сбора и обмена информацией по данной проблеме в научных кругах. Различное территориальное расположение специалистов и отсутствие единой информационной базы являются серьезной помехой в научной и практической деятельности. Становится актуальным организация эффективного доступа не только к публикациям, описывающим методы и подходы к исследованию генетического разнообразия инфекционных агентов, переносимых клещами разного типа, но и к фактическому материалу, связанному с клещами, территорией и средой обитания насекомых. Целью работы является описание подходов к разработке информационного ресурса, основанного на онтологическом подходе, ориентированном на эпидемиологическую опасность, на примере Новосибирской области. Ареал обитания клещей очень широк. Встречаются виды, обитающие даже в Арктике и Антарктике. Они являются основными переносчиками множества вирусных, бактериальных и протозойных паразитических простейших возбудителей заболеваний человека и животных клещевого энцефалита, боррелиоза, эрлихиоза и др. Вирус клещевого энцефалита ВКЭ и боррелии наиболее социально опасный среди перечисленных возбудителей природно-очаговых инфекций человека 4 . На территории России встречается около 60 видов иксодовых клещей, основными переносчиками клещевой энцефалит и клещевой боррелиоз являются таежный клещ, обитающий в азиатской части страны, и европейский лесной клещ, обитающий в европейской части страны. Недавно обнаружена новая разновидность вируса Кемерово 5. В зависимости от вида клещи могут содержать различные вирусы, бактерии и пр. Часто их называют патогенами. Многие переносимые клещами заболевания имеют сходные ранние симптомы, что затрудняет точную диагностику и лечение . Иногда клещи могут переносить несколько возбудителей заболеваний, а это еще сильнее осложняет постановку диагноза и оказание медицинской помощи. Только полная информация о клещах и переносимых ими инфекциях может помочь врачу правильно диагностировать заболевание и назначить лечение. Для обеспечения эффективных мер профилактики вирусных заболеваний необходим пространственный и временной анализ распространения клещей, в том числе инфицированных теми или иными возбудителями. Отсутствие эффективной технологии раннего выявления известных и новых патогенов и прогнозирования их распространения является одной из важных и острых проблем. И в этой связи одним из наиболее перспективных способов контроля над возбудителями инфекций может стать система непрерывного наблюдения. Важным шагом к созданию подобной системы является пространственный и временной анализ на основе геоинформационных технологий 6. Геоинформационная система ГИС система сбора, хранения, анализа и графической визуализации пространственных географических данных и связанной с ними информации о необходимых объектах. Понятие ГИС также используется в более узком смысле как инструмент программный продукт, позволяющий пользователям искать, анализировать и редактировать как цифровую карту местности, так и дополнительную информацию об объектах. Основной задачей создаваемой информационной системы является получение, интеграция и предоставление данных и знаний в интересах научных исследований в предметной области. Концептуальной основой систематизации знаний и информации предметной области являются онтологии. Как правило, они исполняют роль модели предметной области 2 3. Онтология является ядром, базовым компонентом информационной модели. С ее помощью можно не только описать систему знаний ИНИР, но и создать формальные структуры для представления его контента. Онтология содержит понятия моделируемой области, связывающие их отношения, атрибуты понятий и отношений, ограничения на значения атрибутов, а также аксиомы, определяющие семантику понятий и отношений. Формализм, используемый в технологии построения порталов научных знаний, обеспечивает компактное и непротиворечивое описание понятий проблемной и предметной областей портала и разнообразных семантических связей между ними, а также выстраивание понятий в иерархию общее частное и поддержку наследования свойств по этой иерархии 7. Важным моментом при разработке онтологии предметной области является построение таксономий. Таксономия это предметная тематическая классификация, которая группирует термины в виде управляемых словарей тезаурусов и упорядочивает их в виде иерархических структур. Разработанная онтология предметной области по клещевой опасности включает четыре базовые иерархические структуры иерархию объектов, иерархию предметов исследования, иерархию методов исследования и иерархию научных результатов 1. Свойства каждого понятия описываются с помощью атрибутов и ограничений, налагаемых на область их значений. Понятия базовых онтологий связаны между собой ассоциативными отношениями, выбор которых осуществлялся исходя не только из полноты представления проблемной и предметной областей портала, но и из удобства навигации по его информационному пространству и поиска информации рис. 1. Одним из этапов создания ИНИР является изучение предметной области, связанной с клещевой опасностью, и формулирование некоторого представления структуры знаний об этой области. При работе со всем многообразием информации, имеющей отношение к клещам и связанной с ними эпидемиологической опасности, были выделены следующие основные объекты исследования собственно клещи, местность их распространения биотоп, инфекционные агенты, переносимые клещами, и гены, которые обнаруживают у клещей и у некоторых инфекционных агентов. Для каждого объекта исследования была составлена таксономия, содержащая элементы, актуальные для предметной области, связанной с клещевой опасностью, на примере Новосибирской области 5 6. В результате изучения предметной области были выделены основные понятия клещ, территория и местность распространения, переносимые клещами патогены и вирусные заболевания. В онтологию были также включены персоны, профессионально связанные с этой областью первооткрыватели, исследователи, специалисты санитарно-эпидемиологической службы и лица, принимающие решения. Для каждого вида клещей были определены связанные с ним ключевые понятия. Схема связей между понятиями представлена на рис. 1. Для того чтобы формализовать структуру полученной информации о клещах, была построена иерархическая структура онтологии рис. 2. Для конкретизации информации об исследуемых объектах, были определены методы исследования выбранных объектов. Наиболее широко используемыми методами являются секвенирование биологического материала и анализ генетической информации. Анализ подразделяется на несколько групп анализ количества клещей по различным территориям, анализ клещей на одной территории по годам и филогенетический анализ генома клещей 6. Онтология также содержит информацию о персонах, которые собирали исходный фактический материал, а потом использовали указанные методы. Этими персонами могут быть сборщики информации, которые собирали статистические данные о клещах, либо исследователи, которые в результате обработки и анализа данных получали научный результат, который, как правило, формулировался в виде публикаций. Концептуальным базисом создаваемого интернет-ресурса портала знаний является описанная выше онтология. Онтология портала вводит формальные описания понятий предметной области в виде классов объектов и отношений между ними, тем самым задавая структуры для представления реальных объектов и их связей 7. В соответствии с этим данные на портале представлены в виде семантической сети, т. е. как множество разнотипных взаимосвязанных информационных объектов 3. Содержательный доступ к систематизированным знаниям и информационным ресурсам обеспечивается с помощью информационной системы, предоставляющей развитые средства навигации и поиска. Архитектуру ИС определяют ее компоненты, их функции и взаимодействие. Система разработана на основе шаблона проектирования MVC . Моделью является хранилище данных, представлением пользовательский интерфейс, контроллером интерпретатор действий пользователя рис. 3. Использование данного подхода позволяет проводить разработку, модификацию или замену каждого компонента независимо друг от друга. При работе с ИС можно выделить две важные части получение данных и изменение данных. В каждой из них можно выделить следующие компоненты навигационная и поисковая системы, редакторы данных и онтологии. Пользовательский интерфейс реализован с помощью технологии JavaServer Pages . Функциями представления являются навигация по ресурсу, отображение контента и результатов поиска. Информация об объекте онтологии представляется в виде HTML-страницы, где показываются свойства и их значения, а также связи с другими объектами в виде гиперссылки. Отображение данных зависит от прав доступа пользователя. Так, незарегистрированному пользователю доступны только навигация и поиск, а эксперту знаний весь функционал ресурса. На рис. 4 представлен интерфейс информационного ресурса. Особое внимание при разработке информационной модели ресурса было уделено связям между экземплярами классов онтологии, поскольку данные, указанные в атрибутах и описаниях, являются основным источником знаний для пользователей. С этой точки зрения важно поддерживать не только навигацию через иерархию наследования, определяемую отношениями is-А, subClassOf и т. п., но и другими видами отношений 8. Онтология как базовый компонент информационной системы должна быть приведена к виду, пригодному для машинной обработки. Базовый компонент был разработан на языке веб-онтологий OWL в редакторе онтологий Protg . Для единообразного хранения онтологии и данных было принято решение использовать RDF-хранилище. Был выбран Jena Fuseki Server как бесплатное мультиплатформенное средство, поддерживающее запрос данных через SPARQL Query Language, изменение данных через SPARQL Update, а также логический вывод для проверки согласованности базы знаний . Контроллер связывает между собой модель и представление, интерпретируя действия пользователя для отображения или изменения данных. Контроллер реализован через Java Servlet интерфейс. Так как модель RDF служит только для описания данных, но не их обработки, то необходимо использовать сторонние средства. Был использован язык запросов SPARQL . Функциональные компоненты ресурса были разделены по типу SPARQL-запро сов на две группы. Навигационная и поисковая системы только обращаются к базе данных, а редактор данных и онтологии еще и модифицирует е. Построена концептуальная модель информационной системы. На ее основе определено представление сущностей и отношений связей между сущностями, и обеспечивается поддержка архитектуры универсальной информационной системы, связанной с конкретной областью научных знаний, ориентированных на эпидемиологическую обстановку конкретного ареала. Концептуальная модель включает в себя основные сущности методы и объекты исследований, научный результат, инфекционные агенты, иксодовые клещи, персоны и публикации. Важной составляющей концептуальной модели являются публикации и данные, включая факты особый вид документа. В свою очередь, факты понимаются как характеристика сущностей, описываемых в онтологии информационной системы, представляемой как единичное значение данных. По результатам изучения предметной области, ориентированной на эпидемиологическую проблему, вызванную инфицированными иксодовыми клещами, была выполнена структуризация информации. На основе структуризации составлена онтология предметной этой области, которая стала базовым компонентом при построении информационной модели ресурса. "}
{"title": "ПРОГРАММНАЯ СИСТЕМА ДЛЯ ОПРЕДЕЛЕНИЯ РЕЧЕВЫХ ДЕЙСТВИЙ   В ТЕКСТАХ ЕСТЕСТВЕННОГО ЯЗЫКА ", "absract": "  Статья посвящена разработке методов извлечения речевых действий из текстов естественного языка. В настоящее время одной из наиболее важных проблем является проблема создания человеко-машинных интерфейсов. В данной работе рассматривается задача построения подобных интерфейсов путем автоматизированного извлечения речевых действий из текстов естественного языка. Использование речевых действий позволяет задавать контекст диалога и уточнять смысл употребляемых понятий. По результатам исследования была разработана программная система, которая способна определять типы речевых действий, представленных в текстах естественного языка. Одно из возможных применений результатов данного исследования заключается в использовании разработанной программной системы при создании чат-ботов. : речевое действие, иллокутивная сила, теоретико-модельные методы, алгебра Линденбаума – Тарского, фрагменты атомарных диаграмм, онтология, естественно-языковые интерфейсы.  Исследование выполнено при частичной финансовой поддержке Президиума СО РАН (проект «Инженерия интенсиональных онтологий в дедуктивных и информационных системах» Комплексной программы ФНИ  СО РАН II.1). ", "text": "В настоящее время проектирование, построение и пополнение семантических и онтологических моделей различных предметных областей являются актуальными задачами, решаемыми как при автоматизации бизнес-процессов предприятий, так и при разработке программных продуктов для конечных пользователей. Одной из наиболее острых проблем является проблема предоставления интерфейсов на естественном языке для коммуникации человека и компьютера. В частности, такие проблемы ставятся и решаются при создании чатботов. Компьютер не всегда способен понять, какую цель хотел достичь человек той или иной фразой, исходя только из синтаксиса текста диалога с пользователем. Интерфейсы на естественном языке призваны помочь определять то, чего хочет человек, посредством не только синтаксического, но и семантического анализа текстов естественного языка. Существуют разные подходы к разработке интерфейсов на естественном языке 15. В рамках данной работы мы используем теоретико-модельные методы 611 и теорию речевых действий для создания естественно-языковых интерфейсов. Целью настоящего исследования является разработка и программная реализация алгоритма определения типов речевых действий, представленных в текстах естественного языка. Достижение данной цели необходимо для решения более общей задачи извлечения речевых действий из текстов естественного языка и их формального теоретико-модельного представления. Извлечнные речевые действия представляются в виде элементов куба алгебры Линденбаума Тарского теории рассматриваемой предметной области 12 13. Одной из важных областей применения результатов данной работы является их использование при разработке чат-ботов нового поколения, которые по своим возможностям будут существенно превосходить существующие. Рассмотрим, например, чат-бот Алиса виртуальный голосовой помощник, созданный компанией Яндекс. Алиса не создает контекста общения с собеседником, и по этой причине не всегда корректно отвечает на вопросы человека. Мы же хотим строить и далее использовать модель диалога между пользователем и чатботом. На основе знаний о диалоге, представленных в модели, будут формироваться дальнейшие реплики чат-бота. Модель формально представляется в виде фрагмента атомарной диаграммы алгебраической системы, а речевые действия в виде троек формул сообщение, побуждение, заявление. Каждая такая тройка является элементом куба алгебры Линденбаума Тарского. Необходимо отметить, что целью данной работы является создание не полностью автоматической, а автоматизированной системы распознавания речевых действий, так как существуют проблемы, которые на настоящем этапе не представляется возможным решать полностью автоматически. К таким проблемам можно отнести полное описание контекста для определения пропозициональной составляющей и иллокутивной силы речевого действия в частности, обработку пресуппозиций, содержащихся в тексте естественного языка 14 15. Разработка теории речевых действий была начата Дж. Л. Остином 16 17 и детально разработана Дж. Р. Серлем и Д. Вандервекеном 1828. Нами была предложена определенная ревизия классической теории речевых действий 12 13. В теории речевых действий диалог между собеседниками рассматривается как совокупность речевых действий. В речевом действии выделяют две основных составляющих высказывание пропозициональная составляющая и иллокутивная сила. Мы расширяем этот подход и рассматриваем текст естественного языка как последовательность речевых действий. Методы определения речевых действий в текстах естественного языка в рамках классической теории речевых действий исследовались в 29. Высказывание пропозициональная составляющая речевого действия отражает общее содержание предложения. Мы формально описываем пропозициональные составляющие речевых действий при помощи фрагментов атомарных диаграмм т. е. конъюнкций атомарных предложений логики предикатов первого порядка. В классической теории речевых действий иллокутивная сила раскладывается на 7 компонентов иллокутивная цель мера стремления к иллокутивной цели способ достижения иллокутивной цели ограничения на пропозицию предварительные условия условие искренности сила выражения условия искренности. В данной работе мы рассматриваем две составляющие иллокутивной силы иллокутивную цель и интенсивность выражения иллокутивной цели т. е. меру стремления к иллокутивной цели. Классическая теория речевых действий предлагает следующую классификацию речевых действий 1 репрезентативы речевые действия, целью которых является сообщение об общем положении дел 2 директивы речевые действия, побуждающие совершать или не совершать какие-либо действия 3 комиссивы речевые действия, направленные на возложение ответственности на говорящего за то, чтобы сделать что-то в будущем 4 экспрессивы речевые действия, служащие для выражения эмоционального состояния говорящего 5 декларативы речевые действия, результатом которых является осуществление главной цели высказывания, т. е. после их озвучивания положение дел в реальном мире соответствует сказанному. Стоит заметить, что данная классификация не представляет собой разбиение на непересекающиеся подмножества, т. е. одно речевое действие может быть представителем нескольких классов. Разработанная нами ранее классификация речевых действий 12 13 выделяет три типа речевых действий более точно три типа компонентов речевых действий сообщение, заявление, побуждение. Каждое речевое действие может иметь один, два или три компонента. Указанные типы речевых действий сопоставимы со следующими аспектами сознания собеседника знания прошлое, настоящее или будущее, представление о текущей ситуации настоящее и намерения будущее. Например, заявление может менять контекст диалога, в частности изменять интерпретацию, смысл употребляемых понятий. Таким образом, с одной стороны, речевое действие представляется как пара, иногда пишут, где иллокутивная сила, а пропозициональная составляющая, а с другой стороны, как тройка предложений логики предикатов первого порядка, где сообщение, заявление, а побуждение. При этом формула может быть тождественно истинной. Это означает, что -й компонент речевого действия отсутствует. Заметим, что классический подход к теории речевых действий обладает рядом существенных недостатков 12 13. 1. Переход от синтаксиса к семантике, определяемый только через иллокутивные гла голы. Однако следующие примеры являются разными речевыми действиями с точки зрения классической теории речевых действий, но обозначают они одно и то же желание говорящего, поэтому с точки зрения семантики не имеет смысла разделять их a. Закрой окно. b. Я прошу тебя закрыть окно. c. Я заявляю свое требование закрыть окно. d. Я сообщаю тебе свою просьбу закрой окно. 2. Наличие в каждом речевом действии не более одной иллокутивной цели. Из-за этого классификация иллокутивных сил становится очень громоздкой. 3. Отсутствие точного определения классов речевых действий. Например, отсутствует четкий критерий, позволяющий ответить на вопрос, что представляет собой заявление. Подобного рода определения крайне важны, так как в настоящей работе для программной реализации необходимы четкие правила для определения типа речевого действия. 4. Изолированность речевого действия от диалога. Речевое действие рассматривается отдельно, как бы в вакууме. 5. Юридическая парадигма на самом деле меняет мир не слово, а его фиксация в рамках определенного контекста протокола, регламента и т. д. Основными преимуществами предлагаемого подхода к классификации речевых действий 12 13 по сравнению с подходом Остина и Серля является следующее. 1. Речевое действие является композицией компонентов трех типов сообщение, заявление и побуждение. 2. Каждый тип речевого действия имеет четкое определение. 3. Речевое действие рассматривается в контексте диалога. Это означает, что мы имеем представление о текущей ситуации например, разговаривают ли два друга либо работодатель и подчиненный, и в зависимости от этого мы можем делать те или иные выводы о принадлежности речевого действия к тем или иным классам. 4. Меняется не мир, а собеседник его знания, представления о текущей ситуации, намерения. Алгоритм автоматизированного извлечения речевых действий из текстов естественного языка можно представить в виде последовательности шагов 1 распознавание речевого действия в предложении 2 извлечение его пропозициональной части 3 извлечение иллокутивной цели и интенсивности речевого действия. Одной из задач данной работы является определение типа речевого действия, представленного в предложении естественного языка. Для наглядности рассмотрим следующие примеры 1 Я объявляю войну заявление 2 Делай уроки побуждение 3 В пятницу будет контрольная работа сообщение 4 В пятницу будет контрольная работа, все должны на нее прийти сообщение заявление. 5 Можно я оставлю у себя твою книгу еще на неделю, пожалуйста побуждение заявление 6 Пообещай, что больше не будешь так делать побуждение 7 Какое красивое небо заявление Разберем подробно пример предложения, содержащего все компоненты речевого действия Завтра в 9 часов утра вы должны прийти на сдачу долгов. Во-первых, в данном предложении присутствует сообщение, семантически выраженное в следующем Завтра в 9 часов утра состоится сдача долгов. Во-вторых, заявление является частью речевого действия, так как отдается приказ быть всем завтра на сдаче долгов. В-третьих, говорящий предположим, что это преподаватель побуждает всех прийти, т. е. он заинтересован в том, чтобы завтра все присутствовали на сдаче долгов, а иначе самому преподавателю не имеет смысла приходить. Перечисленные составляющие представляют 3 разных пропозиции, выделенные из основного предложения. Для определения того или иного типа речевого действия можно задать определенные вопросы. Если ответы на эти вопросы могут быть получены из предложения, то речевое действие относится к тому или иному типу в противном случае речевое действия не содержит искомого компонента. Ниже перечислены вопросы, являющиеся содержательными критериями проверки наличия в речевом действии каждой из трех составляющих. Другими словами, на какие вопросы необходимо ответить, чтобы убедиться, что речевое действие имеет тот или иной компонент. Предполагается, что целью является определение типа речевого действия фраз субъекта в диалоге с субъектом . 1. Ставил ли целью говорящий передать собеседнику какие-то знания об уже совершившихся, текущих или будущих событиях 2. Было ли целью говорящего установить, что имела место определенная речевая ситуация вопрос, просьба, приказ, мольба и т. д. 3. Хочет ли говорящий, чтобы у собеседника после разговора было намерение что-то сделать при этом не имеет значения, было ли такое намерение у до разговора важно, чтобы после диалога это намерение появилось Данные вопросы можно задавать пользователю в интерактивном режиме в том случае, если нельзя однозначно определить тип речевого действия. Также в случае невозможности однозначной классификации речевого действия можно выдавать пользователю несколько вариантов, отличающихся в зависимости от контекста. Помимо этого, мы можем задавать вопросы, помогающие выяснить содержание каждой конкретной составляющей речевого действия 1., что узнал нового 2., что произошло во время разговора и какая речевая ситуация имела место 3., что намеревается сделать . В ходе работы был составлен следующий список правил определения типа речевого действия. a. повелительное наклонение глагола b. условное наклонение глагола c. будущее время глагола 2-е или 3-е лицо d. глагол давай e. слово пожалуйста f. слова следует должен обязан необходимо нужно надо и т. д. g. можешь ли ты не мог бы ты почему бы тебе не и т. д. a. настоящее время глагола b. прошедшее время глагола c. 1-е или 3-е лицо. a. я хотел бы мне хотелось бы b. настоящее время глагола. a. было бы хорошо чудесно здорово и т. д., если бы... b. любой изолированный вопрос. Видно, что некоторые правила совпадают для разных типов речевых действий. Это означает, что в исходном предложении речевое действие представляет собой комбинацию типов, например сообщение и побуждение, а возможно, и все три типа одновременно. Предложенный список правил не является финальной версией алгоритма, используемого в программе, т. е. данный список является расширяемым и пополняемым в процессе использования программной системы для разных текстов русского языка. Алгоритм разработанной программной системы состоит из следующих шагов. На вход программной системе подается предложение на русском языке. В данном исходном предложении осуществляется морфологический анализ слов. После этого предложение проверяется на наличие каждого из типов речевого действия сообщение, заявление, побуждение. На выходе программа выдает найденные типы компонентов речевого действия, представленного в данном предложении. Опишем этапы работы программной системы более подробно. Итоговой идентификации типа речевого действия в предложении предшествует этап морфологического анализа предложения. Несмотря на то что данный этап не играет определяющей роли в идентификации типа речевого действия, он очень важен для предобработки предложения, так как именно на этом этапе происходит первоначальный выбор того или иного типа речевого действия. Для морфологического анализа предложения естественного языка используется программа MyStem, предоставленная компанией Яндекс для открытого использования. Программа делает следующее на вход подается предложение русского языка, а на выходе мы получаем всю информацию о каждом слове часть речи, время и наклонение для глаголов, падеж для существительных и т. п. К системе MyStem можно подключить свой словарь также она позволяет строить гипотетические разборы для слов, не входящих в словарь. Рассмотрим пример работы программы для входного файла sapgir.txt, содержащего текст В мурели шлепают пельсиски. В стакелках светится мычай., вывод будет следующим Описанная программа встроена в разработанную программную систему SpeechActs и используется для предварительной обработки предложений. После проведения морфологического разбора предложения мы переходим к его семантическому анализу. Этот этап играет большую роль в определении типа комбинации типов речевого действия, так как первоначально мы выбираем тип в соответствии с определенными морфологическими формами слов, а затем корректируем выбранный тип посредством семантического анализа. Так, к примеру, предложение Какая прекрасная погода сегодня на этапе морфологического анализа мы определим как сообщение, а после семантического анализа поймем, что в действительности это заявление, так как данным предложением говорящий хотел выразить свое отношение к погоде, а в другом контексте это может быть побуждением отдохнуть на природе. На этапе семантического анализа мы ищем употребленные в предложении глаголы в словаре иллокутивных глаголов, встроенном в программу. Нахождение глагола в одном из словарей определяет принадлежность речевого действия тому или иному типу. Таким образом, на данном этапе мы подтверждаем выбор типа речевого действия, осуществленный на предыдущем этапе этапе морфологического анализа, либо добавляем к уже выбранному типу еще один тип речевого действия, определенный в ходе семантического анализа. Алгоритм работы программной системы заключается в следующем на вход подается предложение на русском языке. В исходном предложении осуществляется морфологический анализ каждого слова в предложении, после чего предложение проверяется на наличие каждого из типов речевого действия сообщение, заявление, побуждение. На выходе программа выдает найденные типы речевых действий в предложении из входных данных. Ниже приведен скриншот пользовательского интерфейса первой версии программной системы. Разработанная программная система состоит из следующих компонентов. Контроллер отвечает за инициализацию всех частей приложения. Он запускает остальные компоненты, а также обеспечивает передачу данных от графического интерфейса к модели и обратно. Модуль, запускающий программную систему LogicText, разработанную О. Г. Махасоевой и Д. Е. Пальчуновым 8 9. Программа делает следующее каждое слово в предложении приводит к нормальной форме, выбирает из них субъект и объект само действие является предикатом. В программу встроен словарь с некоторыми известными предикатами, где с каждым глаголом сопоставлены вопросы кто, что, где, когда и т. д.. Алгоритм работы программной системы LogicText основан на применении теории Смысл-Текст И. А. Мельчука 30. Модуль, который обрабатывает каждое слово в предложении и возвращает полную характеристику каждого из слов. Модель представляет собой главный компонент, в котором происходит обработка предложения, его анализ и определение типа речевого действия. Данный модуль отвечает за отображение введенного пользователем предложения, а также за визуализацию ответа программной системы. Речевое действие представлено в программной системе в виде композиции трх компонентов сообщение, заявление, побуждение. Если компонент определнного типа присутствует в речевом действии, то приводится соответствующее правило, которое позволило определить этот тип. В данной работе были проведены исследования речевых действий, представленных в текстах естественного языка. В результате сделана классификация иллокутивных глаголов, соответствующих различным типам речевых действий, а также разработан алгоритм по определению типа или комбинации типов речевого действия. На основе разработанного алгоритма была реализована программная система SpeechActs, которая позволяет определять тип речевого действия по предложению на естественном языке. Программная система также позволяет выводить информацию о том, по какому признаку правилу был определен тип речевого действия. Программная система SpeechActs интегрирована с программной системой LogicText, на основе которой она производит формальное представление информации, содержащейся в предложении естественного языка. Разработанная программная система может быть применена для построения модели диалога, а также для построения модели пользователя при его общении с чат-ботом. Извлечение речевых действий дает возможность формального представления контекста диалога. В частности, речевые действия могут определять и переопределять смысл определения используемых понятий в контексте данного диалога. Для дальнейшего усовершенствования разработанной программной системы необходимо добавлять новые правила для более точного определения типа речевого действия. Помимо этого, планируется использовать методы определения интенсивности речевого действия, а также предполагается разработать методы построения фрагментов атомарных диаграмм для полного извлечения речевых действий из текстов естественного языка. "}
{"title": "АВТОМАТИЗИРОВАННАЯ ВЕРИФИКАЦИЯ АЛГОРИТМОВ УПРАВЛЕНИЯ  СЛОЖНЫМИ ТЕХНОЛОГИЧЕСКИМИ ОБЪЕКТАМИ   НА ПРОГРАММНЫХ ИМИТАТОРАХ      ", "absract": "Статья посвящена проблеме проверки алгоритмов управления, созданных в рамках процесс-ориентированного подхода, на соответствие входным спецификациям. Представлена общая схема верификации алгоритма управления, приведены ее реализация в автоматизированном варианте и результаты практической апробации в проекте по автоматизации Большого солнечного вакуумного телескопа. : автоматизация, промышленные алгоритмы управления, верификация, процесс-ориенти рованные языки программирования.  Работа выполнена при финансовой поддержке Федерального агентства научных организаций (государственная регистрация № АААА-А17-117060610006-6) и при финансовой поддержке РФФИ (проект № 17-07-01600). ", "text": "Алгоритмы управления сложными технологическими объектами обладают рядом свойств, специфичных для области промышленной автоматизации 14 открытость наличие окружающей среды, внешнего мира, с которым взаимодействует алгоритм управления событийность алгоритм управления формирует управляющие воздействия как реакцию на события значимые изменения во входных данных, в том числе на управляющие команды от оператора неопределенная продолжительность функционирования алгоритма управления синхронизм необходимость синхронизации реакции алгоритма управления с событиями на объекте управления логический параллелизм алгоритм управления структурно отражает параллелизм физических процессов на объекте управления, их независимость. Реализация алгоритмов управления средствами объектно-ориентированных языков общего назначения чревата чрезмерным усложнением программной архитектуры при росте сложности алгоритма 5. Поэтому в области промышленной автоматизации используются специализированные языковые средства для разработки алгоритмов управления языки МЭК 61131-3, G NI LabVIEW, Reflex 68. Использование языков МЭК 61131-3 трудоемко из-за низкой выразительности этих языков, а в некоторых случаях и неприемлемо, например при необходимости интеграции кода в сторонние системы 6. Исследователи альтернативных лингвистических средств для описания алгоритмов управления 2 4 710 предлагают и практически обосновывают эффективность предметноориентированных языков на основе модели конечного автомата, в частности процесс-ори ентированного языка Reflex 10. При использовании конечно-автоматных языков в промышленной автоматизации 7 8 11 12 основную проблему представляет решение задачи тестирования и верификации созданных алгоритмов, поскольку методы, разработанные для тестирования и верификации программного обеспечения в области объектно-ориентированного программирования, слабо применимы 5. Управляющий алгоритм невозможно тестировать автономно. Тестирование алгоритма на реальном объекте управления может привести к поломке оборудования или аварийной ситуации. Поэтому наиболее распространенный подход ручная проверка на этапе пуско-наладки проверяющий контролирует реакцию алгоритма на различные ситуации, постепенно усложняя тесты. Подход очень трудоемкий. Он приводит к серьезным психологическим нагрузкам на разработчиков, не гарантирует полноту верификации, затрудняет контроль качества верификации и в итоге усложняет разработку управляющих алгорит мов 11. Поэтому разработка методов верификации алгоритмов управления интересна не только с теоретической, но и с практической стороны 5 1318. Современная тенденция использовать для тестирования и верификации алгоритмов управления программные имитаторы объекта управления 11 1921. В статье предлагается подход к верификации алгоритмов управления сложными технологическими объектами на основе концепции виртуальных объектов управления ВОУ, включающий в себя создание кода алгоритма управления и программную реализацию объекта управления в виде ВОУ. Основные положения, изложенные в статье, были представлены на V Международной научной конференции Математическое и компьютерное моделирование Омск, 2017 22. Общая схема итерационной разработки алгоритмов управления рис. 1, предложенная ранее в 11, включает следующие шаги верифицируемый алгоритм управления его часть реализуется программно и оформляется в обособленный алгоблок модель технологического объекта его часть также реализуется программно и оформляется в обособленный алгоблок, называемый виртуальным объектом управления проводится верификация через создание тестовых ситуаций сценариев и контроль реакции алгоритма управления коррекция кода алгоритма управления и или виртуального объекта управления по результатам верификации. Схема позволяет использовать итерационный подход к разработке промышленных алгоритмов управления сложными технологическими объектами. В упрощенном виде схема была опробована при создании набора виртуальных лабораторных стендов для обучения студентов ИТ-специальностей, специализирующихся в области промышленной автоматизации 23. Упрощение заключалось в неизменности ВОУ. При этом ВОУ выполнены с использованием графики для повышения наглядности и визуального контроля корректности алгоритма управления. Несмотря на высокую эффективность при использовании в учебном процессе, подход не нашел практического применения в реальных проектах в силу высокой трудоемкости создания графических моделей ВОУ. Для использования в реальных проектах автоматизации предложенная схема была программно реализована в автоматизированном комплексе верификации алгоритмов управления. В автоматизированном варианте рис. 2, таблица управление сценариями работы и контроль реакции алгоритма производится оператором через графический интерфейс . Графический интерфейс предоставляет оператору возможность отправлять штатные команды алгоритму управления через очередь сообщений и контролировать сообщения от алгоритма управления через очередь сообщений, управлять поведением ВОУ через очередь сообщений и контролировать сообщения от ВОУ через очередь сообщений . Также на графическом интерфейсе оператора ГИО отображаются состояния входных и выходных дискретных сигналов алгоритма управления. Для имитации входных аналоговых сигналов от датчиков АЦП организован дополнительный канал связи между ВОУ и АУ, а для имитации выходных аналоговых сигналов ЦАП канал связи . Программный комплекс автоматизированной верификации алгоритмов управления был реализован на базе пакета LabVIEW рис. 3. Комплекс включает ГИО, который конфигурируется через модуль загрузки конфигурационных файлов МЗКФ и взаимодействует с целевыми модулями алгоблоков АУ и ВОУ . Модули загрузки конфигурационных файлов и ГИО реализованы на языке G LabVIEW. Исполняемые модули АУ и ВОУ генерируются из описания на языке Reflex и в виде DLL интегрируются в LabVIEW, что в отличие от подхода, использованного при разработке виртуальных лабораторных стендов, обеспечивает возможность итерационно развивать не только АУ, но и ВОУ. Управление верификацией ведется оператором через ГИО рис. 4. ГИО представлен расположенной внизу окна неизменяемой панелью управления верификацией и шестью вкладками генерации входных сообщений для АУ и ВОУ, переменных АУ рис. 5, переменных ВОУ, отладочной информации АУ рис. 6, отладочной информации ВОУ и вкладки Помощь с руководством по работе с комплексом. Панель управления верификацией содержит элементы управления режимом отладки пошаговый непрерывный, запуска и остановки алгоблоков. Используемые условные обозначения Вкладка генерации входных сообщений АУ и ВОУ см. рис. 4 разделена на две области панель управления АУ и панель управления ВОУ для ввода входных сообщений для АУ и ВОУ соответственно. Вкладка Переменные АУ рис. 5 разделена на три области панель значений входных портов АУ с указанием имени входного порта, источника, который генерирует значения порта ВОУ РУЧН, и значения битов порта, отображаемых цветом панель значений входных и выходных глобальных переменных АУ с указанием типа, имени переменной и ее текущего значения панель режима управления входным портом АУ, позволяющая оператору устанавливать значения битов выделенного порта вручную. Вкладка Переменные ВОУ выглядит аналогично. На вкладке Отладочная информация АУ см. рис. 6 отображаются выходные сообщения АУ и текущие состояния процессов АУ . Вкладка Отладочная информация ВОУ выглядит аналогично. При запуске комплекса МЗКФ на основании конфигурационных файлов, создаваемых транслятором языка Reflex, настраивает вкладки ГИО имена переменных, портов, процессов, входных выходных сообщений и передает управление ГИО. ГИО выделяет память под очереди сообщений, буферы входных выходных переменных, буфер состояния процессов, и затем передает указатели на выделенные области памяти алгоблокам. По началу верификации кнопка Запуск на панели управления верификацией ГИО циклически активирует алгоблоки в определенной последовательности сначала ВОУ, затем АУ. Создание тестовых ситуаций производится оператором через вкладки Генерация входных сообщений АУ и ВОУ, Переменные АУ, Переменные ВОУ. Контроль корректности алгоритма управления ведется визуально. Разработка алгоритма управления соответствует общей схеме итерационной разработки см. рис. 1. Решение было практически апробировано на задаче автоматизации Большого солнечного вакуумного телескопа пос. Листвянка, Иркутская обл. 5 24. В проекте был создан и верифицирован алгоритм управления системой вакуумирования. Верифицировалась работа алгоритма при создании вакуума в трубе телескопа, развакуумировании перед техническими работами, реакция алгоритма на изменение температуры окружающей среды, уровня воды в системе охлаждения, на разгерметизацию трубы телескопа, отказ отсечных клапанов, вакуумных заслонок, насосов, вытяжных вентиляторов, датчиков и исполнительных органов системы климат-контроля и т. д. Верификация была проведена на территории разработчика и обеспечила значительное сокращение общей трудоемкости работ, в частности, продолжительности пусконаладки на целевом объекте была сокращена более чем в два раза. Выявленные недостатки подхода визуальный контроль за реакцией алгоритма и сложность анализа отображаемой информации не исключает вероятности пропуска ошибки при верификации в силу того что на каждой итерации должна быть заново проверена реакция алгоритма в соответствии со списком тестовых ситуаций, возникает большое количество рутинных действий. В работе была предложена и рассмотрена автоматизированная схема итерационной разработки алгоритмов управления технологическим объектом. Итерационная схема разработки предполагает верификацию алгоритма управления, специфицированного на процесс-ориен тированном языке Reflex, на виртуальном объекте управления до начала приемо-сдаточных испытаний на целевом объекте. Эффективность автоматизированной схемы верификации была подтверждена в проекте автоматизации Большого солнечного вакуумного телескопа при создании ПО подсистемы вакуумирования. "}
{"title": "ПРИМЕНЕНИЕ FPGA ДЛЯ УСКОРЕНИЯ РАСЧЕТА  ВОЛНОВОГО ФРОНТА ЦУНАМИ", "absract": "Рассматривается вопрос ускорения численного расчёта распространения волны цунами от очага до берега  в рамках дифференциальной модели мелкой воды с применением аппаратного ускорения на базе FPGA. Разработана программная архитектура для расчета системы мелкой воды без учёта внешних сил, являющейся эквивалентной используемой в пакете MOST для численного моделирования движения волны цунами по водной акватории. Численная реализация системы мелкой воды осуществлялась по схеме Мак-Кормака. Точность вычислений разработанного решателя была проверена сравнением с точным решением, известным в случае плоского наклонного дна. Достигнутая точность не уступает, а местами и превосходит точность известного программного пакета MOST. : расчет цунами, ускорение, FPGA, Мак-Кормак, MOST, численные модели.  Работа выполнена в рамках бюджетного проекта 0319-2018-0010 «Исследование и развитие методов и технологий построения интегрированных программно-аппаратных комплексов для задач моделирования и управления динамическими системами обработки и отображения данных» (регистрационный номер: АААА-А17117062110016-4). ", "text": "Возможность оценки опасности побережий в случае возникновения цунами до прихода туда волны является востребованной и актуальной задачей для прибрежных регионов, находящихся в зоне риска. Основная проблема служб предупреждения цунами это своевременное оповещение населения и реализация различных эвакуационных сценариев в зависимости от ожидаемой высоты волны в тех местах побережья, где это требуется 1 2. Работа направлена на ускорение численного расчта распространения волны цунами от очага до берега в рамках дифференциальной модели мелкой воды с применением аппаратного ускорения на базе FPGA. Широко известен и применяется подход на основе численного моделирования распространения волны с использованием дифференциальной модели мелкой воды. Наибольшее распространение получили несколько разностных схем, корректно решающих нелинейные уравнения мелкой воды, реализованные в виде алгоритмов пакеты прикладного программного обеспечения MOST, TUNAMI и COMCOT. Численный расчт распространения волны на персональном компьютере в достаточной области порядка 10 миллионов расчтных узлов длится 23 часа 3 . При этом пространственные шаги сетки, покрывающей область такого размера, в которую входят и очаговая область, и береговая линия, не может быть достаточно детальной для корректного моделирования вблизи берега и в бухтах. При использовании в расчтах шага, равного нескольким метрам вместо нескольких сот метров, потребуется на 23 порядка больше вычислительных ресурсов оперативной памяти и времени расчтов, что практически исключает использование персональных компьютеров для получения результата в течение имеющихся в запасе десятков минут. В пакете MOST для численного моделирования движения волны цунами по водной акватории используется следующий эквивалентный вид так называемой системы мелкой воды без учта внешних сил донное трение, сила Кориолиса и т. д. 4 где полная глубина слоя жидкости, глубина возмущенного слоя, профиль глубин, считающийся известным цифровая батиметрия, время, компоненты вектора скорости вдоль осей и соответственно, g ускорение свободного падения. Моделирование происходит в прямоугольной и не меняющейся со временем области, с применением разностных схем прямоугольной сетке, где, шаги сетки по пространственным переменным и, шаг по времени. В данной работе для простоты используется равномерный шаг как по пространственным переменным, так и по времени. Для аппроксимации уравнений мелкой воды используется явная двух шаговая конечноразностная схема второго порядка аппроксимации типа Мак-Кормака 5 6. 1 шаг 2 шаг Вентильные матрицы, программируемые пользователем FPGA для различных задач, используются с 1990-х гг. При этом вначале наибольшее применение нашли вариации программируемых логических матриц PLDCPLD, имеющие энергонезависимую память для хранения конфигурации. PLD успешно применялись для решения небольших задач по разработке автономных устройств и контроллеров, имеющих малое энергопотребление и массагабаритные размеры. Увеличение объема логических элементов и возможность неограниченного перепрограммирования для изменения алгоритмов обработки данных стало возможным при появлении FPGA. Такие FPGA позволяют реализовывать трудоемкие математические алгоритмы обработки данных, а также выполнять прототипирование вычислительных устройств для дальнейшего производства серийных заказных микросхем ASIC. Но до недавнего времени существовало 2 основных препятствия для применения FPGA, связанных с необходимостью ручной реализации алгоритмов с точностью до регистров и триггеров уровень регистровых передач RTL register transfer level 1 трудоемкость реализации программных модулей, требующая значительно больше времени до 2 порядков больше, чем реализация для PC на высокоуровневых языках 2 высокие требования к квалификации разработчика. Создаваемые средства для автоматизации процесса разработки Simulink MatLab, SystemVerilog, SystemC не позволяли производить полноценную разработку алгоритмов на высокоуровневом языке происходило значительное снижение производительности и требования к ресурсам по сравнению с RTL моделью. Современная технология High-Level Synthesis HLS позволяет использовать для описания цифровых схем C-подобный язык 7. Это является новым витком развития способов создания различных вычислительных устройств, обеспечивающих полный цикл от описания архитектуры до верификации проекта с использованием различных средств моделирования. HLS представляет собой автоматизированный процесс проектирования, который интерпретирует алгоритмическое описание поведенческой модели и позволяет создавать цифровые устройства, четко реализующие заданные условия. С помощью HLS можно легко изменять параметры конвейера, подстраиваясь под временные timing или пространственные utilization требования. Также технология HLS позволяет производить верификацию программного кода до его преобразования в схему для конкретной микросхемы FPGA. Именно технология HLS и большие ресурсы современных микросхем FPGA позволяют сегодня применять их для решения новых типов задач в новых областях. Изложенная вычислительная схема была реализована на платформе вентильных матриц программируемых пользователем FPGA. Для реализации алгоритма на FPGA была предложена архитектура поточного вычислителя, состоящая из процессорных элементов ПЭ. ПЭ осуществляет вариант двумерной прогонки конвейера с последовательным потоком данных. Вспомогательными данными для каждого узла, которые необходимо хранить, являются значения всех используемых функций в 4-х соседних узлах. Особенность архитектуры FPGA позволяет использовать внутреннюю память BRAM для организации соответствующего буфера данных и линии задержки, что позволяет реализовать конвейер при количестве памяти до . Математические операции, необходимые для алгоритма Мак-Кормака, реализованы вычислительным конвейером, обеспечивающим производительность обработки одной точки сетки за один такт. Полученное решение позволяет гарантировать производительность с точностью до такта. Блок-схема предложенной архитектура всего спецпроцессора представлена на рисунке см. далее. Помимо самого вычислителя, спецпроцессор имеет контроллеры памяти DDR3, контроллер PCIe, модуль DMA, обеспечивающий взаимодействие вычислителя с памятью компьютера-хоста в режиме прямого доступа. Данные поступают в вычислитель из памяти через FIFO, что позволяет легко варьировать частоту отдельных вычислительных блоков, подстраиваясь под конкретный кристалл FPGA и характеристики внешней памяти и интерфейсов. Сам вычислитель в зависимости от доступных ресурсов FPGA состоит из одного или нескольких процессорных элементов. Спроектированный вычислитель на уровне алгоритмов был протестирован с применением технологий HLS. Модули, обеспечивающие работу всего процессора, протестированы с помощью RTL-симуляторов. Для практической реализации и тестирования были использованы следующие платформы SLEDv7 на базе кристалла семейства Virtex-6 8 VC709 на базе кристалла Virtex-7 . Итоговая производительность и затраты ресурсов зависят не только от количества ПЭ, но также от частоты их работы. В результате тестирования было выяснено, что реализованные конвейеры способны работать на частоте 200 MГц на плате SLEDv7 и до 300 MГц на платах VC709 и KU115. Далее в таблице представлена производительность вычислителя для двух платформ. Замеры представлены для тестовых данных, используемых NOAA 2580 2879 точек, акватория Тихого океана с временным шагом 10 с. В случае платы SLEDv7 использовалась цепочка из 2 ПЭ одинарной точности на частоте 200 MГц. В результате была получена производительность в 52 итерации в секунду, или час модельного времени за 6,84 с. Сравнение производительности вычислителей при использовании разных кристаллов xc6vsx315-1 SLEDv7 xc7vx690-2 VC709 Кол-во ПЭ 2 8 Частота МГц 200 250 Время одного прохода мс 38 31 Время одной итерации мс 19 3,8 Платформа VC709 позволила разместить в себе 8 процессорных элементов на частоте 250 MГц. Итоговая производительность составила 263 итерации в секунду, или час модельного времени за 1,368 с. Для тестирования описанного численного метода и его реализации было проведено сравнение результатов численного решения модельной задачи распространения цунами от круглого источника над наклонным дном с известным точным решением, а также с решением, полученным пакетом MOST 5. Сравнение распределения высот и времен прихода волны показало хорошее их соответствие вне зоны шельфа, т. е. там, где глубина превышает 150 200 м. В целях ускорения расчета распространения волны цунами по глубоководной части океана был спроектирован спецвычислитель на базе архитектуры вентильных матриц программируемых пользователем FPGA. Численная реализация системы мелкой воды осуществлялась по схеме Мак-Кормака. Точность вычислений разработанного решателя была проверена сравнением с точным решением, известным в случае плоского наклонного дна. Достигнутая точность не уступает, а местами и превосходит точность известного программного пакета MOST. Предложенная архитектура поточного вычислителя на базе FPGA основана на процессорных элементах ПЭ для двумерной прогонки конвейера с последовательным потоком данных, что позволяет масштабировать решение для различных кристаллов, получая максимально возможную производительность. Архитектура предложенного ПЭ позволяет одновременно обрабатывать точек входного потока данных, что дает возможность параметризовать ПЭ в зависимости от особенностей используемой вычислительной платформы для получения максимальной производительности. "}
{"title": "РАЗРАБОТКА ПРЕЦЕДЕНТНО-ОРИЕНТИРОВАННОГО ПОДХОДА   ОБРАТНОГО РЕИНЖИНИРИНГА WEB-ИНТЕРФЕЙСОВ   ", "absract": "Статья посвящена применению рассуждений на основе прецедентов (case-based reasoning, CBR) в области web-разработки. Учитывая собственный практический опыт в данной сфере, автор предлагает автоматизировать составление html/css-макета путём агрегирования прецедентов кода из предыдущих опытов, что на методологическом уровне крайне близко к подходу CBR, а именно: предлагается методика конструирования систем, генерирующих html-код из растрового изображения и основанных на подходе рассуждений на основе прецедентов.  В частности, в статье изложена оригинальная теория составления структуры изображения и описан алгоритм получения такой структуры. Кроме того, рассматривается модификация подхода case-based reasoning, которая  позволяет получить требуемый результат решения поставленной задачи. Также описываются результаты прохождения экспериментов разработанной системы в определённых условиях. : рассуждения на основе прецедентов, компьютерное зрение, оптическое распознавание символов, обратный инжиниринг, web-разработка. ", "text": "Web-технологии являются одним из самых развитых направлений современных информационных технологий. Они используются не только для разработки коммерческих сайтов компаний, но и как один из важных узлов любой ИT-инфраструктуры. Соответственно можно говорить о том, что практически вся отрасль информационных технологий в том или ином виде использует web-разработку. Вместе с тем автоматизация самой web-разработки является недостаточно полной. Существуют средства автоматизации развртывания сред окружения, механизмы конструирования каркасов приложений и некоторые другие направления. Однако почти не охваченным остатся одна из ключевых задач создание HTMLCSS-макетов. С одной стороны, эта часть считается одной из наиболее рутинных с другой ряд особенностей этого процесса не позволяет применить классические средства автоматизации. К таким особенностям можно отнести наличие не формализуемых требований к макету, вариативность корпоративных стандартов написания кода, требование кроссбраузерности и кроссплатформенности, что предполагает постоянную адаптацию решения к новым средам. Автоматизация создания HTMLCSS-макетов не только ускорит процесс разработки webприложений, но и сделает его более гибким, позволяя масштабировать его результаты, проверять гипотезы, помогать тестированию. Это обусловливает целесообразность описываемой разработки. Ввиду сказанного объектом исследования является обратный реинжиниринг в области web-технологий, а предметом автоматизация обратного реинжиниринга интерфейсов webприложения. Цель работы создать технологию построения систем генерации html-кода на основе растрового изображения. Методическую основу теоретических оснований составляет подход CBR, рассуждения на основе прецедентов. Кратко описывая его суть, можно сказать, что это способ решения проблем путм адаптации решений аналогичных проблем в прошлом к текущей ситуации. Такой подход выбран в связи с поставленной в работе гипотезой о том, что формализация изображений чем, по сути, является создание HTML-макета посредством трансдуктивных выводов, или рассуждений по аналогии, порождает результат, наиболее близкий к тому, что производит человек. К тому же такая схема позволяет решить описанные выше проблемы автоматизации. Следует отметить, что поставленная выше гипотеза обусловливает использование подхода, который отличает данное исследование от смежных см. раздел Обзор литературы, что можно рассматривать как элемент научной новизны. Кроме того, к новым результатам можно отнести разработку алгоритма извлечения структуры элементов изображения. В последние годы в зарубежной практике появляется повышенный интерес к поставленной проблеме. Полученный в работе 1 результат проект DeepCoder дат основания полагать, что современный уровень развития искусственного интеллекта позволяет автоматизировать создание артефактов работы ИТ-специалистов, которые ранее считались не поддающимися автоматизации. Так, DeepCoder это система генерирования программного кода на основании входных и выходных данных требуемого алгоритма. Хотя такая проблематика отличается от рассматриваемой в текущей работе, разработки, полученные в ходе этого проекта, послужили основой для многих других исследований 2 3, родственных рассматриваемой задаче. К таким разработкам можно отнести, в частности, использование моделей машинного обучения, основанных на рекуррентных нейронных сетях, и специальные техники поиска блоков кода. Разработку достаточно близкой задачи осуществлял Т. Нгуен 4 обратный инжини ринг интерфейсов мобильного приложения. Напрямую перенести этот опыт на инжиниринг web-интерфейсов не получится. Однако сильная сторона исследования техники оптического распознавания символов OCR может быть повторно использована для распознавания элементов изображения страницы Интернет-сайта. Самым последним успешным случаем решения описываемой задачи можно назвать работу организации UIzard Technologies 5 под названием pix2code. Авторы отмечают схожесть данной задачи с задачей генерирования текста на естественном языке, описывающего изображение. Соответственно, и метод они выбирают схожий в основе их решения лежит каскад рекуррентных нейронных сетей типа LSTM long-short term memory, долгая краткосрочная память. При несомненных достоинствах этого подхода и успешных практических результатах следует выделить недостатки. Наиболее значимым видится, как утверждают сами авторы, отсутствие использования экспертной эвристики. Принимая преимущества этой особенности в некоторых условиях, необходимо отметить, что в общем случае это ведт к ограниченности подхода, так как многие требования к реализации макетов нельзя извлечь исключительно из изображения необходим контекст, который существует в знаниях экспертов. Другой важный недостаток формирование обучающей выборки. Нейронные сети, несомненно, мощный инструмент машинного обучения, однако он требует на вход огромное количество данных порядка миллионов записей, чтобы быть по-настоящему эффективным. Безусловно, учитывая колоссальные размеры Интернета, такую выборку собрать технически несложно. Но возникает вопрос о репрезентативности данных далеко не всякий web-сайт положительно скажется на обучении нейронных сетей. В связи с этим появляется дополнительная задача определения качества HTML-кода, что видится существенным увеличением сложности реализации. В работах 6 7 рассуждения на основе прецедентов и методы онтологического моделирования применялись для диагностирования заболеваний позвоночника. Знания извлекались и обрабатывались при помощи онтологической модели данной предметной области 8. В качестве прецедентов рассматривались истории болезни пациентов. Множество прецедентов формально было представлено в виде прецедентной модели, являющейся частным случаем булевозначной модели 9. Порождение оценочных знаний о болезнях пациентов производилось при помощи нечтких моделей, полученных фазификацией булевозначных прецедентных моделей 9 10. Опыт и результаты этих исследований, учт их сильных и слабых сторон будут использованы в текущей работе. Опишем подробнее, что требуется от системы. Алгоритм должен распознать структуру изображения, выделить как можно больше характеристик объектов в этой структуре цвет, шрифт, отступы и сгенерировать код, реализующий построение распознанной структуры. При этом не требуется распознать атрибуты, воссоздать картинку пиксель-в-пиксель. В идеале достаточно, чтобы алгоритм безошибочно сгенерировал около 85 кода так, чтобы HTML-специалист любой квалификации мог без труда добавить оставшиеся 15, при этом чтобы не нужно было принципиально менять структуру кода, а также думать о решении стандартных задач. Поставим этот показатель в качестве ориентира при разработке прото типа. Во введении и обзоре литературы были упомянуты условия, которые следует учесть при решении задачи. Необходимо разработать ряд требований к системе таких, чтобы можно было получить положительные результаты при работе в этих условиях. Изображение само по себе не нест всю полноту информации о том, каким должен быть конечный HTML-макет. Соответственно, требуется, чтобы в разрабатываемую систему можно было заносить дополнительное знание о требованиях. Существует несколько методологий HTML-врстки адаптивная не адаптивная, bem-методология, bootstrap и т. д.. Более того, как правило, в каждой команде разработчиков существуют внутренние стандарты. Соответственно, от системы требуется умение создавать код в разных стилях и стандартах. HTML-код должен не только быть валидным, но и одинаково восприниматься всеми современными браузерами и операционными системами. Кроме того, необходимо ввести ограничения к входным данным на этапе разработки прототипа. Изображение сайта не должно содержать градиентный тип заливки, элементы анимации, выпадающие элементы элементы, возникающие на странице в результате определнных событий. Данные ограничения вводятся на этапе создания прототипа в целях лучшего решения базовых проблем. В дальнейшем предполагается создание алгоритма, работающего и без этих условий. В основе архитектуры лежит попытка воссоздать процесс составления кода человеком. Базовое утверждение состоит в том, что человек, формализуя визуальную информацию, преимущественно применяет трансдуктивные рассуждения он извлекает из изображения структуры разного уровня абстракции и описывает эти структуры по аналогии со своим или чужим прошлым опытом. В частности, такая ситуация наблюдается при написании html-кода. Встречая незнакомый паттерн располо жения блоков, специалист находит в справочниках и вообще в литературе, как реализовать это на языке html. Далее, с опытом, обращений к справочникам становится вс меньше, но принцип остатся тем же сталкиваясь с очередным шаблоном, он достат из памяти подходящий пример и адаптирует к текущей ситуации. Данный процесс реализуется следующим образом рис. 1 1 из изображения извлекаются все элементы текст, картинки, блоки и т. п. 2 извлечнные элементы собираются в древовидную структуру согласно специальному алгоритму 3 совершается префиксный обход дерева, на каждой итерации которого происходит обращение к базе прецедентов с целью поиска подходящего описания архитектурного паттерна, лежащего в обрабатываемом узле, на языках HTML и CSS 4 полученные на предыдущем шаге артефакты сохраняются в виде требуемых файлов. Шаги 1 и 4 являются инженерными задачами, которые уже имеют решения в общедоступной практике. Шаги 2 и 3 наукомкая часть архитектуры. В разделах Извлечение структуры изображения и Построение CBR-системы приводится разработка теории и алгоритмов, которые были использованы для реализации этих шагов. Цель данного этапа получить так называемую растрового изображения, т. е. математический объект заданного формата, описывающий взаимное расположение частей изображения. Поставленная задача является задачей построения дерева. В данной статье предлагается жадный тип алгоритма решения. На вход алгоритму податся множество узлов, каждый из которых содержит ровно один элемент изображения, упорядоченное по координатам левой верхней точки описанных прямоугольников. Общая идея заключается в последовательной обработке элементов данного множества и попытке на каждой итерации объединить обрабатываемый элемент со следующим в определнный узел рис. 2. При объединении элементов в узлы мощность множества будет сокращаться. Алгоритм завершит работу, когда во множестве останется ровно один элемент именно этот элемент, представляющий собой дерево всех элементов, является решением задачи. Проведм оценку сложности алгоритма по времени и по памяти. Заметим, что алгоритм не использует дополнительную память, т. е. не зависит от количества элементов в множестве. Соответственно, оценка по памяти равна 1 . С оценкой по времени ситуация сложнее. В зависимости от расположения элементов, алгоритм может обладать совершенно разной сложностью. В лучшем случае изображение состоит из ряда элементов, расположенных в линию, горизонтальную или вертикальную. Тогда алгоритму достаточно пройти один раз по множеству и объединить их все в один определнный узел. Оценка сложности по времени в этом случае линейная . К сожалению, такой случай почти не встречается на практике только, быть может, в очень узких задачах. Чтобы оценить худший случай, проанализируем, как собирается дерево. При каждом проходе элементов см. рис. 2, цикл на строке 2 собираются узлы, которые в конечном дереве будут лежать на одном уровне. При этом каждый такой проход в худшем случае оценивается как . Соответственно, оценка сложности всего алгоритма равна, где высота дерева. Наихудшая высота дерева равна количеству элементов на каждом проходе цикла получается максимум один узел. Получаем как оценку времени выполнения алгоритма в худшем случае. Хорошая новость состоит в том, что таких примеров на практике хоть и больше, чем наилучших случаев, но вс же не так много. В среднем ожидается, что на каждой итерации цикла см. рис. 2, строка 2 количество элементов будет логарифмически сокращаться, поэтому среднюю сложность можно оценить как log . Для более точных данных об истинном распределении наилучших, наихудших и прочих случаев, а также справедливости приведнных в данном параграфе формул необходимо провести дополнительные эксперименты и исследования. Рассуждения на основе прецедентов CBR, case based reasoning одно из успешных направлений развития искусственного интеллекта. Будучи изобретнным в конце 70-х гг. XX века, case-based reasoning использовался в разработке многих интеллектуальных систем. Работы Шэнка и Абельсона 1977 г. 11 считаются истоками рассуждений на основе прецедентов. Роджер Шенк предложил следующую концепцию наше знание о мире организовано в виде пакетов памяти, хранящих эпизоды жизни. Такие пакеты MOPs memory organizations packets и их элементы не изолированы, а пересекаются с нашими ожиданиями развития событий сценариями. В свою очередь, MOPs образуют иерархию, где более общие пакеты объединяют более специфичные. Если MOP содержит ситуацию, в которой некоторая проблема была успешно решена, и человек находит себя в подобной ситуации, то он стремится использовать предыдущий опыт, чтобы найти решение. Таким образом, вместо следования общему набору правил происходит повторное применение схемы решения в новых, но схожих условиях. В 1990-х гг. было написано большое количество научных работ, посвящнных этому направлению 1217. Тем не менее в 2000-х гг. популярность CBR стала падать вследствие вытеснения другими подходами. Несмотря на это, рассуждения на основе прецедентов остаются достаточно эффективной методологией, которую до сих пор используют в самых разных предметных областях. Кратко описывая суть рассуждений на основе прецедентов, можно сказать, что это способ решения проблем путм адаптации решения схожих проблем в прошлом к текущей ситуации. Процесс нахождения такого решения называется CBR-циклом и состоит из 4 фаз 14. 5 Из хранилища прецедентов извлекается прецедент с проблемой, наиболее похожей на ту проблему, которую нужно решить. 6 Решение извлечнного прецедента адаптируется так, чтобы решить исходную проблему. 7 Полученное решение оценивается если оно не удовлетворяет заданным критериям, то либо извлекаются дополнительные прецеденты и снова происходит попытка адаптации, либо процедура завершается с неудачным результатом. 8 Прецедент с полученным решением сохраняется в хранилище прецедентов. Более подробно остановимся на представлении прецедентов. В CBR прецедент это тройка элементов проблема состояние мира предметной области, при котором возникает прецедент, решение приемлемый в данном контексте ответ для проблемы, результат состояние мира предметной области после применения решения. Как было сказано в предыдущем разделе, чтобы построить CBR-систему, необходимо определить следующие вещи формат прецедента, меру сходства, процедуру адаптации, словарь, а также реализацию 4 шагов CBR-цикла. В разделе Архитектура сказано, что генерация кода производится путм префиксного обхода дерева структуры изображения. На каждом этапе этого обхода запускается CBRцикл. Требуется определить, что является проблемой, решением и результатом в контексте решаемой задачи. Иными словами, описать структуру прецедента. набор свойств обрабатываемого узла и свойств его прямых потомков. шаблоны htmlи css-кода, реализующие врстку описываемой структуры. htmlcss-код, сгенерированный из решения-шаблона применительно к конкретному случаю. Так, при обработке каждого узла дерева формируется проблема описание текущего элемента структуры изображения вместе с описанием структуры изображения на один уровень детализации глубже. В хранилище лежат прецеденты, проблемы которых представляют собой типовые случаи расположения элементов, а решения типовые варианты их врстки. Задача CBR-цикла используя хранимые решения, получить htmlcss-код для реализации текущей структуры. Опишем этот цикл подробнее. Для условных обозначений назовм обрабатываемый прецедент общепринятым термином . Дальнейшие термины будем вводить по мере их появления. . содержит проблему, но не имеет решения и результата. Задача данного этапа извлечь из хранилища прецеденты, максимально близкие по проблеме к . В общем случае имеем задачу -классовой классификации, где количество прецедентов в хранилище. На этапе построения концепции выберем в качестве решения метод ближайших соседей с евклидовой мерой расстояния. Для этого векторизуем и нормализуем проблемы. Это означает, что, во-первых, все категориальные признаки приведм к числовому виду во-вторых, заменим абсолютные значения относительными по формуле . Далее, вычисляем расстояния между текущим вектором и векторами прецедентов в хранилище, и выбираем прецедент, расстояние до которого оказалось минимальным. В терминах CBR такой прецедент называется . . Шаг адаптации реализуется алгоритмом, принимающим на вход проблему прецедента и решение, а отдающим на выход результат. Прецедент, составленный из проблемы прецедента, решения прецедента и результата, полученного на шаге адаптации, называется, а само решение называется . В текущем исследовании предлагается деривационный тип адаптации, т. е. перегенерация старого решения в новых условиях. Так как решение прецедента это шаблон кода, то результат получается путм применения выбранного языка шаблонизации. Трудность заключается в том, что результаты разных прецедентов в ходе обработки структуры могут конфликтовать друг с другом. Особенно это касается конфликтов в css-коде ситуации, когда различные результаты описывают по-разному один и тот же css-класс. Поэтому на этапе адаптации важным является процесс разрешения конфликтов. . В классическом подходе CBR этап оценки служит валидацией полученного результата. Прецедент, который положительно прошл данный этап, называется, а его решение . Что касается текущей работы, задача оценки качества htmlcss-кода заслуживает отдельного исследования. На этапе проверки концепции данный шаг опускается, а проверка полученного решения осуществляется для всего документа целиком, а не на каждой итерации CBR-цикла, как предлагается в методологии. . Последний шаг цикла призван сохранить подтвержднное решение в базе, для того чтобы использовать его в будущем для решения схожих проблем. В текущей работе этот шаг несколько отличается от классического подхода. В отличие от использования одного хранилища прецедентов разрабатываемая CBR-система поддерживает глобальное хранилище и несколько локальных хранилищ см. таблицу. Первый тип это база прецедентов, используемая по умолчанию для всех изображений. Второй база прецедентов, используемая только в рамках обработки одного документа. Можно сказать, что локальное хранилище это контекст документа оно содержит результаты решнных проблем в ходе его обработки. Отличия локального и глобального хранилищ Хранится в оперативной памяти Хранится во внешней памяти Уничтожается после обработки документа Существует независимо от обработки документа Заполняется в процессе обработки документа Заполняется специальной процедурой до обработки документа Прецеденты имеют приоритет при извлечении Смысл состоит в том, что на этапе сохранения решнный прецедент всегда записывается только в локальное хранилище. При этом на этапе извлечения поиск происходит во всех базах, но преимущество есть у прецедентов в локальном хранилище. Другими словами, глобальное хранилище служит источником прецедентов, имеющих решения генерации кода типичных примеров расположения элементов. Далее локальное хранилище используется для точной и быстрой адаптации этих решений в контексте конкретного документа. Компьютерная система, реализующая описанный выше подход, была протестирована на множестве изображений существующих сайтов. Такой вид тестирования позволил оценить, насколько близко к человеческому решению получает результат построенный алгоритм. В качестве примера рассмотрим одну из страниц сайта Новосибирского Государственного Университета. В результате выполнения первого этапа обработки изображения были выделены элементы и сгруппированы в узлы рис. 3. Далее, описанный выше алгоритм сформировал из полученных узлов древовидную структуру рис. 4. Полученный результат имеет достаточно хорошее качество рис. 5. Несмотря на некоторые ошибки не был выбран подходящий шрифт, не подгружены некоторые изображения, небольшие ошибки в размерах, система справилась с самой главной задачей воссоздала структуру элементов и сгенерировала легко поддерживаемый человеком код. Из данного примера видно, что прототип системы удовлетворяет поставленным требованиям. В общем, учитывая эксперименты на других изображениях, можно утверждать, что средняя точность работы системы составляет 87 . Также стоит заметить, что увеличение структурной сложности добавление колонок, резиновой ширины ожидаемо снижает результаты. Эти выводы полезны для определения следующих направлений развития. Помимо количественных требований, в постановке задачи были выдвинуты три условия, в которых система должна эффективно функционировать 1 наличие не формализуемых требований к макету, 2 вариативность корпоративных стандартов написания кода, 3 требование к кроссбраузерности и кроссплатформенности. Выполнение всех этих условий учитывается в системе за счт вариативности заполнения хранилища прецедентов. Действительно, помимо автоматического получения множества прецедентов, есть возможность создавать их с помощью экспертов. В этом случае в решенияхшаблонах будет находиться экспертный опыт и дополнительное знание. А производя замену хранилищ, каждое из которых специфицировано для разных стилей и стандартов, можно получать заданный результат в разном исполнении. Следующими шагами в развитии разработанной концепции являются 1 разработка процедуры автоматического заполнения хранилища прецедентов 2 сбор тренировочного набора реальных примеров изображений и проведение экспериментов на этом наборе 3 разработка наилучшей меры близости прецедентов 4 разработка этапа оценки в CBR-цикле. Таким образом, получен прототип интеллектуальной системы, эффективность которой доказана экспериментально. Предлагаемый подход является перспективным решением многих практических проблем в web-разработке. Важно и то, что разработанная теоретическая модель распознавания структур изображений может быть обобщена и использована в других вопросах компьютерного зрения. "}
{"title": "АЛГОРИТМ ПРЕДОБРАБОТКИ СИГНАЛА   ИМПУЛЬСНОГО НЕЙТРОННОГО ГАММА-КАРОТАЖА   С УЧЕТОМ СТАТИСТИЧЕСКОЙ ЗАВИСИМОСТИ СОСЕДНИХ ЭЛЕМЕНТОВ СПЕКТРА  ", "absract": "На фоне множества методов проведения геофизических исследований выделяется и является одним из перспективных, за счет возможности определения состава горных пород, импульсный нейтронный гамма-ка ротаж. Однако существуют сложности при интерпретации результатов такого исследования. Полученные после предварительной обработки сигнала, записанного в процессе импульсного нейтронного гамма-каротажа, спектры гамма-излучения зашумлены и обладают высокой флуктуацией, что влияет на качественную оценку результатов исследования. Качественная оценка наряду с автоматической важна при работе с каротажными данными. Она позволяет предотвратить передачу заведомо ложных результатов, а также работу неисправных приборов. В данной статье рассмотрен алгоритм, позволяющий уменьшить флуктуацию с учетом статистической зависимости соседних элементов спектра, для улучшения качественной оценки результатов исследования. Так как спектры сигнала являются случайными величинами, в ходе рассмотрения различных способов обработки спектров решено применять функции сглаживания, а именно B-сплайн. В процессе применения различных вариаций параметров B-сплайна к спектрам гамма-излучения оказалось, что квадратичный однородный  B-сплайн с интервалом узлов 7 показал лучшие результаты в достижении цели улучшения качественной оценки. Таким образом, разработан алгоритм дополнительной предобработки, уменьшающий флуктуацию спектров гамма-излучения, для улучшения качественной оценки результатов такого геофизического исследования, как импульсный нейтронный гамма-каротаж. ", "text": " Импульсный нейтронный гамма-каротаж ИНГК привлекает к себе особое внимание ввиду уникальной возможности определения химического состава горных пород 1. ИНГК это радиоактивный метод проведения каротажа, при котором при помощи генератора нейтронов происходит кратковременное импульсное облучение горных пород потоком быстрых нейтронов, следующее через одинаковые промежутки времени . Выпущенные генератором быстрые нейтроны взаимодействуют с околоскважинным пространством, содержащим химические элементы замедлители и поглотители. В ходе столкновений или поглощений нейтронов ядра атомов в процессе ядерной реакции испускают гамма-излучение гамма-кванты, которое впоследствии и регистрируется датчиками пробора ИНГК рис. 1. Метод ИНГК предназначен для определения химического состава околоскважинного пространства и пространственно-временных характеристик полученного в ходе ядерных реакций гамма-излу чения 2 3. Несмотря на привлекательность данного метода, существуют сложности качественной оценки зарегистрированных данных, а скорость проведения исследований для решения прикладных задач ограничена. Чем ниже скорость спускоподъемных работ, тем меньше флуктуация в зарегистрированных данных энергетических спектров гамма-квантов. Рекомендуемая скорость каротажа в открытом стволе скважины составляет 4050 мч, что сопоставимо со скоростью бурения и является самым медленным методом геофизического исследования скважин. Однако даже при такой низкой скорости метод не дает необходимого качества отображения зарегистрированных данных для качественной оценки. В силу того что полученные спектры данных зашумлены и обладают достаточно высокой флуктуацией, их качественная оценка затруднена. В данной работе будет рассмотрен алгоритм, позволяющий уменьшить флуктуацию и улучшить возможность качественной оценки зарегистрированных данных ИНГК. Рассмотрим результаты измерения, полученные методом ИНГК, подробнее. Как говорилось ранее, при облучении горных пород быстрыми нейтронами происходят ядерные реакции, при которых быстрые нейтроны передают часть своей энергии ядрам атомов химических элементов, из которых состоит околоскважинное пространство. В процессе упругого и неупругого рассеяния энергии быстрых нейтронов замедляются до энергии тепловых нейтронов 0,025 эВ 4. В результате первых взаимодействий нейтронов с ядрами атомов химических элементов, наиболее вероятно, происходит неупругое рассеяние. При неупругом рассеянии быстрый нейтрон, сталкиваясь с ядром атома, временно им поглощается. Во время поглощения ядро, получив некоторое количество энергии от нейтрона, переходит в возбужденное состояние. Затем нейтрон переиспускается из возбужденного ядра, замедляясь до энергии ниже 1 МэВ, что происходит за 10 10 с 1. Возбужденное ядро, чтобы выйти из возбужденного состояния, за 10 с производит вторичное гамма-излучение испускает гамма-кванты 4. Этот процесс называется ГИНР. Дальнейшее замедление нейтронов происходит при упругом рассеянии. Быстрый нейтрон, сталкиваясь с ядром атома, передает ему часть первоначальной энергии, а сам меняет направление отклоняется и продолжает движение уже с меньшей энергией. Энергия нейтрона передается ядру в виде кинетической энергии из-за чего ядро, с которым произошло взаимодействие, начинает движение. Такое замедление быстрых нейтронов происходит до уменьшения их энергии до энергии тепловых нейтронов, которая наблюдается примерно 10 10 с 1. Упругое рассеяние не сопровождается гамма-излучением. После того как нейтроны замедлились и стали тепловыми, происходят реакции радиа ционного захвата. Такие нейтроны при взаимодействии с ядрами поглощаются. В результате поглощения ядро получает всю энергию от нейтрона и переходит в возбужденное состояние. Чтобы выйти из этого состояния, возбужденное ядро за 10 с производит вторичное гаммаизлучение испускает гамма-кванты 4. Этот процесс называется ГИРЗ. В первые микросекунды измерения происходит регистрация упругих и неупругих взаимодействий, т. е. спектра ГИНР. Далее возникает всплеск излечения гамма-квантов, спектров ГИНР. Так как жизнь тепловых нейтронов в типичных нефтегазовых скважинах колеблется от 100 до 500 мкс 4, спектры ГИНР и ГИРЗ включая спектры от предыдущих всплесков накладываются друг на друга на время, пока живут тепловые нейтроны рис. 2. Прибор ИНГК регистрирует энергии ГИНР и ГИРЗ, которые впоследствии оцифровываются. Таким образом, результатами измерений метода ИНГК являются массивы спектров гамма-квантов, состоящие из значений скоростей счета, соответствующих различным энергетическим окнам, энергия в которых варьируется от 0 до 10 МэВ 4. это интервалы энергий, возникающие после оцифровки данных. В нашем случае оцифровка образовала 1 024 интервала, следовательно, интервалы энергий составляют 0,0098 МэВ. По полученным спектрам ГИРЗ и ГИНР можно определить такие основные породообразующие химические элементы, как углерод C, кислород O, кальций Ca, кремний Si, железо Fe, водород H и др. Энергетические характеристики ГИНР и ГИРЗ для основных породообразующих химических элементов представлены в таблице. Основные породообразующие химические элементы и их характеристики ГИНР и ГИРЗ 6 The main rock-forming chemical elements and their characteristics Gamma Ray Inelastic Scattering GRIS and Gamma Ray Neutron Capture GRNC 4 Элемент Среднее содержание в горных породах, Энергия, МэВ ГИНР ГИРЗ C 0.02298 4.43 4.95, 3.68, 1.26 O 46.89 6.13, 7.12 2.18, 1.09, 3.27 Ca 2.87 3.73, 3.90 1.94, 6.42, 4.42 Si 28.54 1.78, 2.84 3.54, 4.93, 1.27 Fe 4.26 1.24, 2.61 7.63, 7.65, 5.9 Н 0.99985 2.23 Для анализа были взяты данные спектров вторичных гамма-квантов, зарегистрированных во время стоянки на глубине 2963,078 м на месторождении в регионе Среднего Поволжья модулем ИНГК, разработанным во ФГУП ВНИИА, входящем в состав автономного комплекса СКЛ-А-102, созданного в НПП ГА Луч . Во время стоянки было произведено 56 измерений 56 спектров по 1024 значения в каждом. Для анализа было решено взять данные ГИРЗ, поскольку порядок счета их меньше, и, следовательно, флуктуация измерений выше. Все входные данные, полученные после оцифровки, являются целыми и неотрицательными. В ходе первоначального анализа входных данных на основании распределения хи-квад рат 5 было установлено, что значения спектров в энергетических окнах практически всех измерений, соответствуют нормальному распределению. Иначе говоря, каждое значение спектра является случайной величиной. Таким образом, далее каждый спектр будем называть экспериментом, а среднеарифметическое по всем 56-ти спектрам математическим ожиданием. При интерпретации данные представляются в виде графика отношения количества гаммаквантов логарифмическая шкала измерения к индексу энергетического окна от 0 до 1 023. График 20-го эксперимента, измеренного во время стоянки на глубине 2963,078 м, представлен на рис. 3. Далее, в данной статье будет рассмотрен метод, использующий построение B-сплайна для предобработки спектров ГИРЗ, зарегистрированных аппаратурой ИНГК, учитывающий статистические зависимости соседних значений спектров. График полученных значений весов для спектров стоянки на глубине 2963,078 м представлен на рис. 4. Рассмотрены два типа узлов автоматически рассчитанные применяемой функцией interpolate.splrep для языка Python неравноудаленные узлы и наборы вручную рассчитанных равноудаленных узлов с шагом от 2 до 10. Вначале был построен неоднородный узлы не равноудалены друг от друга B-сплайн с автоматически рассчитанными узлами рис. 5. Затем составлены массивы однородных узлов и рассчитаны сами B-сплайны по всем наборам узлов. После этого необходимо было определить, при каком наборе узлов для конкретных экспериментальных данных полученный B-сплайн в большей мере соответствует требуемому результату, а именно имеет наименьшую флуктуацию. Для определения степени флуктуации производилось сравнение результатов построения B-сплайнов с разными наборами узлов с математическим ожиданием. Для расчетов использовалась формула fl, 1 где значение, соответствующее -му энергетическому окну математического ожидания значение, соответствующее -му энергетическому окну аппроксимированной функции с одним из равномерных наборов узлов номер энергетического окна от 1 до 1 024 количество значений. В расчетах не учитывались значения энергетических окон с 1 по 50 и с 800 по 1 024. В энергетических окнах с 1 по 50 имеется быстро растущий пик значений, сильно влияющий на среднее значение по всем измерениям, что, в свою очередь, влияет на определение флуктуации. Кроме того, в связи с величиной значений данные измерения не нуждаются в предобработке для корректной интерпретации. В энергетических окнах с 800 по 1 024 значения варьируются в среднем в интервале от 0 до 2 и не несут при этом необходимой смысловой нагрузки. Таким образом, флуктуация определялась в интервале энергетических окон с 50 по 800. В процессе применения формулы 1 строилась таблица, данные из которой приведены на рис. 6, в которой отображалась степень флуктуации при различных типах и шагах узлов. В результате оказалось, что при применении к спектрам ГИРЗ интерполяции однородным B-сплайном с шагом узлов 7 возникает минимальная флуктуация. Результат сравнения применения однородного B-сплайна с шагом узлов 7 и применения неоднородного B-сплайна с автоматически рассчитанными узлами к экспериментальным данным можно увидеть на рис. 7. Кроме того, на рис. 7 можно заметить, что по сравнению с исходными полученные после обработки спектры лучше поддаются качественной обработке, и мы можем с большей уверенностью выделить пики, соответствующие определенным химическим элементам. Неоднозначность качественной оценки спектров ИНГК усложняет работу данным методом. Автоматический метод оценки и обработки данных, в свою очередь, является несвоевременным, так как данная информация может повлиять на текущий процесс бурения и не всегда оказывается точной. При помощи алгоритма предобработки сигнала ИНГК, позволяющего минимизировать флуктуацию, качественная оценка интерпретатора данных для определения минерального состава горных пород станет более однозначной и информативной. В настоящее время рассмотрен и применен к экспериментальным данным, зарегистрированным во время стоянки на глубине 2963,078 м на месторождении в регионе Среднего Поволжья модулем ИНГК, разработанным во ФГУП ВНИИА, входящем в состав автономного комплекса СКЛ-А-102, созданного в НПП ГА Луч, метод построения сглаживающего квадратичного однородного B-сплайна с шагом узлов 7, который показал положительные результаты в достижении цели уменьшения флуктуации и позволил улучшить метод предобработки спектральных сигналов. Для первичного анализа и определения подходящего метода и его параметров предобработки данных использовался язык программирования Python, для работы со сплайнами библиотека scipy.interpolate для языка Python. В дальнейшем планируется оформить данный алгоритм предобработки данных ИНГК в виде встраиваемого программного модуля в программный комплекс RealDepth5 6, разрабатываемый в ИНГГ СО РАН совместно с НПП ГА Луч. После внедрения модуля будут произведены испытания в полевых условиях. Также планируется расширить возможности алгоритма для применения его к спектрам импульсного нейтрон-нейтронного каротажа. "}
{"title": "ЭЛЕКТРОМАГНИТНОЕ ПРОФИЛИРОВАНИЕ КОМПАКТНОЙ АППАРАТУРОЙ:  НОВЫЙ ПОДХОД И РЕЗУЛЬТАТЫ ПРИМЕНЕНИЯ      ", "absract": "Современные портативные приборы для электромагнитного профилирования и малоглубинного зондирования позволяют изучать распределение удельного электрического сопротивления грунта. К типичным сферам применения подобных комплексов можно отнести: исследование археологических объектов – курганы, древние поселения; решение экологических задач – изучение отвалов и хвостохранилищ горнодобывающих предприятий, зон распространения вредных веществ; локализация инженерных объектов – труб и коммуникаций, исследование состояния дамб и плотин. Перспективной сферой являются объекты агропромышленного комплекса – оценка плодородности почв (распределение минерализации), контроль эффективности мелиорации. Целью проводимых исследований является разработка и создание переносного программно-аппаратурного комплекса электромагнитного профилирования, позволяющего с высокой достоверностью и точностью обнаруживать и дифференцировать по удельному электрическому сопротивлению объекты различного рода. На основании оригинального принципа компенсации первичного поля генераторной катушки была разработана компактная многочастотная аппаратура для электромагнитного профилирования. В результате прототипирования создана оптимальная конструкция корпуса, позволяющая реализовать данный принцип компенсации. Для эффективного использования аппаратурного комплекса было создано программное обеспечение QZond, позволяющее управлять процессом сбора информации и в режиме реального времени визуализировать полученные данные. Проведенные полевые испытания на известных объектах электрометрического полигона ИНГГ СО РАН, при поиске локальных и протяженных проводников, а также археолого-геофизические исследования показывают эффективность реализации компактной аппаратуры электромагнитного профилирования. : геофизические методы поиска, электромагнитное профилирование, аппаратура, археологические исследования, инженерная геофизика, программное обеспечение.  Исследовательская работа выполнена при частичной финансовой поддержке проекта РФФИ «Комплексные исследования археологических памятников Западной Сибири геофизическими методами: новые полевые технологии и способы интерпретации данных» (№ 17-29-04314). ", "text": "В настоящее время широко известны приборы EM-31 и EM-38 для электромагнитного профилирования канадской фирмы Geonics Ltd, аппаратура EMP-400 американской фирмы GSSI 1. Малоглубинное частотное зондирование и профилирование позволяют выполИз-за сложного процесса настройки патент RU 2 461 850, проблем с ложными аномалиями, характерных для трехкатушечных зондов, потери полезного сигнала при вычитании прямого поля актуальным остался вопрос о нахождении альтернативного метода компенсации поля генератора. В ИНГГ СО РАН запатентован способ компенсации первичного поля генераторной катушки, особым расположением приемных катушек 9. Структура поля магнитного диполя в изотропном пространстве имеет характерную линию, на которой вертикальная компонента напряженности магнитного поля меняет знак рис. 2. Уравнение этой поверхности легко получить из выражения для расчета напряженности поля магнитного диполя в однородном пространстве 3 3 2 2 4, 1 где и цилиндрический и сферический радиусы момент генераторной катушки, представляющий собой произведение тока, площади и количества витков в катушке электропроводность пространства. Из выражения 1 при малых можно найти условие компенсации прямого поля 2, где разнос, разность высот между приемной и генераторной катушками. Это дало предпосылки к созданию прибора, у которого набор приемных катушек расположен в зоне минимального прямого поля см. рис. 2 и на разном удалении от генератора. В такой реализации параметрами зондирования выступают частота генерируемого поля и расстояние между источником и приемником. Разнесение генераторной и приемной катушек по вертикали приводит к однозначному расположению точки привязки сигнала к центру генераторной катушки и существенно уменьшает эффект возникновения нескольких экстремумов сигнала над приповерхностными объектами 10. В результате макетирования и физического моделирования на электрометрическом полигоне ИНГГ СО РАН 7 были выбраны оптимальный разнос и рабочие частоты, которые позволяют обнаруживать большинство мишеней полигона, имитирующих реальные объекты 11. Авторами был разработан и изготовлен прототип компактной трехчастотной аппаратуры электромагнитного профилирования. На рис. 3 приведены различные варианты исполнения новой аппаратуры от первого макета до более современного прототипа . Все они выполнены из листового стеклотекстолита, имеют небольшой вес и компактные размеры. Несмотря на внешние отличия, любой из указанных прототипов в полной мере позволяет реализовать запатентованный способ компенсации прямого поля и за счет жесткого каркаса обеспечивает точное расположение генераторной и приемной катушек относительно друг друга. Генераторная катушка содержит две обмотки, резонансную и накачивающую, диаметр 270 мм, высота намотки 20 мм. Расстояние между генератором и приемником 70 см. Размер приемной катушки 42 мм, высота намотки 10 мм. Управляющие элементы аппаратуры расположены вдоль поверхности с минимальной напряженностью прямого поля генератора, тем самым минимизируется влияние на измеряемые данные. Взаимодействие с аппаратурой осуществляется через беспроводные протоколы Bluetooth и Wi-Fi смартфоном или планшетным компьютером. Для этих целей разработано и реализовано программно-алгоритмическое обеспечение, предназначенное для проектирования системы наблюдений, управления работой и предварительной обработки данных аппаратуры электромагнитных индукционных исследований. QZond рис. 4 представляет собой приложение диалоговой структуры для ОС Android и сочетает следующие возможности подготовка и редакция системы наблюдений управление аппаратурой индукционных исследований сбор данных GPS примника предварительная обработка измеренных данных визуализация в режиме реального времени построение постобработанных карт, разрезов и псевдо трехмерное отображение данных. Программное обеспечение внедрено в пользование и является неотъемлемой частью аппаратурно-программных комплексов отечественного производства ЭМС, Геовизер. Прототип аппаратурно-программного комплекса был испытан на электрометрическом полигоне ИНГГ СО РАН 7. Рисунок 5 демонстрирует результаты площадного профилирования на частоте 28 кГц. На исследованном участке на различной глубине заложены три металлические мишени с различной пространственной ориентацией. Все мишени находятся на глубине не более 1 м, поэтому обусловливают несколько экстремумов в сигнале. Горизонтально ориентированные объекты при исследовании прототипом аппаратуры проявляются в единственной для объекта на глубине 0,8 м либо одной преобладающей аномалии объект на глубине 0,2 м. Вертикально ориентированный объект проявляется в виде нескольких аномалий различного знака. Результаты профилирования над алюминиевыми флягами и металлическими мкостями показаны на рис. 6. Две алюминиевые фляги зарыты на глубине 0,5 и 1 м, расположены на 3-м и 7-м метре соответственно на оси наблюдений. Железные бочки заложены на 12-м и 18-м метре по профилю, на глубинах 1 и 2,5 м соответственно. Несмотря на общий высокий уровень сигнала 5 000 единиц АЦП это шестая часть всего рабочего диапазона, все четыре бочки выделяются на профильной кривой. Однако уровень сигнала от бочек на глубине более 2 м приближается к уровню собственных шумов. Вероятнее всего, необходимо увеличивать отношение сигнал шум в измерительной части аппаратуры. Практические работы по поиску металлических труб большого диаметра до 1 м демонстрируют эффективность применения разработки для решения такого типа задач. На рис. 7 приведены графики зависимости сигнала от расстояния вдоль исследуемых профилей. Профильные кривые показывают наличие хорошо проводящих объектов на 10-м рис. 7, и 16-м рис. 7, метрах по измеряемым профилям, об этом свидетельствует резкое увеличение сигнала. В обоих случаях уровень полезного сигнала позволяет локализовать положение искомых объектов на профилях, что говорит о достаточной чувствительности прибора. К тому же при отсутствии помех постройки, металлический мусор трубы являются высококонтрастной и яркой мишенью. Был проведен ряд экспериментальных измерений над локальными проводящими объектами. На рис. 8 изображена схема эксперимента и заложенные мишени, представлены результаты измерений в виде карт распределения модуля э.д.с., реальной компоненты и фазы сигнала. Наиболее контрастно на всех картах выделяется аномалия, вызванная замкнутой многовитковой катушкой металлоискателя локальные координаты мишени 3 м, 2 м. Металлический лист координаты 4 м, 0,3 м выделяется на картах распределения реальной компоненты и фазы сигнала см. рис. 8, . Аномалия, соответствующая алюминиевому тазу координаты 5 м, 3 м отчетливо выделяется на более низкой частоте 40 кГц, рис. 8, в модуле э.д.с. Наибольшее негативное влияние нецелевых объектов алюминиевый каркас парника слева от исследуемой площадки наблюдается на карте распределения реальной компоненты э.д.с. рис. 8, влияние на фазу сигнала минимально рис. 8, . Что касается археологических задач, то и в этой области аппаратура показывает неплохие результаты. На рис. 9 показаны карты распределения сигнала от среды. Целью работ являлось картирование остатков древних построек. Работы проводились в Сузунском районе Новосибирской области вблизи р. Слезянка. Исследовалась площадка размером 50 44 м. На рис. 9, изображена карта распределения сигнала по данным аппаратуры индукционных исследований ЭМС, пунктирными линиями показаны контуры строений, выделяющиеся визуально в рельефе, как углубления грунта на глубину не более 20 см в самом центре. Видно, что аномалии, обозначенные голубым цветом, неплохо совпадают с этими контурами, следовательно, аномалии соответствуют остаткам древних сооружений. На рис. 9, показан фрагмент карты, полученной по данным разработанной аппаратуры. Видно, что аномалии сигнала, зеленые и голубые цвета на фоне синего, также неплохо совпадают с контурами западин. Следовательно, можно сделать вывод, что аппаратура Геовизер не уступает по своим характеристикам аппаратуре ЭМС, а наблюдаемые в данном случае аномалии более контрастны. На основании оригинального запатентованного в ИНГГ СО РАН принципа компенсации первичного поля генераторной катушки в результате цикла прототипирования разработана компактная многочастотная аппаратура для электромагнитного профилирования. Проведенные полевые испытания на известных объектах электрометрического полигона ИНГГ СО РАН, при поиске локальных и протяженных проводников, а также археолого-геофизические исследования показывают высокую эффективность разработанной аппаратуры. "}
{"title": "ПРИМЕНЕНИЕ МОДЕЛЬНО-ОРИЕНТИРОВАННОГО ПРОЕКТИРОВАНИЯ   К СОЗДАНИЮ АСУ ТП ОПАСНЫХ ПРОМЫШЛЕННЫХ ОБЪЕКТОВ  ", "absract": " Представлена реализация подхода «модельно-ориентированного проектирования» для решения задачи создания автоматизированных систем управления технологическими процессами (АСУ ТП) горнодобывающих предприятий.  Подход «модельно-ориентированного проектирования» заключается в организации контура тестирования,  в котором испытуемый объект функционирует в среде, идентичной реальному процессу по входным сигналам. Подход основан на использовании математических моделей, имитирующих протекание технологического процесса под управлением АСУ ТП. Математические модели используются для формирования наборов тестовых данных.  Разработан имитационный программно-аппаратный комплекс. Основными частями комплекса являются: рабочая станция оператора SCADA, рабочая станция оператора модели, среда передачи данных, блок формирования физических сигналов, блок дублирования физических сигналов и программируемые логические контроллеры АСУ ТП. В качестве среды имитационного моделирования применена система MTSS. Предложен и реализован вариант развития способа Hardware-in-the-loop, обеспечивающего создание совместимых компонентов систем автоматизации.  Приведено описание методики тестирования АСУ ТП. Данная методика успешно применена для разработки, отладки и тестирования АСКУ ТО М (Автоматизированная система контроля и управления технологическим объектом во взрывозащищенном исполнении).  : модельно-ориентированное проектирование, автоматизированная система управления технологическими процессами, промышленные системы управления, тестирование, прикладное программное обеспечение.  Работа выполнена при частичной поддержке РФФИ (проект № 16-07-01179).  О промышленной безопасности опасных производственных объектов // Федеральный закон № 116-ФЗ  от 21.07.1997 (с изм. и доп. от 07.03.2017); Приказ федеральной службы по экологическому, технологическому  и атомному надзору от 19 ноября 2013 г. № 550 «Об утверждении Федеральных норм и правил в области промышленной безопасности «Правила безопасности в угольных шахтах» (с изм. от 8.08.2017)». ", "text": "Создание автоматизированных систем управления технологическими процессами для опасных промышленных объектов требует не только строгого соблюдения стандартов в этой области, но и принятия дополнительных мер со стороны изготовителя для обеспечения повышенной надежности систем . Ошибки, допущенные на этапе проектирования системы и разработки прикладного программного обеспечения, могут приводить на этапах пусконаладки и опытной эксплуатации к увеличению сроков и стоимости ввода системы автоматизации в работу на этапе эксплуатации к возникновению нештатных и аварийных ситуаций. В связи с этим возникает задача проверки надежности прикладного программного обеспечения АСУ ТП на предприятии изготовителе на всех этапах разработки. Это позволяет повысить безотказность системы и, соответственно, безопасность технологического процесса снизить расходы на пуско-наладку и опытно-промышленную эксплуатацию упростить сопровождение, модернизацию и оптимизацию прикладного программного обеспечения. Для тестирования прикладного программного обеспечения на всех этапах создания систем применяют подход МОП модельно-ориентированное проектирование, англ. modelbased design approach, который основан на использовании моделей проектируемой системы и модели контролируемого процесса 1 2. Эти модели являются спецификацией проектируемой системы, которая актуализируется во время выполнения разработки. Данная спецификация позволяет выполнить анализ корректности и возможности выполнения требований посредством моделирования . Применение подхода МОП обеспечивает повышение надежности создаваемых программных, аппаратных и программно-аппаратных систем . Появлению этого подхода предшествовали этапы становления общей теории систем, создание CASE Computer-Aided Software Engineering совокупность средств автоматизации разработки программного обеспечения, разработка языка UML Unified Modeling Language в 1990-х гг., обеспечивающего проектирование систем на разных уровнях абстракций и появление в 2001 г. MDA Model Driven Architecture . Подход МОП основан на применении концепции in-the-loop testing 2. Существуют следующие основные способы тестирования на базе подхода МОП, в которых в качестве объекта тестирования может выступать модель Model-in-the-loop MiL, программное обеспечение Software-in-the-loop SiL, прототип устройства Processor-in-the-loop PiL, готовое устройство Hardware-in-the-loop HiL. В способе HiL используется система целиком или ее компонент данный способ применяется для организации приемочных тестов оборудования. Как правило, подход МОП используется совместно с V-подходом разработки программного обеспечения . Подход МОП получил широкое распространение, особенно в сфере автоматизации, его применяют известные во всем мире компании Ford, Tesla, Festo и др. Также подход МОП или его элементы MiL, SiL, PiL, HiL, отдельно или совместно в разных комбинациях активно применяется исследователями, например, в разработке генератора случайных чисел 3 одновременном применении способов SiL и HiL для разработки программного обеспечения манипуляторов для роботов 4 моделировании канала связи командно-измерительной системы космического аппарата 5 модельно-ориентированном проектировании системы автоматического управления температурой с циркуляцией промежуточного теплоносителя 6 разработке системы управления электроприводом на основе метода модельно-ориентиро ванного программирования 7 быстром прототипировании систем управления как части модельно-ориентированной разработки теплового насоса сушилки 8 управлении встроенной моделью в полунатурном моделировании для индустриальных беспроводных сетей предприятий с применением WirelessHART стандарта 9, разработке сервиса задания сценариев предъявления стимулов с использованием модельно-ориентированного подхода 10 и др. В Институте вычислительных технологий СО РАН ИВТ СО РАН разрабатываются автоматизированные системы управления технологическими процессами для шахт, рудников, объектов нефтегазовой отрасли и др. 11. Функционально системы автоматизации, создаваемые в институте 12 для объектов горнодобывающей отрасли, можно разделить на две части подземную нижний уровень, обеспечивающую контроль, управление и сбор информации от различных технологических объектов шахты, и наземную верхний уровень, выполняющую функции центрального вычислительного комплекса и рабочего места диспетчера. С развитием систем автоматизации в ИВТ СО РАН 1214 на контроллеры АСУ ТП стали возлагаться все более сложные алгоритмические и функциональные задачи. Разработка новой системы автоматизации, в которую планируется включить компоненты, разработанные ранее для других систем или функционирующие на объекте, требует проведения проверки совместимости компонентов в рамках созданной единой системы автоматизации. Интеграция новой системы автоматизации или ее компонентов требует внесения изменений в программное или аппаратное обеспечение существующей АСУ ТП, что во время пуско-наладочных работ на объекте замедляет процесс внедрения этих систем, а также может привести к аварийным ситуациям. В связи с этим на этапе проверки АСУ ТП необходимы не только отладка и тестирование, но и контроль совместимости созданных компонентов системы автоматизации с компонентами других версий и исполнений, функционирующих на действующем объекте. Разработка систем автоматизации требует выполнения тестов и проверок уже на этапе проектирования и разработки элементов системы. Выявленные на этих этапах недочеты и ошибки могут быть исправлены с минимальными дополнительными затратами. Сложность комплексной отладки и тестирования программ управления АСУ ТП заключается в трудоемкости искусственного формирования полного набора согласованных сигналов технологического оборудования. Для разработки, отладки и тестирования прикладного программного обеспечения АСУ ТП применяют такие средства, как программные и физические имитаторы сигналов и интерфейсов. Но более эффективно применять специализированные комплексы, содержащие в своей структуре проблемно-ориентированные математические модели автоматизируемых технологических процессов, обеспечивающих согласованную генерацию сигналов датчиков и управляющих сигналов. Существуют различные специализированные комплексы, например имитационная модель гидроагрегата для тестирования АСУ ТП 15, тренажерно-управляющий программнотехнический комплекс для объектов химической технологии 16, стенд для отладки ПО бортовой авиационной аппаратуры 17, продукт xPC Target Matlab, продукт WinMOD и др. К специализированным комплексам относится и разработка ИВТ СО РАН имитационный программно-аппаратный комплекс для тестирования прикладного программного обеспечения АСУ ТП шахт и рудников 18. Комплекс осуществляет тестирование программ управления прикладного программного обеспечения по принципу замещения реальных сигналов от датчиков существующего технологического оборудования и диспетчерских команд управления на виртуальные сигналы, сформированные на основе моделируемых параметров технологического оборудования. Комплекс имеет двухуровневую структуру, содержащую программный и аппаратный уровни. Внешний вид комплекса изображен на рис. 1. Программный уровень содержит SCADA от англ. Supervisory Control And Data Acquisition диспетчерское управление и сбор данных систему БЛАКАРТ 19, среду имитационного моделирования MTSS 20, менеджер связи, модели технологических процессов, модели технологического оборудования, программы управления АСУ ТП. Аппаратный уровень комплекса содержит рабочую станцию оператора модели, рабочую станцию оператора SCADA, среду передачи данных, блок формирования физических сигналов и оборудование АСУ ТП контроллеры, устройства ввода и вывода сигналов, датчики и т. п.. Блок формирования физических сигналов генерирует на основе модельных данных соответствующие аналоговые или дискретные электрические сигналы. Имитационная модель учитывает особенности предметной области, а именно параметры технологического оборудования и его составных частей насосов, двигателей и т. п., проектные данные о конфигурации технологического оборудования настройки и уставки, набор датчиков и сигналов управления, параметры реальных технологических процессов. Процесс разработки модели технологического оборудования МТО для среды моделирования MTSS заключается в создании концептуальной модели и ее переводе в машинное представление, а именно набор Java классов. В общем виде МТО представлена набором множеств взаимосвязь между ними изображена на рис. 2 MTO SUBM,KTO,KACS,PIC,PORT,PARAM,VAR,M,COM,SIG,MS,I,STAT, где MTO объект, представляющей собой модель технологического оборудования с интегрированным прикладным программным обеспечением АСУ ТП SUBM набор моделей составных частей технологического оборудования например, двигатель, редуктор и гидромуфта приводной станции конвейера и т. п., детализирующий функционирование моделируемого объекта KTO алгоритм функционирования технологического оборудования, представляющий собой конечный автомат, описывающий состояния, в которых МТО может находиться в процессе имитации, KACS конечный автомат программы управления АСУ ТП PIC условное графическое обозначение МТО PORT входные и выходные порты каналы передачи данных, имеющие графическую часть на условном графическом обозначении модели, связывающую данную модель с другими МТО, входящими в имитационную модель системы PARAM параметры моделируемого объекта VAR переменные состояния объекта M математическое описание зависимостей между переменными и параметрами моделируемого объекта COM список команд управления технологическим оборудованием, при выполнении которых МТО переходит из одного состояния в другое, и сигналов управления составными частями технологического оборудования например, двигатель приводной станции конвейера SIG хранилище сигналов датчиков и команд управления MS модели аналоговых датчиков, выполняющие функцию преобразования модельных сигналов к сигналам датчиков I интерфейсная часть, обеспечивающая взаимодействие между МТО и интерфейсной частью комплекса, где выполняется формирование цифровых тестовых сигналов в соответствии с конфигурацией АСУ ТП STAT интерфейс сбора статистики о функционировании МТО. Значения сигналов датчиков формируются в процессе взаимодействия блоков конечных автоматов, описывающих алгоритмы функционирования технологического оборудования и АСУ ТП, и математического описания взаимосвязей между параметрами и переменными. Физические сигналы формируются алгоритмом интерфейсной части МТО, обеспечивающим сопряжение между моделью и преобразователями блока формирования физических сигналов. Этот алгоритм преобразует виртуальное значение переменной например, скорость конвейерной ленты из физической величины в кодовое значение, нормированное в диапазон значений датчика. Нормированное значение впоследствии преобразуется соответствующим преобразователем в физический сигнал, поступающий на вход тестируемой АСУ ТП. Основная задача имитационного программно-аппаратного комплекса это создание среды функционирования контроллеров полностью идентичной реальной по внешним сигналам. Это достигается путем замены сигналов датчиков технологического оборудования на физические аналоги, численные значения которых формируются имитационной моделью. Тестирование осуществляется подачей последовательности сигналов с заданными порядком, временными задержками, длительностями и амплитудами. Тестовую последовательность можно формализовать выражением, где -я тестовая последовательность сигналов -е множество состояний сигналов датчиков -е множество команд управления длительность -го состояния порядковый номер тестового набора данных, в котором 0... количество тестовых наборов данных набор сигналов, задающий начальное состояние системы, на боры сигналов, приводящие систему к тестовому состоянию, набор сигналов на входе системы, находящейся в тестовом состоянии. Адекватность сгенерированной тестовой последовательности сигналов обусловливается точностью формирования этого набора сигналов и его временных параметров. Точность формирования сигналов определяется погрешностью вычисления виртуальных сигналов, преобразованием значений виртуальных сигналов в код, преобразованием кода в реальный сигнал в соответствующем блоке формирования физических сигналов и влиянием схемы коммутации комплекса и контроллера АСУ ТП. Применительно к токовому сигналу 020 мА, относительная погрешность генерации тестового сигнала составила не более 2 . Точность задания временных параметров важна с точки зрения выполняемых проверок АСУ ТП, которые в рассматриваемой предметной области сводятся к контролю пороговых значений например, для параметра время разгона конвейера необходимо задавать значения задержки меньше и больше уставки. Описанный выше комплекс применяется в ИВТ СО РАН при тестировании прикладного программного обеспечения систем автоматизации угольных шахт. На созданном комплексе поставленная в статье задача была решена путем модификации способа HiL. Способ HiL заключается в автономном тестировании оборудования АСУ ТП сигналами, числовые значения которых формируются с использованием математической модели, а преобразование модельных сигналов в физические осуществляется соответствующими преобразователями 21. Способ модифицирован таким образом, что для тестирования контроллера наряду с математической моделью используется параллельно подключенный контроллер другой версии или модели. Это позволяет выполнить проверку и добиться идентичного функционирования тестируемого и эталонного контроллеров на одних и тех же входных сигналах и командах управления. На рис. 3 приведена схема усовершенствованного имитационного программноаппаратного комплекса. Модель системы генерирует виртуальные сигналы, которые поступают в блок формирования физических сигналов по интерфейсу RS-485 в формате строкового протокола. Блок, в свою очередь, формирует электрические аналоги сигналов датчиков и преобразует в цифровую форму сигналы управления тестируемого оборудования. Модуль дублирования физических сигналов обеспечивает дублирование сигналов аналоговых и дискретных датчиков. После чего сигналы датчиков синхронно подаются в Контроллер 1 тестируемый и Контроллер 2 эталонный. Управляющие команды верхнего уровня АСУ ТП передаются в контроллеры через интерфейс RS-485 по протоколу Modbus. Преобразованные в цифровую форму сигналы управления передаются в модель системы, где в специализированном модуле осуществляется сравнение сигналов от Контроллера 1 и Контроллера 2, который в данном случае играет роль эталонного. Модель технологического процесса интерпретирует сигналы управления, полученные от тестируемого контроллера Контроллер 1. В отличие от классической реализации HiL в данной схеме добавлены модули дублирования физических сигналов и модуль сравнения управляющих воздействий, формируемых тестируемым и эталонным контроллерами. Анализ идентичности функциональных возможностей контроллеров состоит из следующих шагов запуск имитационной модели, генерирующей управляющие команды для контроллеров и сигналы датчиков формирование управляющих сигналов, которые поступают непосредственно в контроллеры, и сигналов датчиков, которые дублируются и после этого поступают в контроллеры сопоставление управляющих сигналов контроллеров в модуле сравнения управляющих воздействий. При идентичных входных воздействиях и различных выходных управляющих сигналах фиксируется ошибочная ситуация. Осуществляется дублирование дискретных кабель-троссовый выключатель, контроль схода ленты, устройство автоматического пожаротушения и т. п. и аналоговых датчик скорости ленты или барабана, датчик температуры, датчик заштыбовки и т. п. сигналов. Реализовано дублирование частотных и токовых сигналов. Проверки при создании АСУ ТП делятся на несколько этапов, соответствующих стадиям проектирования АСУ ТП контроль проектных данных, отладка прототипов программноаппаратных средств на уровне разработчика, первичное тестирование крупномасштабное, приемочное тестирование проверка серийного образца перед выпуском продукции, пусконаладочные работы, опытно-промышленная эксплуатация. Стадии создания АСУ ТП проектирование, разработка, отладка и тестирование включают в себя создание модели функционирования системы автоматизации и модели технологического процесса, выполнение отладки и первичных тестов опытных образцов оборудования. Контроль проектных данных это проверка перед началом разработки прототипа на соответствие описания программно-аппаратных средств требованиям задачи достаточна ли функциональность для выполнения задач автоматизации, корректно ли заданы параметры сигналов, корректно ли сформулированы требования для выполнения первичного и приемочного тестирований и др. Отладка прототипов программно-аппаратных средств на уровне разработчика осуществляется с помощью локальных тестов, нацеленных на проверку корректности алгоритма управления. Первичное тестирование крупномасштабное осуществляется в соответствии с разработанной программой и методикой испытаний. Выявленные ошибки или недочеты устраняются, и проводится повторное испытание. Программа и методика испытаний разработана в соответствии с требованиями нормативных стандартов и учетом условий эксплуатации АСУ ТП. Созданный документ регламентирует содержание тестовых испытаний и содержит следующие основные пункты. 1. Общесистемное тестирование, включающее проверку цепей электропитания, прохождения отдельных сигналов, исправное функционирование информационных линий, корректную работу индикации. 2. Проверка карты регистров протокола MODBUS 22, в том числе корректное отображение данных у диспетчера SCADA. 3. Контроль выполнения команд, заданных локально с пульта контроллера и удаленно со SCADA или модели. 4. Контроль корректной идентификации контроллером состояний дискретных и аналоговых сигналов в каждом режиме работы, формирования соответствующих выходных управляющих сигналов и соответствующей записи состояния контроллера в карту MODBUS. 5. Проверка технологических ситуаций и достижимость состояний контроллера, включающая контроль типовых ситуаций например, пуск и останов конвейера, контроль уставок контроллера затянувшиеся разгон и торможение, пробуксовка, минимальная и максимальная скорости и др., подача нештатных например, сброс датчиков контроля двигателя и тормоза, разрешающего сигнала от предыдущего конвейера и др. и некорректных сигналов например, при рабочем значении скорости ленты заданы нулевые показания датчика скорости приводного барабана. 6. Проверка циклической подачей тестовых наборов сигналов в разных режимах и состояниях контроллера. 7. Тестирование интерфейса пользователя. 8. Технологический прогон 72 часа. Приемочное тестирование направлено на контрольную проверку серийных изделий перед выпуском продукции, выявление сбоев программного обеспечения, вызванных причинами, не зависящими от разработчиков. Такие тесты в рамках текущей работы выполняются по сокращенной программе, содержащей пункты 1, 3, 4 и 8 разработанной методики. По разработанной программе и методике испытаний проводилось тестирование совместимости созданной системы АСКУ ТО М Автоматизированная система контроля и управления технологическим объектом во взрывозащищенном исполнении и АСКУ ТО 2 Автоматизированная система контроля и управления технологическим оборудованием. В рамках работ по созданию автоматизированной системы конвейерной линии шахты Грамотеинская выявлено более 30 ошибок и замечаний к созданному прикладному программному обеспечению АСУ ТП. Выявленные ошибки в прикладном программном обеспечении исправлены до начала пуско-наладочных работ на объекте. Подход МОП получил широкое распространение, особенно в сфере автоматизации. Наиболее часто он применяется для узкоспециализированных задач, таких как стендовые испытания, верификация программного обеспечения, проектирование алгоритмов и др. Применение совокупности классических способов разработки, отладки и тестирования MiL, SiL, PiL и HiL подхода МОП наиболее эффективно для крупномасштабных систем. Такой вариант комплексного применения подхода МОП в основном используется крупными предприятиями. Применение подхода МОП позволяет упростить контроль над созданием программноаппаратных систем на протяжении всего жизненного цикла разработки. Это сокращает время выпуска новой продукции, повышает ее качество и безопасность. Предложен вариант развития способа HiL, позволяющий выполнять не только проверку создаваемых систем на наличие ошибок проектирования и разработки, но также обеспечить контроль совместимости компонентов двух разных систем одинакового назначения. Программы тестов, входящих в созданную методику, разработаны с учетом охвата типовых технологических ситуаций при функционировании АСУ ТП, обеспечивая этим полноту тестирования контроллера. Наиболее значительной по влиянию на безопасность АСУ ТП является проверка достижимости состояний контроллера, так как она позволяет выяснить, все ли состояния и переходы между ними заданы корректно. Созданный комплекс с модифицированной структурой применен при разработке и тестировании системы АСКУ ТО М. Контроллеры нового поколения внедрены в состав действующей системы АСКУ ТО 2 и успешно эксплуатируются на шахте Грамотеинская. Применение функции дублирования также позволяет при соответствующем расширении аппаратной части комплекса обеспечить серийное тестирование нескольких контроллеров АСУ ТП, что, в свою очередь, ускорит выполнение приемочных тестов. "}
{"title": "ТЕОРЕТИКО-АЛГОРИТМИЧЕСКАЯ БАЗА   И КОМПЬЮТЕРНОЕ МОДЕЛИРОВАНИЕ ДАННЫХ   ДИЭЛЕКТРИЧЕСКОГО КАРОТАЖА ДЛЯ ИЗУЧЕНИЯ ЧАСТОТНОГО СПЕКТРА   ЭЛЕКТРОФИЗИЧЕСКИХ ПАРАМЕТРОВ ГЕОЛОГИЧЕСКОЙ СРЕДЫ   ", "absract": "  Статья посвящена разработке теоретической базы компьютерного моделирования данных диэлектрического каротажа с целью обоснования нового импортозамещающего оборудования для каротажа нефтяных и газовых скважин. Разработаны алгоритмы и реализованы быстрые программы компьютерного моделирования высокочастотных электромагнитных сигналов в рамках слоисто-однородных моделей сред. По результатам масштабного моделирования амплитудно-фазовых характеристик высокочастотного поля установлена их зависимость от частотного спектра электрофизических параметров. Проведенные исследования позволяют выполнить научное обоснование и оптимальное проектирование новой электромагнитной зондирующей системы. : компьютерное моделирование, прямая задача, геоэлектрическая модель, электрофизические параметры, частотная дисперсия, диэлектрический каротаж.  Исследования выполнены в рамках проекта «Идентификация математических моделей акустики, электродинамики и теории упругости» комплексной программы фундаментальных исследований СО РАН «Междисциплинарные интеграционные исследования». ", "text": "Электромагнитные методы играют важную роль в комплексе геофизических методов исследования геологической среды в поисковых, разведочных и эксплуатационных скважинах. Современной тенденцией в развитии аппаратурно-методического обеспечения электромагнитного каротажа является создание многочастотных, многоэлементных, многокомпонентных зондовых систем. На этом пути уже преодолены многие технические и методические сложности, такие как глубокая компенсация прямого поля, коммутация пространственнонаправленного условия возбуждение прим, оперативная обработка данных, быстрая передача сигналов, в том числе беспроводным способом, и многое другое. Модификация зондирующих установок, а зачастую создание приборов следующего поколения на новой микропроцессорной и элементной базе есть следствие прорыва в информационно-вычисли тельных технологиях, в частности для каротажных исследований. Каротаж на переменном электрическом токе в области высокий частот 20500 МГц называется диэлектрическим каротажем ДК. ДК предназначен для исследования пространственного распределения диэлектрической проницаемости ДП горных пород. Отечественная аппаратура ДК разработана в 6070-е годы прошлого столетия 1. Развитие теоретической и аппаратурной базы связано с волновым 25 и индуктивным 6 ДК, использующими мегаи гигагерцовый диапазоны частот соответственно. Диэлектрический каротаж на предельно высоких частотах в условиях слабопроводящих сред оперирует приближениями лучевого ряда и кинематической картиной волнового поля 711. В настоящее время в компаниях Halliburton и Schlumberger применяется аппаратура волнового ДК. Она успешно используется в различных геологических условиях, где традиционные комплексы геофизических исследований и подходы к интерпретации недостаточно эффективны 1215. Наряду с аппаратурой ДК изучение ДП горных пород проводят по данным электромагнитного каротажа в диапазоне частот от сотен килогерц до единиц мегагерц. При этом основные результаты интерпретации данных ЭМК связывают с выявлением эффекта частотной дисперсии комплексной УЭП, определением ДП для оценки характера насыщения пород-коллекторов и изучением глинистых отложений 1626. В связи с повсеместным вовлечением в изучение новых типов геологических залежей, в том числе с трудноизвлекаемыми запасами, существенно усложняется и расширяется круг задач скважинной геоэлектрики. Это приводит к необходимости создания новых электромагнитных методов исследования геологической среды, разработки новых подходов в решении прямых и обратных задач электродинамики, а также использования новых реалистичных интерпретационных моделей. Текущее развитие теоретико-методической базы электромагнитных зондирований геологических сред связано с вовлечением математического аппарата, учитывающего как сложную геометрическую структуру объектов, так и различные эффекты взаимодействия и распространения электромагнитного поля в горных породах. Чрезвычайно актуальными в последние годы стали задачи геоэлектрики в геологических средах, имеющих высокие значения удельного электрического сопротивления, характерные для флюидонасыщенных карбонатных и высокобитуминозных терригенных коллекторов. В последнее десятилетие наблюдается большой интерес к исследованию механизмов и установлению зависимостей электромагнитных свойств горных пород от возбуждаемого поля на основе измерений в скважинах, лабораторных исследований на образцах керна и математического моделирования 23 2734. Дисперсия электрофизических параметров горных пород наблюдается и при изучении нефтегазовых скважин с применением высокочастотного электромагнитного каротажа. Здесь используется промежуточный диапазон частот от 875 кГц до 14 МГц, где влияние на сигнал оказывает не только диффузионные, но и волновые процессы в среде 1922. Современное состояние и развитие ДК детально проанализировано С. М. Аксельродом 27. Однако в связи со сложной структурой объекта на микрои макромасштабах исследования, а именно его пространственной неоднородностью и контрастностью физических характеристик в областях моделирования, в теории электромагнетизма до настоящего времени не существует единого математически обоснованного подхода к решению этого класса задач. Большие перспективы вовлечения в разработку глубокозалегающих юрских и палеозойских залежей обуславливают настоятельную необходимость опережающего развития геофизических технологий для этих слабо изученных объектов. В настоящей работе выполняется изучение возможностей новых методов электромагнитных зондирований с использованием математического моделирования в реалистичных постановках применительно к изучению новых типов залежей с трудноизвлекаемыми запасами. Для восстановления частотного спектра электрофизических параметров предлагается использовать широкий диапазон частот от 20 до 500 МГц, где влияние как удельного электрического сопротивления УЭС, так и относительной диэлектрической проницаемости ОДП, на измеряемые электромагнитные сигналы значительно. Датчики прибора прижаты к стенке скважины для того, чтобы увеличить чувствительность измеренных данных к параметрам пласта, особенно на высоких частотах и в проводящем буровом растворе, где сигналы быстро затухают. Генераторная и приемные катушки расположены соосно скважине в двух приемных катушках измеряется разность фаз и затухание амплитуды э.д.с. или магнитного поля. Длины зондов составляют от 0,1 до 0,8 м, база трехкатушечного зонда равна 0,2. Длины выбраны исходя из возможности технической реализации и с учетом минимально допустимого уровня э.д.с. в приемных катушках. Данная конструкция допускает следующие упрощения при моделировании источник электромагнитного поля можно считать точечным магнитным диполем, вычисление электромагнитного поля для дальнейшей трансформации в разность фаз и затухание амплитуды можно также производить в точке, характеризующей положение измерительной катушки. Рассмотрим задачу о поле вертикального магнитного диполя в цилиндрически-слоистой среде рис. 1. Диполь находится в первом слое скважине, плотность тока в нем изменяется по закону . Для решения задачи используется метод разделения переменных 35 36. В первом слое с источником электромагнитное поле представляется в виде суммы нормального и аномального поля, . 1 Поля, а также поля в -м слое, подчиняются уравнениям Максвелла, . 2, . 3 Здесь комплексная проводимость, 0,0, магнитный ток, момент диполя, площадь генераторной катушки, число ее витков, функция источника, координата источника, координата приемника, . На границах цилиндрических слоев тангенциальные компоненты электромагнитного поля непрерывны, 0, 0, 2, . 4 Индексом обозначена или -компонента поля. Квадратные скобки в формуле 4 означают скачок функции. Уравнения. 24, а также условия убывания поля на бесконечности и конечности поля на оси скважины однозначно определяют электромагнитное поле в произвольной точке модели среды. Будем искать аномальные поля, предполагая, что нормальные поля, известны. Определим прямое и обратное преобразование Фурье, 1, . 2 5 Из уравнений 3 получаем, что Фурье-трансформации тангенциальных компонент выражаются через Фурье-трансформации вертикальных компонент следующим образом 1, 1, 1, 1, 6, а последние подчиняются уравнениям 1 1 0, 1 1 0. 7 Уравнения 4 преобразуются к виду, 1 1, 1 1 . 8, 2, 0, 0, 1 0, 1 0. 9 Разложим, и, в ряды по угловой координате cos sin, cos sin, cos sin, cos sin . 10 Здесь и далее, cos, sin, cos, sin, 2 cos . Подставляя уравнение 10 в 79, получаем уравнения 1113, определяющие неизвестные функции, угловые гармоники 1 0, 1 0. 11, 1 1, 1 1 . 12 0, 0, 1 0, 1 0, 2, . 13 Решение уравнений 11 есть линейная комбинация модифицированных функций Бесселя 37,Re 0. 14 Используя условия, 0 и, 0, получаем 0 . Оставшиеся коэффициенты, 1, и, 2, 1 могут быть определены из граничных условий 12, 13. Способ определения угловых гармоник для нормального поля, входящих в граничные условия, следующий. Функция источника из уравнения 2 записывается в виде, . К уравнению 2 применяется преобразование Фурье по всем координатам, в результате чего получается алгебраическое уравнение для, в то время как 0 . Выполняя обратное преобразование Фурье по координатам, для полученного выражения для магнитного поля и разлагая в ряд определенное таким образом, имеем, 1, 2, 0 2 0, 0. 15 Учитывая 15, получаем 0, 1, и 0, 2, 1 . Чтобы определить ненулевые коэффициенты, используется уравнение 14, а 12 и 13 представляются в матричной форме, ... 1,2 . 16 0 0 0 0, 17 1 0 1 0 . 1 0 1 0 18, . 1,2 это первый и второй столбцы матрицы . 0, . Множитель учтен в последующем выражении 20. Из уравнений 16 с использованием 17 и 18 определяются неизвестные коэффициенты, а соотношения 10 и 14 дают выражение для Фурье-трансформации магнитного поля в первом слое cos . 19 Применяя обратное преобразование Фурье 5 к и, а также используя четность подынтегральных функций, окончательно имеем cos cos, 1 3 3,Re 0. 2 20 Отметим, что решение задачи об электромагнитном поле, возбуждаемом смещенным с оси скважины магнитным диполем, выполнено в 38. На основе полученного решения разработан вычислительный алгоритм для быстрого моделирования электромагнитных сигналов диэлектрического каротажа и выполнена его программная реализация. Высокая точность вычислений и быстродействие компьютерной программы достигается путем представления полученного решения в виде, сокращающем число вычислительных операций, использования необходимой нормировки, предотвращающей экспоненциальный рост затухание компонентов решения, схем эффективного интегрирования быстро осциллирующих слабозатухающих функций и суммирования медленно сходящихся рядов Фурье. Разработка программы сопровождается оценками точности и обязательным внутренним и внешним тестированием. Компьютерная программа написана на языке программирования Fortran 77 и работает под операционной системой Microsoft Windows. Цель данного исследования выяснить, как ведут себя электромагнитные сигналы в интересующем диапазоне значений электрофизических параметров, установить чувствительность сигналов к изменению параметров, что обеспечит в последующем возможность определения частотного спектра УЭС и ОДП в результате инверсии данных диэлектрического прибора. Для анализа поведения сигналов при изменении УЭС и ОДП выбрана модель среды скважина пласт. УЭС скважины 2 Омм, ОДП 1, радиус 0.108 м. Учитывая конечный размер катушек, при моделировании источник и приемник электромагнитного поля были расположены на расстоянии 1 см от стенки скважины. На рис. 2 приведены зависимости разности фаз и затухания амплитуд от УЭС и ОДП пласта для зонда 0,5 м на частотах 20500 МГц. На низкой частоте 20 МГц рис. 2, преобладает зависимость измеряемых сигналов от сопротивления, чувствительность к диэлектрической проницаемости повышается при увеличении УЭС, особенно для разности фаз. На частоте 100 МГц рис. 2, для сопротивлений меньше 10 Омм разность фаз зависит как от УЭС, так и от ОДП, при увеличении сопротивления зависимость от УЭС практически исчезает, исключая только малые значения ОДП. Для затухания амплитуд зависимость от УЭС и ОДП наблюдается во всем диапазоне параметров, но для высоких значений УЭС и ОДП на фоне небольших отрицательных значений сигнала. Видимые артефакты резкая смена цвета на рисунках, отражающая уровень сигнала связаны с переходом значения э.д.с. через ноль. На высокой частоте 500 МГц рис. 2, зависимость разности фаз от УЭС еще более ослабевает. Затухание амплитуд чувствительно и к УЭС, и к ОДП. В целом на высоких частотах 100500 МГц разность фаз и затухание амплитуд ведут себя качественно по-разному, что видно при сравнении рисунков разность фаз слабо зависит от сопротивления, а для амплитуды сохраняется зависимость от обоих параметров. При уменьшении длины зонда снижается уровень сигнала, а качественное поведение сигналов сохраняется и соответствует описанному выше. Также на высокой частоте количество переходов э.д.с. через ноль сокращается картина распределения уровня сигналов становится более гладкой. При увеличении длины зонда уровень сигналов увеличивается, на высокой частоте количество переходов э.д.с. через ноль возрастает, а основные выводы о поведении сигналов остаются в силе. Так как определение УЭС и ОДП происходит на одной частоте по измеренным разности фаз и затуханию амплитуд в нескольких трехкатушечных зондах, то, возможно, целесообразно иметь больше рабочих частот пять-восемь в диапазоне от 20 до 500 МГц для обеспечения устойчивости подбора электрофизических параметров с использованием сглаживания частотных спектров. Таким образом, в выбранном частотном и геометрическом диапазонах конструктивных параметров прибора существует устойчивая зависимость измеряемых характеристик от электрофизических параметров пласта, пересекаемого скважиной. Разность фаз и затухание амплитуд демонстрируют качественно разное поведение, являясь, таким образом, независимыми измерениями, что важно для надежной инверсии данных диэлектрического зонда. Для развития методов и создания новых приборов электромагнитных зондирований в скважинах выполнена разработка теоретической базы математического моделирования данных диэлектрического каротажа, необходимая для установления возможностей его применения к изучению залежей углеводородов с трудноизвлекаемыми запасами. Разработаны быстрые программно-алгоритмические средства численного моделирования высокочастотных электромагнитных сигналов на основе полученного решения прямой задачи диэлектрического каротажа в рамках слоисто-однородных моделей сред. Масштабное моделирование и сравнительный анализ амплитудно-фазовых характеристик высокочастотного электромагнитного поля позволили установить их устойчивую зависимость от частотного спектра электрофизических параметров в широком диапазоне частот от 20 до 500 МГц. Расчеты показали, что на измеряемые электромагнитные сигналы значительное влияние оказывают и УЭС, и ОДП. Разработанная теоретическая база и всесторонний анализ результатов численного моделирования в дальнейшем позволит выполнить научное обоснование параметров и оптимальное проектирование конфигурации новой электромагнитной зондирующей системы, предназначенной для изучения электрофизических свойств залежей углеводородов с трудноизвлекаемыми запасами. "}
{"title": "ПАРАЛЛЕЛЬНЫЙ АЛГОРИТМ ДЛЯ ЧИСЛЕННОГО МОДЕЛИРОВАНИЯ   ВСТРЕЧНЫХ ПУЧКОВ УЛЬТРАРЕЛЯТИВИСТСКИХ ЧАСТИЦ   С УЧЕТОМ УГЛА ВСТРЕЧИ  ", "absract": "Представлен алгоритм для численного моделирования динамики пучков в суперколлайдерах. При взаимодействии высокоэнергетичных пучков возможна их деформация и разрушение, и изучение устойчивости пучка является актуальной задачей. Рассматривается движение пучков в самосогласованных электромагнитных полях  с учетом угла встречи в полностью трехмерном случае. Задача решается методом частиц-в-ячейках. Распараллеливание по области и по частицам позволяет проводить численные эксперименты с 10 модельных частиц. Приведены результаты моделирования и сравнение с существующим аналитическим решением. : метод частиц-в-ячейках, эффекты встречи, коллайдеры, численное моделирование.  Работа выполнена в рамках государственного задания ИВМиМГ СО РАН (проект 0315-2016-0009). ", "text": "Ускорители на встречных пучках остаются одним из важных инструментов изучения фундаментальной физики. Постоянный интерес к высоким энергиям и светимостям сталкивается с научными и технологическими сложностями. В проекте Международного Линейного Коллайдера International Linear Collider, ILC энергия пучков в системе центра масс достигает 500 ГэВ, а ожидаемые светимости 210 с см 1. Однако критические плотности частиц в пучке приводят к высоким силам отталкивания между частицами пучка и возможному быстрому разрушению пучка, приводящему к понижению светимости. Перераспределение электромагнитных полей может вывести дорогую установку из строя. Угол встречи пучков 225 мрад определяется системой финальная линза вывод пучка, при этом параметры пучка тесно связаны с углом встречи 24. Изучение нелинейной динамики пучков является значимой задачей конструирования коллайдеров и их использования, в то время как их сложность и стоимость являются ограничивающими факторами их создания и проведения численных экспериментов. Численное моделирование может помочь избежать неожиданных проблем и оптимизировать параметры. В работе представлен алгоритм для численного моделирования однопролетного взаимодействия встречных ультрарелятивистских пучков 10 10 при наличии угла встречи. Существующие коды для моделирования динамики пучков основаны на разделении пучков в продольном направлении на слои частиц 5 6. Трехмерная динамика моделируется перестановкой двумерных слоев частиц двумерные поля каждого слоя действуют на частицы слоя встречного пучка с теми же продольными координатами 79. Сведение задачи к двумерной основано на допущении, что коллективное движение частиц происходит вдоль одной оси и является оптимальным для моделирования многопролетных режимов взаимодействия пучков в циклических коллайдерах, где деформации пучков малы на каждом обороте, а различия существенны лишь после тысяч оборотов. В случае резкого разрушения пучков с высокой плотностью и при наличии угла встречи численные эксперименты должны проводиться на основе трехмерной модели алгоритма. Предлагаемый нами алгоритм учитывает трехмерность задачи. Смешанная лагранжево-эйлерова декомпозиция позволяет проводить численные эксперименты для гауссовых пучков с нелинейной фокусировкой. В работе представлены результаты взаимодействия пучков и сравнение с аналитическим решением в докритическом случае. Рассматривается динамика пучков электронов позитронов в лабораторной системе координат. Расчетная область представляет собой параллелепипед, пучки двигаются в вакууме в самосогласованных электромагнитных полях. В модели используется кинетическое уравнение Власова для функции распределения электронов и позитронов и уравнения Максвелла 0 1 4 1 4 0. Здесь 1, есть сила Лоренца. Скорости частиц обозначены как, импульсы, координаты, при этом релятивистские факторы 11, . Уравнения характеристик уравнения Власова совпадают с уравнениями движения, . Плотности токов и заряда вычисляются как моменты функции распределения, . Уравнения автоматически учитывают трехмерность задачи. Начальные и граничные условия также должны ее учитывать. В начальный момент времени задаются координаты 0 и импульсы частиц 0, поле в области определяется как поле пучков, сфокусированных полем коллайдера 0 0 0, 0 0 0 Граничные условия предполагаются открытыми, границы находятся в ближней волновой зоне, и в поперечном направлении эффектом релятивистского запаздывания можно пренебречь. На границах в продольном направлении поля равны нулю в любой момент времени, так как частицы до них не долетают. В качестве безразмерных величин взяты характерная скорость движения частиц пучка скорость света 2.997910 смс и размер пучка 1 см. Время измеряется в единицах, импульсы, силы, поля и, плотности заряда 4 и плотности тока . Для решения уравнений используется метод частиц-в-ячейках со схемой Бориса 11 и схемой Лэнгдона Лазински 12 на сдвинутых сетках 13, . Схемы обладают вторым порядком точности по времени и пространству. Применение алгоритма Бунемана 14 для расчета токов позволяет удовлетворить разностный аналог уравнения неразрывности. В работе рассматриваются пучки с одинаковым распределением, различие состоит в знаке заряда и углах с продольной осью . Плотности заряда невозмущенных пучков определяются фокусировкой квадрупольной линзой, 2 exp 2 2 2 1 exp . 2 2 2 Поперечные размеры пучков с центрами, определяются значениями, где, эмиттансы, значения бетафункции в месте встречи. Поперечные импульсы также имеют гауссово распределение с, пучки моноэнергетические, 1 и . Ось первого пучка направлена под углом к оси в плоскости, . Огибающие пучков определяются значениями, и обозначены соответствующим пучку цветом для 3.5 на рис. 1 эффект песочных часов. Электрическое поле пучка может быть вычислено по формуле для движущегося релятивистского заряда 1, 1 sin где радиус-вектор точки пространства, где вычисляется поле, из местоположения заряда, угол между направлением скорости и 15. Электрическое поле в перпендикулярном движению направлении увеличивается в раз, в продольном направлении сокращается в раз по сравнению с нерелятивистским случаем. Для задания начальных и граничных условий проводится суммирование вкладов полей от элементов плотности заряда с помощью специального вида модельных частиц 16. Для пучков, двигающихся вдоль оси релятивистские факторы 10 10 позволяют суммировать вклады в поле лишь от узлов плотности с той же продольной координатой, так как поле сосредоточено в экваториальной плоскости. Поскольку углы встречи в суперколлайдерах составляют 220 мрад, а соотношение размеров пучков 10 нм 1 мм, то даже хорошее разрешение сетки в продольном направлении 1000 узлов не является достаточным для описания различия в поле с учетом угла встречи и без его учета. Таким образом, электрическое поле пучка, двигающегося под углом к оси, вычисляется также по 16. Начальные и граничные поля для магнитного поля вычисляются по формуле, . Светимость описывает количество актов взаимодействия между частицами в сечении за единицу времени и может быть вычислена как, где кинематический фактор, расстояние до места встречи 17 18. Численно этот интеграл вычисляется суммированием, где 1.5, 1.5, 1.5, а 1 в безразмерных переменных. В общем случае аналитических решений задачи динамики пучков не существует, но для пучков с малыми зарядами взаимодействием частиц можно пренебречь, и светимость может быть вычислена по формуле 19 cos 2, 2 cos 2 cos 2 1 1 1 где cos 2 sin 2 . cos 2 1 Поскольку светимость интегральная величина, то ее можно использовать в качестве теста на качество работы алгоритма при моделировании докритических режимов динамики пучков. Пучок в начальный момент времени находится далеко от места фокусировки, его размеры в поперечном направлении достаточно велики, и расчетная область должна быть соответствующего размера. Размеры в месте встречи определяются малыми величинами, на них должно приходиться не менее 510 узлов сетки. Поэтому для расчетной области большого размера должна использоваться сетка с достаточно большим количеством узлов 20. При этом распределение частиц в пучке существенно неравномерно, за счет эффекта песочных часов в малой области вокруг места встречи может скапливаться более 70 частиц, и вместить все данные частиц в память одного процессора не представляется возможным 21. Точность метода частиц зависит от количества частиц в ячейке, поэтому измельчение сетки должно сопровождаться соответствующим увеличением общего числа частиц. Условная устойчивость схемы Лэнгдона Лазински приводит к необходимости измельчать временной шаг при измельчении минимального пространственного шага. Таким образом, для проведения численных экспериментов с 107 модельными частицами на сетках 803 уже требует ся распараллеливание. Для этого применяется смешанная декомпозиция область делится на подобласти, каждая из которых обрабатывается группой процессоров. Частицы, находящиеся в этой области, распределены равномерно между процессорами группы, число процессоров в группе определяется количеством частиц в области в начальный момент времени. Также допускается ручная настройка, поскольку при критических плотностях пучков неизвестно, как будет деформироваться пучок и где будут находиться частицы. Обмены сеточными значениями полей, плотностей, токов требуют двух вспомогательных узлов для каждой подобласти 22. При пересылках данных частиц выбирается случайный процессор из соседней группы, что позволяет сохранить равномерность распределения частиц внутри групп. Количество модельных частиц определяется количеством используемых процессо ров 2325. Рассмотрим два встречных пучка с 1.6 см, 0.034 см, 2.0310 смрад, 1.1910 смрад, 0.03 см, 6850 в расчетной области размерами 0.005 см, 0.0006 см, 0.4 см, пучки сталкиваются в 2, 2, 2. На рис. 2, показана зависимость увеличения светимости от параметра разрушения . Здесь увеличение светимости сравнивается с ее значением для 10 частиц, учитывает эффект песочных часов, заряд пучков, 10, параметр разрушения определяется как 2 . Для некритических режимов 1 пучки не испытывают возмущений, и светимость совпадает с геометрической. Зависимость демонстрирует падение светимости, что связано с деформацией пучков. На рис. 3. показаны координаты пучков с зарядами при 410, угле встречи 0.08 в момент времени 0.36 нс. Выбор параметров может привести к другим эффектам. Например, при с 0.08 см, 0.034 см, 2.5310 смрад, 1.7910 смрад, 0.03 см, 6850 размеры области 0.001 см, 0.0004 см, L 0.4 см. На рис. 2, представлены зависимости от при 0 синий цвет и 0.0008 красный цвет. Углы встречи снижают устойчивость пучка, выше при лобовом столкновении пучков. Также наблюдается повышение светимости в 4 раза по сравнению с некритическим режимом за счет сильного сжатия пучков. На рис. 1 показаны координаты пучков с малыми зарядами 10, которые отвечают некритическому режиму. На рис. 4 показаны координаты пучков для зарядов с 10 10, 60 в момент времени 0.41 нс. Плотность пучков высока, пучки разрушаются вследствие сильной фокусировки полем встречного пучка, и светимость в этом случае примерно такая же, что и для случая 48. Сравнение светимости может быть сделано для некритических режимов. На рис. 5, для первого случая показано приращение светимости 0 в зависимости от угла встречи для пучков с 10 красные точки и для режима с разрушением пучка 410, синие точки и приращение 0 черная линия, где интеграл 1 был получен численно методом прямоугольников. На рис. 5, аналогично показаны 0 для второго случая с 10 красные точки и с 10 синие точки, а также светимость 0. Для меньших бета-функций угол встречи играет существенную роль в понижении устойчивости пучка. а б В обоих случаях зависимость светимости от угла в некритическом режиме совпадает с теоретически ожидаемой. Для вычислений использовалась сетка с 100 100 100 узлами, 10 модельных частиц, 5610 временных шагов 3.3310 для первого случая и 6210 временных шагов 310 для второго 224 процессорных ядра были распределены между 25 группами, в центральной группе было 136 ядер для первого случая и 104 для второго. В обоих случаях вычисления длились 27 часов. Для меньших сеток, например, 50 50 50 при 10 модельных частиц соответственно более крупный временной шаг был использован, и при вычислениях использовалось 56 ядер в 11 группах, на каждый расчет потребовалось 5 часов. Расчеты проводились на суперкомпьютере Ломоносов МГУ, Москва, Политехник СПбПУ, Санкт-Петербург и кластере ССКЦ ИВМиМГ СО РАН, Новосибирск. Предложен новый параллельный алгоритм для численного моделирования взаимодействия пучков с высокими энергиями в суперколлайдерах. Алгоритм позволяет проводить вычисления для однопролетного взаимодействия пучков в полностью трехмерном ультрарелятивистском случае с учетом угла встречи и эффекта песочных часов, когда возможна сильная нелинейная деформация и разрушение пучков. Алгоритм основан на решении уравнения Власова методом частиц-в-ячейках и уравнений Максвелла. Распараллеливание по области и по частицам позволяет решить проблему неравномерного распределения частиц в пространстве и времени. Представлены результаты численного моделирования и анализ эволюции пучка в трехмерном случае. Результаты демонстрируют качественное совпадение с теоретическими ожиданиями для критических режимов и количественное совпадение для некритических режимов. Таким образом, показана работоспособность и перспективность метода для математического моделирования эффектов взаимодействия пучков при наличии угла встречи. Код может быть использован при исследовании проблем, связанных с устойчивостью пучка и оптимизацией параметров, а также для подготовки студентов соответствующей специальности. "}
{"title": "ПРОГРАММНАЯ СИСТЕМА УПРАВЛЕНИЯ ОБРАЗОВАТЕЛЬНЫМ ПРОЦЕССОМ   ИТОС  ", "absract": "Статья посвящена описанию программной системы ИТОС (индивидуальных траекторий обучения студентов), предназначенной для автоматизации работы с основной образовательной программой (ООП) и соответствующим ей учебным планом. В системе реализована возможность отслеживать логику следования учебных курсов, что позволяет на этапе составления ООП выявлять необходимость перестановки или слияния дисциплин, а также достижимость всех заданных компетенций. Имеется возможность устанавливать взаимосвязь между ООП и различными профессиональными стандартами. В системе реализован алгоритм построения и оценки всевозможных индивидуальных траекторий обучения студента в рамках данной ООП, а также модуль рекомендательной системы, помогающей пользователям (студентам) в выборе индивидуальных траекторий обучения. : основная образовательная программа, профессиональный стандарт, индивидуальная траектория обучения, рекомендательная система.  http://www.tkodeksrf.ru/  https://fzakon.ru/laws/federalnyy-zakon-ot-29.12.2012-n-273-fz/ ", "text": "Научно-технический прогресс, развитие производств и технологий, а также изменяющийся рынок труда требуют постоянного развития профессиональных навыков и компетенций работника. Именно поэтому в настоящее время в Российской Федерации производится пересмотр квалификационных справочников и вводятся новые профессиональные стандарты 1. Профессиональный стандарт это характеристика квалификации, необходимой работнику для осуществления определенного вида профессиональной деятельности ст. 195.1 ТК РФ . Для работодателей профессиональный стандарт будет являться основой для установления более конкретных требований при выполнении трудовой функции работника с учетом специфики деятельности организации. В соответствии с Федеральным законом Об образовании в Российской Федерации ст. 11, п. 7 с целью наиболее полного и качественного удовлетворения потребности рынка труда федеральные государственные образовательные стандарты должны быть сопряжены с соответствующими профессиональными стандартами. Это позволит обеспечить подготовку высококвалифицированных кадров, востребованных на рынке труда и способных качественно выполнять свои функциональные обязанности в соответствии с действующими профессиональными стандартами 2. В связи с этим положения соответствующих профессиональных стандартов должны учитываться при формировании федеральных государственных образовательных стандартов высшего образования ФГОС ВО. Практическая реализация ФГОС ВО ставит основной целью высших учебных заведений формирование личной профессиональной компетентности выпускников 3. Принципиальная задача ФГОС новых поколений при массовости образования сделать его индивидуальным, отвечающим требованиям различных профессиональных стандартов. В содержании образовательных стандартов подчеркиваются права обучающихся на формирование своей индивидуальной образовательной программы, на получение консультаций в вузе по выбору дисциплин модулей предусмотренных ООП. В связи с этим обязанностью вуза становится обеспечение обучающимся реальной возможности участвовать в формировании своей программы обучения. Однако на сегодняшний день составление индивидуальных образовательных программ в вузовской практике сталкивается с определенными трудностями. Во-первых, принятие студентом ответственности за собственное образование, осознание его цели и выбора профессионального стандарта до начала обучения не возможно ввиду постоянных изменений потребностей и индивидуальных возможностей личности. Во-вторых, проектирование такой программы не может учесть индивидуальный темп обучения студента. Таким образом, индивидуальная образовательная программа студента должна рассматриваться как динамическая сущность, которая может меняться и корректироваться в ходе образовательного процесса. Но каждая индивидуальная образовательная программа должна гарантировать, что студент, успешно окончивший вуз, на выходе будет обладать всеми компетенциями, предусмотренными тем или иным профессиональным стандартом. Таким образом, на сегодняшний день становится актуальной проблема разработки модели, которая будет учитывать вариативность и индивидуализацию высшего образования. В данной модели ФГОС и ООП будут определять лишь исходные и конечные точки для образования студентов, на основе которых можно реализовать значительное количество различных индивидуальных траекторий обучения студента. В данной статье описывается программная система ИТОС индивидуальных траекторий обучения студентов, учитывающая индивидуализацию и вариативность образовательного процесса в вузе. В связи с постоянным развитием науки и техники структура и содержание учебных дисциплин, а также требования работодателей постоянно меняются. Следовательно, разрабатываемая программная система должна уметь работать с постоянно пополняемыми базами учебных дисциплин и профессиональных стандартов. Применение методологии онтологического моделирования 47 позволяет быстро адаптировать ООП факультета под актуальные профессиональные стандарты. Основными документами, рассматриваемыми в модели процесса формирования ООП, являются Федеральный государственный образовательный стандарт ФГОС документ, выдвигающий требования к определнному уровню образования или к направлению подготовки Основная образовательная программа ООП набор документов, описывающих структуру образовательного процесса документ, в котором определены общие сведения об образовательной программе, такие как цель миссия программы, объем и сроки освоения, требования к абитуриенту и возможные виды профессиональной деятельности выпускника учебный план рабочие программы дисциплин календарный учебный график Набор профессиональных стандартов документы, описывающий требования к знаниям и умениям для выполнения определнного вида профессиональной деятельности, обучение которым планируется в ходе реализации ООП. Для описания связей между данными документами была построена онтологическая модель рис. 1. В соответствии с данной онтологической моделью разработана база данных, позволяющая хранить все описанные множества документов. Эта база разделена на три функциональных модуля база нормативных документов, база дисциплин и база профессиональных стан дартов. В базе нормативных документов системы ИТОС хранятся общие требования, взятые из ФГОС и ООП, такие как перечень обязательных дисциплин, максимальный объм образовательной программы, сформированные компетенции и т. п. 8. База дисциплин системы ИТОС формируется на основе учебного плана и рабочих программ дисциплин. Для каждой дисциплины формируется экземпляр данного документа, содержащий название, аннотацию, формируемые знания и умения, формируемые компетенции, зависимости от других дисциплин, структуру и содержание. В ходе работы с системой имеется возможность редактирования базы дисциплин, т. е. добавление удаление дисциплин, изменение зависимостей между дисциплинами и т. д. Одним из ключевых направлений деятельности структурных подразделений вузов, отвечающих за разработку и реализацию образовательных программ, является соотнесение профессиональных и образовательных стандартов, обеспечивающее выполнение требований профессионального стандарта в результате реализации образовательного 9. Профессиональный стандарт состоит из четырех частей 1 общие сведения 2 описание трудовых функций, входящих в профессиональный стандарт функциональная карта вида профессиональной деятельности 3 характеристика обобщенных трудовых функций 4 сведения об организациях разработчиках профессионального стандарта. Наибольший интерес для данной работы представляет третья часть, где можно сопоставить трудовые функции и необходимые для них знания и умения. В связи с этим была построена онтология рис. 2 профессиональных стандартов 10. База профессиональных стандартов системы ИТОС формируется из реестра профессиональных стандартов с сайта Министерства труда и социальной защиты Российской Федерации, где они хранятся в виде xml-файла. Программная система ИТОС имеет возможность принимать на вход данный файл, парсить его и переносить необходимую информацию в базу данных в соответствии с составленной онтологической моделью. В системе ИТОС реализована возможность поиска с подсказками по названию профессионального стандарта, специальности, набору трудовых функций, знаниям, умениям. Также в программе реализован функционал контроля введения профессиональных стандартов, что подразумевает просмотр развиваемых дисциплинами умений и навыков и выяснением, покрывают ли они требования профессионального стандарта. Программа показывает введенные в данный момент профессиональные стандарты и профессиональные стандарты, для введения которых нужны дополнительные курсы рис. 3. Знания Профессиональный стандарт Навыки Специальность Трудовая функция Также при нажатии на не введенный профессиональный стандарт отображаются необходимые для его введения знания и умения рис. 4. Для хранения данных используется графовая база данных neo4j вершинами графа являются пользователи, все виды документов и вспомогательные сущности, такие как знания, умения, роли и др. Рбра описывают отношения принадлежности или зависимости элементов рис. 5. Ввиду большого числа учебных дисциплин, зависимостей в порядке их изучения, а также направленности дисциплин на развитие различных профессиональных навыков появляется потребность контролировать корректность составленной образовательной программы. Руководство факультета составляет общий вид образовательной программы и задат множество профессиональных стандартов, которые должны быть достигнуты. После этого преподаватели составляют учебные планы для своих дисциплин, описывая зависимости между дисциплинами и развиваемые профессиональные навыки и компетенции. В процессе формирования образовательной программы система ИТОС отслеживает необходимость изменения списка дисциплин или порядка их следования и достижимость всех заданных профессиональных стандартов, тем самым проверяет внутреннюю согласованность образовательной программы. Кроме того, система ИТОС проверяет образовательную программу на предмет соответствия актуальному ФГОСу. Таким образом, в системе ИТОС реализована возможность в автоматическом режиме выявлять ошибки и неточности в структуре образовательной программы ещ на этапе е составления. Пункт 2.1. ФГОС содержит требования к объму программы бакалавриата. Для проверки данного требования вычисляется суммарный объм образовательной программы, складывающийся из суммы объмов базовых дисциплин и суммы объмов блоков вариативных дисциплин. После чего определяется соответствие вычисленного объма требованиям. Пункты 2.2. и 2.3. ФГОС содержат требования к обязательному наличию заданного множества дисциплин. Для проверки данного требования производится поиск всех требуемых дисциплин среди составленных рабочих программ дисциплин. Пункт 2.9. ФГОС содержит требования к процентному соотношению базовой и вариативной частей образовательной программы. Для проверки данного требования вычисляется отдельно суммарный объм всех базовых дисциплин и отдельно суммарный объм всех блоков, после чего определяется соответствие соотношения данных объмов требованиям. Представим множество дисциплин в виде ориентированного графа, где множество дисциплин. Бинарное отношение задается следующим образом, если необходимо изучить дисциплину перед изучением дисциплины . На каждую вершину графа накладываем метку, где номер семестра, с которого начинается изучение дисциплины, и либо равна 0, если дисциплина базовая, либо равна номеру блока вариативных дисциплин, которому принадлежит дисциплина . Для каждой дисциплины определим множество, дисциплин, знание которых необходимо для изучения дисциплины . Будем считать, что образовательная программа обладает внутренней согласованностью, если 1 для любой вершины и для любой вершины выполняется условие 2 для любой вершины и для любой вершины выполняется условие если 0, то 0 3 для любой вершины и для любых вершин, выполняется условие если 0, то . Алгоритм проверки внутренней согласованности заключается в упорядочивании множества вершин согласно лексическому упорядочиванию меток и последующему обходу графа согласно данному упорядочиванию с проверкой в каждой вершине всех трех условий. В последнее время образовательные стандарты все больше акцентируют внимание на том, что у студентов должна быть возможность корректировки процесса своего обучения. У учебных заведений появляется обязанность предоставить такую возможность. Корректировка отображается на учебной траектории студента. Индивидуальная учебная траектория должна быть корректной после прохождения всех курсов траектории студент обязан обладать полным набором необходимых умений и знаний, чтобы получить выбранную специальность. В программной системе ИТОС реализован алгоритм построения всевозможных корректных индивидуальных траекторий в рамках заданной модели основной образовательной программы 11. Основная образовательная программа определяет набор курсов, которые являются базовыми. Эти курсы обязательно должны присутствовать во всех итоговых траекториях обучения. Также основная образовательная программа определяет блоки вариативных курсов. Студент вправе выбирать какой-либо курс из каждого блока. Следовательно, перед алгоритмом поставлена задача перебрать все варианты курсов из каждого блока, сконструировать траектории на основе перебора, проверить каждую траекторию на корректность и выдать в качестве результата только те траектории, которые прошли все проверки. Под корректностью в данном случае подразумевается следующий набор правил. 1. Траектория должна охватывать такой набор курсов, чтобы после завершения обучения по данной траектории студент обладал всеми необходимыми знаниями и умениями для получения какой-либо специальности. Другими словами, не должно получиться так, что студент закончил все курсы из сгенерированной траектории, но при этом не смог получить желаемую специальность. 2. Траектория должна содержать все зависимости своих внутренних курсов. Иначе говоря, если в траектории есть курсы, зависящие от внешних курсов, которых, в свою очередь, нет в сгенерированной учебной траектории, то данную траекторию следует исключить из результата работы алгоритма. Если во время работы алгоритма были обнаружены траектории, которые не удовлетворяют заданным критериям, алгоритм исключает их из результата работы и оповещает о случившемся пользователя системы. Полный перебор всех курсов из каждого блока может потребовать больших временных и мощностных ресурсов. Отсюда появляется еще одна деталь реализации алгоритма программный модуль, содержащий алгоритм генерации всевозможных траекторий обучения, не должен работать отдельно каждый раз для каждого запроса пользователя. Результат работы алгоритма зависит от основной образовательной программы. Поэтому запускать алгоритм можно только после ее изменения, а результат работы сохранять в базе данных. После этого пользователи должны взаимодействовать не с самим алгоритмом для получения траекторий обучения, а с базой данных, которая хранит результат работы траектории обучения. Множество вариативных дисциплин, реализуемых в рамках данной ООП, может быть достаточно велико порядка 5070 дисциплин. Кроме того, оно может меняться из года в год. Следовательно, множество всевозможных траекторий обучения студента также достаточно велико и непостоянно. В такой ситуации студенту сложно самостоятельно анализировать происходящие изменения, потому необходима автоматизация данного процесса. Для того чтобы облегчить студентам выбор траекторий, в системе ИТОС реализован модуль рекомендательной системы, позволяющий выбирать траектории исходя из предпочтений и возможностей каждого конкретного студента и исходя из текущего учебного плана и всех программ курсов 12. Взаимодействие рекомендательной системы с пользователем происходит в режиме диалога 13. Входные параметры, по которым система помогает пользователю выбирать индивидуальные траектории следующие. . Студент имеет возможность определить список специальностей, одну или несколько из которых он хотел бы получить по завершении обучения, а также список специальностей, в получении которых он не заинтересован. . Студент имеет возможность определить список дисциплин, которые он предпочитает посещать, а также список дисциплин, в посещении которых он не заинтересован. . На момент выбора или смены индивидуальной траектории студент старших курсов уже обладает множеством освоенных дисциплин. Система корректирует список рекомендованных траекторий согласно этой информации. Рекомендательная система предоставляет пользователю список возможных траекторий, подходящих под заданные условия. Кроме того, возможен случай, когда траекторий, удовлетворяющих заданным условиям, не существует. Тогда система рекомендует пользователю траектории, удовлетворяющие части требований. Пользователь, в свою очередь, может пересмотреть критерии поиска. Также не имеет смысла выдавать пользователю все возможные траектории, в случае, если таких нашлось много. Это вновь приведт к затруднению выбора из-за большого объема информации. Система упорядочивает траектории в порядке убывания множества требований, которым они соответствуют, и выдает пользователю первые траекторий. При этом требования относительно профессиональных стандартов считаются более приоритетными, нежели требования относительно дисциплин. На рис. 6 показан интерфейс работы рекомендательной системы. Уже выбранные критерии отображаются над строкой поиска в виде кнопок красного или зелного цвета, цвет определяет, включена данная дисциплина или профессиональный стандарт как желаемая или как не желаемая. Нажатие на любую из кнопок исключит критерий из запроса. Результат поиска отображается ниже в виде двух представлений список траекторий, для каждой из которых указаны входящие в не вариативные дисциплины траектории отсортированы исходя из соответствия требованиям граф, вершинами которого являются вариативные дисциплины, рбрами порядок их прохождения. В одной линии располагаются дисциплины, входящие в состав одного блока. При нажатии на траекторию в списке, на графе подсветятся соответствующие ей дисциплины. В статье описана программная система ИТОС Индивидуальные траектории обучения студентов. Она представляет собой совокупность четырех модулей, и предназначена для автоматизации работы с основной образовательной программой ООП и соответствующим ей учебным планом. Первый модуль предназначен для автоматизации формирования ООП в соответствии с актуальным ФГОСом. Данный модуль помогает отслеживать логику следования учебных курсов и позволяет на этапе составления ООП выявлять необходимость перестановки или слияния дисциплин, а также достижимость всех заданных компетенций. Второй модуль системы реализует алгоритм построения и оценки всевозможных индивидуальных траекторий обучения студента в рамках данной ООП. Данный алгоритм позволяет принимать решения о добавлении новых курсов в ООП с целью увеличения количества различных специальностей, которые можно получить в вузе, или количества дополнительных траекторий для получения уже существующих специальностей. Третий модуль реализует возможность устанавливать взаимосвязь между ООП и различными профессиональными стандартами. Четвертый модуль реализует рекомендательную систему, помогающую пользователям студентам в выборе индивидуальных траекторий обучения. Программная система реализована в виде web-приложения. Для реализации серверной части программного модуля используется фреймворк Spring, а для реализации клиентской части фреймворк Angular. Все наборы курсов, все индивидуальные траектории это граф. В связи с этим с помощью графовой БД работа с данными упрощается по сравнению с использованием реляционной БД. Нами была выбрана графовая база данных Neo4j. "}
{"title": "ОПИСАНИЕ ДОЛГОВРЕМЕННОЙ ЭВОЛЮЦИИ БЕРЕГОВОГО ПРОФИЛЯ   НА ОСНОВЕ ДИФФУЗИОННОЙ МОДЕЛИ   ", "absract": "Рассматривается диффузионная модель для описания долговременной эволюции профиля глубин в прибрежной зоне. Для калибровки модели решалась обратная задача восстановления коэффициентов по дополнительным граничным условиям путем минимизации функционала невязки. Многомерная оптимизация функционала проводилась методом дифференциальной эволюции. Для вычисления профиля глубин применялся метод конечных элементов. Тестирование проводилось на базе данных JARKUS при различных пространственных и временных интервалах. Достигнута относительная погрешность описания эволюции берегового профиля на уровне не более 5 %. : эволюция берегового профиля, обратная задача, функционал невязки, дифференциальная эволюция, метод конечных элементов.  Работа выполнена при финансовой поддержке проекта 0319-2018-0010 IV.36.1.4. «Исследование и развитие методов и технологий построения интегрированных программно-аппаратных комплексов для задач моделирования и управления динамическими системами обработки и отображения данных». Регистрационный номер:  АААА-А17-117062110016-4. ", "text": "Возрастающее влияние деятельности человека на окружающую среду начинает приводить к заметным экологическим последствиям. Это относится, в частности, к инженерным сооружениям в прибрежной зоне, таким как дамбы, искусственные острова и каналы. Естественные процессы массопереноса приводят к постоянному изменению профиля глубин, что влечет за собой ощутимые последствия как для экологии прибрежной зоны, так и к необходимости дополнительных инженерных работ. Понимание механизмов, влияющих на изменение профиля глубин, а также возможность предсказания такого изменения позволят минимизировать отрицательное влияние на экологию прибрежной зоны при проектировании и осуществлении инженерных работ. В настоящей работе рассматривается программный инструментарий решения задачи калибровки диффузионной модели для описания долговременной эволюции берегового профиля. Для моделирования процесса долговременной эволюции профиля глубин в прибрежной зоне, в работе 1 была предложена следующая диффузионная модель где, изменение глубины на расстоянии от береговой линии, коэффициент диффузии, некоторая функция, описывающая внешние источники. Данная модель применима только для песчаного дна. Согласно 1 наличие компоненты дает возможность ввести эффекты случайных воздействий, различных процессов переноса и вмешательства человека таких как добыча песка и полезных ископаемых. Что касается общих подходов по изучению долговременной эволюции берегового профиля, см. работы 26. Модель 1 была выбрана в качестве основы для дальнейших исследований, со следующими изменениями функция изменения глубины, представлена как функция глубины, функция, описывающая внешние источники, по аналогии с другими физическими процессами, была выбрана как функция переноса вещества, добавлена временная зависимость в коэффициент диффузии, . В данной работе мы предполагаем, что долговременная эволюция профиля глубин в прибрежной зоне описывается линейным диффузионным уравнением Параметр представляет собой расстояние замыкания, т. е. расстояние от береговой линии, где моделируемые процессы диффузии и переноса вещества практически не имеют влияния на изменение профиля глубин. Для решения уравнения 2, в качестве начальных и граничных условий использовались данные измерений например, с помощью сонаров 7 профиля глубин в прибрежной зоне Поскольку основная информация, необходимая для описания эволюции профиля глубин, содержится в коэффициентах, и, задача состоит в подборе данных коэффициентов таким образом, чтобы уравнение 2 с начальными и граничными условиями 3 оптимально описывало измеренные данные, т. е. эволюцию профиля глубин. Термин оптимально означает, что разница между измеренными данными, и вычисленным профилем, должна быть возможно меньше. Калибровка модели вычисление коэффициентов, и, проводилась в пространственно-временной области 0, 0 . Для получения лучшего приближения коэффициентов решалась обратная задача восстановления коэффициентов уравнения, 1, 0, 0. 2,0,0, 0, 0,. 3 2 по дополнительным граничным условиям данным измерений. Задача решалась путем минимизации функционала невязки на каждом шаге по времени 8 9 Для минимизации функционала невязки 4 использовался метод дифференциальной эволюции, реализованный в библиотеке Pallas Solver . Данный метод представляет собой стохастический алгоритм многомерной оптимизации, основанный на генетическом алгоритме. Общий принцип работы метода дифференциальной эволюции можно представить следующим образом рис. 1. 1. Алгоритм генерирует начальную, состоящую из случайных векторов мерного пространства, в котором определена целевая функция . Размерность популяции определяется эмпирически и задается в настройках алгоритма. 2. Выполняется воспроизводство набора векторов текущего поколения с использованием стратегии и . Стратегия мутации генерирует новые мутантные вектора путем стохастического комбинирования векторов предыдущего поколения . Стратегия скрещивания замещает координаты мутантных векторов на соответствующие координаты базовых векторов с некоторой вероятностью . Значение задается в настройках алгоритма. 3. Выполняется этап . Если после скрещивания полученный оказывается лучше базового вектора значение целевой функции улучшилось, то в новом поколении базовый вектор заменяется пробным. 4. На каждой итерации алгоритма или с заданной периодичностью определяется лучший вектор поколения для контроля скорости поиска оптимального решения. Помимо этого, на данном этапе проверяются условия остановки алгоритма, такие как достижение предельного количества итераций, нахождение глобального или субоптимального решения, неизменность лучшего вектора поколения на протяжении заданного предельного количества итераций., . 4 Преимущества метода дифференциальной эволюции заключаются в следующем возможность применения к недифференцируемым, нелинейным, мультимодальным функциям от многих переменных отсутствие требования начального приближения для искомого решения, что позволяет рассматривать решения разных порядков на области определения целевой функции метод не пытается поддерживать одно текущее решение, а развивает популяцию кандидатов решений. Для решения прямой задачи, а именно, вычисления профиля, в области при заданных значениях, был реализован метод конечных элементов 10. В качестве базисных функций для, и коэффициентов, использовались полиномы первой степени по на каждом интервале по времени. Другими словами, функции рассматривались как кусочно-линейные. Отладка и тестирование разработанного метода конечных элементов проводилась с использованием аналитически заданных функций по следующей схеме. 1. Аналитически задаем функцию, и коэффициенты, . 2. Определяем функцию, вида 3. Подставляем функцию 5 в исходное уравнение 2 в качестве правой части 4. Используя разработанный метод конечных элементов, вычисляем численное решение уравнения 6 и сравниваем с аналитическим решением, . Результаты тестирования показали, что относительная погрешность меньше 0,01 при различных аналитически заданных функциях, . Тестирование проводилось на многолетних данных измерений профиля глубин у побережья Голландии, которые собираются в рамках проекта JARKUS . Поскольку предложенная модель зависит только от одной пространственной переменной, задача рассматривается как одномерная относительно пространственных переменных. Поэтому для тестирования была выбрана одна точка на побережье рис. 2, относительно которой и решалась задача калибровки модели. Набор тестовых данных состоит из массива 201 34 точек рис. 3 201 точка наблюдений по расстоянию от берега с шагом 3 метра и 34 точки по времени с шагом 1 год. Калибровка модели выполнялась на временных интервалах длиной в 10 лет. Точность описания измерений берегового профиля предложенной моделью оценивалась путем вычисления относительной ошибки 7 между измеренными данными, и вычисленными данными, 100 ., 7, . 5,. 6 Относительная погрешность описания эволюции берегового профиля глубин на разных временных и пространственных интервалах, 0 10 5 15 10 20 15 25 0 3,17 2,9 3,62 3,85 10 3,01 2,23 2,53 2,71 4 2,56 1,44 1,82 2,33 При тестировании использовались также разные пространственные интервалы. Это проводилось из соображений, что вблизи берега, помимо диффузии и переноса, существуют другие процессы, которые влияют на данные измерений. Из результатов, представленных в таблице, видно, что при смещении пространственного интервала от берега относительная погрешность уменьшается. Также следует отметить, что при смещении окна по времени относительная погрешность вычисленных профилей сохраняется в пределах 5 . Для моделирования процесса долговременной эволюции профиля глубин в прибрежной зоне использовалась диффузионная модель 2. Решалась задача подбора коэффициентов этой модели, которые обеспечивают соответствие решения данным измерений. Для получения лучшего приближения коэффициентов решалась обратная задача путем минимизации функционала невязки 4. Модель тестировалась на наборе данных JARKUS для различных пространственных и временных интервалов измерений. Из приведенных результатов видно, что предложенная диффузионная модель способна описать долговременную эволюцию профиля глубин с относительной погрешностью на уровне не более 5 . В дальнейшем будет исследоваться возможность предсказания долговременной эволюции профиля глубин путем экстраполяции найденных коэффициентов по времени. "}
{"title": "СРАВНИТЕЛЬНЫЙ АНАЛИЗ   ИСПОЛЬЗОВАНИЯ РЕЛЯЦИОННЫХ И ГРАФОВЫХ БАЗ ДАННЫХ   В РАЗРАБОТКЕ ЦИФРОВЫХ ОБРАЗОВАТЕЛЬНЫХ СИСТЕМ", "absract": "Рассмотрены вопросы выбора варианта реализации базы данных при разработке цифровых образовательных систем. Проведен сравнительный анализ реляционного и графового подходов к хранению базовых сущностей. Продемонстрирован ряд преимуществ графовой модели в контексте удобства разработки и эффективности реализации за просов. : графовые базы данных, реляционные базы данных, Neo4j, цифровые образовательные системы.", "text": "В настоящее время лидирующее положение среди средств хранения данных занимают системы управления базами данных СУБД, основанные на реляционном подходе рис. 1 на трех лидирующих позициях реляционные СУБД Oracle, MySQL и MS SQL, на 4-м месте также реляционная СУБД PostgreSQL самая распространенная нереляционная СУБД MongoDB занимает 5-е место, на 6-м месте вновь находится реляционная БД DB2. Реляционный подход был сформулирован в 19691970 гг. Э. Ф. Коддом 1. Он заключается в хранении данных в таблицах с определенными между ними связями и ограничениями для поддержки целостности, корректности и неизбыточности данных. Однако за последние несколько лет начала расти доля рынка СУБД, реализующих альтернативные модели хранения данных, которые объединяют в класс нереляционных NoSQL, not only SQL. Такие модели имеют преимущество перед реляционными БД при работе со специфическими структурами данных, в частности они могут превосходить реляционные СУБД в работе со слабоструктурированными данными или с данными, явным образом связанными с визуальным представлением информации графы, диаграммы и др.. На рис. 2 представлена динамика роста популярности использования всех нереляционных СУБД независимо от модели, например, MongoDB документоориентированная СУБД, Redis СУБД, реализующая модель ключ значение, Neo4j графовая БД. Вопрос выбора подхода к организации базы данных актуален при разработке цифровых образовательных систем и сред. В последние годы в сфере образования наблюдается тенденция к индивидуализации 2, что означает организацию учебного процесса с учетом индивидуальных особенностей каждого обучающегося. В 3 показана возможность реализации такой индивидуализации с помощью специальных цифровых инструментов, которые анализируют перечень компетенций, достижений и характеристик обучающегося и генерируют его индивидуальную траекторию, представляющую собой граф. Предложенный способ генерации основан на обработке образовательных программ вуза. Сущность образовательная программа с точки зрения данных может быть представлена в виде связных ориентированных графов, описывающих зависимости между учебными дисциплинами, компетенциями, модулями и др. Авторами данной статьи было сделано предположение, что при работе с сущностями предметной области графовые базы данных могут иметь преимущество в эффективности работы и удобстве разработки в сравнении с реляционными. В данной работе рассмотрены реализации хранения данных, характерных для цифровых образовательных систем, в реляционной PostgreSQL и графовой Neo4J системах управления базами данных. Сравнительный анализ реляционных и графовых баз данных проводился в некоторых работах например, 4, нашей же целью является сравнительный анализ именно удобства использования реляционной и графовой моделей при разработке цифровых образовательных систем в контексте модели данных. Нами были проанализированы образовательные программы высшего и дополнительного образования и выявлены сущности баз данных, характерные для каждой образовательной системы. Любая информационная система, которую можно назвать образовательной, хранит данные, характерные для таких систем. Отметим, что работа посвящена разработке образовательных систем с технической точки зрения, поэтому, несмотря на различия в образовательной терминологии, некоторые разные понятия были рассмотрены с точки зрения данных как одна и та же сущность. Именно поэтому ниже приведены все подходящие термины, а в скобках вариант, выбранный в рамках данной статьи. . Содержит информацию об учебном предмете название, цель, методы обучения. Термин может также подразумевать некий обособленный раздел дисциплины, который можно изучать отдельно, например, модуль Язык SQL в курсе Базы данных., . То, что может чем владеет обучающийся по окончании образования. Если рассматривать высшее образование, то образовательными результатами являются компетенции ФГОС и связанные с ними знания, умения и навыки. Программы дополнительного образования, корпоративного образования, переподготовки могут также определять конкретные требования к сотрудникам, прошедшим обучение. . То, на что ориентировано образование на получение диплома по конкретному направлению или, в случае дополнительного или корпоративного образования, на некоторую специализацию или соответствие некоторой вакансии на рынке труда. Между выделенными сущностями можно определить следующие типы отношений, . Описывает зависимость между двумя модулями, когда изучение одного должно предшествовать изучению другого., . Описывает зависимость между двумя предметами, когда один модуль является частью другого модуля как показано выше с модулем Язык SQL в модуле Базы данных. . Компетенции знания образовательные результаты, получаемые при изучении предмета. . Компетенции знания умения навыки, которые необходимо освоить в рамках обучения по данному направлению. Структурным аспектом реляционной модели данных являются отношения таблицы 1. Для описания структуры реляционной базы данных, а также управления создание, модификация, удаление данными в уже существующем хранилище используется декларативный язык программирования Structured Query Language SQL . Таблицы реляционных баз данных можно рассматривать в двух аспектах. С одной стороны, они могут пониматься как структуры для хранения выделенных сущностей. На этом понимании основан, в том числе, подход Object-Relational Mapping объектно-реляционное отображение, когда структура таблицы понимается как некоторый класс, столбец как атрибут класса, а строка как объект класса. С другой стороны, реляционный подход к БД предполагает, что таблица хранит сами отношения между сущностями. Так, например, можно рассмотреть отношение Подписка между пользователями в социальных сетях. Подписка является не сущностью в привычном понимании, а отношением между двумя экземплярами сущности Пользователь Пользователь1 подписан на Пользователь2. Схема реляционной базы данных для модели данных представлена на рис. 3. Таблицы Module модуль, Major направление, Competence компетенции содержат сущности, описанные выше. Все связи являются отношением типа многое-ко-многим Many-To-Many, что традиционно реализуется введением так называемых промежуточных таблиц для хранения этих связей. Кроме внешних ключей, эти таблицы могут содержать дополнительные данные. Например, таблица modules-major может содержать информацию о семестрах, в которых изучается модуль для конкретной образовательной программы. Отметим, что в рамках этой статьи отдельная спецификация таких данных не требуется. Использование реляционного подхода для баз данных образовательных систем имеет несколько недостатков. Во-первых, реляционная схема не различает таблицы, хранящие сущности, и таблицы, хранящие связи между объектами. Во-вторых, визуализация результатов запросов к реляционным БД опять же выглядит как таблица, которая не является естественным способом визуализации данных, носящих графовый характер. Не уменьшая достоинств реляционных БД, для повышения качества и удобства разработки цифровых образовательных систем необходимо обратиться к другим моделям хранения данных, имеющим собирательное название NoSQL not only SQL. Они призваны не целиком заменить существующие реляционные решения, а дополнить их там, где они недостаточно гибки и удобны. Создатели нереляционных решений отмечают более высокую производительность при использовании специфических моделей данных и легкость работы с ними 5. Одна из классификаций NoSQL базы данных приведена в 6. Основываясь на модели данных, можно разделить нереляционные хранилища на 4 группы 1 Базы данных NoSQL на основе модели ключ значение Redis, MemcacheDB и т. п. 2 хранилища колонок Cassandra, HBase 3 документоориентированные базы данных MongoDB, Couchbase 4 графовые СУБД OrientDB, Neo4J. Графовые БД являются одним из наиболее популярных и актуальных подвидов нереляционных хранилищ 5. Такие БД оперируют представлениями данных в виде графов и позволяют эффективно совершать привычные для них операции. Для реализации хранения модели данных, описанной выше, была выбрана Neo4j самая популярная на сегодняшний день графовая СУБД 6. В основе ее работы лежит аппарат ориентированных графов. Узлы nodes хранят основную информацию об объектах и сгруппированы по видам с помощью специальных меток labels. Также узлы связаны друг с другом отношениями ребрами, в метках которых можно хранить данные . Для манипуляций с данными используется язык Cypher, синтаксис которого достаточно близок к современным языкам разработки. Как было отмечено ранее, представленная выше модель данных может быть описана ориентированным графом, что означает естественную возможность реализации в Neo4j. Для основных сущностей определены три метки Модуль, Направление и Компетенция. Вершины разных меток могут хранить разный набор атрибутов. Определены следующие связи между сущностями Связь Описание ПРЕДШЕСТВУЕТ Описывает зависимость между двумя модулями, когда один модуль необходим для освоения другого СОДЕРЖИТСЯ Описывает зависимость между двумя модулями, когда один модуль является составной частью другого ИМЕЕТНАПРАВЛЕНИЕ Связывает предмет и направление подготовки. Ребро также содержит свойства первый и последний семестр преподавания предмета РАЗВИВАЕТКОМПЕТЕНЦИИ Связывает предмет и компетенции. Описывает компетенции, которые являются результатом освоения предмета. Также связывает направление подготовки и компетенции. Описывает компетенции, которыми должен обладать выпускник данного направления Для сравнительного анализа удобства использования реляционного и графового подходов в контексте разработки цифровых образовательных систем обратимся к конкретным примерам типовых запросов, которые могут быть использованы при работе с такими системами., Реализация на языке SQL Реализация на языке Cypher, Для сокращения запроса считаем, что id модуля заранее известен и равен 0. Реализация на языке SQL Реализация на языке Cypher Приведенные примеры показывают, что обе модели данных эмулируют обход графа. Однако в силу своей структуры реляционная модель для прохода по графу требует явного рекурсивного прохода с операцией соединения на каждом уровне, при этом осуществляется многократный проход по одному и тому же набору записей. Графовые БД, опираясь на представление графа, естественным образом осуществляют переход от вершины к ее смежным вершинам за один шаг. Обратим внимание, что запросы 1 и 2 практически не отличаются. Это связано с тем, что Cypher позволяет указать максимальную и минимальную глубины связей, которые надо пройти. В данном случае эти значения не указаны возвращаются все предки. Помимо выигрыша в удобстве проектирования запросов к базе данных и в количестве операций, Neo4J предоставляет удобный интерфейс визуализации данных в запросах, встраиваемый автоматически в каждую БД. Так, выполняя запрос на получение предмета с названием Системное программное обеспечение, можно также получить информацию о связанных узлах рис. 4. Представленная визуализация при работе с графовой БД позволяет видеть данные в естественном для них представлении, что облегчает восприятие данных и позволяет быстрее проверять корректность запросов. Проведенный анализ позволяет говорить о преимуществе в цифровых образовательных системах в ряде случаев графовых баз данных перед реляционными в контексте проектирования запросов, скорости их выполнения и удобства работы с самой базой данных. Возможно применение графовых БД с опорой на большое количество различных связей между объектами в образовательных системах, что позволяет рассматривать такие объекты как графы. Еще раз подчеркнем, что графовая структура воспроизводима в реляционных базах данных, но для эффективной работы с графовыми данными в таких БД потребуются больше времени, более сложные запросы, а также, возможно, использование сторонних библиотек. Чем больше запрос использует графовую структуру, тем он становится сложнее и медленнее 7. В дальнейших исследованиях предполагается продолжить анализ NoSQL-средств для работы с данными в цифровых образовательных средах, а также выполнить разработку специализированных расширений для графовых баз данных, позволяющих более эффективно разрабатывать соответствующие приложения в области образования. "}
{"title": "ЭКСПЕРИМЕНТАЛЬНОЕ ИССЛЕДОВАНИЕ ТОЧНОСТИ МЕТОДОВ ПРОГНОЗА   БАЗИРУЮЩИХСЯ НА АРХИВАТОРАХ ", "absract": " В теории информации известно, что методы сжатия данных могут быть использованы для прогнозирования стационарных процессов. В данной работе предложен базирующийся на архиваторах алгоритм прогнозирова ния временных рядов и проведено экспериментальное исследование его эффективности. В процессе работы описанного алгоритма могут быть использованы произвольные методы сжатия данных, причем прогнозные значения от разных методов комбинируются, и наибольшее влияние на конечный результат оказывает метод, способный сильнее других сжать временной ряд. Данный алгоритм может быть использован для прогнозирования рядов  с дискретными и непрерывными алфавитами. Для повышения точности прогноза возможно применение существующих методов предварительной обработки данных. Экспериментальное исследование эффективности предложенного алгоритма проводилось на временных рядах из M3 Competition и ряде T-индекса, при этом были использованы хорошо известные архиваторы. Результаты вычислений показали, что полученный метод обладает сравнительно высокой точностью и быстродействием. : универсальное кодирование, прогнозирование временных рядов. ", "text": "Задача прогнозирования привлекает внимание многих исследователей в силу ее большой практической значимости. Например, существует большое количество приложений в экономике можно построить прогноз для уровня безработицы, объемов промышленного производства и т. д., геофизике прогнозирование числа солнечных пятен, уровня моря и во многих других областях человеческой деятельности. Математически временной ряд может быть описан как случайный процесс с дискретным временем 1, значения которого, как правило, находятся на равном расстоянии друг от друга. При прогнозировании временного ряда требуется оценить значения процесса в нескольких будущих моментах времени на основании имеющейся в наличии его предыстории. Для решения описанной задачи разработано большое количество разнообразных мето дов как статистических, так и из области машинного обучения. К наиболее распространенным можно отнести экспоненциальное сглаживание, модель авторегрессии скользящего среднего и различные ее модификации, а также экспертные системы и нейронные сети 2 3. Тем не менее задача построения высокоточного прогноза еще далека от разрешения. Поскольку между сжимаемостью последовательности и ее вероятностью существует тесная связь, одним из возможных подходов к решению данной задачи является использование методов сжатия данных. В статье 4 было показано, что любой архиватор может быть использован для прогнозирования. Важно отметить, что в архиваторах, помимо теоретических результатов, используются различные эвристики, повышающие их способность улавливать закономерности во встречающихся на практике данных и улучшающие степень сжатия. В данной статье разрабатывается и исследуется метод прогнозирования временных рядов, основанный на распространенных архиваторах и библиотеках для сжатия данных таких, как библиотека zlib, лежащая в основе архиватора gzip, библиотека ppmd 5, используемая среди прочих алгоритмов в 7-z, и др.. Для экспериментальной оценки эффективности метода были проведены расчеты для временных рядов из известного исследования M3-Competition 3 далее M3C, основной целью которого было сравнение точности различных методов прогнозирования на реальных данных преимущественно из социально-экономической сферы. Проведено сравнение предлагаемого метода с методами, участвовавшими в этом исследовании. Еще одним рядом, результаты вычислений для которого приводятся в данной статье, является временной ряд T-индекса, тесно связанный с солнечными пятнами. Результаты экспериментального исследования показывают, что описываемый метод обладает точностью, сравнимой с другими методами прогнозирования, и представляет практический интерес. Сначала покажем, как связаны сжатие данных и прогнозирование. Пусть,..., временной ряд или в терминах теории информации передаваемое сообщение, порожденный некоторым вероятностным источником. Все члены временного ряда принадлежат конечному множеству, называемому . В теории информации хорошо известно, что для любого разделимого кода выполняется неравенство Крафта Макмиллана 6 2 1, 1 где множество всевозможных последовательностей длиной над алфавитом, длина кодового слова для сообщения при кодировании по методу . Величину 2 далее для краткости будем называть сообще ния . В работе 4 было предложено использовать неравенство 1 для задания распределения вероятностей на множестве кодируемых сообщений 2 . 2 Условная вероятность того, что следующие символов,..., будут равны соответственно,..., может быть найдена с использованием имеющейся предыстории по формуле,...,..., 2 . 2 2 Приведем пример вычислений по формуле 2. Построим прогноз на два шага вперед для последовательности 0110011001 над алфавитом 0,1 . Будем поочередно дописывать в конец данной последовательности различные комбинации длиной 2 из нулей и единиц и сжимать ее каким-либо архиватором. Например, воспользуемся библиотекой zlib версии 1.2.11, в частности, ее функцией compress2 с флагом ZBESTCOMPRESSION. Получившиеся длины кодовых слов и дальнейшие вычисления приведены в табл. 1. Жирным шрифтом в столбце 1 выделены два дописанных символа. Последовательности в программе на языке C были представлены как массивы типа unsigned char, на каждый символ последовательностей отводился 1 байт единица была представлена байтом со значением 1, а нуль со значением 0 . Пример построения распределения вероятностей для следующих двух элементов временного ряда Последовательность Размер сжатого представления, бит Кодовая вероятность Вероятность 0110011001 128 2.939E-39 1.520E-5 0110011001 128 2.939E-39 1.520E-5 0110011001 112 1.926E-34 9.961E-1 0110011001 120 7.523E-37 3.891E-3 Сумма 1.933E-34 1.000 Как видно из табл. 1, согласно данному методу, следующими двумя символами будут 10 с вероятностью 0.996. Таким образом, архиватор смог успешно выявить закономерность даже на короткой последовательности. Более подробное изложение метода, описанного в данном и следующем разделах, а также обоснование приведенных в них формул можно найти в книге 7. Описанный в предыдущем разделе метод применим только для временных рядов с конечным алфавитом, но на практике чаще всего встречаются ряды, у которых алфавитом является некоторый отрезок вещественной прямой. В таких случаях необходимо перейти от подобного отрезка к конечному алфавиту. Это можно сделать путем разбиения отрезка на непересекающихся равных интервалов с номерами 0,1,..., 1 обозначим интервал с номером через, последующего преобразования временного ряда в ряд номеров интервалов и прогнозирования номеров для следующих значений. Предположим, что требуется построить прогноз на шагов вперед. Тогда вероятность того, что в момент времени, 1, значение процесса попадет в интервал с номером, может быть получена из маргинального распределения вероятностей по совместному распределению номеров, вычисленному по формуле 2,...,..., . 3 В качестве точечного прогноза можно использовать математическое ожидание случайной величины, значениями которой являются середины интервалов, и их вероятности задаются по формуле 3. Рассмотрим далее вопрос о выборе количества интервалов . Проблема заключается в том, что при малых точность прогноза может оказаться низкой из-за грубого округления, а при больших из-за слишком короткой предыстории процесса и присутствия шумов в данных. Кроме того, с увеличением экспоненциально возрастает время вычислений. В данной работе был использован подход, описанный в статье 8. Отрезок, из которого принимают значения члены временного ряда, разбивается последовательно на 2 интервалов, 1,2,..., 2. Для каждого прогноз строится независимо, и затем прогнозы взвешиваются. Пусть член исходного временного ряда, а соответствующий ему номер интервала при разбиении исходного отрезка на 2 интервалов. Взвешивание можно провести по следующей формуле 2,..., 2 4 где 0,1,...,2 1 алфавит, состоящий из номеров интервалов 0, 1 весовые коэффициенты, в данной работе вычислялись по формуле 1 1, 1 1, . 1 Поясним, зачем прибавлять величину 1 к длине кодового слова в формуле 4. Без нее нельзя сравнивать длины кодовых слов для сообщений из разных алфавитов. Предположим, что область значений временного ряда поочередно разбивалась на 2 и 4 интервала разбиения 1 и 2 соответственно. В данном случае log4 2. Заметим, что каждому интервалу разбиения 1 соответствует 2 интервала разбиения 2 нулю соответствуют нуль и единица, единице два и три. Для того чтобы сообщить, в какой из двух возможных интервалов разбиения 2 попадает элемент из ряда с разбиением 1, требуется 1 бит. Поскольку всего элементов, требуется добавить 2 1 бит к ряду с разбиением 1. Для того чтобы избежать больших отрицательных степеней при расчетах по формуле 4, после того, как длины всех кодовых слов будут известны, можно вычесть наименьшую из них из каждого кодового слова. Данная идея будет проиллюстрирована в примере 2. Далее покажем, как можно взвесить прогнозы, полученные по различным архиваторам. Пусть имеется методов сжатия данных архиваторов,..., . Можно скомбинировать прогнозы, полученные от каждого архиватора в отдельности, в общий прогноз по следующей формуле 2, 2 5 где 0, 1 весовые коэффициенты,..., данный временной ряд,..., одно из возможных продолжений ряда ряд, полученный путем дописывания ряда в конец ряда . В данной работе при вычислениях по формуле 5 были использованы равные веса 1. Отметим, что формулы 4 и 5 можно использовать совместно. В вычислениях, приводимых в данной статье, сначала оценки вероятностей, полученные при различных мощностях разбиений, взвешивались по формуле 4, и тем самым получалось единственное распределение интервалов содержащее номера интервалов из наибольшего рассматриваемого разбиения для каждого используемого архиватора. Затем распределения от разных архиваторов объединялись в одно по формуле 5. Рассмотрим, как построить прогноз для временного ряда с непрерывным алфавитом при помощи двух архиваторов. Пусть дан следующий временной ряд 3.4 0.1 3.9 4.81.51.82.04.95.12.1 Требуется построить по нему прогноз на два шага вперед. Для этого воспользуемся библиотекой zlib, реализацией алгоритма сжатия Re-Pair 9 и формулой 5. Сначала перейдем к конечному алфавиту. Разобьем интервал, в который попадают все значения временного ряда, на 2 и 4 части одинаковой длины, построим прогнозы независимо для этих разбиений, а затем скомбинируем их по формуле 5. Наименьшее значение в рассматриваемом временном ряде 0.1, наибольшее 5.1. Хотя все значения ряда попадают в отрезок 0.15.1, отступим на некоторую величину от крайних значений поскольку следующее значение может быть больше меньше предыдущего максимума минимума. При расчетах, результаты которых приводятся в данной статье далее, отступ составлял 10 от ширины интервала, поэтому в данном примере поступим также. Получим 0.1 0.4, 0.1 5.6. При разбиении на два интервала одинаковой длины в случае, если значение временного ряда меньше чем 2.6, будем считать, что оно попало в интервал с номером 0, иначе в интервал с номером 1. Получим следующий временной ряд 3.4 0.1 3.9 4.81.51.82.04.95.12.1 1 0 1 1 0 0 0 1 1 0 Будем последовательно дописывать к ряду всевозможные комбинации из символов 0,1 и сжимать получающиеся сообщения. Размеры сжатых файлов и соответствующие вычисления вероятностей приведены в табл. 2. При склеивании кодовых вероятностей, полученных от zlib и Re-Pair, были использованы веса 0.5. Проведем аналогичные вычисления для разбиения области значений ряда на 4 интервала. Получим следующий временной ряд 3.4 0.1 3.9 4.81.51.82.04.95.12.1 2 0 2 3 1 1 1 3 3 1 Интервалу с номером 0 при разбиении на 2 интервала соответствуют интервалы 0, а при разбиении на 4 интервала 1, соответственно интервалу с номером 1 интервалы 2 и 3. Поэтому, например, прогнозному значению 13 при разбиении на 4 интервала соответствует прогнозное значение 01 при разбиении на два интервала. К значениям в пятом и шестом столбцах табл. 2 было прибавлено 12 бит, поскольку длина каждой из последовательностей равна 12, и log4 log2 1. В данной таблице наименьшая длина сжатого сообщения составила 100 бит, для уменьшения риска переполнения при вычислениях с плавающей точкой эту величину можно вычесть из всех значений в столбцах 2, 3, 5, 6 табл. 2. Результаты вычислений при разбиении на два и четыре интервала Сообщение 4 интервала Размер сжатого сообщения, бит Сообщение 2 интервала Размер сжатого сообщения, бит zlib Re-Pair zlib Re-Pair 2023111331 160 112 1011000110 120 12 104 12 2023111331 160 112 2023111331 144 120 2023111331 136 104 2023111331 160 120 1011000110 128 12 88 12 2023111331 160 112 2023111331 144 120 2023111331 144 120 2023111331 160 120 1011000110 136 12 88 12 2023111331 160 112 2023111331 160 112 2023111331 160 112 2023111331 160 112 1011000110 136 12 88 12 2023111331 160 120 2023111331 160 112 2023111331 144 112 Далее нужно перейти к кодовым вероятностям, а затем взвесить и нормировать их. Окончание расчетов приведено в табл. 3. Теперь построим прогноз на первый и второй шаги. Просуммировав вероятности в строках таблицы, в которых первый дописанный символ равен 0, получим вероятность того, что следующее значение временного ряда попадет в интервал с номером 0. Аналогичным образом вычисляются вероятности для интервалов с номерами 1, 2 и 3. Распределения вероятностей номеров интервалов, а также середины соответствующих интервалов, приведены в табл. 4. В качестве прогнозных значений используются математические ожидания, значения которых также приведены в таблице. е Обозначим через мощность алфавита источника максимальная мощность разбиения в случае непрерывного алфавита. Если требуется построить прогноз на шагов, то потребуется сжать последовательностей. В то же время в M3C для ежемесячных данных требовалось вычислять прогноз на 18 шагов вперед, что приводит к необходимости сжатия 2 262144 последовательностей при минимально возможной мощности алфавита 2. Сократить время вычислений позволяет следующий подход. Предположим, что является четным. Удалим из ряда все члены с четными номерами и построим прогноз на 2 шагов вперед с нечетными номерами. Затем удалим из исходного ряда все элементы с нечетными номерами и построим прогноз для недостающих 2 элементов с четными номерами. В результате вместо возможных продолжений ряда получим 2 вариантов. Для повышения точности можно построить прогноз на первые 2 шагов по полному ряду. Данный метод легко можно обобщить. К примеру, если кратно 6, то на первом этапе нужно оставить только члены ряда с номерами, для которых mod6 0, и вычислить прогноз на 6 шагов вперед и т. д. Окончание расчетов из примера 2 Сообщение 4 интервала Кодовая вероятность 4 интервала Сообщение 2 интервала Кодовая вероятность 2 интервала Кодовая вероятность после склеивания Вероятность после склеивания zlib Re-Pair zlib Re-Pair 2023111331 2.939E-39 2.441E-04 1011000110 2.328E-10 1.562E-05 6.485E-05 2.150E-05 2023111331 2.939E-39 2.441E-04 6.485E-05 2.150E-05 2023111331 1.926E-34 9.537E-07 4.053E-06 1.344E-06 2023111331 4.930E-32 0.063 0.016 0.005 2023111331 2.939E-39 9.537E-07 1011000110 9.095E-13 1.000 0.250 0.083 2023111331 2.939E-39 2.441E-04 0.250 0.083 2023111331 1.926E-34 9.537E-07 0.250 0.083 2023111331 1.926E-34 9.537E-07 0.250 0.083 2023111331 2.939E-39 9.537E-07 1011000110 3.553E-15 1.000 0.250 0.083 2023111331 2.939E-39 2.441E-04 0.250 0.083 2023111331 2.939E-39 2.441E-04 0.250 0.083 2023111331 2.939E-39 2.441E-04 0.250 0.083 2023111331 2.939E-39 2.441E-04 1011000110 3.553E-15 1.000 0.250 0.083 2023111331 2.939E-39 9.537E-07 0.250 0.083 2023111331 2.939E-39 2.441E-04 0.250 0.083 2023111331 1.926E-34 2.441E-04 0.250 0.083 Сумма 3.016 1.000 Вычисление прогнозных значений на два шага вперед для ряда из примера 2 Номер интервала Маргинальная вероятность Середина интервала шаг 1 шаг 2 0 0.166 0.166 0.35 1 0.171 0.171 1.85 2 0.332 0.332 3.35 3 0.332 0.332 4.85 Математическое ожидание 3.093 3.093 При проведении экспериментальных расчетов, результаты которых приведены в данной статье, были использованы библиотеки zlib, ppmd и реализация алгоритма Re-Pair 9. В их основе лежат разные идеи. В zlib реализована схема Deflate, в которой используется алгоритм LZ-77 совместно с кодом Хаффмана. Библиотека ppmd является реализацией алгоритма PPM Prediction by Partial Matching, предсказание по частичному совпадению. Re-Pair алгоритм сжатия данных, основанный на грамматической модели. В процессе работы этого алгоритма выполняется построение контекстно-свободной грамматики, задающей язык из единственной цепочки сжимаемого файла. При этом сжатие достигается за счет замены повторяющихся фрагментов во входной последовательности на нетерминальные символы. В рамках данной работы была выполнена программная реализация описанного метода и проведены вычисления для набора временных рядов из исследования M3-Competition 3, а также временного ряда T-индекса. Соревнование M3-Competition проводилось в 2000 г., и основной его целью являлось сравнение точности методов прогнозирования на реальных данных. В нем были представлены 3 003 временных ряда, длина которых составляла от 14 до 144 наблюдений. Присутствовали ежегодные, ежемесячные и ежеквартальные данные, а также небольшое количество рядов, не относящихся ни к одной из вышеперечисленных категорий категория другие. Требовалось построить прогноз на 6 шагов для ежегодных данных, на 8 шагов для ежеквартальных данных и данных из категории другие, на 18 шагов для ежемесячных данных. На веб-сайте Международного института прогнозистов размещены временные ряды из M3C и реально зафиксированные значения прогнозируемых величин, поэтому имеется возможность провести аналогичные вычисления и оценить качество построенного прогноза. В данной статье используется один из способов оценки точности в M3C симметричная средняя абсолютная процентная ошибка symmetric mean absolute percentage error, sMAPE, определяемая по следующей формуле sMAPE, 100, 2 6 где,..., ряд прогнозных значений,..., ряд зафиксированных значений. Поскольку ни один временной ряд из M3C не содержит отрицательных значений, величина, вычисляемая по формуле 6, не может быть отрицательной. При вычислениях по описываемому в данной статье алгоритму использовалась предварительная обработка данных. В частности, для ежемесячных и ежеквартальных данных использовалось выделение сезонной компоненты временного ряда была использована реализация метода STL 10. Затем выполнялось построение прогноза для тренда и случайной составляющей, а сезонная компонента принималась постоянной. Кроме того, для всех категорий временных рядов осуществлялся переход к первой разности первой разностью ряда,..., называется ряд,..., и применялось сглаживание по формуле 2 4. В процессе экспериментального исследования была предпринята попытка выбора такого порядка разности, при котором среднеквадратичное отклонение для ряда будет наименьшим. За исключением одного случая ежемесячные данные такой подход приводил к небольшому ухудшению точности прогноза по сравнению с постоянным выбором первой разности. Поскольку при вычислениях возникает потребность в работе с очень маленькими числами с плавающей точкой, в программной реализации описанного метода была использована библиотека для арифметики с высокой точностью . При построении всех прогнозов применялась ранее описанная процедура оптимизации вычислений при помощи прореживания ряда. При прогнозировании ежегодных, ежеквартальных и других данных оставлялся каждый второй элемент временного ряда, при прогнозировании ежемесячных каждый шестой. Выбор таких значений был обусловлен сооб ражениями трудоемкости при прогнозировании ежегодных данных для каждого ряда дважды строился прогноз на 3 шага вперед, ежемесячных данных шесть раз на 3 шага вперед и т. д. Результаты вычислений приведены в табл. 58. Формат таблиц близок к таблицам из 3. В таблицах приводятся данные, полученные по различным архиваторам и некоторым их комбинациям. В строках Лучший M3C и Худший M3C содержатся соответственно наименьшие и наибольшие ошибки на каждый шаг среди всех участвовавших в M3C архива торов. В двух из четырех таблиц метод прогнозирования на основе архиваторов показал точность, сравнимую с другими методами. На ежеквартальных и ежемесячных данных его точность оказалась сравнительно низкой, но, тем не менее, при прогнозировании на первые четыре шага сопоставимой с методами из M3C. При этом увеличение количества интервалов с 16 до 32 ни в одном случае не привело к существенному повышению точности прогноза. Далее приведем результаты вычислений для ряда T-индекса, который рассчитывается метеорологическим бюро Австралии и тесно связан с солнечными пятнами. Временной ряд ежемесячных значений T-индекса можно найти на веб-сайте httplistserver.ips.gov.au mailmanlistinfoips-tindex-predictions. На этом же сайте размещается прогноз T-индекса на данный момент доступен прогноз на 44 шага вперед, а также архивные данные. В рамках нашей работы для каждого из месяцев с апреля 2011 по апрель 2016 г. был построен прогноз на 18 шагов вперед в этом временном интервале отсутствуют пропущенные значения, и проведено сравнение его точности с прогнозом метеорологического бюро. В данном ряде, в отличие от рядов из M3C, встречаются отрицательные значения, поэтому точность прогноза оценивалась по средней абсолютной ошибке mean absolute error, MAE, вычисляемой по следующей формуле 1 MAE, 7 где,..., ряд прогнозных значений,..., ряд зафиксированных значений. Вычисления были проведены следующим образом. На основании данных из файла за некоторый месяц например, январь 2014 г. строился прогноз на 18 шагов вперед. Затем по более позднему файлу на 18 месяцев по формуле 7 рассчитывалась ошибка вычисленного прогноза и прогноза, содержащегося в исходном файле за январь 2014 г. в данном примере, в каждом файле помимо зафиксированных значений приводятся прогнозные значения. Результаты расчетов приведены в табл. 9. Как видно из этой таблицы, при прогнозировании на 1 шаг метод на основе архиваторов оказался точнее метода метеорологической службы, в остальных случаях точность прогноза метеорологической службы оказалась выше. Результаты прогнозирования ежегодных данных из M3C Метод Ошибка sMAPE для номера шага Среднее Количество рядов 1 2 3 4 5 6 14 16 Лучший M3C 7.6 12.1 16.1 18.2 20.8 22.7 13.65 16.42 645 Худший M3C 10.7 15.2 20.8 24.1 28.1 31.2 17.57 21.59 645 zlib 16 интервалов 9.9 14.9 20.8 22.9 28.0 28.2 17.13 20.79 645 ppmd 16 интервалов 10.1 14.5 20.6 22.4 27.3 27.2 16.76 20.25 645 rp 16 интервалов 10.5 14.9 19.5 21.9 26.2 27.4 16.70 20.06 645 zlib ppmd rp 16 интервалов 10.4 14.5 19.4 21.8 26.5 27.3 16.51 19.97 645 zlib ppmd rp 32 интервала 10.3 14.5 19.3 21.8 26.4 27.3 16.49 19.95 645 Результаты прогнозирования ежеквартальных данных из M3C Метод Ошибка sMAPE для номера шага Среднее Количество рядов 1 2 3 4 5 6 8 14 16 18 Лучший M3C 4.8 6.6 7.4 8.8 9.4 10.9 12 7 8.04 8.96 756 Худший M3C 7.7 8.9 9.1 10.7 11.8 13.7 15.7 8.86 9.6 10.96 756 zlib 16 интервалов 5.8 7.6 9.0 11.5 14.0 14.4 17.0 8.47 10.39 12.02 756 ppmd 16 интервалов 5.8 7.5 8.8 10.6 12.7 13.3 15.4 8.16 9.77 11.12 756 rp 16 интервалов 6.5 9.0 10.0 12.0 13.5 13.6 15.2 9.35 10.75 11.96 756 zlib ppmd rp 16 интервалов 5.8 7.5 8.8 10.5 13.0 13.2 15.0 8.16 9.80 11.11 756 zlib ppmd rp 32 интервала 5.8 7.5 8.8 10.5 13.0 13.2 14.9 8.16 9.81 11.11 756 Результаты прогнозирования ежемесячных данных из M3C Метод Ошибка sMAPE для номера шага Среднее Количество рядов 1 2 3 4 5 6 8 12 15 18 14 18 118 Лучший M3C 11.2 10.7 11.7 12.4 11.8 12.2 12.6 13.2 16.2 18.2 11.54 12.06 13.85 1428 Худший M3C 15.3 13.8 15.7 17.0 15.3 15.6 17.4 17.5 22.2 24.3 15.39 15.89 18.4 1428 zlib 16 интервалов 14.4 14.9 17.3 19.4 20.9 17.9 20.4 19.0 25.6 26.5 16.51 18.42 21.23 1428 ppmd 16 интервалов 14.0 14.1 15.7 20.2 16.8 20.6 17.7 18.0 24.6 25.5 17.23 18.76 19.95 1428 rp 16 интервалов 15.6 15.7 17.9 19.7 21.2 18.5 19.1 20.7 26.4 26.9 15.44 17.26 21.55 1428 zlib ppmd rp 16 интервалов 14.0 14.1 15.8 19.6 21.2 18.3 19.1 20.6 25.9 26.7 15.86 18.02 21.13 1428 zlib ppmd rp 32 интервала 14.0 14.1 15.8 19.6 21.2 18.4 19.1 20.6 26.0 26.7 15.86 18.02 21.13 1428 ppmd 16 интервалов, подбор порядка разности 13.4 13.2 14.7 17.5 19.1 16.4 17.5 17.6 22.3 24.4 14.70 16.52 18.87 1428 Результаты прогнозирования прочих other данных из M3C Метод Ошибка sMAPE для номера шага Среднее Количество рядов 1 2 3 4 5 6 8 14 16 18 Лучший M3C 1.6 2.7 3.8 4.3 5.3 5.1 6.0 3.17 3.86 4.38 174 Худший M3C 2.7 3.8 5.4 6.3 7.8 7.6 9.2 4.38 5.49 6.3 174 zlib 16 интервалов 2.5 3.4 4.9 6.3 8.3 7.7 8.9 4.25 5.49 6.33 174 ppmd 16 интервалов 2.4 3.2 4.7 5.1 7.1 6.9 8.2 3.85 4.90 5.68 174 rp 16 интервалов 2.7 3.9 5.8 6.9 8.0 8.5 10.3 4.84 5.97 6.87 174 zlib ppmd rp 16 интервалов 2.4 3.2 4.7 5.1 7.3 6.8 8.1 3.85 4.91 5.70 174 zlib ppmd rp 32 интервала 2.4 3.2 4.7 5.0 7.2 6.8 8.1 3.84 4.90 5.69 174 Результаты расчетов для временного ряда T-индекса Метод Ошибка MAE для номера шага Среднее Количество рядов 1 2 3 4 5 6 8 12 15 18 14 18 118 Прогноз метеорологического бюро 13.0 14.2 14.8 15.7 16.5 18.0 21.2 23.5 25.6 27.0 14.43 16.69 21.09 61 zlib 16 интервалов 12.3 16.0 18.3 20.4 19.1 21.5 24.9 24.5 28.8 26.5 16.75 19.70 23.68 61 ppmd 16 интервалов 11.9 15.2 17.4 20.9 21.5 22.7 18.8 25.7 30.6 25.5 16.34 18.56 22.87 61 rp 16 интервалов 12.5 18.1 18.6 18.3 24.9 24.5 22.6 33.4 38.3 41.9 16.86 21.10 28.2 61 zlib ppmd rp 16 интервалов 11.9 15.2 17.4 20.8 21.5 22.0 18.8 24.9 29.4 24.2 16.31 18.46 22.57 61 zlib ppmd rp 32 интервала 11.8 15.2 17.4 21.2 21.5 22.0 18.8 25.4 28.7 26.1 16.39 18.51 22.67 61 В рамках данной работы был разработан и экспериментально исследован метод прогнозирования временных рядов, базирующийся на широко известных архиваторах. Показано, что точность данного метода во многих случаях сравнима с точностью других методов прогнозирования и он представляет практический интерес. Возможно совмещение предлагаемого метода с распространенными методами предварительной обработки данных для повышения точности прогноза. "}
{"title": "АДАПТАЦИЯ СТРУКТУРЫ МЕНЮ УСЛУГ   ДЛЯ РАЗЛИЧНЫХ ТИПОВ ПОЛЬЗОВАТЕЛЕЙ   С ПРИМЕНЕНИЕМ ОНТОЛОГИЧЕСКОГО МОДЕЛИРОВАНИЯ    ", "absract": "Статья посвящена решению проблемы адаптации больших древовидных и линейных меню мобильных и интернет-услуг для различных типов пользователей на основании их интересов, социального статуса, а также иных параметров. Разработана программная система, строящая оптимальное меню услуг для классов пользователей, разделенных по социально-экономическим и физическим параметрам, с использованием модифицированного алгоритма построения оптимального графа USSD-меню. В работе используется онтологический подход для формального представления понятий данной предметной области, извлечения, представления и обработки знаний. Для адаптации интерфейсов используются модели пользователей, представляющие описания их потребностей, целей, интересов. Формализация поведения пользователей осуществляется при помощи онтологической модели мобильных и интернет-услуг. Каждого пользователя можно отнести к определенной модели на основании его физических и социальных параметров. Программа, реализующая адаптацию меню, состоит из двух модулей: модуль получения частот вызова услуг на основе запросов к онтологии и модуль оптимизации графа меню. Алгоритм оптимизации меню работает с языком описания графов DOT. : онтология, онтологическое моделирование, атомарные диаграммы, извлечение знаний, порождение знаний, иерархические меню, адаптация меню, анализ потребностей, задача оптимизации, пользовательские интерфейсы. ", "text": "Статья посвящена адаптации иерархических меню для различных типов пользователей. Решается проблема адаптации больших древовидных и линейных меню мобильных и интернет-услуг на основании интересов пользователей, их социального статуса, а также иных параметров. В работе используется онтологический подход для формального представления понятий данной предметной области, извлечения, представления и обработки знаний. Оптимизация интерфейсов проводится с помощью модифицированного алгоритма построения оптимального графа USSD-меню. Формализация поведения пользователей осуществляется при помощи онтологической модели мобильных и интернет-услуг. Информационные технологии глубоко проникли в нашу жизнь. С развитием сети Интернет и увеличением ее доступности бизнес начал двигаться в сторону автоматизации своих процессов и предоставления своих услуг в удаленном режиме клиенту нет необходимости приходить в офис или точку продаж, достаточно открыть приложение на компьютере или телефоне, нажать несколько кнопок и радоваться совершению покупки. Оплата ЖКХ, замена паспорта, заказ еды, бронирование отелей вс осуществляется через глобальную паутину путем взаимодействия пользователей с меню услуг. Более того, в последнее время крупные сети кафе и ресторанов начали внедрять электронные меню человеку не нужно звать официанта, чтобы заказать обед у него на столе есть планшет с установленным приложением ресторана, в котором все блюда разбиты на категории, а также есть дополнительные опции, вроде регулирования количества сахара и различных добавок. Гостю заведения необходимо просто выбрать то, что ему нравится, и ожидать, когда подадут блюда. Очевидно, что у разных людей разные интересы. Для одного клиента нужные услуги могут быть на верхнем уровне меню, а для другого спрятаны где-то глубоко. Соответственно, компания может потерять покупателя, который не смог найти требуемую ему услугу или товар, а покупатель, блуждая в лабиринтах программы, теряет свое время на бесполезный поиск. Аналогично с контекстной рекламой. Например, вегетарианцу нет смысла демонстрировать акцию о скидке на стейки или человеку со средним доходом турпутевки за 2 миллиона рублей. Таким образом, чтобы избежать перечисленных проблем или свести их к минимуму, существует необходимость адаптации меню для конечного пользователя. Адаптация это оптимизация с учетом пользовательской модели, которая представляет собой набор параметров, описывающих целевого пользователя его возраст, бюджет, социальный статус, интересы, географическое расположение и т. п. Области использования адаптации меню достаточно широки и разнообразны USSD-сервисы интернет-каталоги товаров электронные меню ресторанов меню порталов туристических услуг и услуг бронирования меню образовательных порталов диалоговые меню чат-ботов интерфейсы программ. В настоящее время уже существуют работы, которые используют онтологический подход к определению потребностей пользователей или других параметров, на основании которых можно определить наиболее релевантные предложения для каждого пользователя. Например, формульное описание диагнозов по симптомам на основании историй болезней 1 или определение предпочтений абонентов мобильных сетей по их характеристикам 2. В данной работе предложены алгоритм получения частот использования услуг на основании модели пользователя и алгоритм оптимизации иерархических меню по полученным частотам, который является модифицированным алгоритмом оптимизации USSD-меню 3. Алгоритм получения частот использования услуг основан на онтологическом подходе для формального представления понятий данной предметной области, извлечения, представления и обработки знаний 46. Для адаптации интерфейсов используются модели пользователей, представляющие описания их потребностей, целей, интересов 10. Формализация поведения пользователей осуществляется при помощи онтологической модели интернет-услуг 8 9 11. Меню услуг это направленный ациклический граф, вершины которого представляют элементы меню, а ребра задают пути между этими элементами. Первый уровень меню множество вершин графа со степенью захода 0. Разделы меню узлы графа. Услуги множество вершин графа с нулевой степенью исхода. Элемент меню элемент множества раздел меню, услуга. Переход по меню ветвь между двумя элементами меню. Выделяются три типа иерархических меню. 1. Линейное меню рис. 1, меню, в котором все услуги имеют степень захода, равную нулю. Другое название такого меню лента услуг. В чистом виде встречается редко, но в любом иерархическом меню можно выделить по крайней мере одно линейное меню для каждого раздела. 2. Древовидное меню моноиерархическое меню рис. 1, меню, в котором любой элемент, не принадлежащий первому уровню, имеет степень захода, равную 1. Является частным случаем мультииерархического меню. 3. Мультииерархическое меню рис. 1, меню, в котором любой элемент, не принадлежащий первому уровню, имеет степень захода, равную натуральному числу. Примером такого меню является любое древовидное меню с разделом Избранное, в котором услуги из этого раздела имеют степень захода, равную двум. Адаптация меню это оптимизация меню для конкретного портрета пользователя на основании его параметров. Для того чтобы дать определение оптимизации меню, необходимо определить целевую функцию. Пусть количество заказов -й услуги пользователем, количество услуг в меню. Тогда обозначим общее количество заказов услуг пользователем . Пусть минимальное количество переходов в меню нажатий клавиш или кликов мышкой для заказа -й услуги. Тогда обозначим общее количество нажатых пользователем клавиш . Функция подвергается минимизации. Но в задаче удобней работать с заказа каждой услуги, а не с заказов. Именно поэтому вводим величину вероятность вызова -й услуги. И вместо функции проводим минимизацию функции . Несложно доказать, что минимизация влечет за собой минимизацию . Действительно, где const, откуда следует, что обе функции имеют экстремумы в одних и тех же точках. Задачей оптимизации меню, предоставляющего услуг, назовем минимизацию функции ., где вероятность вызова -й услуги, а минимальное количество нажатий клавиш, необходимое для заказа -й услуги. Для минимизации сумм нам необходимо определить параметр для каждой услуги. В данной работе применяется теоретико-модельный подход для определения вероятностей строится онтологическая модель предметной области на основе ключевых понятий этой предметной области, ее законов и постулатов, а также множества прецедентов. Для описания прецедентов портреты пользователей и статистика заказа услуг. Таким образом, получаем следующие этапы адаптации меню 1 получение информации о пользователях и составление их портретов на основе полученных характеристик 2 построение векторов вероятностей заказа услуг для конкретного портрета пользова теля 3 оптимизация меню с помощью алгоритма оптимизации на основании вероятностей заказа услуг. Самый простой способ адаптировать меню услуг под определенного пользователя это изучить историю его заказов этих услуг. Соответственно чем больше заказов определенной услуги, тем больший вес она будет иметь в итоге, и тем ближе к началу меню ее расположит алгоритм оптимизации. Но здесь есть две важные проблемы. Во-первых, у пользователя такой истории может не быть а тем более достаточно подробной, чтобы для каждой услуги можно было вычислить частоту ее использования. Во-вторых, история теряет актуальность список услуг и портрет пользователя постоянно меняются. Поэтому для более релевантной адаптации меню следует найти способ получения более актуальной и полной информации о пользователях и услугах. И на основании этой информации можно будет составить список характеристик пользователя и услуг и построить онтологическую модель для определения вероятностей использования определенных услуг определенными пользователями. В наше время, наверно, почти не осталось людей, которые не имеют аккаунтов в социальных сетях ВКонтакте, Одноклассники, Facebook, к которым присоединились Twitter и Instagram. С развитием рынка смартфонов и беспроводного Интернета пользователи все больше и больше времени проводят в соцсетях. Вместе с этим соцсети оказываются отличным описанием профиля пользователей. Можно посмотреть личную информацию о человеке пол, возраст, место жительства, интересы, количество друзей и подписчиков, его сообщества, добавленную музыку, фотографии и т. п. Самая популярная социальная сеть в России и СНГ ВКонтакте. Именно поэтому она была выбрана в качестве целевой платформы для получения информации о пользователях. ВКонтакте предоставляет публичный программный интерфейс VK API, с помощью которого можно программно получить подробную информацию о пользователях в виде JSON-объектов рис. 2. В работе с помощью VK API были получены параметры для нескольких тысяч обезличенных пользователей, каждому из которых был приписан уникальный id для последующей идентификации. Среди параметров были город, образование, место работы, стаж работы по сумме лет, интересы по ключевым словам, книги, фильмы, музыка, количество друзей, количество подписчиков, количество фотографий, сообщества. Есть один важный параметр, который невозможно напрямую получить с помощью социальных сетей, уровень дохода. Однако его можно приблизительно вывести с помощью информации об образовании, месте жительства, месте работы и стаже работы. Также в работе уровень дохода не исчисляется абсолютными величинами, а выражается фиксированным набором значений, аппроксимирующим определенные интервалы чисел очень маленький, маленький, ниже среднего, средний. Таким образом, используя социальные сети, можно построить достаточно полный портрет пользователя и список характеристик, на основании которых можно адаптировать меню под пользователя с определенным портретом. В работе целевой предметной областью был выбран рынок туристических услуг. Во-пер вых, туризм всегда актуален, во-вторых, предложения имеют очень широкий ценовой спектр и спектр интересов, в-третьих, туристический рынок имеет очень богатую классификацию услуг билеты на самолеты и поезда, аренда автомобилей, отели, визы, гиды, переводчики, круизы... Для построения и структурирования знаний о предметной области рынка туристических услуг была определена онтологическая модель, состоящая из четырех уровней набор ключевых понятий предметной области, универсальные общие утверждения, эмпирические данные и оценочные знания. На первом уровне онтологической модели описываются понятия предметной области, а также даются определения этим понятиям. Для предметной области рынка туристических услуг описываются такие понятия, как рейс, отель, лоукостер, виза, отель, достопримечательность, культура, религия, тур местный, внутренний, внешний, санаторий, туроператор, бронирование, сезон, попутчик, гражданство, страховка, хостел, город и т. п. На втором уровне онтологической модели представлены знания о предметной области, т. е. строится формальное описание всех объектов, которые были выделены на первом уровне онтологической модели, а также принципов и закономерностей. Ключевым моментом является то, что все описываемые знания являются достоверными лишь на данный момент, в будущем они могут меняться. Таким образом, онтологическая модель поддерживает актуальность. Для описания знаний выбран формат обмена данными JSON рис. 3, так как он хорошо читается и удобно сериализуется. Каждый объект может иметь внутри себя множество свойств трех типов характеристику, другой объект и массив объектов. Характеристика это такой тип свойства, который может принимать значения из конечного множества. Например, характеристика класс обслуживания может принимать значение из множества Первый класс, Бизнес-класс, Премиальный-экономический класс, Экономкласс. Центральный объект онтологической модели предметной области рынка туристических услуг Услуга. Он обладает четырьмя характеристиками название, тип услуги, стоимость и дата. Характеристика Тип услуги, как будет описано далее, требуется алгоритму подсчета вероятностей заказов услуг. Она может принимать два значения простая услуга и контейнер. Все остальные объекты наследуют эти характеристики и имеют свои уникальные. Особняком стоит объект Тур, который и сам является услугой, и внутри себя содержит массив услуг, при этом его стоимость равна сумме стоимости входящих в него элементов. Эмпирические данные это данные, описывающие прецеденты предметной области, иными словами, это история взаимодействия пользователей с системой, предоставляющей услуги. Формальное описание каждого прецедента задается в виде фрагмента атомарной диаграммы 7. Атомарная диаграмма модели это множество атомарных предложений, т. е. предложений вида,...,..., где,..., константы, а предикат. В нашем случае каждое атомарное предложение имеет следующий вид Человек с характеристиками Доход 70000, Город Новосибирск, ... заказал услугу с характеристиками Название Рейс в Санкт-Петербург, Авиакомпания S7, Стоимость 10000, .... Таким образом мы получаем описание всех профилей пользователей. Вероятностные знания можно получить двумя способами взять из каких-либо внешних источников или провести анализ эмпирических данных нашей онтологической модели и сопоставить их с универсальными знаниями. Информация, получаемая в результате анализа эмпирических данных, подразделяется на два уровня уровень данных и уровень знаний. Уровень данных это информация, полученная полностью автоматическим способом на основе разбора ассоциативных правил и вычисления частот использования услуг по определенному алгоритму. На уровне знаний информация не может быть получена в полностью автоматическом режиме. Необходимо вмешательство эксперта, который анализирует информацию, полученную на уровне данных, и делает финальные выводы. Однако по информации, полученной на уровне данных, можно получить знания об интересах каждого пользователя, если ввести аксиому о том, что чем выше вероятность заказа услуги в прошлом, тем она выше и в будущем. Таким образом, построив алгоритм вычисления вероятностей заказа услуг, можно будет проводить адаптацию меню на основе этой информации. На втором уровне онтологической модели были описаны все туристические услуги. Каждая услуга имеет набор характеристик. Характеристики потребителей, в свою очередь, были получены путем анализа аккаунтов в соцсетях. Итак, имеем следующее пользователя определяют характеристики пользователя, и, в свою очередь, услугу определяют характеристики услуги. Поэтому, определив частоту, с которой каждая характеристика с названием и значением, фигурирующая у пользователей, и каждая характеристика, принадлежащая услугам, встречались вместе в атомарном предложении, можно для каждого пользователя вычислить вероятность заказа любой услуги. Из рассуждений, описанных выше, можно построить алгоритм, который выглядит следующим образом. 1. Для всех возможных характеристик потребителей составляется вектор весов каждой характеристики услуг по всем ее значениям на основании анализа эмпирических данных, а именно подсчета связей Характеристика x пользователя Характеристика y услуги для всех x, y, i, j, где x и y названия характеристик, а x и y значения из множества значений. Пример для анализа берем характеристику Город Новосибирск. Из всех атомарных предложений выбираются те, где пользователи имеют характеристику Город Новосибирск, и для каждой характеристики услуг подсчитываются ее вхождения в атомарные выражения. Таким образом, для каждого значения каждой характеристики пользователя получается список весов значений характеристик услуг Компания S7 Компания Аэрофлот ... Город Новосибирск 40 40 Город Томск 35 32 ... Стоимость 610 тыс. Стоимость 1115 тыс. ... Город Новосибирск 39 12 Город Томск 47 11 ... 2. Для конкретного потребителя составляется список частот услуг следующим образом. A. По очереди выбирается каждая услуга и ее характеристики образуют список. B. Для каждой характеристики из списка подсчитывается ее вес по частотам, полученным в п. 1. Вес услуги это среднее арифметическое весов ее характеристик. C. После того как посчитан вес для каждой услуги, эти веса делятся на общую сумму весов всех услуг. D. Дополнительно. Если тип услуги контейнер например, услуга Тур, то шаг 2 выполняется рекурсивно для всех услуг, входящих в массив, и считается их среднее арифметическое. В результате получаем вероятность выбора каждой услуги. Следует отметить, что шаг 1 алгоритма выполняется всего один раз, а при каждом новом заказе услуги просто пересчитываются некоторые значения, которые относятся к характеристикам данной услуги. Шаг 2 выполняется многократно для каждого пользователя отдельно. Более того, с определенной периодичностью следует пересчитывать и для одного и того же пользователя, чтобы предложения услуг не теряли свою актуальность. Таким образом, мы построили онтологическую модель предметной области рынка туристических услуг и с помощью нее для каждого пользователя вычислили вероятность заказа каждой услуги. Алгоритм оптимизации иерархических меню получает на вход список пар название услуги вероятность использования услуги. Пусть свободный узел графа это узел графа, который не имеет родителей. Таким образом, алгоритм оптимизации получает на вход список свободных узлов, которыми являются пары название услуги вероятность использования услуги. Пусть максимально возможное количество ветвей узла, которое задается пользователем. Если обратиться к исследованиям в области когнитивной психологии, то найдем оптимальное значение 7 2. Однако в действительности оптимальное значение зависит от задачи. Пусть количество оставшихся свободных узлов на -м шаге итерации алгоритма. Выбирается свободных узлов с наименьшей вероятностью использования услуги. Затем создается родитель этих узлов, значение частоты которого является суммой частот его прямых потомков. Далее его потомкам присваиваются идентификаторы от 1 до, сами потомки удаляются из списка свободных узлов, поскольку у них появился родитель, а их родитель добавляется в этот список рис. 4. Имя родителя во время работы алгоритма задается случайным образом например, по первым буквам имен его потомков и в алгоритме роли не играет. В любом случае после процесса оптимизации меню для всех новых узлов название определяется человеком. Далее все шаги повторяются до тех пор, пока количество текущих свободных узлов не станет равным максимальному количеству ветвей на узле . Эти свободные узлы и образуют корневые порталы меню. В итоге получается оптимальная структура меню, а именно такая структура, где чем выше вероятность использования определенной услуги, тем эта услуга будет находиться ближе к корню меню. Каждая услуга в полученном меню строго определяется последовательностью переходов в графе, т. е. последовательностью кликов мышки или нажатий клавиш, которые должен сделать пользователь, чтобы вызвать ее. В чистом виде приведенный алгоритм может в определенных ситуациях не строить оптимальное меню. Проблема заключается в том, что на последнем шаге алгоритма иногда останется менее, чем свободных узлов. Это происходит в тех случаях, когда количество услуг в меню будет иметь такое значение, что 1, где число шагов, за которое алгоритм построит меню. В этом случае на первом уровне меню количество ветвей будет меньше максимального рис. 5, когда ожидаемый результат работы алгоритма недостаток ветвей возможен только на последнем уровне. Для того чтобы решить эту проблему, перед первым шагом алгоритма следует оценить число свободных узлов, которое останется на последнем шаге, и, если оно окажется меньше, на первом шаге за максимальное количество элементов на узле вместо принять, получившееся в результате оценки рис. 6. Таким образом, количество ветвей ниже максимального окажется именно на последнем уровне меню, что вполне допустимо, и, более того, является достаточно частой ситуацией, так как почти всегда количество услуг имеет кратность, отличную от количества подменю рис. 7. Для тестирования адаптации меню с помощью Json-генератора были созданы 913 услуг, а также построена история о 30 000 заказах услуг. Эти услуги были разбиты на следующие категории билеты на самолет, отели, круизы, визы, сувениры, гиды, переводчики, аренда автомобилей. Каждая категория была разбита, в свою очередь, еще на несколько подкатегорий. Тестирование проводилось на полной выборке из 30 000 заказов услуг, а также на выборках случайных 10 000 и 20 000 заказов из полной выборки. Программа тестировалась в двух режимах режим пагинации и режим дерева. В первом режиме категории меню разбивались на страницы, а во втором режиме строилось мультииерархическое меню. Сокращение количества нажатий клавиш пользователем для выбора требуемой услуги составило от 29 до 35 рис. 8. В настоящей работе решается задача адаптации структуры меню услуг для различных типов пользователей. Разработан алгоритм составления векторов вероятностей услуг на основе построения онтологической модели предметной области. Построена трехуровневая модель предметной области рынка туристических услуг. Характеристики пользователей были получены с помощью анализа профилей социальной сети ВКонтакте программным модулем, использующим публичный программный интерфейс VK API. Разработаны два алгоритма оптимизации меню в зависимости от его структуры режим построения пагинации для линейного меню и режим построения дерева для древовидных меню. Если для алгоритма используется уже ранее построенное меню, в котором нельзя удалять переходы, то алгоритм поддерживает построение мультииерархического меню. Онтологическая модель реализована программно на языке OWL в редакторе Protege с маппингом в базу данных MongoDB для более удобных операций над данными на уровне кода. В качестве языка программирования выбран C, а в качестве платформы для приложения ASP.NET MVC. Для работы с графами на языке C использовалась библиотека QuickGraph, поддерживающая язык описаний DOT. Тестирование адаптации было проведено на меню услуг, состоящим из 913 элементов, в двух режимах пагинации и построения дерева. Среднее сокращение количества времени выбора услуги пользователем составило 2935 . В дальнейшем планируется модифицировать алгоритм построения частот использования услуг. "}
{"title": "НЕКОТОРЫЕ ПОДХОДЫ К ХРАНЕНИЮ ИНФОРМАЦИИ   О КНИГООБЕСПЕЧЕННОСТИ УЧЕБНОГО ПРОЦЕССА   ВЫСШЕГО УЧЕБНОГО ЗАВЕДЕНИЯ  ", "absract": "Рассматриваются три подхода к хранению информации о книгообеспеченности учебного процесса при различных вариантах интеграции автоматизированной библиотечной информационной системы (АБИС) с информационной системой вуза: внутри АБИС в формате RUSMARC, в виде реляционной базы данных, с использованием технологии OLAP. Анализируются преимущества и недостатки каждого подхода, приводятся примеры организации хранения данных (поля RUSMARC, измерения и меры для кубов OLAP). : книгообеспеченность, вузовская библиотека, АБИС, интеграция с информационной системой вуза, OLAP. ", "text": "Книгообеспеченность КО как понятие это определение числа экземпляров книг, отобранных по разным критериям, в расчете на одного студента по специальностям, направлениям и профилям обучения, по видам и формам обучения, по конкретным дисциплинам, по видам учебной литературы и т. д. В качестве основного показателя коэффициента книгообеспеченности предлагается показатель КО конкретной дисциплины, который определяется как частное от деления количества экземпляров учебной литературы, имеющейся в библиотеке по данной дисциплине, на число студентов, ее изучающих. Таким образом, в библиотеках учебных заведений электронная картотека книгообеспеченности ЭКК является активной подсистемой и реализует основные функции управления библиотечными фондами 1 2 рис. 1, 2. Нормативные документы 3 4 для высших учебных заведений определяют нормы и правила доступа обучающихся к литературе. Из 3 через федеральные государственные образовательные стандарты ФГОС следует наличие основной учебной литературы из расчета обеспечения каждого обучающегося по всем дисциплинам реализуемых образовательных программ в количестве 0,5 экземпляра на 1 студента, дополнительной учебной литературы в количестве 0,25 экземпляра на 1 студента. Также во ФГОС задано право обучающихся на индивидуальный неограниченный доступ к электронно-библиотечной системе, содержащей издания учебной, учебно-методической и иной литературы по основным изучаемым дисциплинам, т. е. вводится применение электронных библиотечных систем ЭБС. В 4 оценивается доля укрупненных групп специальностей и направлений подготовки, обеспеченных литературой из ЭБС. Соответственно коэффициент КО отражает степень обеспеченности книгой того количества студентов, для которых она предназначена. Если учитывать множественность критериев для ее оценки, то становится ясно, насколько это трудоемкий процесс, требующий большого числа расчетов. Поэтому вполне закономерно, что в течение последних лет в составе многих систем автоматизации библиотек появились средства ведения ЭКК 1 2 5. Основными исходными данными для функционирования ЭКК являются учебные планы высшего учебного заведения контингент студентов вуза учебные программы дисциплин издания, рекомендуемые к использованию в учебном процессе независимо от вида документа. Таким образом, построение ЭКК ведется на стыке двух крупнейших информационных систем образовательной организации электронного каталога библиотеки, хранимого в автоматизированной библиотечной информационной системе АБИС, и информационной системы учебного процесса вуза ИС ВУЗ 1 2. Характер информации, хранимой в перечисленных информационных системах, определяет требования к организации системы хранения данных ЭКК 1 совместимость с АБИС 2 совместимость с ИС ВУЗ 3 отсутствие необходимости в моментальном online обновлении данных. Указанные требования к системе хранения данных в определенных комбинациях противоречат друг другу. Также в системе ЭКК может находиться информация, ранее накопленная, но к настоящему моменту исключенная из требований нормативных документов например, требование к устареваемости фонда, циклы дисциплин и т. п. По результатам проведенного анализа предлагаются 3 модели хранения данных о книгообеспеченности учебного процесса в ЭКК вуза модель данных на базе формата UNIMARC RUSMARC модель данных на базе реляционных баз данных БД модель данных на базе технологии OLAP 5. Каждый метод имеет свои преимущества и недостатки в части хранения данных. Формат UNIMARC призван быть посредником при осуществлении обмена библиографическими записями между книгоиздателями и потребителями библиотеками. Официальной российской версией UNIMARC является RUSMARC или российский коммуникативный формат, разработанный по заказу Министерства культуры РФ в рамках программы LIBNET под эгидой Российской библиотечной ассоциации. Описание UNIMARC RUSMARC разбито на блоки с 3-значными описаниями, каждый из которых отвечает за строго определенную часть описания. Блоки с номерами больше 900 оставлены для свободного описания в так называемом Блоке локального использования 6. Соответственно для ведения ЭКК предлагается использовать следующие поля из блока 900 пример 930 дисциплина, которая комплектуется данным изданием 931 код книгообеспеченности литературы со значениями 1 основная литература, 2 дополнительная литература и т. д. 932 наличие электронного издания со значениями 0 отсутствует,1 присутствует 933 наличие этого издания в ЭБС, доступных в вузе со значениями 0 отсутствует, 1 присутствует 934 название ЭБС если присутствует 935939 резерв, например для указания циклов компонент дисциплин. К достоинствам данной модели хранения информации следует отнести полную интеграцию в электронный каталог библиотеки. Например, библиотекарь может построить списки рекомендованной литературы по дисциплине для преподавателей и студентов. Недостатком модели является отсутствие связей с информационной системой вуза, в том числе отсутствие данных о численности студентов и, как следствие, самих коэффициентов КО. Ситуация может быть решена за счет импорта данных из ИС ВУЗ в АБИС. Предлагается использовать следующие поля 940 количество студентов 941 количество студентов по дневной форме обучения 942 количество студентов по заочной форме обучения 943 приведенное количество студентов 1 студент очной формы обучения 10 студентов заочной формы обучения 944 количество студентов, изучающих дисциплину в этом учебном году 945 количество студентов, изучающих дисциплину в 1-м семестре в этом учебном году 946 количество студентов, изучающих дисциплину во 2-м семестре в этом учебном году 947 кафедра, ведущая данную учебную дисциплину 948 направление специальность, которое изучает данную учебную дисциплину 949 профиль внутри направления, которое изучает данную учебную дисциплину 950 коэффициент книгообеспеченности основной литературой 951 коэффициент книгообеспеченности дополнительной литературой и т. д. 5. Основным назначением UNIMARC RUSMARC является обмен данными, т. е. данный формат изначально был оптимизирован для обмена информацией, но не для хранения и выбора. Поэтому АБИС, как правило, имеют собственный движок, основанный на принципах реляционных баз данных, либо используют тиражируемые системы управления базами данных. Переход от формата UNIMARC RUSMARC к формату, поддерживающему реляционные системы управления базами данных, осуществляется по следующей схеме каждый блок в описании RUSMARC рассматривается как отдельная сущность см. таблицу. Перевод хранения данных ЭКК в формат реляционных БД позволяет подключать данные об учебном процессе вуза. Следовательно, внедрение данных о книгообеспеченности в ИС ВУЗ позволит оценивать необходимость комплектования библиотеки для существующих и планируемых специальностей, проводить мониторинг состояния обеспеченности учебного процесса, оперативно информировать кафедры о книгообеспеченности отдельных дисциплин и необходимости доукомплектования литературой. Список измерений и их иерархии Измерения куба Описание измерения и мер 1 Виды книгообеспеченности см. прим. к таблице 1.1 Книгообеспеченность основной литературой 1.2 Книгообеспеченность дополнительной литературой 2 Учебные дисциплины 2.1 Количество студентов 2.1.1.2 Количество студентов по дневной заочной форме обучения 2.1.3 Приведенное количество студентов 1 студент очной формы обучения 10 студентов заочной формы обучения 2.2 Количество студентов, изучающих дисциплину в этом учебном году 2.2.1.2 Количество студентов, изучающих дисциплину в 1-м 2-м семестре 3 Издания 3.1 Вид издания 3.1.12, Учебники, учебные пособия, монографии и т. д. 3.2 Признак наличия изданий в ЭБС 3.3 Количество экземпляров 3.3.1 Количество экземпляров за весь срок 3.3.2.3 Количество экземпляров, изданных за последние 5 10 лет Поскольку часть информации из ИС ВУЗ может быть доступна студентам, то появляется возможность их информирования о рекомендуемой учебной литературе, распределении учебной литературы по группам, семестрам, формам обучения и т. д. 5. При всех достоинствах применения модели хранения информации на базе реляционных БД процесс формирования показателей о КО в основном использует крайне трудоемкую операцию выбора данных из БД т. е. команду SELECT. Таким образом, логично перейти от систем управления БД к системам управления банками данных по технологии OnLine Analytical Processing OLAP 5 7. OLAP делает мгновенный снимок реляционной БД и структурирует ее в пространственную модель для запросов. Заявленное время обработки запросов в OLAP составляет около 0,1 от аналогичных запросов в реляционную БД. OLAP-структура, созданная из рабочих данных, называется OLAP-куб или куб данных. Куб создается из соединения таблиц с применением схемы звезды или схемы снежинки. В центре схемы звезды находится таблица фактов, содержащая ключевые факты, по которым делаются запросы. Множественные таблицы с измерениями присоединены к таблице фактов. Эти таблицы показывают, как могут анализироваться агрегированные реляционные данные. Количество возможных агрегирований определяется количеством способов, которыми первоначальные данные могут быть иерархически отображены. Индексам массива соответствуют измерения dimensions или оси куба, а значениям элементов массива меры measures куба 8. Для ЭКК предлагается проект куба данных по хранению информации о книгообеспеченности учебного процесса. Для наполнения куба данных возможен экспорт данных из АБИС библиотеки как правило, в формате RUSMARC и данных ИС ВУЗ как правило, из реляционных БД 5. Минимальное количество измерений проектируемого куба 2 Учебные дисциплины, описывающие перечень дисциплин, изучаемых в вузе, и Издания, представленные количеством изданий, закрепленных за дисциплиной. Список иерархий измерений и мер куба представлен в таблице см. выше, на рис. 1 и 2 приведены графические представления проектов кубов данных при различных вариантах измерений и мер. Еще одной мерой куба данных является количество экземпляров литературы, закрепленных за дисциплиной, которое позволит библиотеке вуза оценить комплектование дисциплины в абсолютных показателях. Распределение экземпляров между сходными и смежными дисциплинами ведется пропорционально числу студентов, изучающих дисциплины. Применение банков данных для хранения данных о книгообеспеченности учебных дисциплин потребует организации экспорта данных как из электронного каталога библиотеки, так и из баз данных системы ИС ВУЗ. Также необходимо разработать приложение для работы с созданным кубом данных OLAP. Однако в результате получаемая автономность от АБИС и ИС ВУЗ в сочетании с высокой скоростью работы за счет заранее вычисленных показателей позволяет говорить о перспективе использования технологии OLAP в плане управления книгообеспеченностью вузовских библиотек 5 7. "}
{"title": "МОБИЛЬНОЕ ПРИЛОЖЕНИЕ НЕПРЕРЫВНОЙ ПЕРЕДАЧИ ВИДЕОДАННЫХ   В ОБЛАЧНЫЕ СЕРВИСЫ  ", "absract": "Представлен способ получения видеодоказательств с помощью мобильного устройства – приложения для Android, позволяющего оперативно начать видеотрансляцию в облачные сервисы. Для оперативности запуска пользователю доступен виджет, который можно разместить на экране устройства. При нажатии на виджет начинается видеосъемка и отправка получаемой записи в облачный сервис, необходимая для обеспечения сохранности уже полученных данных даже в случае повреждения устройства. Для того чтобы в непредвиденной ситуации, повлекшей за собой утрату телефона, как можно больше данных оказалось сохранено на облачном сервисе, выбрана малая продолжительность одного передаваемого фрагмента – одна секунда. По завершении записи пользователь имеет возможность собрать составляющие записи воедино, при необходимости загружая недостающие фрагменты из облачного сервиса. Практическая ценность приложения заключается в том, что оно позволяет достаточно быстро и надежно фиксировать события, а собранные видеоматериалы могут быть полезны как в судебных процессах, так и для самостоятельного изучения. В статье проведен анализ существующих решений, позволяющих вести видеотрансляцию; выявлены их недостатки, затрудняющие использование этих средств для получения доказательств. Рассмотрена архитектура приложения, построенная на базе шаблона проектирования MVC и включающая в себя 6 модулей. Описана реализация приложения и показан разработанный интерфейс. ", "text": "В современной российской судебной практике в качестве доказательств принимаются аудиои видеоматериалы. Ранее процессуальное законодательство было недостаточно проработано решение о приобщении видеоматериалов к делу в административном, уголовном, гражданском и арбитражном процессах принимал судья. Однако в апреле 2016 г. был подписан указ 1, согласно которому звукои видеозаписи признаются документами и выступают как доказательства в административных делах, если они имеют значение для рассмотрения и разрешения дела . Благодаря этому указу, рассматривая административные дела, судьи обязаны принимать к рассмотрению видеозапись, и теперь вопрос уже о признании ее достоверности. Ведение видеозаписи полезно не только как средство фиксирования событий в потенциально опасных ситуациях, но и как превентивная мера. Если возможный правонарушитель осознает, что его действия записываются, то более вероятно, что он воздержится от правонарушения. Видеозапись может использоваться не только для фиксации правонарушений. При соблюдении соответствующего законодательства человек вправе снимать различные эпизоды своей жизни, чтобы в дальнейшем вернуться к ним, проанализировать произошедшие события. Ему даже необязательно пересматривать записи целиком, чтобы найти что-либо интересное уже существуют многочисленные способы автоматизированного извлечения информации из видеоматериалов. Так, например, были предложены способы обнаружения некоторых типов событий оставление, перебрасывание предмета и пр. 2 Доступным способом сделать видеозапись является использование мобильного телефона. Как правило, когда случается что-то экстренное, у человека под рукой нет видеокамеры. Зато есть мобильное устройство еще в 2013 г. мобильными телефонами пользовалось 98 российских граждан 3. Однако при создании видеозаписи с помощью мобильного устройства существует две проблемы 1 на запуск видеосъемки может затрачиваться много времени 2 в случае утраты телефона не обеспечивается сохранность данных. Таким образом, актуальными задачами являются выбор способа быстрого запуска видеозаписи с мобильного устройства и создание средств, обеспечивающих сохранность видеозаписи даже при разрушении мобильного устройства. В статье описано мобильное приложение, которое обеспечивает оперативность запуска записи с помощью виджета на экране и сохранность видеозаписи за счет непрерывной передачи видеофрагментов длительностью 1 секунда в облачные сервисы. Авторами статьи был выбран определенный набор используемых технологий. Для обеспечения сохранности видеозаписи было предложено отправлять запись на удаленные серверы непосредственно в процессе ее создания. Удаленные серверы должны удовлетворять двум основным требованиям они должны быть надежными и предоставлять минимум 5 Гб хранилища без взимания платы. Таким требованиям удовлетворяют многие облачные сервисы, вследствие чего они и были выбраны как место, куда транслируются данные пользователя. Одним из возможных решений передачи видеозаписи на удаленные серверы во время ее создания является потоковое вещание англ. . К примеру, можно было бы использовать набор технологий WebRTC, который позволил бы работать с видеопотоками через браузер 4. Однако многие облачные сервисы не поддерживают потоковое вещание, поэтому был выбран иной подход. Каждую секунду очередной созданный фрагмент видеозаписи сохраняется локально, после чего отправляется в облачный сервис. Таким образом, сохранность видеоданных достигается за счет отправки большого количества видеофрагментов малой длины, которые впоследствии могут быть собраны в единую запись. Среди множества облачных сервисов для хранения данных выбор пал на Google Диск, поскольку он гарантирует сохранность данных и предоставляет 15 Гб для хранения данных бесплатно. Мобильной платформой, под которую разработано приложение, выбран Android. По статистике на первый квартал 2017 г., 85 мирового рынка мобильных устройств занимают Android-устройства, поэтому ориентация на данный сегмент представляется достаточной. Главное требование, предъявленное к способам запуска трансляции, запись должна начинаться как можно быстрее. В связи с этим сделан выбор в пользу использования виджета. Пользователь может расположить виджет на любом экране мобильного устройства, в том числе и на главном, и тогда ему не нужно тратить время на поиск приложения в общем списке и нажатие кнопки в запущенном приложении достаточно один раз нажать на виджет. В настоящее время существуют мобильные приложения под различные платформы, занимающиеся передачей видеоданных на удаленные серверы. Был произведен анализ известных Android-приложений, наиболее приближенных к решению упомянутых проблем с получением и сохранностью видеоматериалов рис. 1. Такие популярные сервисы, как YouTube, Periscope, Instagram, предоставляют возможность делать потоковую видеозапись так, что ее могут увидеть пользователи других устройств. Соответствующие приложения хорошо знакомы широкой публике и обладают высокой степенью надежности. Однако все они были созданы для иных целей, вследствие чего обладают рядом особенностей, которые являются недостатками в контексте цели разработанного приложения. Это, во-первых, отсутствие локального сохранения при невозможности получить доступ в Интернет и, во-вторых, достаточно долгий запуск чтобы запустить трансляцию, пользователю как минимум нужно запустить приложение и нажать в нем соответствующую кнопку. Этих недостатков лишено ОКО, которое позволяет начать запись при нажатии на виджет. Однако и у него есть свои недостатки. 1. Отсылка фрагментов видеозаписи происходит каждые 5 или 10 секунд, что является достаточно большим промежутком времени. Если устройство будет повреждено на 4-й или 9-й секунде, есть шанс потерять важные данные. 2. Отсутствие возможности получить единую запись из снятых фрагментов. Приложение способно проиграть фрагменты один за другим, однако функция создания цельной видеозаписи отсутствует. Главная функция разработанного приложения создание видеозаписи и передача ее в облачный сервис. При этом запись передается по фрагментам каждую секунду очередной фрагмент видеозаписи сохраняется локально и отправляется в облачный сервис рис. 2. После запуска приложения и авторизации пользователю доступен предварительный просмотр камеры и кнопка Начать запись. При нажатии на кнопку начинается видеозапись и ее передача по фрагментам в отдельном, не главном, потоке. Этот процесс продолжается до тех пор, пока пользователь не нажмет на кнопку Стоп. Если пользователь уже авторизован, для начала записи ему достаточно нажать на виджет, не заходя предварительно в приложение. Если в процессе ведения записи пользователь временно потерял доступ в Интернет, после повторного подключения записанные во время автономного режима работы фрагменты все равно будут отправлены в Google Диск, что обеспечивается сервисами Google. Так же, к примеру, функционирует и Google Analytics 5. Разработанная архитектура приложения включает в себя 6 модулей рис. 3. 1. Модуль авторизации выполняет необходимую для работы с Google Диском авторизацию пользователя через аккаунт Google. 2. Модуль ведения видеозаписи занимается получением видеоданных с камеры, разбиением их на фрагменты и локальным сохранением этих фрагментов. 3. Модуль трансляции фрагментов отправляет во время ведения записи уже сохраненные локально фрагменты в облачный сервис. 4. Модуль управления записями служит для предоставления пользователю возможности просматривать имеющиеся видеозаписи, сведения о дате их создания, их местоположение локально и или в облачном сервисе и состояние фрагментирована запись или едина. Также дает возможность удалить запись как локально, так и с облачного сервиса. 5. Модуль сборки записи собирает фрагменты в единую видеозапись. 6. Модуль синхронизации записей с облачным сервисом позволяет загрузить недостающие фрагменты с облачного сервиса на мобильное устройство. Рассмотрим особенности реализации приложения. Минимальная поддерживаемая версия операционной системы Android 5.0 Lollipop, что позволяет охватить 79,8 от всех Android-устройств по состоянию на декабрь 2017 г. . Дизайн учитывает Material Design, разработанный компанией Google рис. 4. Создаваемая видеозапись имеет формат MP4, ее кадровая частота FPS равна 30 кадров в секунду. Время между ключевыми кадрами составляет одну секунду. Приложение реализовано на языке Java. Архитектура разработана на базе шаблона MVP Model-View-Presenter, что делает ее гибкой и позволяет добавить новые способы запуска видеотрансляции без модификации существующего кода. Для работы с камерой используется android.hardware.camera2 API, пришедший на смену Camera API с уровня Android API 21. Для получения с камеры видеопотока, отображения его на дисплее устройства и одновременно с этим разбиения видеопотока на фрагменты за основу была взята библиотека AudioVideoRecordingSample, переработанная в собственный переиспользуемый компонент. Для рендеринга видеопотока применяется OpenGL ES. Чтобы создавать видеофайлы-фрагменты, была предпринята попытка использовать MediaRecorder API, однако выявилась проблема. Управление записью в классе MediaRecorder основано на простом конечном автомате. После окончания записи одного фрагмента вновь перейти в состояние записи можно лишь снова проведя инициализацию, конфигурацию источника данных и подготовку каждому из этих действий соответствует отдельное состояние. Все эти операции занимают время порядка 700 миллисекунд 6, а поскольку, согласно требованиям, перезапуск должен осуществляться каждую секунду, многие моменты оказываются незафиксированными. Поэтому для видеозаписи используются более низкоуровневые классы MediaCodec и MediaMuxer. MediaCodec используется для сжатия видеопотока, в то время как MediaMuxer записывает видеопоток в MP4-файл. Для того чтобы видеофрагменты отправлялись в облачные сервисы в отдельных потоках, применяется RxJava 2, в частности планировщики Schedulers. Работа с Google Диском осуществляется через Google Drive Android API. С целью создать на основе снятых видеофрагментов цельную видеозапись применяется написанная на языке программирования Java библиотека mp4parser, созданная специально для работы с MP4-файлами. Резюмируем представленное Android-приложение является удобным способом сбора видеоинформации, которая может не только использоваться для личных нужд, но и выступать в качестве доказательства в судебных разбирательствах. В целях обеспечения сохранности данных в процессе создания видеозаписи ведется ежесекундное локальное сохранение полученного фрагмента и его передача в облачный сервис Google Диск, где любой зарегистрированный пользователь может получить пространство достаточного размера для хранения данных бесплатно. Для того чтобы не пропустить важные моменты, приложение снабжено способом оперативного запуска видеотрансляции с помощью виджета, который пользователь может разместить на экране там, где ему удобно. Приложение выгодно выделяется среди конкурентов небольшой продолжительностью создаваемого и отправляемого видеофрагмента, что при внезапной поломке устройства в процессе видеосъемки позволяет сохранить больший объем данных. Кроме того, поскольку работать с множеством фрагментов вместо единой записи по меньшей мере неудобно, предусмотрена возможность произвести сборку фрагментов в один MP4-файл. При этом, если на мобильном устройстве не хватает каких-либо фрагментов, имеющихся в облачном сервисе, они загружаются на устройство перед сборкой. В настоящий момент ввиду малой продолжительности самостоятельных фрагментов собираемая запись имеет достаточно большой размер. В дальнейшем планируется работа по его уменьшению. Помимо этого, приложение передает данные только в облачный сервис Google Диск. При поддержке иных облачных сервисов таких как Яндекс.Диск, Dropbox была бы удобна функция автоматического переключения на другой облачный сервис при достижении лимита в каком-то хранилище. В перспективе возможно добавление запуска видеозаписи по голосовой команде, а также введение системы оповещений в виде push-нотификаций при начале записи кругу доверенных лиц с предоставлением им доступа к создаваемой видеозаписи. Push-нотификации могут показаться недостаточно привлекающим внимание способом сообщить о важном событии, однако их использование в этом качестве активно применяется на практике 7. "}
{"title": "ИНТЕЛЛЕКТУАЛЬНАЯ СИСТЕМА ОБРАБОТКИ   И ИНТЕГРАЦИИ ЗНАНИЙ НА ОСНОВЕ ТЕХНОЛОГИЙ   СЕМАНТИЧЕСКОЙ ПАУТИНЫ ", "absract": "Статья посвящена разработке методов извлечения из текстов естественного языка определений ключевых понятий предметной области на основе теоретико-модельного подхода. Извлеченная из текстов информация путем преобразования через фрагменты атомарных диаграмм алгебраических систем представляется в виде утверждений в логике описаний (DL). Подобное представление позволяет получать тексты с большей выразительностью по сравнению с алгоритмами, где источником информации являются данные, представленные в виде баз данных или в виде выражений на формализованных языках (например, SQL). : онтология, теоретико-модельные методы, фрагменты атомарных диаграмм, определения понятий, извлечение определений, полнота определений понятий, явная определимость, неявная определимость, генерация текстов, порождение фраз естественного языка.  Исследование выполнено при частичной финансовой поддержке Президиума СО РАН (проект «Инженерия интенсиональных онтологий в дедуктивных и информационных системах» Комплексной программы ФНИ  СО РАН II.1). ", "text": "Современные модели представления информационных ресурсов интенсивно развиваются и внедряются в практику. Важнейшим элементом современных информационных технологий являются онтологии, которые позволяют производить автоматизированную обработку семантики информации с целью ее эффективного использования. С ростом объемов обрабатываемых данных онтологии становятся очень масштабными, что усложняет восприятие конечным пользователем хранящейся в ней информации. Так как в повседневной жизни наиболее распространенной формой представления знаний являются естественно-языковые тексты, проводится все больше исследовательских работ по извлечению описаний объектов OWL-онтологий в виде набора согласованных по смыслу предложений определений. Существует целый каталог систем генераций текстов 1, содержащий краткую информацию обо всех известных более 340 разработках. Большинство из них относятся к 1963 1980 гг. и имеют алгоритмы шаблонного типа система хранит уже готовую строку, возможно, с несколькими пропусками, которые заполняются при выдаче сообщения значениями, соответствующими характеру ошибки. Более сложные шаблонные системы дополнительно проводят ограниченную лингвистическую обработку генерируемого текста. Примером программ с подобной структурой могут служить следующие диалоговая система ELIZA 2, система Employee Appraiser Austin-Haynes и Performance Now KnowledgePoint. Шаблонный метод генерации, безусловно, имеет существенный недостаток. Генерируемые тексты сравнимы с естественными до тех пор, пока они имеются в единственном экземпляре. Вс, что написано на базе шаблона, похоже друг на друга за исключением тех частей, куда вставляются параметры. Также для большинства программ источником информации являются данные, представленные в виде баз данных или в виде выражений на формализованных языках, например SQL. Примеры систем генерации из формального представления REMIT 3, система Минока 4. Однако подобный формат представления данных имеет существенные недостатки. Так как SQL полностью отображается на один из профилей OWL, а именно OWL SQL, то можно провести следующий анализ рис. 1. Отсюда делаем вывод, что полученные определения из текстов с использованием представления информации на языке SQL достаточно тривиальны и не могут включать в себя более выразительные конструкции. Таким образом, главная идея настоящей работы заключается в разработке системы извлечения из текстов естественного языка определений ключевых понятий предметной области на основе теоретико-модельного подхода. Для извлечения из текстов естественного языка определений ключевых понятий предметной области мы используем результаты наших предыдущих исследований. Ранее в 5 был разработан теоретико-модельный подход к извлечению знаний из текстов естественного языка. В основе него лежит представление знаний при помощи конечных фрагментов атомарных диаграмм моделей. Были разработаны и реализованы в виде программной системы методы интерпретации различных частей речи и синтаксических связей с целью автоматического порождения сигнатуры модели 6. В 7 были предложены алгоритмы отображения бескванторных предложений логик предикатов первого порядка сигнатуры, не содержащей функциональных символов, в логику описаний DL. Разрабатываемая на данный момент система сначала извлекает из утверждений на языке DL те, которые имеют отношение к классу или индивидууму, требующему описания в виде текста. Формирует фрагмент OWL онтологии при помощи алгоритмов, также представленных в 7. Далее определяет, каким образом выбранная информация будет реализована языковыми средствами в виде предложений на естественном языке. Для этого используются так называемые текстовые планы, представляющие собой последовательность слотов, инструкции, определяющие правила их заполнения, а также лексические словари в виде OWL-он тологий. В данной работе мы продолжаем разработку теоретико-модельного подхода к формализации определений ключевых понятий предметной области. В частности, мы продолжаем исследование различных подходов к описанию полноты определений понятий относительно онтологии, контекста, множества прецедентов предметной области и т. д., явной и неявной определимости понятий, которое проводилось в 710. В 8 была установлена необходимость неявных определений понятий в формальных глоссариях. В данном параграфе мы изучим взаимосвязь этих результатов с хорошо известной теоремой Бета о неявной определимости. Необходимые определения можно взять из работ 7 11. В 8 было введено понятие формального глоссария. . Пусть сигнатура. Последовательность предложений, назовем, если выполнено а б добавление каждого нового предложения консервативно расширяет предыдущий набор предложений, т. е. Th Th S . Здесь Th теория, порожденная аксиоматизируемая предложением . Мы говорим, что формальный глоссарий, представляет предложение, если Th Th . Были доказаны следующие утверждения. 8. Существуют сигнатура, состоящая из имен двух понятий, и предложение, определяющее смысл понятий из, для которых нет формального глоссария, представляющего предложение, такого, чтобы сигнатура состояла из имени одного понятия, а сигнатура из имен обоих понятий. 8. Не всегда определения понятий могут быть представлены в виде глоссария, определяющего понятия по одному. 8. Не всегда определения понятий могут быть представлены в виде явного глоссария. На первый взгляд этот результат противоречит известной теореме Бета, которая говорит, что любое неявное определение предиката можно преобразовать в явное. 11. Пусть некоторое множество предложений сигнатуры, т. е. . Будем говорить, что отношение, если выполнено ...,...,..., . Будем говорить, что отношение, если существует такая формула ..., что выполнено ...,...,..., . 11. Множество неявно определяет отношение тогда и только тогда, когда определяет отношение явно. Таким образом, теорема Бета утверждает, что понятие, смысл которого неявно задается множеством предложений, может быть явно определено формулой . В чем разница между понятиями неявной определимости соответственно в 8 и в 11, и почему в данном случае не возникает противоречия между указанными теоремой 8 и теоремой Бета 11 Дело в том, что понятие неявной определимости в смысле Бета по существу означает не определение, а задание отношения происходит полное задание объема определяемого предиката. Формула,..., выделяет на модели множество кортежей, на которых предикат является истинным. Иначе говоря, это явное задание в первую очередь объема предиката экстента в терминах анализа формальных понятий 12, а не его содержания ин тента. В то же время формальный глоссарий 8, определяющий некоторый набор понятий, объемы предикатов, соответствующих этим понятиям. Это, в частности, означает, что возможны обогащения одной и той же модели данным новым набором понятий т. е. новым набором сигнатурных символов таким, что у соответствующих предикатов будут разные объемы при разных обогащениях модели. С другой стороны, явная определимость в смысле Бета в точности означает формульную определимость предиката на моделях, на которых истинно множество предложений, а именно в любой формуле мы можем заменить все вхождения предиката,..., на формулу,..., получив в результате формулу . При этом для любой модели, если, то на модели истинность формул и равносильна ...,...,..., . Таким образом, новое понятие, описываемое предикатом, добавленным к сигнатуре, и определяемое множеством предложений, на самом деле не дает ничего нового с точки зрения содержания, а является своего рода синтаксическим сахаром просто сокращением для формулы, выразимой в исходном наборе понятий . Именно формульная определимость предиката обуславливает то, что формула,..., из теоремы Бета полностью и однозначно задает объем предиката на моделях, на которых истинно множество предложений . Рассмотрим вопрос а задает ли полностью формула смысл, содержание предиката А именно, из определения мы имеем ...,...,..., . Будет ли верно обратное, т. е. истинно ли предложение ...,...,..., Отрицательный ответ на этот вопрос дает следующее утверждение. . Существуют сигнатура и множество предложений такие, что ...,...,..., ...,...,..., но неверно ...,...,..., . Таким образом, предложение ...,...,..., всегда полностью задает объем предиката, но не всегда полностью задает его смысл, содержание предиката если считать множество предложений неявным описанием смысла понятия, обозначаемого предикатом . Здесь можно было бы возразить, что мы можем добавить к что угодно, и при этом сохранится истинность утверждения ...,...,..., а утверждение ...,...,..., перестанет быть верным, даже если оно было верно до того. В связи с этим мы можем сформулировать вопрос а следует ли из ...,...,..., вместе с множеством всех следствий множества предложений в сигнатуре, т. е. вме сте с множеством предложений Th Положительный ответ на этот вопрос дает следующее утверждение. . Пусть ...,...,..., и . Тогда выполнено Th ...,...,..., . Тем не менее сделанное нами выше утверждение, что формула ...,...,..., полностью задает объем предиката, но не всегда полностью задает его смысл, остается верным. Это иллюстрирует следующий пример. . Пусть, а, . Тогда, где . С другой стороны, формула не является полным определением смысла предиката, задаваемого множеством предложений . А именно, из не следует, что предикат выделяет ровно один элемент т. е. предикат истинен ровно на одном элементе однако это свойство предиката следует из его неявного определения . Таким образом, явное определение полностью задает объем предиката, но не определяет его смысл. Стало быть, из теоремы Бета не следует, что . Можно было бы сказать, что, но это также является не совсем верным. Дело в том, что у неявного определения и у явного определения классы моделей разные. Действительно, любую модель сигнатуры можно доопределить до модели сигнатуры так, чтобы выполнялось утверждение . С другой стороны, множество предложений из приведенного выше примера может быть истинно только на одноэлементных моделях. Неявное определение объема предиката в теореме Бета на самом деле сводится не к предложению ...,...,..., а к множеству предложений Th ...,...,..., . Множества предложений и Th ...,...,..., как было показано выше, семантически эквивалентны, т. е. на них истинны одни и те же модели. Таким образом, не явное определение предиката сводится к явному определению его объема ...,...,..., но по модулю множества предложений Th сигнатуры . Это множество предложений задает класс моделей сигнатуры, на которых далее задается предикат через его объем. С другой стороны, является неверным утверждение, что неявное определение предиката сводится к явному определению его смысла ...,...,..., по модулю множества предложений Th . В рассмотренном выше примере, существенное свойство предиката то, что он истинен только на одном элементе т. е. в определенном смысле задает константу имя этого элемента, не содержится в яв ном определении . В этом примере множество предложений Th может быть истинно только на одноэлементных моделях. Поэтому из Th и дедуктивно следует предложение . При этом очевидно, что в множестве предложений Th ...,...,..., свойство предиката содержится неявно, в то время как в неявном определении, это свойство содержится явно. Получается, что в данном примере теорема Бета сводит не неявное определение смысла предиката к явному определению, а наоборот, явное определение к неявному. Таким образом, с точки зрения смысла предиката, а не его объема, понятия явного и неявного определения, используемые в теореме Бета, не являются полностью адекватными и требуют пересмотра. Общая и полная схема генерации без детализации происходящих процессов состоит из трех основных блоков 1 планирование содержания текста построение структуры текста 2 микропланирование построение планов предложений 3 языковое оформление реализация построенных планов предложений соответствующими грамматическими структурами. В прикладных системах генерации к этим трем этапам часто добавляется четвертый этап физическое представление, на котором производится форматирование текста согласно выбранному формату PDF, HTML и др.. состоит из следующих частей выбор контента информационного содержания, в котором система выбирает информацию для передачи в следующий этап кон вейера, и текстовое планирование, где она планирует структуру текста, который будет сгенерирован. Когда систему просят описать целевой объект, она прежде всего извлекает из онтологии все OWL-утверждения, связанные с объектом вниз по иерархии вплоть до уровня, указанного в настройках пользователя. Затем алгоритмы преобразуют извлеченный набор OWL операторов в триплеты см. таблицу. OWL-утверждения и соответствующие им формы триплетов OWL-утверждения Триплеты Object экземпляр ClassAssertionClass, object object, instanceOf, Class ClassAssertion ObjectComplementOfClass, object object, notinstanceOf, Class ClassAssertion ObjectOneOfindiv1,indiv2 object object, one of, orindiv1, indiv2, ClassAssertionObjectHasValueojbProp, indiv object object, objProp, indiv ClassAssertion ObjectHasValuedataProp,dataValue object object, dataProp, indiv ClassAssertion ObjectHasSelfobjProp object object, objProp, object ClassAssertion ObjectMaxCardinality number,prop,Class object object,maxCardinalityprop,numberClass ClassAssertion ObjectMinCardinality number,prop,Class object object,minCardinalityprop,numberClass ClassAssertion ObjectExactCardinalitynumber,prop,Clas s object object,exactCardinalityprop,numberClass ClassAssertion ObjectSomeValuesVromobjProp,Class object object, someValuesFromobjProp,Class ClassAssertion ObjectAllValuesVromobjProp,Class object object, allValuesFromobjProp,Class ClassAssertion ObjectIntersectionOfC1,C2, object convertClassAssertionC1, object convertClassAssertionC2, object ClassAssertionObjectUnionOf C1,C2,object orconvertClassAssertionC1,object,convert ClassAssertionC2, object, ObjectPropertyAssertion objProp,object,indiv object, objProp, indiv DataPropertyAssertion dataProp,object,dataValue object, dataProp, dataValue NegativeObjectPropertyAssertion objProp,object,indiv object, notobjProp, indiv NegativeDataPropertyAssertion dataProp,object,dataValue object, notdataProp, dataValue DifferentIndividualsobject,indiv object, differentIndividuals, indiv OWL-утверждения Триплеты DifferentIndividualsindiv,object object, differentIndividuals, indiv SameIndividualobject,indiv object, sameIndividuals, indiv SameIndividualindiv object object, sameIndividuals, indiv Object класс EquivalentClassesObject, Classexpr convert SubClassOf Object, Classexpr EquivalentClassesClassexpr, Object convert SubClassOf Object, Classexpr SubClassOfObject, Class Object, isA, Class SubClassOfObject, ObjectComplementOfClass Object notisA, Class SubClassOfObject,ObjectOneOfindiv1, indiv2 Object, one of, orindiv1, indiv2 SubClassOfObject,ObjectHasValue objProp, indiv Object, objProp, indiv SubClassOfObject,ObjectHasValue dataProp, dataValue Object, dataProp, dataValue SubClassOf Object, ObjectHasSelfobjProp Object, objProp, Object SubClassOfObject, ObjectMaxCardinality number,prop, Class Object,maxCardinalityprop,numberClass SubClassOf Object,ObjectMinCardinality number,prop,Class Object,minCardinalityprop,numberClass SubClassOfObject, ObjectExactCardinality number,prop,Class Object,exactCardinalityprop,numberClass SubClassOfObject, ObjectSomeValuesFromobjProp, Class Object, someValuesFromobjProp, Class SubClassOfObject, ObjectAllValuesFromobjProp, Class Object, allValuesFromobjProp, Class SubClassOfObject,ObjectIntersectionOf C1expr, C2expr convertSubClassOfC1expr, Object convertSubClassOfC2expr, Object SubClassOfObject,ObjectUnionOf C1expr, C2expr orconvertSubClassOfC1expr,Object convertSubClassOfC2expr, Object DisjointClassesObject, Class Object, notisA, Class DisjointClassesClass, Object Object, notisA, Class представляет собой упорядочивание предложений по тематике с использованием дополнительных ресурсов системы. Для работы метода группировки предложений по темам автор онтологии может определить разделы и назначить каждому из них свойства. Если разделы будут определены, то на этапе текстового планирования система распределит триплеты по соответствующим группам. Также эксперт может задать порядок самих разделов, что приводит к дополнительной итерации упорядочивания. Все секции, принадлежность свойств секциям и порядок разделов и свойств определяются в зависимых от онтологии ресурсах генерации. В нашем случае ресурсы также имеют представление OWL-онтологий. В общем случае алгоритм сортировки имеет следующий вид Процедура t0 целевой объект t1, ..., tn объекты второго уровня L0 неотсортированный список триплетов, описывающих t0 ... Ln неотсортированный список триплетов, описывающих tn SMap Карта соответствий между отношениями предикатами и наименованием секции SOrder Отсортированные наименования секций POrder Частично отсортированный массив отношений Отсортированный список триплетов от i 0 до n orderMessageTriplesAuxLi, SMap, SOrder, POrder от i 1 до n insertAfterFirst, L0, Li Вернуть L0 Процедура L Неотсортированный список триплетов об одном объекте SMap Карта соответствий между отношениями предикатами и наименованием секции SOrder Отсортированные наименования секций POrder Частично отсортированный массив отношений S1, ..., Sk списки с триплетами по каждой секции Отсортированный список триплетов об одном объекте S1, ..., Sk splitInSectionsL, SMap от i 1 до k Si orderTriplesInSectionSi, POrder S1, ..., Sk reorderSectionsS1, ..., Sk, SOrder Вернуть concatenateS1, ..., Sk это блок, который позволяет от предметных знаний перейти к языковым. В нем решается, каким образом выбранная информация будет реализована языковыми средствами в виде предложений на естественном языке. В нашем случае микропланирование состоит из трех подэтапов. 1. Лексикализация концептов сообщения, т. е. выбор подходящих слов для выражения выбранного в них содержания. Для каждого глагола, существительного или прилагательного, которые эксперт хочет использовать в планах предложений, должны быть представлены соответствующие синтаксические формы. Большинство синтаксических форм слов русского языка можно автоматически создавать из базовых форм, используя простые правила морфологии. Расширение нашей системы подобными компонентами будет рассмотрено в дальнейших работах. 2. Агрегирование сообщений до структур, соответствующих отдельным предложениям создаваемого текста. Системы генерации текстов часто объединяют предложения, полученные после обработки триплетов, в более длинные, чтобы улучшить читаемость. Агрегация предложения выполняется при помощи набора определенных правил, которые применяются к структурам, полученным в ходе работы текстового планировщика. Другими словами, они применяются к предложениям, уже отсортированным и сгруппированным по семантике. Действительно, объединение не связных по смыслу предложений будет звучать неестественно. Так как агрегация происходит по четко заданным шаблонам, ее возможности полностью зависят от результата работы предыдущего этапа. Рассмотрим теперь каждое из используемых правил. . Последовательность триплетов сообщений в форме S, P, O1, ..., S, P, On будет объединена в один триплет S, P, и О1, .... Оn., причем M это один из minCardinality, maxCardinality, exactCardinality. Применение данного правила снимает ограничение на maxMessagesPer Sentence., для того же S, где P является свойством онтологии., где Pi это свойство онтологии. В каждом из последующих или предшествующих предложений должен быть сам объект, за которым сразу следует только прилагательное. Прилагательные вписываются в результирующее предложение, сохраняя их порядок, определенный планировщиком., где S одинаковый во всех предложениях, а Pi это свойства онтологии. Результирующее предложение может быть сформировано путем однократного использования существительного и глагола. Соединительный союз и вставляется перед последним существительным., где S одинаковое во всех тройках, а Pi свойства онтологии. Для программного продукта были выработаны следующие требования 1 форма десктопного приложения 2 работа с уже существующей системой логического вывода 3 работа с уже существующей системой получения фрагментов атомарных диаграмм и алгоритмами получения DL утверждений 4 удобство и простота использования. Под эти требования подходило большое число языков программирования, однако основной выбор пал на объектно-ориентированные. Также были сформулированы не функциональные требования 1 быстрота и удобство разработки 2 возможность устройства модульной архитектуры 3 знания и умения разработки на выбранном языке программирования. Поскольку быстрота работы программы в данном случае не является существенным требованием, был выбран кроссплатформенный язык программирования Java, так как он удовлетворил всем поставленным требованиям. Структура программы представлена следующими директориями. Основные классы программы 1 пакет, отвечающий за возможность графической работы 2 пакет представления данных 3 пакет классов, реализующих основную логику приложения. В программе используются дополнительные библиотеки 1 Apache Commons 2 OWLAPI библиотека для работы с OWL-онтологиями 3 Jena библиотека для работы с OWL-онтологиями 4 Hermit машина логического вывода. Основной модуль разработан с использованием архитектурного шаблона Pipeline. На рис. 2 представлена его use-case диаграмма, отображающая основные возможные действия пользователя. В рамках дополнительных возможностей все загружаемые элементы можно проверить машиной логического вывода Hermit. В работе изучены вопросы полноты определений ключевых понятий предметной области, явной и неявной определимости ключевых понятий. Исследована полнота определений понятий относительно объема и содержания соответствующих сигнатурных предикатов. Разработаны методы интеграции фрагментов определения ключевого понятия, извлечен ных из текстов естественного языка. Методы интеграции частей определения понятия основаны на представлении знаний, извлеченных из текстов естественного языка, в виде фрагментов атомарной диаграммы алгебраической системы и на преобразовании фрагментов атомарной диаграммы в логику описаний DL и в OWL. Полученные OWL-спецификации погружаются в OWL-онтологию, соответствующую данной предметной области. Разработаны методы интеграции OWL-спецификаций, представленных в OWL-онтологии, и порождения по ним фраз естественного языка. "}
{"title": "ФОРМИРОВАНИЕ БАЗОВОГО СЛОВАРЯ ЖЕСТОВ   ДЛЯ ЕСТЕСТВЕННОГО КОМПЬЮТЕРНОГО   БЕСКОНТАКТНОГО ИНТЕРФЕЙСА  ", "absract": "Исследуются возможности бесконтактных систем и интерфейсов, главные принципы работы с такими технологиями. Рассмотрена возможность применения подобных систем для упрощения взаимодействия пользователей с ограничениями возможностями здоровья с компьютерным интерфейсом. Приведены особенности и преимущества использования естественных интерфейсов и систем, основанных на жестовом управлении. Также детально рассмотрены этапы формирования базового словаря жестов для дальнейшего его применения в бесконтактном интерфейсе. В качестве дополнительного аппаратного обеспечения для получения более точных результатов распознавания таких жестов рассмотрено устройство Microsoft Kinect. : человеко-машинное взаимодействие, программное приложение, компьютерный интерфейс, прототип программы, захват движения, технологии бесконтактного взаимодействия, пользователи с ограниченными возможностями здоровья.  Работа выполнена при поддержке Фонда содействия инновациям в рамках программы «УМНИК», договор № 12394ГУ/2017. ", "text": " Современные научные работы, посвященные исследованию человеко-машинного взаимодействия, направлены в основном на создание вычислительных машин, оборудованных большим количеством различных датчиков и сенсоров, а также на изучение средств межчеловеческой коммуникации, таких как речь и сопровождающие жесты. Разрабатываемые интерфейсы ориентированы исключительно на опытных пользователей, однако почти не затрагиваются вопросы человеко-машинной коммуникации для лиц с ограниченными возможностями инвалидов. Так, глухонемые люди не могут использовать речевые интерфейсы, а люди с проблемами мелкой моторики не способны работать с клавиатурой или жестовыми интерфейсами. Главной целью является разработка универсального бесконтактного интерфейса, пригодного для всех категорий пользователей, и реализация этого интерфейса, демонстрирующего возможности многомодальной человеко-машинной коммуникации. Такой интерфейс будет включать различные естественные для человека способы передачи и восприятия информации речь, жесты, движения головой и телом, чтение по губам, а также комбинации этих бесконтактных модальностей. Многомодальный интерфейс сможет обрабатывать входную информацию и выводить информацию в той форме, которая доступна конкретному пользователю 1. Естественный интерфейс подразумевает, что основным путем взаимодействия человека с компьютером являются прикосновения, жесты, речь, а также другие виды поведения, которые практикуются в течение многих лет и или которые являются врожденными. Прежде всего, понятие естественного интерфейса относится к процессу взаимодействия пользователя с системой насколько оно комфортно и понятно. Управление должно быть одинаково простым, интуитивным, как для опытного пользователя системы, так и для новичка 2. Пользователи предпочитают избавляться от барьеров, воздвигаемых традиционными интерфейсами между ними и техникой, гораздо удобнее управлять устройствами без посредников, а жестикуляция вполне естественный способ общения. Интерфейсы на жестикуляционном управлении предлагают привычными движениями, например, имитирующими перелистывание страницы, реализовать то же самое действие на экране. Нажатие на клавиши не относится к естественным способам общения для человека, поэтому основное преимущество жестикуляционного управления в том, что оно позволяет быстрее и проще отдавать команды устройствам. Помимо этого, подобные интерфейсы позволяют избавить экранное пространство от кнопок, клавиш и других наглядных элементов управления 3. Кроме того, жестикуляция дает возможность сосредоточиться на экране, а не на компьютерной мыши, клавиатуре или пульте дистанционного управления. Для реализации необходимо разработать интерфейс для работы с компьютером при помощи жестов, предварительно задаваемых пользователем. Подобный интерфейс предназначен, в основном, для помощи следующим категориям пользователей людям с проблемами мелкой моторики слабослышащим или глухонемым людям. Жестикуляционные интерфейсы могут упростить инвалидам взаимодействие с электроникой. Помимо этого, существует еще несколько областей, где возможно их потенциальное применение. Одна из них автомобили. С помощью телодвижений можно управлять развлекательной системой, очистителями стекол, фарами и другим оборудованием, не отрывая глаз от дороги. Ford Motor уже выпускает автомобили, у которых автоматически открывается багажник, если под ним провести ногой 1. Жестикуляционные интерфейсы также позволят врачам и медсестрам управлять компьютерами и другими устройствами, не дотрагиваясь до них. Это очень ценная возможность в ситуациях, когда медикам нужны чистые руки, а также в случаях, когда оборудование находится вне прямой досягаемости. Пользователь жестовой системы управления должен в первую очередь догадаться о следующем что системой можно управлять с помощью жестов какой набор жестов поддерживает эта система. Эту информацию пользователь должен узнать при работе с самой системой, а не из руководства или другой документации. В целом довольно трудно ответить на вопрос, как достигнуть affordance с англ. воспринимаемая доступность управления жестами. Термин affordance означает это качество системы или продукта, которое предложил Джеймс Гибсон, основатель направления в психологии, рассматривающего восприятие как процесс, не предполагающий умозаключений, промежуточных переменных. В данной ситуации, обратную связь целесообразно дополнить подсказками-предсказаниями в процессе распознания показать, какие жесты доступны на данном этапе. Помимо конечной цели, пользователь сможет узнать, какие еще возможности поддерживает система. Также, если у некоторых жестов траектория одинаково начинается, это может стать полезным для пользователя дополнением 4. Управление интерфейсом должно быть интуитивным и простым, он должен легко настраиваться и работать. В частности, нужно помнить, что пользователи не должны знать, как устроена система и как она работает, поэтому ошибочное распознавание и неверное использование в идеале необходимо выявлять на стадии тестирования и игнорировать его. В случае если система неверно распознала жест, необходимо предусмотреть простой механизм отмены действия и возможность отметить, что жест распознан неправильно 5. Чтобы персонифицировать набор жестов, необходим интерфейс, который предполагает определение персональных жестов. Понятие доступности требует равных прав для людей в получении доступа к информации независимо от физических и когнитивных затруднений, которые они могут испытывать в связи с временными или хроническими нарушениями и болезнями. Управление жестами должно быть доступно для пользователей с разными физическими или техническими ограничениями 6. Также в идеале при управлении в жестовых системах не должны накладываться ограничения на окружающую среду, в которой они используются. Фактически система должна быть работоспособна в любое время, при любом освещении и при любом пространственном положении . На сегодняшний день распознавание жестов в таких интерфейсах базируется преимущественно на получении данных с одной или нескольких камер, а это накладывает ограничения на среду, в которой они используются. Помимо этого, калибровка камеры может оказаться достаточно сложной задачей для среднестатистического пользователя. При разработке системы жестового управления есть два варианта создать универсальный набор жестов или дать возможность пользователям самостоятельно определять этот на бор 5. В первом случае достаточно сложно персонифицировать жесты, так как многое может зависеть от культуры пользователей, их личных особенностей правша или левша и других характеристик, которые влияют на естественные жесты пользователей. Поэтому интерфейсу, основанному на жестовом управлении, требуется либо приспосабливаться к персональным жестам, либо модифицировать универсальные жесты, либо определять персональные жесты. Возможность приспосабливаться к персональным жестам, основанная на наблюдении, предполагает обнаружение оптимальных жестов для такой задачи, однако это довольно длительный процесс, следовательно, этот вариант может не подойти для ежедневного использования 4. Остальные варианты предпочтительнее всего для повседневных систем. Для их реализации нужно применять алгоритмы машинного обучения. При автоматической сегментации могут возникнуть проблемы алгоритма распознания, так как захватываются движения, которые не являются частью жеста. Подобные движения считаются шумом, поэтому машинные модели обучения это должны учитывать . В целом список жестов для управления компьютером должен представлять собой какойто базовый набор жестов, и при этом некоторые из них могут быть уникальными в рамках всей системы например, жест отмены, а некоторые не уникальны, так как один и тот же жест в зависимости от контекста может использоваться по-разному 5. Однако при этом у системы должна быть возможность адаптации персонализации под каждого конкретного пользователя, а также под условия использования интерфейса. Формирование набора естественных жестов для бесконтактного управления имеет корни в ставших обыденными жестах при сенсорном взаимодействии, используемом в современной цифровой технике смартфонах, планшетах, некоторых ноутбуках laptop. Интерактивная технология multi-touch interaction MT позволяет пользователю путем прикосновений управлять графическим интерфейсом одновременно несколькими пальцами руки. Поддерживаемые жесты щелчок выбор элемента, сдвиг пролистывание вправо, сдвиг влево, уменьшение масштаба, увеличение масштаба, поворот 2 рис. 1. Данный набор жестов стал основой для базовых жестов бесконтактного взаимодействия с той лишь разницей, что главными управляющими инструментами стали не пальцы, а кисти и руки. Исходя из этого масштаб управления был расширен от экрана сенсорного телефона до бесконтактного управления интерфейсом с помощью рук. Прежде всего следует определить условные обозначения, которые будут указаны в словаре жестов как начальное, конечное положение руки и направление ее движения. Для этого используются интуитивно понятные графические примитивы, которые дополняются сопроводительными подписями рис. 2. Основными движениями в данном бесконтактном интерфейсе являются перелистывание вправо и влево, а также прокрутка вверх и вниз. Это базовые движения, которые на сегодняшний день интуитивно понятны любому пользователю, который хотя бы раз работал с персональным компьютером. Эти жесты осуществляются взмахом руки в нужную сторону рис. 3. Они необходимы в ситуациях, когда информация полностью не помещается на экране монитора, разделяется на части страницы, поэтому для просмотра новой порции информации требуется переход в следующую часть. Для облегчения взаимодействия пользователя с ограниченными возможностями здоровья ОВЗс интерфейсом было разработано такое функциональное улучшение, как предпросмотр содержимого. Зачастую пользователи, которые сортируют документы по множеству папок, не могут вспомнить точное месторасположение того или иного файла. Поэтому была создана функция предпросмотра содержимого, которая позволяет вывести список последних открытых в определенных папках файлов, что может сэкономить много времени на поиск необходимых документов. Данная возможность реализуется путем изображения круга по часовой стрелке для раскрытия списка файлов и против часовой для их закры тия рис. 4. Также было принято решение создать новое движение, которое упростит работу с меню, подобным элементу Пуск в ОС Windows. Так как у пользователей с ограниченной моторикой возникает необходимость совершать действия в системе, затрачивая как можно меньше сил и совершая не очень активные движения, то было принято решение сделать жест максимально понятным и удобным для людей с ОВЗ 1. Для того чтобы отобразилась панель меню, следует немного поднять ладони вверх, как при прокручивании снизу. Чтобы панель скрыть, следует сделать такое же движение, но в обратном направлении рис. 5. Однако многие пользователи с ограничениями в движении не имеют возможности двигать две руки одновременно, к тому же в одном направлении. Поэтому интерфейс предоставляет возможность совершать данные манипуляции одной рукой. Чтобы совершить клик по выбранному жестом элементу интерфейса, следует удерживать ладонь на месте 3 секунды. Если задать возможную амплитуду размаха руки в попытках удержать ее на одном месте, что не всегда удается людям с ограниченной моторикой из-за судорог или непроизвольных спазмов мышц, то можно настроить систему для восприятия дрожащей или даже колеблющейся в пределах 510 см руки как жест выбора элемента 3. Последней из возможных базовых функций, адаптированных под пользователей с ОВЗ, является функция увеличения и уменьшения размеров объектов. При просмотре изображения или документа в его начальном состоянии не всегда достигаются необходимые для корректного восприятия величины объекта с самого его запуска. Поэтому функция увеличения и уменьшения размеров особенно необходима. Увеличение достигается путем раздвигания рук из центра в стороны по диагонали см. рис. 5. Не имеет значения, какая именно рука окажется в верхней точке жеста, а какая в нижней. Система распознает оба положения как один и тот же запрос. Соответственно уменьшение элемента может быть получено в том случае, когда руки, разведенные в стороны и находящиеся по диагонали друг от друга, собираются в центре. Причем степень увеличения и уменьшения может достигаться как поэтапно, если указать в настройках, что одно такое движение рук это один шаг масштабирования элемента, так и плавно, что актуально для пользователей без ограничений в моторике. Таким образом, был разработан базовый словарь жестов для естественного бесконтактного взаимодействия с компьютерным интерфейсом, который удовлетворяет основным принципам естественных интерфейсных систем. Быстрое погружение. Прилагая минимальные усилия и время, человек сам овладевает системой. Отсюда не следует, правда, что обучения вообще не должно быть, но оно должно быть минимальным и без посторонней помощи. Важно понимать, что мы говорим именно об интерфейсе, естественный интерфейс может быть и у промышленного робота, и у баллистической ракеты, и у шахмат, но овладение им в данных контекстах не сделает вас опытным пользователем с точки зрения системы. Недостаточно понять базовые элементы и правила их комбинирования, нужно изучить их идиоматическое использование. Легкое управление. Компьютер должен приспосабливаться к пользователю, а не наоборот. Человек через некоторое время перестает думать о том, что ему надо сделать, чтобы произошло нужное действие. Впечатление игровой момент. Эффект новизны пользовательского опыта, как следствие, положительные эмоции от самой системы. Со временем и частотой использования этот эффект будет исчезать 4. Рынок систем жестикуляционного управления относительно нов, стандартов еще практически нет, и в различных системах используются совершенно разные интерфейсы, камеры и алгоритмы. Это дает возможность выбора инструментов для использования в разработке и применении естественных интерфейсов. В разрабатываемом продукте предполагается использование устройства Microsoft Kinect в качестве дополнительного аппаратного обеспечения. Оно определяет до шести человек в пространстве и 25 суставов каждого из них рас познает лица, эмоции, пульс. Аудиосистема последней модели может определить двух одновременно говорящих людей и распознать два потока речи 3. Помимо широких возможностей и относительно низкой цены по сравнению с аналогами, устройство Microsoft Kinect может также адаптироваться под особенности пользователей, просчитывая возможные варианты жестов. Так что если человек с ОВЗ не повторит определенное движение в точности, как указано в словаре жестов, то устройство захвата движения все равно идентифицирует кисть, распознает движение и определит его тип в соответствии со словарем. Таким образом, создание и внедрение естественных человеко-машинных интерфейсов, основанных на автоматическом распознавании речи и жестов, предлагает пользователям-ин валидам новый способ персонифицированного бесконтактного взаимодействия с компьютером полностью без использования стандартных устройств ввода, таких как клавиатура и компьютерная мышь. Адаптивность и индивидуализация интерфейса, а также способность осуществить настройку словаря движений для управления системой в соответствии с потребностями каждой категории граждан с ОВЗ являются отличительной особенностью разработки. Еще одним важным дополнением будет возможность встраивания его в виде программного модуля для управления операционной системой MS Windows и ее системными приложениями. "}
{"title": "МОДЕЛИ И ПРОЕКТНЫЕ РЕШЕНИЯ СИСТЕМЫ ХРАНЕНИЯ   И ОБРАБОТКИ ИССЛЕДОВАТЕЛЬСКИХ ДАННЫХ ECCLESIA  ", "absract": "В ходе научных исследований порождается большое количество данных в цифровом формате, и для после дующего использования этих данных (обработки, анализа, публикации) их необходимо организованно собирать  и хранить. Построение информационной инфраструктуры для решения этих задач – одна из наиболее актуальных  проблем в области организации работы с экспериментальными данными. Авторами настоящей статьи разра батывается информационная система для автоматизации сбора, хранения и анализа данных, в качестве отправной  точки для которой используются три задачи обработки данных из области физиологии. Рассмотрены и проана лизированы возникающие в процессе разработки такой системы проблемы, а также существующие подходы  и готовые решения этих и схожих задач. На основе результатов проведенного анализа предложен ряд моде лей и механизмов для решения возникших проблем. Разработанные решения включают в себя модели  и механизмы сбора и хранения экспериментальных данных, модель для описания и формализации сценариев обработки данных и механизмы для обработки собранных данных в распределенной вычислительной системе.  В результате представлена архитектура вычислительной системы для сбора, хранения и обработки эксперимен тальных данных. Система предлагается в качестве инструмента для решения широкого спектра задач, возни кающих при проведении научных исследований и требующих сбора, хранения и многоэтапной обработки  различных типов данных. : управление научными данными, информационная система, обработка и анализ данных, дан ные физиологических исследований, объектное хранилище данных, функциональный язык, распределенные вы числения. ", "text": "В современных исследованиях часто приходится сталкиваться с большим объемом экс периментальных данных, получаемых из различных источников. Вс чаще данные собира ются и сохраняются с расчетом на то, что некоторые задачи их анализа будут поставлены в будущем. Перспективные задачи могут предполагать использование дополнительных данных, собранных независимо, в другое время другими исследователями. Нарастающие проблемы организации исследовательских данных и систематизации работы с ними стали, таким образом, самостоятельной задачей. Управление научными исследовательскими данными research data management и циф ровое курирование digital curation 1 к настоящему моменту являются устоявшимися терминами, выражающими потребности научного сообщества в инструментах и сервисах для работы с генерируемыми данными. В то время как в Европе и США эта проблематика вынесена на государственный и даже межгосударственный уровень поддерживаются и раз виваются узкоспециализированные инфраструктуры для хранения научных данных, напри мер DataONE, разрабатываются и реализуются крупные программы, направленные на обоснование необходимости развития таких инфраструктур и проработку соответствующей нормативной базы, которая, в частности, будет стимулировать исследователей делиться своими данными см. проект Research Data e-Infrastructures Framework for Action in H2020 . В обзоре 1 приводится западная оценка общей стоимости формирования инфра структуры научных данных 1015 от стоимости всей инфраструктуры науки. При этом в России на уровне федеральных властей обсуждение необходимости и путей создания инфраструктуры для науки, основанной на цифровых данных, активизировалось только в 20162017 гг. в связи с разработкой и принятием программы Цифровая экономика 2, хотя отдельные инициативы в этом направлении реализовывались и ранее 3 4. Несмотря на более чем 10-летнюю историю вопроса, работа с исследовательскими дан ными, за исключением отдельных научных направлений например, 5, остается слабо упорядоченной и в лучшем случае организуется путем составления и следования инструк циям, таким как Data management Helping MIT faculty and researchers manage, store, and share data they produce . Такое положение дел в дальнейшем будет только сдерживать раз витие науки, поэтому исследователи нуждаются в создании инструментов, которые позволят им решать задачи организации сбора, хранения, обработки и анализа данных, обмена ими и их публикации. В работе 6 предлагается подход к систематизации и соответствующей автоматизации процессов, связанных с согласованным хранением и обработкой неоднородных исследова тельских данных. В общем виде рассмотрены требования к организации специализированной информационно-аналитической системы, представлено видение е архитектуры, описано состояние развития инфраструктуры Института вычислительных технологий ИВТ СО РАН для работы с научными данными. В настоящей работе представлен следующий этап в рамках инкрементального подхода к созданию этой информационно-аналитической системы поддержки научных исследований. Анализируется опыт Лаборатории технологий анализа и обработки биомедицинских данных ИВТ СО РАН в решении задач сбора, хранения и анализа данных, возникших в рамках ряда физиологических исследований. На основе этого анализа формулируются минимальные тре бования к информационно-аналитической системе для работы с такими данными, предла гаются основные проектные решения по созданию ее прототипа системы Ecclesia. Одним из немногих проектов, нацеленных на целостное решение проблемы автомати зации сбора, хранения, обработки и публикации научных данных, является проект раз работки платформы и сервиса для биомедицинских исследований Galaxy Project . Несмотря на направленность проекта на конкретную предметную область, результаты его могут быть использованы и в других областях научных знаний. Однако сервис достаточно сложен в освоении, не поддерживает включение интерактивных сессий с пользователями в качестве этапов автоматически выполняющихся сценариев обработки данных и более приспособлен к накоплению отдельных объектов данных, воспроизводимости отдельных сценариев обра ботки данных, чем к систематизации накопления и автоматизации применения знаний о предметной области. Системы для хранения или обработки данных в целом можно разделить на три класса системы общего назначения например, Dell EMC Elastic Cloud, Globus, специфичные для предметной области например, SIMBioMS, CARMEN, XTENS 2 и решающие частные задачи например, МedMining 7. В системах общего назначения особое внимание уде ляется надежности хранения, но не предоставляются инструменты для описания данных и их связей. Системы для решения частных задач, напротив, поддерживают связи между дан ными, но в рамках специфичной для задачи схемы, которая чаще всего не переносима на другие задачи. Среди специфичных для предметной области систем рассматривались системы хранения биомедицинских данных 810. Достаточной степенью универсальности не обладает ни одна система. Так, например, они не поддерживают возможность проверки структуры загруженных данных и не позволяют вводить и тем более строить новые связи между данными. Среди систем формирования и исполнения сценариев обработки данных также можно выделить системы общего назначения например, Google Cloud Dataflow или ActiveEon ProActive Workflows Scheduling и системы, специфичные для предметной области на пример, LabView и Unipro UGENE 11. Системы общего назначения по большей части направлены на пользователей с навыками программирования. Важным примером системы, позволяющей создавать предметно-ориентированные визуальные языки программирования, является CoCoViLa 12, которая для этого требует от пользователя решать более широкую задачу, чем задание и выполнение отдельных сценариев обработки данных. Узкопредметные системы избавляют пользователей от таких сложностей, но изначально не приспособлены для решения междисциплинарных задач. Разрешению обозначенных проблем различных систем для работы с данными и посвя щена наша работа. В основе требований, предъявляемых к разрабатываемой системе, лежит опыт решения задач сбора, хранения и анализа данных для ряда физиологических исследований и резуль таты обсуждения соответствующих проблем со специалистами-физиологами. Рассматривается задача создания велотренажера для реабилитации больных после ин сульта. Врач задает программу тренировки пациента с помощью графиков требуемой ско рости вращения педалей и величины сопротивления тренажера кручению педалей. Эти значения преобразуются мобильным приложением в управляющие воздействия контроллера тренажера. Необходимо индивидуально подбирать программу тренировки так, чтобы па циент получил нагрузку, адекватную его состоянию. Для этого необходимо собирать и ана лизировать данные, характеризующие фактическое прохождение тренировки. Собираемые данные включают в себя частоту сердечных сокращений ЧСС и реальную скорость кру чения педалей. Мобильное приложение собирает данные и формирует пары вида отметка времени, значение ЧСС и отметка времени, значение реальной скорости. Для анализа процесса тренировки требуется сохранять и визуализировать получаемые данные, сопоставляя их с программой тренировки. Все данные являются одноканальными временными рядами ОВР. Программу тренировки также можно представить в виде ОВР. Требуется делать выборки в заданных временных интервалах как отдельных рядов, так и их совокупностей, совмещенных по времени. Предложено ввести абстракцию ОВР на уровне решения для хранения, что позволяет унифицировано представлять данные. Помимо данных ряда предложено сохранять ряда 1 тип ряда в данном случае некоторые идентификаторы, позволяющие отличать ряды ЧСС от рядов скорости кручения педалей и др. 2 идентификатор устройства-источника 3 время начала и окончания записи. Доступ к системе хранения данных предоставляется через веб-сервис, который позволяет сохранять и извлекать ОВР. Данные ОВР хранятся в бинарных файлах, атрибуты отдельных записей со ссылкой на бинарный файл хранятся в реляционной БД. Решение позволяет уни фицировано сохранять и извлекать ОВР и независимо разрабатывать различные клиентские приложения для работы с ними. В частности, реализовано сохранение данных в мобильном приложении и выгрузка данных в веб-интерфейс для визуализации. Поскольку на уровне понятий в системе была поддержана логика работы с ОВР, поль зователи получили возможность выбирать данные в веб-интерфейсе по заданным временным промежуткам записи и типу ряда, а не по именам или датам создания файлов. С поль зователей также сняты типичные задачи организации данных в некоторую структуру ди ректорий, запоминания этой структуры и ручного поиска в ней. В ходе решения задачи проявилась необходимость обеспечивать в рамках информацион но-аналитической системы реализацию понятий предметной области и поддержку работы с соответствующими объектами данных в терминах предметной области на уровне програм мных и пользовательских интерфейсов. Типичная система организации данных в виде файлов, собранных в структуры директорий, является в подобных ситуациях неадекватной задачам поиска и обработки данных. Запись электроэнцефалограммы ЭЭГ состоит из каналов, в которых фиксируется ди намика разности потенциалов между электродами и электродом-референтом. ЭЭГ-записи могут использоваться для выявления схожести и различий в реакции пациентов на одина ковые стимулы 13, для восстановления позиций источников сигналов в мозге 14 и др. Однако предваряет содержательный анализ данных очистка ЭЭГ-записей от шумов 15. В рамках этапа очистки от шумов используются запись сигналов ЭЭГ, а также инфор мация о размещении электродов на голове пациента 16, время подачи стимулов, протокол эксперимента, в котором описаны детали проведения эксперимента. Приемы очистки записи могут применяться отдельно либо в некоторой последовательности. Наиболее распростра ненные из них 1 применение частотных фильтров для удаления известных помех 2 выявление экспертом зашумленных каналов и их удаление 3 смена электрода-референта и соответствующий перерасчет значений ЭЭГ во всех ка налах 17 4 усиление значимого сигнала за счет суммирования выровненных по моменту предъ явления стимула участков записи, так называемых эпох 5 коррекция нулевой линии baseline correction 18 6 выявление экспертом поврежденных эпох и их удаление 7 применение анализа независимых компонент 19, выявление экспертом шумовых ком понент и их удаление каждая компонента при этом визуализируется в виде карты актив ности мозга. Как правило, в физиологических лабораториях можно наблюдать, что все собираемые данные, а также данные, получаемые в ходе этапов обработки, хранятся как отдельные фай лы протокол эксперимента и вовсе может храниться в бумажном лабораторном журнале, структурирование которых в упорядоченные системы каталогов, именование, формирование наборов данных для очередных этапов обработки осуществляются вручную. Автоматизация сбора и обработки должна освободить исследователей от этого рутинного труда и ликви дировать ошибки, обусловленные человеческим фактором. Должна быть обеспечена возмож ность формировать и автоматически выполнять сценарии, состоящие из набора связанных операций обработки данных, а перенос данных между операциями должен быть автома тизирован. На практике в ходе обработки данных от пользователя требуется выбор конкретных методов. Например, существует множество алгоритмов для проведения ICA 20, нужно сделать выбор частотных фильтров и т. д. Не все эксперты в предметной области задачи яв ляются экспертами в математической обработке данных, и для них были бы ценны советы при выборе методов обработки. Для этого целесообразно, чтобы система собирала и накап ливала опыт других пользователей в составлении сценариев. Нужно учитывать, что некоторые операции обработки данных пока или принципиально не могут быть автоматизированы, поэтому может потребоваться анализ и принятие решения экспертом. Таким образом, должна быть заложена возможность включать сессии взаимодей ствия с пользователями в качестве этапов сценариев обработки данных. Задача состоит в поиске нейрональных сетей на основе анализа выявляемой с помощью функциональной магнитно-резонансной томографии фМРТ активности мозга пациента на пример, 2123. С помощью фМРТ измеряется связанная с активностью нейронов гемо динамика. Каждый снимок фМРТ характеризует насыщенность крови кислородом в раз личных областях головного мозга. Дискретное представление насыщенности основано на разбиении куба, в который вписана голова пациента, на кубические единичные объемы воксели. Снимок фМРТ представляет собой, таким образом, трехмерный массив чисел. В ходе решения задачи анализируется последовательность фМРТ-снимков головы па циента. В каждом снимке выделяются группы вокселей по выбору исследователя, и для каждой группы строится индекс активации некоторое усреднение значений всех вокселей группы. Эти операции повторяются для всей последовательности снимков, таким образом получается временная развертка индексов активации. Представляет интерес выделение групп вокселей, демонстрирующих различную или сходную динамику индекса активации 24. Для одного эксперимента в этой задаче нужно обработать тысячи групп вокселей во временной развертке. Каждая группа вокселей может быть рассмотрена независимо, что позволяет обрабатывать их параллельно. Таким образом, задачу целесообразно решать на параллельных вычислительных системах. На основе анализа пользовательских историй в совокупности с общими представления ми о назначении системы 6 сформулированы требования к минимальному жизнеспо собному продукту MVP Minimal Viable Product. Необходимо обеспечить следующее 1 возможность сохранять и извлекать разнородные экспериментальные данные вместе с информацией об их структуре и связях с другими данными 2 возможность модифицировать сведения о данных и связях между ними в любой мо мент времени 3 проверку соответствия данных заданной структуре с возможностью исправления выяв ленных несоответствий при сохранении в системе 4 возможность задавать сложные пользовательские сценарии обработки данных 5 обращение к данным и сохранение новых данных из сценариев 6 выполнение сценариев на параллельных вычислительных системах, при этом поль зователь должен быть по возможности избавлен от необходимости императивного парал лельного программирования 7 возможность интерактивного вмешательства пользователя в ход исполнения сценария 8 накопление знаний о предметной области и поддержку действиям пользователя в по строении сценария 9 автоматизированный анализ и оптимизацию процессов обработки данных. На основе выявленных требований к системе в ходе проектирования были выделены три ее относительно самостоятельные подсистемы 1 хранения и управления данными 2 формирования сценариев 3 организации распределенной обработки. Для возможности независимой разработки подсистем и применения различных тех нологий для их реализации выбрана микросервисная модель архитектуры системы, пред ставленная на рис. 1. реализуется в виде надстройки над су ществующим распределенным высоконадежным хранилищем. Надстройка представляет со бой промежуточный сервер менеджер данных, организующий данные пользователя в соот ветствии с предлагаемой моделью представления данных см. ниже и предоставляющий программный интерфейс API Application Programming Interface для работы с этими дан ными. На основе API менеджера данных независимо могут быть построены различные клиентские приложения. Базовым пользовательским интерфейсом является веб-интерфейс с функциями загрузки и извлечения данных, просмотра каталога данных и поиска в нем. Для обеспечения хранения и извлечения разнородных экспериментальных данных вместе с информацией об их структуре и связях предложена следующая модель представления дан ных. Вводится понятие как единицы хранения. Для каждого объекта при создании формируется его идентификатор. Все объекты автоматически или по указанию пользователя относятся к одному из, зарегистрированных в системе, в одном из Таким образом, любой файл или некоторым образом структури рованный набор файлов, будучи сохраненными в качестве объекта данных, могут быть со держательно интерпретированы системой. Например, данные одного ЭЭГ-исследования на энцефалографах BrainVision сохраняются в виде тройки файлов запись сигналов ЭЭГ в файле формата .eeg, файл разметки ЭЭГ по времени подачи стимулов .vmrk и файл, содержащий информацию о каналах энцефалографа .vhdr. После загрузки файлов в си стему хранения эта тройка рассматривается как один объект данных типа в формате Такой подход отражает связь между файлами, позволяет обращаться к ним совместно и избегать ошибок совмещения сигналов и времени подачи стимулов от разных записей при многократном обращении. Для обеспечения расширяемости подсистемы хранения предлагается механизм введения нового типа. Новый тип в системе задается, списком возможных задаются строковыми идентификаторами и набором, которые могут при нимать на вход или вырабатывать в качестве своего результата объекты данного типа, возможно, наряду с объектами других типов см. раздел Подсистема организации рас пределенной обработки Схема метаданных задает название типа, синонимы для названия и текстовое описание типа, а также специфицирует набор свойств объектов данного типа в виде множества пар атрибут, тип. Атрибут произвольная строка, имя некоторого свойства объекта данных, тип строковый идентификатор типа значения атрибута, выбирается из типов, зарегист рированных в системе, например атрибут Дата регистрации, тип Дата. Одним из типов является ссылка на другой объект данных по идентификатору объекта. Ссылки в метаданных на другие объекты позволяют задавать произвольные между данными. С каждым объ ектом данных хранятся его метаданные. Значения атрибутов заполняются пользователем или автоматически, например, некоторым клиентским программным обеспечением. Типы, у которых задана только схема метаданных, называются и мо гут быть включены в определения схем метаданных других типов для переиспользования набора атрибутов, заданных в типе-стикере. Экземпляр такого типа, стикер, объект мета данных, содержание которого составляют только метаданные с присвоенными атрибутам значениями. Стикер может быть прикреплен к произвольному объекту данных, даже если этот стикер не включен в схему метаданных типа данного объекта. С помощью атрибутов-ссылок и стикеров можно, в частности, сохранить связь между исходным объектом, например записью ЭЭГ, и преобразованным, например ЭЭГ, отфильт рованной от наведения электросети. Для этого нужно создать и прикрепить к полученному после фильтрации объекту стикер с названием Без наведения с атрибутом Получено из типа для сохранения ссылки на исходный объект и атрибутом Частота на ведения типа вещественное число для сохранения параметров фильтрации рис. 2. Согласно требованию о проверке структуры загружаемых данных, в подсистеме вводится понятие операции проверки соответствия структуры данных заданному типу и формату этих данных. Вызов этих операций при загрузке данных в хранилище позволяет автоматически выявлять несоответствие между содержанием объекта данных и указанными пользователем или автоматически определенными типом и форматом объекта данных. Разработан программный интерфейс веб-сервиса доступа к данным в терминах управ ления ресурсами сервиса, согласно архитектурному стилю REST 25. Типы ресурсов сервиса имеют прямое соответствие терминам модели представления данных тип данных, формат данных, стикер, операция, объект. Таким образом, каждый тип данных, каждый объект и т. д., а также коллекция таких сущностей, является ресурсом в терминах REST и получает имя URI Uniform Resource Identifier, посредством которого клиенты сервиса могут обра щаться к ресурсу и осуществлять действия из набора CRUD 26. Относительно способов передачи значений при запросе объектов типы разделены на два класса. 1. . В результате запроса объекта по его идентификатору клиенту ин терфейса возвращается информация URL Unified Resource Locator о том, как может быть получен доступ непосредственно к данным объекта. К этому классу относятся все сложные типы например, запись ЭЭГ. Для получения данных в случае записи ЭЭГ в формате BrainVision это тройка файлов, описанная выше необходимо сделать отдельный запрос по URL. Ссылочные типы позволяют вынести в отдельный блок работ исследование и внед рение механизмов оптимизации доступа к данным, например, таких, как размещение копий данных кэши ближе к месту их использования. 2. Объекты таких типов возвращаются клиенту непосредственно при обращении по идентификатору объекта. К этому классу относятся примитивные типы на пример, числа и строки. Предложенная модель доступа к данным предоставляет инструменты доступа к системе хранения как из клиентских приложений веб-интерфейс системы хранения, приложения для персональных компьютеров и мобильных устройств, программное обеспечение регистри рующего оборудования собираемые устройствами данные могут непосредственно отправ ляться в хранилище, и т. д., так и из подсистемы распределенной обработки данных. Поскольку одним из требований к системе является выполнение сценариев на различных параллельных вычислителях, то предлагается модель, в которой вычислитель может испол нять сценарии, описанные в виде частично упорядоченного множества операций. Операция характеризуется множеством входов, множеством выходов, а также именем функции, кото рую она применяет к входам для получения выходов. Входы и выходы это объекты дан ных. Предполагается, что по имени функции может быть найдена конкретная программная реализация этой функции программа, которую может исполнить вычислитель. Все объекты неизменяемы и либо известны до исполнения сценария входные данные сценария, либо являются выходами операций. Каждая операция имеет список зависимостей список операций, которые должны быть выполнены до исполнения этой задачи. Операция может быть исполнена, если нет неис полненных операций, от которых она зависит. Таким образом, множество списков зави симостей определяет частичный порядок на множестве операций. Списки зависимостей фор мируются разработчиком сценария либо, как будет представлено далее, компилятором высокоуровневого языка описания сценариев. Возможность задавать произвольный порядок помимо обусловленного зависимостями по данным позволяет использовать операции с по бочными эффектами, при этом с исполнительной системы планировщика снимается задача отслеживания и обработки побочных эффектов. Примерами побочных эффектов могут быть операции ввода вывода или инициализации ресурсов вычислителя например, буфера па мяти GPU в одной из операций, потребление в другой. Вычислитель принимает на вход тройку множеств, где множество опе раций, множество зависимостей между операциями, таблица сопоставления объ ектов данных, являющихся входными для сценария, с их именами мнемониками, исполь зуемыми в сценарии. В таблице указывается URI объекта, если это ссылочный тип, или непосредственно некоторая сериализация объекта в противном случае. Запись сценария в виде тройки, называется внутренним представлением сценария. Такая модель абстрагирует подсистему формирования сценариев от деталей реализации вычислителя, позволяет создавать варианты языков описания сценария текстовые, визуаль ные и оставить свободу выбора конкретной реализации сценария подсистеме организации распределенной обработки см. ниже. Для накопления знаний предлагается использовать методы машинного обучения. Бла годаря этому система сможет самостоятельно извлекать взаимосвязи между объектами пред метной области исходя из действий пользователей. У подхода есть свои недостатки. Так, методы машинного обучения не дают однозначной интерпретируемости и доказуемой кор ректности вывода, но для целей создаваемой системы достаточно, чтобы сохранялась информация об истории происхождения того или иного утверждения. Основная идея состоит в том, чтобы оценивать вероятность использования пользователем функции в контексте при формировании сценария на основе статистики других пользова телей. Для этого адаптируется задача анализа рыночной корзины, сформулированная в 27 и получившая широкое развитие в 2006 г. во время конкурса Netflix Prize по предсказанию пользовательских оценок фильмам и рекомендациям фильмов на их основе 28. Задача конкурса формулировалась так есть множество пользователей и множество фильмов . Известна матрица размерностью, содержащая пользовательские оценки фильмов. Требуется научиться предсказывать оценку пользователя и предлагать пользователю фильмы с наивысшей предсказанной оценкой. Для этой задачи эффективным решением оказались латентные модели 28. В задаче рекомендации функций есть заметные отличия 1 пользователь не ставит оценки функциям это сильно отличается от основных пользо вательских задач и будет отвлекать пользователя 2 так как система рекомендаций нужна для помощи неопытным пользователям, необ ходимо строить рекомендации только на основе действий более опытных пользователей, т. е. информации от одних пользователей система должна доверять меньше, чем информации от других. Для решения этих проблем предлагается следующее. 1. В качестве оценки функции здесь берется вероятность применения пользователем конкретной функции в сценарии с учетом контекста набора других использованных в сце нарии функций. Эта вероятность для каждого пользователя рассчитывается эмпирически на основе анализа статистики применения функций в разработанных пользователем сце нариях. 2. Вводится мера доверия системы пользователю, которая используется как вес поль зователя при обучении латентной модели. При расчете вероятности использования функций пользователем делаются два предпо ложения. Первое заключается в том, что распределение вероятности использования функций пользователем не меняется со временем это предположение можно смягчить, если рассмат ривать только сценарии не старше некоторого порогового значения, второе вероятность использования функций в сценарии не зависит от других сценариев. Для вычисления меры доверия пользователю используются следующие эвристики 1 чем больше используется различных функций, тем лучше пользователь владеет мето дами обработки данных 2 чем больше в среднем функций в сценариях пользователя, тем они сложнее и тем лучше он владеет методами обработки данных. Исходя из этого мера доверия пользователю вычисляется следующим образом, где количество различных методов, применяемых пользователем, среднее ко личество методов в сценариях пользователя, веса, константа-смещение сейчас характеризует экспертную оценку навыка пользователя при его регистрации в системе. Изначально веса устанавливаются вручную и при необходимости будут скорректированы по мере появления новых пользователей. В будущем при увеличении количества пользовате лей планируется собрать экспертные оценки их навыка и на их основе обучить модель линейной регрессии для автоматической настройки весов. В качестве базового языка описания сценариев разработан текстовый язык, за основу которого принят язык F по следующим причинам 1 F является функциональным языком, что позволяет извлекать из кода информацию о функциональных зависимостях между операциями, абстрагирует от деталей исполнения сценария на конкретной вычислительной системе 2 синтаксис F, как и Python который является де-факто стандартом в анализе данных, основан на отступах, в нем нет избыточных ключевых слов, поэтому код на F краток и легко читаем 3 F основан на системе типов Хиндли Милнера 29, поэтому в программах, как и в Python, не требуется явно указывать типы при определении значений и функций при этом язык является статически типизированным, что позволяет обнаруживать большое коли чество ошибок до отправки сценария на исполнение 4 компилятор F обладает открытым исходным кодом, а также предоставляет програм мный интерфейс для анализа кода на предмет наличия ошибок, построения типизированного и нетипизированного абстрактного синтаксического дерева, а также поддержку таких функ ций интегрированных сред разработчика IDE Integrated Developer Environment, как автозавершение кода и сборка inline-документации. Для адаптации языка к целям формирования сценариев, а также спецификации генери руемых параллельных программ изменена семантика некоторых конструкций языка 1 let-связывание связывает объект данных константу или выход функции с мнемо никой, но при этом не определяет порядок вычислений и не задает других зависимостей, помимо зависимостей по данным 2 do-связывание служит для явного обозначения побочных эффектов например, опе раций ввода-вывода, если это требуется вычислителем, в случае использования do-связыва ния с операцией все остальные операции, описанные в сценарии после нее, получают за висимость от этой операции см. пример на рис. 3 3 директива open используется как для подключения наборов сигнатур функций, до ступных на вычислителе, так и для переиспользования других сценариев пользователя. Набор сигнатур это множество объявлений функций, реализации которых доступны на вычислителе в качестве исполняемых программ. Объявления оформляются в виде функ ций на языке F. Они необходимы для того, чтобы произвести проверку соответствия типов в сценарии. На первом этапе наборы сигнатур добавляются в систему вручную совместно с добавлением реализаций функций в подсистему организации распределенной обработки. Впоследствии они будут генерироваться автоматически по описаниям операций. Перед запуском код сценария обрабатывается компилятором, который анализирует сце нарий на наличие ошибок, выявляет зависимости между операциями и транслирует его во внутреннее представление сценария, формируя множества, . Наборы сигнатур функций, как и сценарии, могут также подключать другие наборы и сценарии с помощью директивы open см. рис. 3. Таким образом, исходные коды, необ ходимые для компиляции, образуют направленный ациклический граф. Информация о связях между исходными кодами дугах в графе исходных кодов выявляется компилятором и хра нится совместно с исходными кодами в системе. Подсистема состоит из следующих компонентов 1 графический интерфейс пользователя UI User Interface позволяет пользователю вво дить сценарии обработки данных на языке описания сценариев, инициирует компиляцию сценария во внутреннее представление и передает его менеджеру сценариев 2 компилятор сценариев анализирует сценарий на корректность и преобразует его во внутреннее представление 3 менеджер сценариев принимает запросы от графического интерфейса, собирает инфор мацию о сценарии в форме внутреннего представления и инициализирует его выполнение 4 менеджер зависимостей хранит исходные коды сценариев и наборы сигнатур функций, а также связи между ними 5 сервис анализа пользовательской статистики собирает информацию о запусках пользо вательских сценариев, инициирует создание моделей машинного обучения, рассчитывает, какие функции можно предложить пользователю. В предложенной архитектуре менеджер сценариев и компилятор никак не связаны, ме неджер сценариев работает напрямую с внутренним представлением сценария. Это сделано для того, чтобы можно было подключать к системе и другие средства описания сценария, которые компилируются во внутреннее представление, например визуальные. Все компо ненты представляют собой веб-сервисы и общаются друг с другом через REST API. Обработка собранных данных зачастую является ресурсоемкой задачей из-за их большого объема или же вследствие вычислительной сложности используемых для обработки алго ритмов. Одним из возможных решений для сокращения времени обработки является использо вание высокопроизводительных вычислительных систем ВВС. Это решение позволяет су щественно сократить время выполнения ресурсоемких этапов обработки, однако может быть неуместно для этапов с низкой вычислительной сложностью. Ввиду этого выполнение об работки данных исключительно на ВВС не решает проблему в полной мере, требуется оптимизация использования привлекаемых вычислительных ресурсов. В то же время сценарии обработки данных, имеющие вид, естественным об разом выполняются в распределенной вычислительной среде операции обработки, не зави сящие друг от друга могут выполняться параллельно. Также при организации распределен ной обработки собранных данных можно использовать гетерогенное множество вычислительных систем, включающее в себя как высокопроизводительные узлы для выполнения ресурсоемких этапов обработки, так и узлы для выполнения менее требователь ных к вычислительным ресурсам операций. Более того, при использовании гетерогенного множества вычислителей становится возможным включать в систему специализированные узлы, более эффективно выполняющие определенные виды обработки например, распола гающие ускорителями GPU, а также вычислительные мощности, предоставляемые пользова телями системы. Именно такой подход распределенная обработка данных на гетерогенном множестве вычислительных систем и закладывается в систему. На основе выбранного подхода разработана модель распределенной обработки данных в системе. Модель предполагает централизованное управление процессом обработки дан ных, реализуемое отдельным сервисом. Здесь с каждой операцией из внутреннего представ ления сценария сопоставляется реализующая ее программа, написанная на некотором языке программирования может быть несколько таких реализаций, отличающихся нефункцио нальными свойствами, например, предназначенных для исполнения на различных устрой ствах. Эти программы обработки данных выполняются на некотором подмножестве доступных вычислительных систем, требования к системам определяются по имеющейся об операции информации метод обработки данных, размер входных данных, нефункциональ ные свойства реализаций. Распределение операций по вычислительным системам проис ходит при составлении плана выполнения сценария. Нужно учесть, что некоторые вычислительные системы могут и не находиться под пол ным контролем системы подсистемы организации распределенной обработки. Например, представляет интерес использование ресурсов суперкомпьютерных центров, однако уста новка системного программного обеспечения для управления обработкой данных на таких вычислителях затруднена. Решением является отказ от использования в обязательном по рядке связующего программного обеспечения, разворачиваемого на используемых вычисли тельных системах. Вместо этого взаимодействие с вычислительными узлами решено осуществлять через штатные для используемых вычислительных систем механизмы уда ленного доступа. Также если вычислительная система использует некоторую систему управления прохождением задач СУПЗ, то задачи обработки данных Ecclesia будут ста виться в очередь СУПЗ на общих основаниях. Для обеспечения расширяемости системы новыми типами поддерживаемых вычислительных систем, механизмы взаимодействия с вычислителями выделяются в изолированные модули внутри системы с единым внешним интерфейсом. Ограниченность контроля над вычислительными системами также требует создания виртуальной среды для всех процессов обработки данных внутри узла, для чего используется технология Docker . Для эффективного использования распределенной системы реализуется механизм опти мизирующего планирования. Используется алгоритм RDPSO Revised Discreet Particle Swarm Optimization поиска приближенного решения задачи в многомерном пространстве, имити рующий движение роя частиц, адаптированный для работы с дискретным пространством решений 30. Алгоритмом составляется план выполнения всего сценария до начала вы числений. Не всегда можно заранее составить план выполнения всего сценария. В сценарии могут присутствовать операции, требующие взаимодействия с пользователем например, обработки данных человеком-экспертом. Предсказать время выполнения таких операций в общем случае не представляется возможным, что делает невозможной и оптимизацию времени выполнения сценария целиком. Также к неточности оценок времени выполнения может приводить невозможность в некоторых случаях предсказать объем входных данных для некоторых операций, поскольку время выполнения операций в существенной мере зависит от объема входных данных. Эта ситуация может возникать, например, при очистке данных с различного рода датчиков от шума соотношение объема исходных и очищенных дан ных неизвестно, поэтому объем очищенных данных после выполнения такой операции трудно предсказать. Для решения этой проблемы предлагаются следующие механизмы планирования и испол нения операций обработки данных в распределенной системе. Планирование производится в несколько проходов для подмножеств операций в сцена рии. Для каждой вычислительной системы формируются очереди задач в рамках подсистемы организации распределенных вычислений. Эти очереди в контексте обсуждения алгоритма планирования следует отличать от очередей СУПЗ, которые, возможно, используются на не которых из вычислительных систем. Для каждого прохода выбираются операции, удовлетво ряющие всем следующим условиям операция еще не выполняется на некоторой вычислительной системе операция не зависит ни от одной незавершенной операции, требующей взаимодействия с пользователем операция не зависит ни от одной операции, объем выходных данных которой не из вестен. По мере выполнения сценария таким образом может быть запланировано выполнение всех операций в сценарии операции, требующие взаимодействия с пользователем, и опе рации с неизвестным объемом выходных данных выполняются, необходимая для оценки вре мени выполнения информация становится известна. При использовании такого механизма планирования порядок поступления операций в очереди вычислительных систем не связан ни с порядком поступления сценариев обра ботки данных в систему, ни с желаемыми сроками завершения выполнения сценариев. Это может привести к завершению сценариев в сроки, значительно превышающие желаемые даже в случаях, когда нагрузка на распределенную систему и ее конфигурация позволяют завершить сценарий в срок, а также к бесконечному ожиданию для задач некоторых сценариев. Чтобы избежать возникновения перечисленных проблем, предложен следующий меха низм управления очередями операций для каждой вычислительной системы. 1. В процессе статического анализа сценария и оценки времени выполнения операций, проводимых перед каждым проходом планирования, для каждой операции вычисляется ее собственный желаемый срок завершения. Эти сроки определяются на основе желаемого вре мени завершения для сценария и оценки относительной длительности выполнения операции. 2. На основе собственных желаемых сроков завершения операции из всех выполняемых сценариев объединяются в группы в одну группу попадают операции, время завершения ко торых попадает во временное окно некоторой длительности например, один час. 3. Очереди операций каждой вычислительной системы приоритезируются на основе рас пределения операций по группам операции из групп с более ранними желаемыми сроками завершения имеют более высокий приоритет. При оценке времени выполнения операций, помимо времени выполнения непосредст венно вычислений, учитываются временные затраты на передачу данных на вычислительную систему и задержки перед началом выполнения задачи на вычислительной системе напри мер, вызванные наличием других задач в очереди на выполнение на этой системе. Поставлена проблема разработки информационной системы инструмента для решения задачи работы с исследовательскими данными полного цикла сбора данных, их хране ния, обработки и анализа, с возможностью построения сценариев обработки и сохранения истории данных, формирования и обмена знаниями об обработке данных, как и самими данными на любой стадии работы с ними. На основе трех пользовательских историй сформулирован ряд требований к системе для сбора, хранения и обработки исследовательских данных в ее минимальном жизне способном варианте продукте, MVP minimal viable product. В двух из этих историй ав торы участвовали, разрабатывая простые программные решения для упрощения работы с данными и организации обратной связи системы сбора и обработки данных с участниками эксперимента, третья история является основой для разработки настоящего MVP. Сформулированные требования позволили разработать следующие модели 1 модель представления данных, позволяющую исследователям самостоятельно расши рять и настраивать описания данных и их связей под нужды текущих исследований и сразу пользоваться внесенными изменениями при поиске и доступе к данным 2 модель организации доступа к данным, позволяющую автоматизировать передачу данных между этапами обработки 3 модель абстрактного параллельного вычислителя и язык описания сценариев, что поз воляет описывать сценарии обработки данных в функциональном стиле и автоматически генерировать по этому описанию параллельные программы 4 модель организации распределенной обработки данных на гетерогенном множестве вычислительных узлов. Кроме того, предложены подходы к накоплению знаний о предметной области, которые будут применяться для поддержки составления новых сценариев. В частности, для этого адаптирована задача об анализе рыночной корзины. Продолжение работы будет направлено на реализацию разработанной концепции и проектных решений, их детализацию и уточнение в ходе тестирования прототипа MVP, а именно 1 разработку или подбор визуального языка описания сценария 2 улучшение системы рекомендаций методов на основе статистики работы реальных пользователей 3 исследование возможностей оптимизации различных этапов работы с данными, в том числе для минимизации задержек при обращении к данным 4 исследование альтернативных алгоритмов планирования для различных классов сце нариев обработки данных, в том числе на основе обратной связи с использованием машин ного обучения для предсказания наиболее подходящей схемы планирования 5 исследование возможностей построения вероятностной модели сценария в конкретной предметной области, чтобы можно было полностью генерировать новый сценарий, фиксируя пользовательские параметры. "}
{"title": "СОЗДАНИЕ СИСТЕМЫ   АВТОМАТИЧЕСКОГО РЕФЕРИРОВАНИЯ НАУЧНЫХ ТЕКСТОВ ", "absract": "Описан новый метод автоматического реферирования текстов. На основе предложенного метода создана система, позволяющая получать краткие аннотации научно-технических текстов и определять их темы. Процесс реферирования состоит из пяти основных шагов: предобработка, риторический анализ и преобразование текста, оценка весов, выбор предложений и сглаживание. Предлагаемый метод формирует аннотацию на основе наиболее значимых предложений исходного документа. Значимость предложений частично определяется в процессе риторического анализа, который выполняется с помощью дискурсивных маркеров и коннекторов. Также учитываются технических текстах. Для извлечения ключевых слов и определения тем текста применялась аддитивная регуляризация тематических моделей. : автоматическое реферирование, теория риторических структур, дискурсивные маркеры, аддитивная регуляризация, тематические модели. ", "text": "Ввиду стремительного увеличения объемов текстовой информации в Интернете активные исследования в области компьютерной лингвистики сохраняют свою актуальность. Разработка алгоритмов и создание систем автоматического реферирования, поиска и извлечения информации, классификации и кластеризации текстовых документов по-прежнему являются сложными задачами. Подход, основанный на применении дискурсивного анализа, используется довольно широко для решения различных задач компьютерной лингвистики. Подробный обзор литературы, представленный в работе 1, показывает, что в большинстве случаев дискурсивный анализ способен улучшить качество автоматических систем на 444 в зависимости от конкретной задачи. В работе 2 теория риторических структур применяется для определения важных предложений в документе. Автор представляет входной текст в виде набора деревьев и предлагает использовать алгоритм ограничений для объединения этих деревьев. Далее применяется несколько эвристик для выбора более подходящих деревьев при формировании реферата. Автоматизированная многоязычная система реферирования текста SUMMARIST описана в 3. Эта система сочетает в себе методы понятийного уровня знаний о мире, методы информационного поиска и статистические методы. Алгоритм состоит из трех этапов идентификация темы, интерпретация и генерация. SUMMARIST формирует аннотации на пяти языках английском, японском, испанском, индонезийском и арабском. Система автореферирования научных статей, основанная на дискурсивном анализе, описана в 4. В ней определены семь риторических категорий. Автор работы 5 применил теорию риторических структур для создания графического представления документа. На основе структурного анализа текста вычисляются веса предложений, из которых в итоге получается краткая аннотация. В работе 6 обсуждается создание реферата, содержащего не только информацию из одного конкретного документа, но и дополнительные знания из других, похожих на него по тематике документов. С. Митхун описывает подход, базирующийся на схемах, для формирования аннотаций на основе запросов, в которых используются структуры дискурса 7. Этот подход выполняет четыре основные задачи, а именно категоризация вопроса, идентификация риторических предикатов, выбор схемы и обобщение. Автор создал систему BlogSum и оценил ее производительность относительно релевантности и согласованности вопросов. Полученные результаты показывают, что предлагаемый подход решает проблему несоответствия и дискурсивной несогласованности автоматически созданных рефератов. Исследования в этой области для английского языка достигли достаточно высокого уровня, но для текстов на русском языке данная область изучена сравнительно мало. Анализ подходов для решения проблемы автоматического формирования рефератов научно-техниче ских текстов на русском языке проводился российскими учеными в работах 8 9 . В исследовании 8 описаны методы и алгоритмы, учитывающие нелинейный и иерархический характер текста. С помощью риторических отношений решается проблема экстракции извлечения фрагментов текста. С. А. Тревгода разработал систему, основанную на правилах вывода и узкоспециализированном словаре, ключевых фраз. Гибридный подход, предложенный П. Г. Осмининым 9, сочетает методы экстракции и абстракции. Этот подход был реализован автором в системе реферирования, ориентированной на автоматический перевод. Описанная система построена для текстов по теме математическое моделирование. Были использованы не только риторические структуры, но и глаголы из предметной области математической логики. С помощью найденных ключевых слов определяется вес предложения, затем полученная аннотация формируется в соответствии с шаблонами. Некоторые особенности риторических отношений описаны в работах 10 11 . Там также формулируются утверждения о свойствах этих признаков. Работа 12 описывает опыт построения корпуса на русском языке, содержащего дискурсивные маркеры. Корпус общедоступен, включает в себя тексты разных жанров, таких как научный, научно-популярный, новостной. Прежде чем использовать теорию риторических структур, ее приходится адаптировать для конкретного языка. Это связано с грамматическими особенностями. В своей статье авторы предлагают иерархию риторических отношений, которая, согласно их исследованиям, является наиболее удобной и корректной для работы с текстами на русском языке. В нашей работе описывается подход, позволяющий получать краткие аннотации научнотехнических текстов и определять их темы. Предлагаемый метод формирует аннотацию на основе наиболее значимых предложений исходного документа. Значимость предложений частично определяется в процессе риторического анализа. Для определения тем текстов применяется метод аддитивной регуляризации тематических моделей АРТМ 13. Этот метод позволяет решить проблему неединственности и неустойчивости при помощи введения дополнительных ограничений на требуемое решение. В качестве регуляризаторов могут использоваться сглаживание и разреживание распределений терминов в темах, сглаживание и разреживание распределений тем в документах и др. Теория риторических структур одна из наиболее широко используемых теорий организации текстов 14. Согласно ей, изначально текст делится на неперекрывающиеся фрагменты, а именно на элементарные дискурсивные единицы ЭДЕ. Кроме того, последовательные ЭДЕ связаны риторическими отношениями. Эти части известны как элементы, из которых строятся более крупные фрагменты текстов и целые тексты. Каждый фрагмент по отношению к другим фрагментам выполняет определенную роль. Текстовая связь формируется с помощью тех отношений, которые моделируются между фрагментами в тексте. В теории риторических структур можно определить два типа ЭДЕ. Один из них, называемый ядром, считается наиболее важной частью высказывания, другой, называемый сателлитом, поясняет ядро и считается вторичным. Ядро содержит основную информацию, тогда как сателлит содержит дополнительную информацию о ядре. Сателлит часто непонятен без ядра. Между тем выражения, в которых сателлит удален, могут быть поняты лишь в некоторой степени. Рассмотрим следующий пример, Elaboration Для удобства введем следующие обозначения ядро маркер сателлит предикат для ЭДЕ, которая является ядром предикат для ядра, которое начинается с прописной буквы, т. е. находится в начале предложения предикат для ЭДЕ, которая является сателлитом предикат для сателлита, который начинается с прописной буквы маркер с прописной буквы символ пунктуации, аргументом может быть ., . Теперь приведенный пример может быть представлен в виде формулы исчисления предикатов . .. В предлагаемом подходе риторический анализ используется на этапе построения квазиреферата. Под квазирефератом понимается перечень наиболее значимых предложений текста. Упрощенно этот этап можно описать следующим образом. Сначала необходимо найти в тексте ядерные ЭДЕ. Далее следует преобразовать высказывания, содержащие эти ЭДЕ, так, чтобы получился сокращенный текст, являющийся промежуточным между исходным текстом и готовой аннотацией. В зависимости от разных маркеров и дискурсивных отношений эти преобразования будут разными. Для формального описания действий, выполняемых системой, было принято решение использовать логику предикатов первого и второго порядков. Согласно обозначениям, введенным в предыдущем разделе, для рассмотренного примера действия, выполняемые системой на этом этапе, могут быть записаны в таком виде . . . . . А именно, вначале надо найти маркер, потом необходимо удалить его вместе с сателлитом, оставив предыдущее предложение, которое является ядерным ЭДЕ. Для предикатов, представленных выше, мы ввели специальные, которые выполняются для создания квазиреферата. Они зависят от некоторых глаголов, существительных, маркеров и коннекторов. это слова или фразы, которые не имеют реального лексического значения, но вместо этого обладают важной функцией формировать разговорную структуру, передавая намерения говорящих. Примеры маркеров и действий, связанных с ними, приведены в табл. 1. группы слов, заменяющие маркеры и характеризующие определенные риторические отношения. Коннекторы обеспечивают связь между фразами, они показывают семантическую неполноту предложения. Например, и т. д. табл. 2. Действия для маркеров Риторические отношения Маркеры Действия 1 Elaboration Кроме того SAVEDELETE 2 Cause-Effect Поэтому DELETESAVE 3 Contrast Однако SAVEDELETE 4 Restatement Другими словами SAVEDELETE 5 Elaboration Например SAVEDELETE 6 Evidence Таким образом DELETESAVE Действия для коннекторов Риторические отношения Коннекторы Действия 1 Elaboration В связи с этим SAVESAVE 2 Elaboration Вместе с тем DELETESAVE 3 Elaboration Тем самым SAVESAVE Во время исследования мы создали словарь, состоящий из 121 маркеров и коннекторов, 120 существительных и 108 глаголов с весами, которые часто встречаются в научных и технических текстах. Всего было рассмотрено восемь действий. Ниже описаны некоторые действия. DELETESAVE это действие удаляет предыдущее предложение и сохраняет предложение с заданным маркером. SAVEDELETE это действие сохраняет предыдущее предложение и удаляет предложение с заданным маркером. SAVESAVE это действие полностью сохраняет предложение с заданным маркером и предыдущим предложением. Как известно, в сложноподчиненном предложении выделяются главное и придаточное предложение. В этом случае ЭДЕ более низкого уровня вложены в ЭДЕ более высокого уровня. Для описания действий с вложенными ЭДЕ удобнее использовать предикаты второго порядка. Чтобы проиллюстрировать, как текст преобразуется в случае вложенных ЭДЕ, приведем следующий пример Для того чтобы записать преобразования в формальном виде, добавим следующие обозначения ядро в придаточном предложении сателлит в придаточном предложении предикат для ядра предикат для ядра, начинающегося с прописной буквы предикат для сателлита предикат для сателлита, начинающегося с прописной буквы маркер. . . . ., ., . . ., где . Следует отметить, что использование формализмов логики первого и второго порядка с данной целью пока недостаточно исследовано. В будущем, возможно, придется дополнить этот формализм, чтобы учитывался порядок следования элементов в тексте. Пусть текст статьи, очищенный после предварительной обработки и состоящий из предложений .,..., представляет собой набор дискурсивных маркеров и коннекторов, которые содержатся в этом тексте.,..., представляет собой набор глаголов и существительных, которые часто встречаются в научных и технических текстах. В нашем понимании задача реферирования состоит в том, чтобы найти преобразование текста в реферат такое, что, . Тогда алгоритм построения реферата можно записать в виде последовательных этапов. 1. Предобработка текста. На этапе предварительной обработки из исходного текста удаляются все изображения, таблицы, предложения с формулами, информация об авторах и библиографические ссылки. Авторские аннотации были убраны и отдельно сохранены, чтобы потом можно было оценить систему, путем сравнения результата с исходной аннотацией. 2. Риторический анализ и преобразование текста. На этом шаге обнаруживаются пред ложения, содержащие дискурсивные маркеры и коннекторы. К этим предложениям при меняются определенные действия см. выше. В результате получается квазиреферат, . 3. Оценка весов предложений. Для формирования аннотации подсчитываются веса предложений. Опишем эту процедуру подробнее. Пусть произвольное предложение квазиреферата . При вычислении веса каждого предложения квазиреферата учитывается наличие в этом предложении ключевых слов или многословных терминов, дискурсивных маркеров и коннекторов, а также некоторых слов, которые характерны для научных текстов. Для извлечения из текстов многословных терминов используется алгоритм Turbotopics, разработанный для определения значимых -грамм в английских текстах 15. В ходе создания системы мы адаптировали алгоритм Turbotopics для работы с текстами на русском языке. В итоге вес каждого предложения вычисляется по следующей формуле 1 1 1, где,..., множество ключевых слов и многословных выражений,..., множество значимых глаголов и существительных, которые часто встречаются в научных текстах,..., множество дискурсивных маркеров и коннекторов . 4. Выбор предложений. Из полученного набора предложений см. п. 2 для аннотации отбираются только те, вес которых см. п. 3 превышает заданную пороговую величину, где 0,15 является константой, которая определяется эмпирически. 5. Операция сглаживания процедура преобразования текста, позволяющая получить связный текст из разрозненных фрагментов и при необходимости дополнительно сократить его. Например, в процессе сглаживания заменяются или удаляются некоторые слова или словосочетания и т. д. В табл. 3 приведены примеры предложений до сглаживания и после него. Примеры сглаживания До сглаживания После сглаживания Данное преимущество TD-методов часто имеет решающее значение при использовании в ИС РВ, в некоторых ситуациях эпизоды могут быть настолько продолжительными, что задержки процесса обучения, связанные с необходимостью завершения эпизодов, будут слишком велики. Данное преимущество TD-методов часто имеет решающее значение при использовании в ИС РВ., использование БСД позволяет анализировать лишь один из возможных диагнозов., использование БСД позволяет анализировать лишь один из возможных диагнозов. Для сглаживания предложений используются шаблоны и индикаторы. Мы рассмотрели два типа шаблонов для удаления фрагментов предложений в случае когда аннотация получилась длиннее 250 слов и для дополнения в случаях, когда в аннотацию попал фрагмент незаконченного предложения. комбинации слов, влияющие на вес предложения. В состав индикаторов входят определенные значимые слова, которые мы включили в созданную лингвистическую базу знаний. Примеры индикаторов и действий, связанных с ними, представлены в табл. 4. В данный момент рассмотрено 95 индикаторов. Действия для индикаторов Индикатор Действие Результат 1 В нашей статье REPLACE В статье 2 Существенным является DELETEUNTILDOT 3 Следует подчеркнуть DELETECOMMA 4 Важным представляется REPLACE Действия, используемые при сглаживании REPLACE замена индикатора на другое слово или словосочетание, или удаление данного индикатора DELETEUNTILDOT удаление до конца предложения, начиная с данного индикатора DELETECOMMA удаление фрагмента предложения до следующей запятой DELETE удаление всего предложения. В ходе данной работы была разработана система, блок-схема которой представлена далее Тематическое моделирование заключается в построении модели некоторой коллекции текстовых документов. В такой модели каждая тема представляется дискретным распределением вероятностей слов, а документы дискретным распределением вероятностей тем. В настоящее время существуют разные методы тематического моделирования, такие как PLSA, LDA, ARTM. Главное преимущество тематических моделей в сравнении с нейронными сетями заключается в том, что они хорошо поддаются интерпретации, пользователю понятны причины обнаружения определенных тем в тексте и структура самих тем. Кроме того, часто требуется, чтобы тематические модели учитывали разнородные данные, выявляли динамику тем во времени, автоматически разделяли темы на подтемы, использовали не только отдельные ключевые слова, но и многословные термины и т. д. Чтобы выбрать алгоритм тематического моделирования, мы провели ряд экспериментов, результаты которых представлены в работе 16 . Б ыло принято решение использовать алгоритм ARTM в реализации библиотеки BigARTM 17. Благодаря своей универсальности и гибкости настройки параметров моделей ARTM позволяет комбинировать регуляризаторы, тем самым комбинируя тематические модели. Этот метод гарантирует единственность и устойчивость решения. У ARTM не наблюдается увеличение количества параметров модели с ростом числа документов, поэтому он может применяться к большим наборам данных. Кроме того, предложенная нами модификация позволяет использовать не только однословные, но и многословные выражения, что, на наш взгляд, повышает интерпретируемость модели. Наша система была протестирована на коллекции из 261 научной статьи на русском языке. Эта коллекция собрана на основе выложенных в открытом доступе архивов журналов Программные продукты и системы за 20132017 гг. Далее приведен пример сравнения автоматически полученной и авторской аннотаций. Пока не существует общепринятого эффективного способа автоматической оценки систем автореферирования 18. Во-первых, мы пробовали оценить качество полученных аннотаций при помощи метрики ROUGE, основанной на подсчете количества совпадающих элементов в сравниваемых текстах, например, -грамм или предложений 19. В метрике ROUGE в случае подсчета совпадающих предложений текст аннотации рассматривается как последовательность предложений. Основная идея состоит в том, что чем длиннее самая длинная общая подпоследовательность двух предложений в сравниваемых аннотациях, тем более похожими считаются эти две аннотации. Как правило, используют -меру на основе для оценки сходства между двумя величинами длиной и длиной, считая, что является образцом для сравнения, а просматриваемый элемент. Точность, полнота и -мера согласно ROUGE определяются следующим образом, 1, где, длина самой длинной общей подпоследовательности и, а . Были получены следующие значения метрики ROUGE точность 32,8, полнота 59,04, -мера 34,47 . К сожалению, в работах 8 9, которые описывают системы обработки текстов на русском языке, не приводятся значения метрики ROUGE, поэтому нет возможности сравнить эти результаты с нашими. Также мы пришли к выводу, что некорректно сравнивать результаты работы нашей системы с результатами работы систем для английского языка, такими как, например, 20, поскольку низкие значения ROUGE могут быть связаны с особенностями языкового строя. В частности, русский язык является флективным языком с развитой морфологией, к тому же порядок слов в русском языке относительно свободный. Во-вторых, мы воспользовались экспертной оценкой. Точность полученных аннотаций, оцененная экспертами, оказалась значительно выше. Экспертная оценка результатов реферирования показала, что 86,43 полученных рефератов совпали с авторскими рефератами по содержанию или незначительно отличались от них что на самом деле не всегда свидетельствует о плохом качестве реферата, и только 13,57 представляли собой некорректно отобранные фрагменты текстов. Следует заметить, что полученная нами экспертная оценка выше, чем в работах 8 9. Нами было замечено, что авторы часто используют синонимы, перефразируют и меняют местами предложения. Э кспертная оценка подтверждает, что порядок предложений в аннотации часто не влияет на ее общий смысл. Однако метрика ROUGE не учитывает это. Кроме того, иногда автоматически сформированная аннотация получается длиннее, чем хотелось бы около 500 слов вместо 250. Это связано со стилем изложения самой статьи, и чаще всего означает, что в тексте имеется много содержательных предложений. В-третьих, мы рассмотрели точность, полноту и -меру, которые вычисляются способом, похожим на предложенный в работах 2 8. Поясним подробнее. Предположим, что автоматически полученная аннотация содержит в себе множество ключевых слов и многословных терминов, множество специальных слов из научных и технических текстов, множество дискурсивных маркеров и коннекторов . Объединение этих множеств обозначим . Аналогичные множества можно выделить в эталонной авторской аннотации . Тогда точность, полноту и -меру будем вычислять по следующим формулам, -measure 2 . Сравнительная оценка результатов приведена в табл. 5. Оценка результатов, Система Точность Полнота -мера Scientific Text Summarizer, Trevgoda 2009 67,03 64,81 66,03 Marcu 1998 73,53 67,57 70,42 Преимущество предложенных формул состоит в том, что они позволяют определить вклад каждого из признаков и разных комбинаций этих признаков в общую оценку результата. Например, можно оценить вклад только маркеров и коннекторов или только специальной научной лексики, или того и другого, но без ключевых слов и выражений и т. д. В дальнейшем мы планируем провести подобное исследование данного вопроса. Возможное улучшение предложенного в данной статье алгоритма, по нашему мнению, состоит в том, чтобы дополнить правила удаления менее важных предложений, увеличить количество шаблонов для сглаживания, расширить списки маркеров, коннекторов и индикаторов. Описан подход к автоматическому построению аннотаций научно-технических текстов на русском языке. Процесс состоит из пяти шагов предобработка, преобразование текста, оценка весов, выбор предложений и сглаживание. Преобразование предложений включает риторический анализ. На основе дискурсивных маркеров и коннекторов извлекаются наиболее значимые предложения в тексте. Также учитываются ключевые слова, многословные выражения и специальная лексика, которая часто присутствует в научных и технических текстах. Далее из полученного набора предложений для аннотации выбираются только те, вес которых превышает заранее заданную пороговую величину. Операция сглаживания позволяет получить более связный текст. В дальнейшем планируется провести эксперименты с текстами из различных научных областей на других языках. "}
{"title": "РАЗРАБОТКА АВТОМАТИЗИРОВАННОГО МОДУЛЯ   МИНЕРАЛИЗАЦИИ ПОЛИВНОЙ ВОДЫ ", "absract": "Статья посвящена разработке системы управления фертигацией, которая позволяет осуществлять автоматическую подачу удобрений с учетом показателей pH и EC, полученных от соответствующих датчиков. Для решения этой задачи разработан модуль минерализации, состоящий из двух подмодулей: подмодуль измерения и регулирования pH и подмодуль измерения и регулирования EC. Данные передаются микроконтроллеру для дальнейших действий по управлению системой. В качестве системы принятия решений в работе использована интеллектуальная система на основе нечеткой логики.  фертигация, нечеткий контроллер, минерализация, концентрация, раствор. ", "text": "Подача удобрений к растениям через поливную воду называется фертигацией 1 2. Фертигация это современная агротехнология, которая дает возможность увеличивать урожай и уменьшать загрязнение окружающей среды 3, при этом повышая эффективность использования удобрений. В фертигации контролируются время, количество и концентрация применяемых удобрений. Состав фертигационного раствора подбирается с учетом потребностей культуры, фазы развития растения, субстрата. Важно учитывать соотношение между элементами питания на каждой стадии преимущественно между основными микроэлементами NPK. Для обеспечения баланса питательных веществ на среднеи тяжелосуглинистых темносероземных почвах Гиссарской долины при капельном орошении хлопчатника поливы необходимо осуществлять питательным раствором из расчета годовой нормы питательных веществ азот 250, фосфор 180, калий 60 кгга 4. Автоматическая система для подачи удобрений в поливную воду оснащена электрическим и гидравлическим управляемыми клапанами, а также автоматическим контролем и коррекцией рН и ЕС кислотность и электропроводность. При выборе удобрения для фертигации следует рассматривать 4 основных фактора 3 вид растения и стадии развития почвенные условия качество пресной воды доступность удобрения и цена. Разработанные модули имеют в своем составе датчики для измерения pH и EC раствора удобрения и почвы. Надо отметить, что PH и EC являются двумя важными показатели фертигации. Величина pH это показатель кислотности раствора, т. е. соотношения кислоты и щелочи 114, где 1 кислота, 14 щелочь. Определяет способность растения усваивать питательные вещества из раствора. Электропроводность прямо пропорциональна расстоянию между электродами и обратно пропорциональна площади этих электродов, которые опущены в раствор, т. е., где удельное сопротивление раствора. В работе создана автоматическая система управления фертигацией на основе нечеткого контроллера с учетом основных показателей датчиков и данных, полученных из базы знаний. Данные передаются микроконтроллеру для дальнейших действий по управлению системой. В модуле pH система корректирует значение pH в смесительном резервуаре с помощью подачи в раствор кислоты или щелочи, а в модуле EC система, получая данные о количестве минеральных удобрений в воде, корректирует скорость истечения поливной воды. Заранее по экспертным оценкам в системе установлены значения величины рН и количество кислоты щелочи, которое должно быть введено в смеситель. Таким образом, переменными обратной связи pH являются расход концентрированного раствора кислоты щелочи из кислотно-основного резервуара значения рН питательного раствора, представляющего собой отрицательный логарифм концентрации ионов водорода в растворе изменение рН питательного раствора представляет собой изменение отрицательного логарифма концентрации ионов водорода в питательном растворе с течением времени. Выходом является величина расхода через кислотно-основной клапан, т. е. представляет собой количество концентрированного раствора кислоты щелочи, которое необходимо добавить в питательный раствор для нормализации его рН. Нечеткие входные переменные контроллера следующие вариационный рН представляет собой изменение текущего значения рН питательного раствора во времени разница рН разница между заданной величиной pH и фактическим значением рН питательного раствора кислота щелочь количество раствора кислоты щелочи, который необходимо добавить. В этой системе используются три резервуара водорастворимых удобрений N, P и K, а также емкость для смешивания удобрений рис. 1. Концентрации кгл трех растворов удобрений и количества каждого компонента кг приведены в качестве входных данных для системы управления. Рассматривая скорость потоков растворов лс, система рассчитывает время с, в течение которого он должен подавать -й раствор каждого из трех резервуаров в емкость для смешивания 1. Входным сигналом, который будет передан системе, является временной интервал между двумя процессами смешивания. Этот интервал может исчисляться в днях или часах. Учитывая это время, система будет ждать, прежде чем запускать другой процесс смешивания. Во время ожидания, система будет контролировать и поддерживать уровень влажности в почве. Содержание влаги в почве будет контролироваться и управляться с установленной дискретностью. После того как смешивание закончено, система обеспечивает подачу этого раствора в трубопровод для поливной воды см. рис. 1. Подача раствора выполняется насосом, который через форсунку впрыскивает раствор в трубопровод. Концентрация минерализованной воды определяется путем измерения ее электропроводности. Например, для уменьшения электропроводности необходимо увеличить скорость подачи минерализованной воды. Таблица соответствия скоростей определена экспериментальным путем. Время наполнения смесительного бака растворами удобрений max, где, соответствующие значения времени подачи из резервуара азотного, фосфорного и калийного удобрений. Время, затраченное на измерение pH полученной смеси, где время работы индикатора по определению величины pH раствора, время опроса датчика и передачи сигнала в модуль. Время одного цикла подготовки раствора минерализации массой, где масса -го раствора минеральных удобрений в резервуаре, масса подаваемого раствора кислота основание. определяется из выражения, где время подачи раствора кислота основание в смеситель. На рис. 1 показана технологическая схема подготовки и подачи удобрений совместно с капельным орошением с учетом показателей pH и EC раствора. Разработанный нечеткий контроллер может обеспечить необходимый уровень рН раствора с учетом нелинейности поведения значений рН раствора питательных веществ. Например, переменная разности pH находится в диапазоне от 1 до 1 данные взяты в относительных единицах как отношение pHpH . Благодаря известным из литературы данным, составлены следующие лингвистические значения этой переменной отрицательный, если значение рН находится в пределах от 1 до 0,4 нейтральный, если рН находится в пределах от 0,2 до 0,4 положительный, если pH находится в пределах 0,5 до 1. В системе нечеткой логики созданы входящие переменные, имеющие лингвистические значения рис. 2. Все значения переменных и набор нечетких правил для разработки системы управления были получены на основании опроса экспертов. Чтобы точно настроить эти правила, а также функции принадлежности, мы использовали стратегию проб и ошибок, которая подразумевает настройку исполнительных органов пока набор правил не достиг удовлетворительного значения в исследуемой модели. Каждому лингвистическому входному значению в соответствии со значением функции принадлежности соответствует некоторое действие в системе. Система состоит из девяти правил, которые можно увидеть в окне редактора правил рис. 3. Результат работы нечеткого контроллера для управления значением pH показан на рис. 4. В подмодуле EC значения проводимости используются для получения информации о количестве вводимого удобрения в поток воды для полива. Высокий показатель ЕС раствора означает, что в составе поливной воды присутствует большое количество удобрений. Нечеткие входные переменные контроллера вариационный EC представляет собой изменение текущего значения EС питательного раствора, ошибка EC разница между заданной величиной EC и фактическим значением EC питательного раствора фазы развития хлопчатника три характерные фазы хлопчатника, где показатели EС имеют разные значения. Выход представляет собой поток воды от насоса. Это количество воды, требуемое для достижения необходимой концентрации поливного раствора. Основные правила, разработанные для нечеткого контроллера, приведены на рис. 5, 6. Блок управления состоит из соленоидных клапанов, управляемых электромагнитным реле, которое позволяет открывать закрывать подачу удобрений в смесительный бак. Электромагнитный клапан должен быть включен выключен в соответствии с нечеткой системой подмодулями с pH и EC. На рис. 7 приведена принципиальная электрическая схема модулей подготовки и подачи жидких удобрений для капельного орошения растений. Далее мы приводим алгоритм управления системой фертигации Чтобы проверить работоспособность системы управления, функционирующей на основе нечеткой логики, был проведен ряд экспериментов на модели в программной среде MatlabSimulink. На рис. 9, показан результат моделирования уровня pH в системе. На графике видно, что система отрабатывает изменения уровня pH плавные линии с достаточной точностью 5 . Уровень pH для большинства сельскохозяйственных культур колеблется от 5 до 8. Для моделирования работы контроллера EC мы выбрали скорость подачи поливной воды от 4 до 25 лмин, что соответствует диапазону концентрации питательного раствора от 10 до 62 по сравнению со стандартным принятым в литературе раствором. На рис. 9, показан результат моделирования подачи раствора для регулирования уровня EC раствора. По результатам моделирования работы системы нечеткого регулирования уровня pH и величины EC можно сделать следующие выводы каждый подмодуль может работать автономно, что упрощает разработку и позволяет в дальнейшем добавлять модули по мере необходимости для улучшения и корректировки работы подмодуля стабильность работы системы была продемонстрирована на примерах для производства сельскохозяйственных культур хлопчатника нечеткое управление легко адаптируется, просто и легко реализуется структура нечеткого контроллера является эффективным вариантом управления подачей минерализованной воды в корневую систему растения в силу применения научно обоснованных методов управления ростом и развитием растения, которые заложены в базе знаний интеллектуальной системы. "}
{"title": "ПРОГРАММЫ СТАТИСТИЧЕСКОЙ ОБРАБОТКИ  КЛАСТЕРИЗАЦИИ   И ВИЗУАЛИЗАЦИИ РАСПРЕДЕЛЕНИЯ САЙТОВ СВЯЗЫВАНИЯ   ТРАНСКРИПЦИОННЫХ ФАКТОРОВ В ГЕНОМЕ", "absract": "Исследование регуляции транскрипции генов на основе данных современных технологий высокопроизводительного секвенирования является актуальной задачей биоинформатики, требующей развития новых компьютерных средств, в том числе на основе суперкомпьютерных вычислений. Рассмотрены задачи обработки данных полногеномных профилей ChIP-seq связывания транскрипционных факторов в геномах, определения пиков профилей и поиска сайтов связывания в нуклеотидных последовательностях таких пиков. Разработаны программы для анализа положения сайтов связывания в геноме относительно районов генов, расчета кластеров таких сайтов и визуализации их положения в геноме. Рассчитаны кластеры сайтов связывания транскрипционных факто ров в геноме человека по базе данных Cistrome, построены матрицы совместной встречаемости пар сайтов связывания различных транскрипционных факторов в геноме для различных типов тканей и культур клеток. Проведен вычислительный эксперимент по компьютерной генерации случайных кластеров в геноме, а также оценке встречаемости кластеров большого размера для экспериментально полученных сайтов связывания транскрипционных факторов в геноме человека. Найдены закономерности встречаемости сайтов факторов плюрипотентности в эмбриональных стволовых клетках. Разработанное программное обеспечение доступно по запросу к авторам. : геномика, секвенирование, сайты связывания транскрипционных факторов, промоторы, большие данные, статистика, визуализация.  Работа была поддержана РФФИ и бюджетным проектом ИЦиГ СО РАН (№ 0324-2018-0017). Авторы благодарны Ирине Вадимовне Медведевой, Владимиру Николаевичу Бабенко и Антону Геннадьевичу Богомолову за помощь в работе, и научную дискуссию. ", "text": "Изучение структурно-функциональной организации генома на основе данных высокопроизводительного секвенирования ДНК продолжает оставаться магистральным направлением, развивающимся на стыке биологии и информационных технологий. Исследование организации генетической информации в геноме на различных уровнях ДНК, РНК и белки требует применения современных технологических подходов высокопроизводительного секвенирования, что, в свою очередь, определяет биоинформационные задачи первичная обработка сырых данных картирование прочтений ДНК, анализ массивов данных анализ дифференциальной экспрессии генов, анализ пиков профилей ChIP-seq и аннотация генома на основе таких прочтений аннотирование транскриптов, определение положения сайтов связывания транскрипционных факторов 1. Ключевую роль в работе клетки играет регуляция транскрипции генов, которые определяют свойства клетки 2. Изучение проблемы регуляции, развитие методов и технологий секвенирования привели к накоплению огромного количества данных, полученных различными методами секвенирования, такими как Hi-C, ChIP-seq, BS-seq, DNaseI-seq, ATAC-seq, NOMe-seq, RNA-seq 1 3 4. Доступны большие объемы данных как для генома человека, так и для геномов других модельных организмов эукариот мышь, крыса, растения. Рассмотрим несколько уровней регуляции транскрипции с точки зрения анализа данных 4. Первый и, возможно, основной уровень это регуляция на уровне ДНК, здесь регуляция осуществляется за счет связывания транскрипционных факторов с сайтами на ДНК, что может приводить как к активации транскрипции, так и к ее остановке 5. Также на этом уровне выделяется влияние метилирования ДНК, которое может оказывать влияние на регуляцию за счет метилирования сайтов связывания транскрипционных факторов ССТФ, что приводит к изменению сродства транскрипционного фактора ТФ к его сайту 6. Следующий уровень это регуляция на уровне хроматина, где в зависимости от модификаций гистонов может меняется структура хроматина, он может быть в открытом или закрытом состоянии, что влияет на транскрипцию генов. Состояние хроматина определяется по данным анализа геномных профилей секвенирования. В закрытом состоянии хроматина транскрипционные факторы и транскрипционная машина эукариотической клетки неспособна подобраться к сайту начала транскрипции из-за физической недоступности ДНК для этих белков 7 8. Третий немаловажный уровень регуляции осуществляется за счет трехмерной структуры хромосом. Трехмерная упаковка в ядре клетки может оказывать значительное влияние на регуляцию экспрессии генов за счет сближения удаленных регуляторных участков эн хансеров, сайленсеров и промоторов генов, тем самым регулируя уровень экспрессии ге нов 9 10. Несмотря на большой массив накопленной информации, остаются пробелы в знаниях о регуляции экспрессии генов, что приводит к необходимости продолжать исследования, связанные с анализом регуляции экспрессии генов эукариот в масштабе генома, и разработку соответствующих программных инструментов. Исследование регуляции экспрессии генов эукариот в масштабе генома требует изучения сайтов связывания транскрипционных факторов ССТФ, контролирующих транскрипцию генов, их геномной локализации, определения их генов-мишеней 3 11. Благодаря развитию методов высокопроизводительного секвенирования ChIP-seq, ChIP-on-chip и другим технологиям, сопряженным с иммунопреципитацией хроматина ChIP Chromatin ImmunoPrecipitation 4, стал доступен огромный массив новых данных, позволяющих исследовать все сайты связывания заданного транскрипционного фактора в геноме, а также комбинации таких сайтов 3 12. Экспериментально установленное число сайтов в геноме может варьировать от нескольких сотен до десятков тысяч 1 3 4 12. Значительная часть ССТФ располагается в дистальных удаленных районах генов, что затрудняет точное определение тех генов, транскрипцию которых они регулируют. Встают задачи анализа регуляторных районов генов, в том числе дистальных, поиска закономерностей расположения в них сайтов и контекстных сигналов с помощью статистических, логических и биоинформационных методов 11 13 14 Исследование влияния близко расположенных и пересекающихся по своему расположению ССТФ в промоторах и энхансерах на уровень экспрессии генов является одним из важных направлений исследований перекрывающиеся нуклеотидными последовательностями сайты связывания изучены недостаточно 15. С использованием данных ChIP-seq для профилей связывания ТФ в геноме мыши ранее были исследованы взаимодействия транскрипционных факторов в плане одновременного связывания различных ТФ в геномных районах так называемые множественные локусы регуляции транскрипции 3 12. Одним из важных биомедицинских приложений является построение полногеномных карт регуляторов плюрипотентности NANOG, OCT4, SOX2, KLF4 в эмбриональных стволовых клетках и связанных с ними кластеров сайтов других транскрипционных факторов 3. Накоплены экспериментальные данные о трехмерной организации геномных участков удаленные энхансеры, пространственные домены, что служит основой для более сложных моделей регуляторных районов 1 4. В настоящей работе представлены скрипты для анализа сайтов по данным ChIP-seq, расчета кластеров сайтов и их визуализации в форме тепловых карт, развивающие подходы, представленные в 12 на новых данных и выполненные в другой среде программирования. В работе использовались пики ChIP-seq для клеточной линии эмбриональных стволовых клеток человека H1. Данные в виде BED-файлов загрузили из базы данных Cistrome 16, были загружены координаты пиков 38 транскрипционных факторов. Отметим, что существует огромное количество баз данных по сайтам связывания транскрипционных факторов, которые содержат в себе как данные по ChIP-seq Expression Atlas, Roadmap epigenomics project, ENCODE, так и данные по непосредственным координатам ССТФ и мотивам связывания ТФ TRANSFAC, JASPAR 17 18, также существуют базы данных, разработанные в России, TRRD 19 20, GTRD 21, HOCOMOCO 22. Для анализа данных был разработан набор скриптов на языке R, в последующем они были собраны в пакет, названый ClanChIPeaks, который можно свободно скачать из репозитория GitHub . При разработке ClanChIPeaks и анализе данных также использовались сторонние пакеты из репозиториев Bioconductor GenomicRanges, AnnotationHub, ChIPeeker и т. д. и CRAN ggplot2, fastclust и т. д.. Общий алгоритм анализа пиков ChIP-seq при работе в пакете ClanChIPeaks и их кластеризация представлены на рис. 1. На первом этапе необходимо загрузить экспериментальные данные в среду R при помощи функции peaks.read, данная функция возвращает объект GenomicRanges. Отдельно этот объект и другие широко используемые классы объектов, используемые в Bioconductor для работы с биологическими данными, представлен в статье 23. На втором этапе отдельно от анализа кластеров ClanChIPeaks позволяет проводить небольшой анализ пиков ChIP-seq. Так, например расчет плотности распределения пиков около начала сайтов транскрипции с использованием функции peaks.near.TSS, а также аннотация пиков, т. е. в каком регионе находятся пики экзон, интрон, 5-нетранслируемая область, 3нетранслируемая область, межгенное пространство, для этого используется функция peaks.annotation. На третьем этапе осуществляется генерация случайных пиков ChIP-seq, которые обладают той же общей шириной пиков, и проводится их кластеризация. Данный этап необходим для выявления размера кластера, который не будет получаться по случайным причинам. На четвертом этапе непосредственно проводится кластеризация пиков ChIP-seq полученных экспериментально, это осуществляется при помощи функции peaks.clustering. Данная функция возвращает стандартный объект list, где каждый элемент list является объектом data.frame, содержит пики из одного кластера и информацию о них начало пика, конец пика, ширина и др.. При помощи функции cal.matrix можно посчитать попарную встречаемость каждого транскрипционного фактора, результат будет представлен в виде матрицы. На последнем этапе можно проводить анализ посчитанных данных при помощи стандартных методов, встроенных в R, а также визуализировать данные при помощи пакетов ggplot2, corrplot и др. На основании геномных координат начало и конец геномного участка пиков профилей ChIP-seq для 38 транскрипционных факторов клеточной линии H1 была рассчитана ширина каждого пика для 9 ТФ E2F6, CREB1, MYC, ZNF143, MXI1, SP4, YY1, NRF1, NANOG построены графики распределения ширины пиков, представленные на рис. 2. Для представленных на рис. 2 транскрипционных факторов минимальное значение ширины пика составляет 147 п. н., медианные значения ширины пиков варьируют от 173 п. н. у MXI1 до 255 п. н. у NRF1, а максимальные значения ширины пиков от 1074 п. н. у NANOG до 2345 п. н. у E2F6. Отметим, что сам сайт связывания ТФ имеет длину порядка 10 п. н., что делает необходимым искать точное положение сайтов связывания ТФ по их мотивам в нуклеотидных последовательностях пиков геномного профиля ChIP-seq размером в сотни нуклеотидов. Также было посчитано распределение положения пиков ChIP-seq для 6 ТФ из общего набора в 38 ТФ клеточной линии H1 в разных участках генома относительно гена интроны Introns, экзоны Exons, промоторы Promoters, 5-НТО 5UTR, 3-НТО 3UTR, межгенное пространствоIntergenic. Результаты представлены на рис. 3. Из рис. 3 видно, что большая часть сайтов находится в интронах и в межгенных районах. В то же время для ТФ JUN доля сайтов в промоторах выше, чем для ТФ CEBP и REST. Распределение сайтов в геноме дает лишь общую картину расположения сайтов относительно генов наибольший интерес представляет определение положения сайта относительно старта транскрипции, что непосредственно влияет на транскрипцию данного гена. Перед тем как изучать кластеризацию пиков ChIP-seq, полученных экспериментально, кластеризацию пиков изучали на сгенерированных данных, при этом суммарная ширина пиков как экспериментальных, так и сгенерированных, совпадала. Случайные пики генерировали следующим образом. Зная общее число экспериментальных пиков на хромосоме, генерировали такое же количество псевдослучайных пиков при помощи генератора псевдослучайных чисел в диапазоне длины хромосомы. Далее сгенерированным пикам задавали значения ширины путем случайного выбора ширины из экспериментальных пиков. Для кластеризации сгенерированных пиков использовали иерархический тип кластеризации и меру расстояния в Евклидовом пространстве. Кластеризацию проводили с использованием стороннего пакета fastclust из репозитория CRAN. Пики ChIP-seq кластеризовались друг с другом, если расстояние от ближайших центров пиков не превышало 25 п. н., таким образом размер кластера увеличивался до тех пор, пока расстояние между кластером и другим пиком не стало больше 25 п. н. Сгенерированные данные ChIP-seq имели 1 485 464 пика, а точка отсечения составляла 25 п. н., для каждой новой кластеризации генерировались новые случайные пики ChIP-seq, всего было проведено 5 реплик. Результаты кластеризации сгенерированных пиков представлены в таблице. Размер и количество кластеров, полученных на сгенерированных пиках Реплика Размер кластера макси мальный количество кластеров предмаксимальный количество кластеров 1 4 5 3 267 2 4 6 3 263 3 4 6 3 263 4 4 4 3 294 5 4 5 3 283 Из результатов, представленных в таблице, видно, что максимальный размер кластера достигает 4, а количество таких кластеров варьирует от 4 до 6. Таким образом, для экспериментальных данных ChIP-seq клеточной линии Н1 при условии, что для анализа мы используем 1 485 464 пика мы приняли гипотезу о том, что минимальный размер кластера, который может образоваться не по случайным причинам, составляет 5 пиков ChIP-seq. Условия кластеризации пиков ChIP-seq, полученных экспериментально, были такие же, как и для сгенерированных пиков иерархический тип кластеризации, мера расстояния Евклидово пространство, максимальное расстояние между пиками в одном кластере 25 п. н.. В кластеризации использовались данные по 31 транскрипционному пику ChIP-seq для клеточной линии человека H1, общее количество пиков составило 1 485 464. Сопоставление размеров кластеров, полученных на экспериментальных данных ChIP-seq и сгенерированных, представлены на рис. 4. Из графика видно, что большая часть кластеров это одиночные сайты и пары сайтов. Логарифм значения числа кластеров уменьшается с ростом количества пиков в самом кластере, при этом для экспериментальных кластеров, полученных из экспериментальных данных, вырисовывается S-образная кривая. Стоит отметить, что логарифм от значения количества кластеров плавно уменьшается только в диапазоне 130, а далее значение становится нестабильным то уменьшается, то увеличивается что связано с малым числом таких больших кластеров. Максимальный размер кластера достигает 37 пиков, а так как количество уникальных транскрипционных факторов всего 31, следовательно, в один кластер могли попадать пики одного и того же ТФ. Для случайно сгенерированных координат не наблюдалось кластеров размером больше 4. Таким образом, кластеры сайтов размером 4 и выше не случайны, что подтверждают сделанные ранее оценки 3 12. Для дальнейшего анализа использовались только значимые кластеры, т. е. кластеры, размер которых составлял 5 пиков или больше. Для ТФ, входящих в такие кластеры, была посчитана матрица встречаемости, которая представляет собой квадратную симметричную матрицу чисел совместной встречаемости пары сайтов для каждых двух транскрипционных факторов из исследуемого набора. Из нее была посчитана матрица корреляций по векторам целочисленных значений встречаемости пар сайтов. Все последующие подсчеты проводили на основе матрицы корреляций. Так, на основе матрицы корреляции был посчитан коэффициент несходства различия, который считается как 1 коэффициент корреляции, для каждой пары ТФ. Этот коэффициент использовался в качестве меры расстояния для построения дендрограммы рис. 5, характеризующей взаимную встречаемость транскрипционных факторов. Из дендрограммы, представленной на рис. 5, можно сделать вывод, что некоторые ТФ предпочитают находиться в одном кластере. Такая, например, группа ТФ, как SOX2, NANOG, BCL11A и POU5F1, образует одну кладу, или PRDM14 и ZNF274, которые также образуют свою кладу. Иным способом представления матрицы корреляции встречаемости ТФ является тепловая карта встречаемости ТФ рис. 6. Более темный синий цвет ячейки соответствует повышенной совместной встречаемости пары сайтов для транскрипционных факторов, представленных в соответствующих строке и столбце матрицы. Две основные ветви на дендрограмме см. рис. 5, соответствующие факторам KLF4, SP2 и др. и факторам SOX2, NANOG и др., визуально выделяются как левый верхний и правый нижний более темные квадраты на тепловой карте см. рис. 6. Тепловую карту построили с помощью пакета corrplot. И действительно, транскрипционные факторы SOX2, NANOG, POU5F1, PRDM14 из второго кластера являются факторами поддержания плюрипотентности, и совместная встречаемость их сайтов связывания обусловлена их общей функцией в клетке 3. Проведен вычислительный эксперимент по анализу кластеров сайтов связывания в геноме человека по базам данных ENCODE и Cistrome. Разработанные программы позволяют оценивать статистические параметры профилей ChIP-seq в геноме человека и модельных геномах, строить распределения пиков по ширине и высоте силе связывания с ДНК или уровнем значимости участка, представленным -value, определять параметры отдельных групп сайтов. Программы позволяют рассчитывать распределение сайтов в геноме относительно старта транскрипции гена для набора сайтов и разметки генов. Возможен статистический расчет положения сайтов в экзон-интронной структуре гена. Программы позволяют рассчитывать колокализацию совместную локализацию сайтов связывания различных транскрипционных факторов, выполнять визуализацию, строить дендрограммы и тепловые карты совместной локализации сайтов. Применение программ для анализа кластеров сайтов связывания в эмбриональных стволовых клетках человека по данным ChIP-seq из ресурса Cistrome позволило уточнить состав кластеров сайтов транскрипционных факторов, описать их функциональную роль. По частоте сигналов в исследованном наборе выделяются группы, относящиеся к NANOG, что подтверждает полученные ранее данные 3. Среди 31 транскрипционного фактора такие группы факторов, как SOX2, NANOG, BCL11A, PRDM14 и POU5F1, имеют тенденцию встречаться совместно более часто. Дальнейший анализ контекстных признаков в геномных последовательностях может опираться на участки низкой сложности текста простые повторы и политракты, сайты связывания нуклеосом 24 25. Интеграция геномных данных позволяет решать качественно новые задачи, представляя описание полногеномной информации, такой как данные проектов ENCODE, FactorBook в геноме человека 26. Интересно отметить паттерны расположения участков простых нуклеотидных повторов пониженной сложности текста в районах однонуклеотидных полиморфизмов в геноме человека 27. Участки простых повторов в геноме труднее картировать в геноме по коротким последовательностям прочтений ДНК при секвенировании 28. Анализ этих сигналов вокруг кластеров сайтов связывания транскрипционных факторов позволит построить модель организации таких геномных районов 13 14, предсказать их функцию по составу сайтов и контекстным характеристикам. В целом данное исследование кластеров сайтов связывания транскрипционных факторов в геноме развивает применение анализа регуляции экспрессии генов в эмбриональных стволовых клетках 29. "}
{"title": "CYTOSCAPE – ПЛАГИН ДЛЯ ПОСТРОЕНИЯ СТРУКТУРНЫХ МОДЕЛЕЙ   БИОЛОГИЧЕСКИХ СЕТЕЙ В ВИДЕ СЛУЧАЙНЫХ ГРАФОВ", "absract": "Современные методы экспериментальных исследований позволяют реконструировать различного типа биологические сети, включая генные и метаболические сети, сети интерактомики, сети коэкспрессии генов, сети заболеваний и т. д. В данной статье представлена разработанная нами система построения структурных моделей  биологических сетей в виде набора случайных графов, структурные закономерности которых совпадают  со структурными закономерностями исходной биологической сети. Такие структурные модели могут быть использованы для проверки различных статистических гипотез на сетях, в исследовании влияния структурных закономерностей в биологических сетях на их функцию и других задачах. При генерации структурных моделей в случайных графах могут быть зафиксированы следующие характеристики: распределение степеней вершин, попарное распределение степеней вершин, средняя степень соседних вершин, коэффициент кластеризации, спектр кластеризации, частота структурных мотивов различных размеров  и др. Разработанная система построена по архитектуре клиент-сервер и состоит из плагина Cytoscape и удаленного вычислительного сервиса. Взаимодействие между клиентом и сервером реализовано посредством фреймворка gRPC с применением протокола сериализации структурированных данных Protocol Buffers. Система позволяет асинхронно конструировать структурные модели заданных биологических сетей в виде случайных графов посредством программ Random Network Generator и GTrie Scanner. Результат построения может быть загружен для визуализации и анализа средствами пакета Сytoscape. С использованием разработанной системы проведен вычислительный эксперимент по реконструкции структурных моделей ряда биологических сетей, для которых удалось построить алгоритм предсказания времени расчетов структурных моделей. : биологические сети, случайные графы, структурные модели, Cytoscape.  Разработка программного обеспечения выполнена в рамках государственного задания ИВМиМГ СО РАН  по проекту № 0315-2016-0005. Подготовка данных для вычислительного эксперимента и расчеты с использованием вычислительных ресурсов ЦКП «Биоинформатика» проведены при поддержке бюджетного проекта № 03242018-0017. ", "text": "Современные методы экспериментальных исследований в молекулярной биологии позволяют реконструировать различного типа биологические сети, включая генные сети, сети метаболических и сигнальных путей, сети интерактомики сети взаимодействий белков, РНК, ДНК, сети коэкспрессии генов, сети ассоциации заболеваний и генетических мутаций, сети кровеносных и лимфатических сосудов, сети контактов в макромолекулах, ассоциативные и семантические сети и др. 111. Сетевое представление сложных биологических систем и процессов достаточно продуктивный подход, который в настоящее время получает широкое распространение. Активно развиваются новые методы анализа сетей для решения различных задач, включая выявление ключевых элементов, структурных мотивов и кластеров в биологических сетях, приоритизацию на этой основе генов, белков, мутаций, поиск биомаркеров заболеваний и т. д. 2 4 6 1113. Для проверки различных статистических гипотез на сетях в качестве нулевых гипотез, как правило, используются различные модели случайных графов, которые могут быть описаны распределением вероятностей на графах или случайным процессом, который генерирует случайные графы. Модели случайных графов, заданные структурные характеристики которых совпадают со структурными характеристиками анализируемой реальной биологической сети, можно рассматривать как структурные модели этой биологической сети. Исследование структурных моделей реальных биологических сетей позволяет выявлять внутренние зависимости между характеристиками сети. Для выявления таких зависимостей осуществляется генерация большого числа случайных графов, имеющих некоторую характеристику, и проверка гипотезы, что с большой вероятностью эти графы также имеют другую характеристику . Структурные модели позволяют также исследовать, от каких характеристик зависит целевой или функциональный признак биологической сети. Все структурные модели являются эквивалентными с точностью до структурных характеристик, по которым построены эти модели. Если имеется возможность оценки целевого или функционального признака биологической сети по ее структуре, то анализ структурных моделей позволяет выявить структурные закономерности в биологической сети, ответственные за проявление ее функций или целевых свойств. Например, сеть капиллярных сосудов характеризуется большой сложностью и может быть описана сетью, от структуры которой зависит кровоток 9 10. Другим примером такого рода целевых свойств могут быть робастность функционирования биологической сети сохранение функций при удалении вершины сети или ребра 14 15. Структурно-функциональные закономерности организации генной сети и сети белок-бел ковых взаимодействий могут быть важны для выделения главных компонент молекулярной системы и использоваться для построения математических моделей генных сетей или молекулярно-генетических систем. Целью настоящей работы является разработка плагина-приложения системы Cytoscape для реконструкции различного уровня приближения структурных моделей исследуемых биологических сетей в виде случайных графов. Мы сосредоточились на одном из типов биологических сетей, описываемых неориентированным графом. К такого рода биологическим сетям относятся сети интерактомики, в частности сети белок-белковых взаимодействий protein interaction network PIN. Исследования в этой области привели к осознанию того, что топологические особенности сетей молекулярных взаимодействий могут дать новые знания об их природе и функциональных характеристиках, участвующих в этих взаимодействиях биологических макромолекул. В статье представлены методы генерации структурных моделей сетей в виде случайных графов и описание распределенной системы генерации структурных моделей, реализованной с использованием клиент-серверной архитектуры клиент-плагин Cytoscape и вычислительный сервис для реконструкции структурных моделей в виде случайных графов. В заключение представлены результаты вычислительного эксперимента по реконструкции структурных моделей реальных биологических сетей. Случайный граф это граф, являющийся результатом случайного выбора из некоторого множества графов генеральной совокупности графов в соответствии с заданным на этом множестве вероятностным распределением. Случайные графы можно описать как распределением вероятности на множестве графов, так и случайным процессом, создающим эти графы. Наиболее простыми и распространенными моделями случайных графов являются модели Эрдша Реньи 16 и Гилберта 17. Для определения модели случайных графов Эрдша и Реньи рассмотрим вероятностное пространство всех графов, имеющих вершин и ребер, где 2 максимальное число всех возможных ребер между вершинами. Пусть, случайный элемент пространства т. е., . Будем считать, что все случайные элементы пространства равновероятны c 1 . Таким образом, заданное вероятностное пространство случайных графов имеет четко выраженную интерпретацию. Другая классическая модель случайных графов введена Гилбертом одновременно с моделью Эрдша и Реньи в 1959 г. 17. В модели Гилберта для определения вероятностного пространства графов задается матрица инцидентности графа в виде массива случайных переменные 1 1, для которых Pr 1 и Pr 0 1 . Случайный граф, в котором вершины и связаны, если случайная величина 1, является случайным элементом вероятностного пространства т. е., . Вероятность получения случайного графа, имеющего вершин и ребер, равна 1 . Для, где максимальное число возможных ребер, эти две наиболее широко используемые модели, и, почти взаимозаменяемы 18. Поэтому многие теоретические результаты получены с использованием модели Гилберта. Однако такие простые модели случайных графов пригодны в качестве нулевых моделей далеко не для всех статистических гипотез. Возможным обобщением модели случайных графов Эрдша и Реньи могут быть модели, в которых вероятности случайных элементов вероятностного пространства различны. Например, часто возникает необходимость использовать модели случайных графов, сохраняющих распределение степеней вершин 19 20 или другие структурные характеристики, наблюдаемые в реальной биологической сети. Такие модели случайных графов можно рассматривать как структурные модели биологической сети. Пусть задана биологическая сеть, которую можно представить в виде простого неориентированного графа, где это конечное множество вершин, а совокупность пар, где, . При этом в графе нет петель, кратных и ориентированных ребер. В данной работе используются следующие численные характеристики графов. 1 степень вершины или число ребер вершины 2 Распределение вероятности степеней вершин графа задается вектором, где вероятность того, что случайно выбранная вершина в графе будет иметь степень . 3 Совместное распределение вероятности степеней вершин определяется матрицей, где, вероятность того, что случайно выбранное ребро объединяет вершины со степенью и . 4 Коэффициент кластеризации 2, 1 где число связей, соединяющих всех соседей вершины, иными словами, есть вероятность того, что два ближайших соседа этой вершины сами есть ближайшие соседи. 5 Коэффициент ассортативности 2 2 2 это коэффициент корреляции Пирсона 0 1 между степенями связанных вершин, где и степень вершин на концах -го ребра, число ребер в графе. Для ассортативных сетей 0 вершины с большим числом ребер чаще связаны с такого же типа вершинами, а вершины с небольшим числом связей, в свою очередь, чаще связаны с вершинами с небольшой степенью, для дисассортативных сетей 0 вершины с большим количеством связей чаще связаны с вершинами с небольшим количеством связей 21. 6 Спектр кластеризации вероятность того, что две вершины, соседних с вершиной степени, будут соседями 22. 7 Структурный мотив неслучайный подграф, частота появления которого в сети значимо выше, чем по случайным причинам 23 24. Одним из подходов для получения случайного графа является рандомизация графа путем перестановки вершин в случайно выбранных парах ребер. В реализованной нами программе RNGmotifs для генерации случайных графов, сохраняющих заданные структурные характеристики, наблюдаемые в исходной биологической сети, используется метод рандомизации сети путем парной перестановки вершин в 2-х случайно выбранных ребрах графа. Процесс рандомизации соответствует Марковской цепи, которая стартует с, . Для рандомизации графа с сохранением распределения степеней вершин на каждом шаге выполняется выбор равновероятно двух непересекающихся ребер графа, и, где, и . Далее делается равновероятно одна замена из двух вариантов замен ребер в графе, или, . Если, простой граф отсутствие петель и параллельных рбер, то с заданной вероятностью принимается, иначе, . В работе 25 показано, что если размер, двух графов и распределение степеней вершин совпадает, то один граф может быть трансформирован в другой с помощью конечного числа шагов данной Марковской цепи. В процессе рандомизации кроме явно задаваемых критериев отбора графов ограничений используются разные алгоритмы реализации Марковских цепочек, которые обеспечивают получение равновероятно всех возможных графов, которые сохраняют либо распределение степеней вершин, либо совместное распределение степеней вершин. Для генерации случайных графов с заданными ограничениями можно задавать вероятность замены ребер, зависящую от функционала отклонения модели на очередном шаге Марковского процесса от исходной биологической сети по заданным структурным характеристикам, которые необходимо сохранить в модели, например коэффициент кластеризации, спектр кластеризации, частота структурных мотивов и т. д. Одним из наиболее распространенных является алгоритм, подобный оптимизации методом имитации отжига, когда вероятность отбора соответствует распределению exp, где функционал отклонения модели от исходной биологической сети, который можно интерпретировать как энергию системы при некоторой температуре . Например, в реализованной нами программе RNGmotifs для генерации случайных графов с частотой структурных мотивов, совпадающей с характеристиками исходной биологической сети, используется, где, частоты наблюдения мотивов в биологической сети и модели соответственно, число мотивов в ограничении. Предполагается, что процесс протекает при постепенно понижающейся температуре с увеличением шага Марковской цепи. В этом случае в начале Марковского процесса используется более мягкий критерий отбора принимаются варианты обмена рбер в графе, которые могут привести к отклонению значения функционала качества, но далее критерий становится более жестким, что обеспечивает, в конечном счете, сходимость структурных характеристик модели к характеристикам исходного графа. Такой вариант управления сходимостью функционала качества обусловлен необходимостью выйти из возможного локального минимума функционала и обеспечить возможность достижимости всех графов, имеющих заданные характеристики. Для отбора статистически значимых мотивов в качестве нулевой гипотезы могут быть использованы случайные графы, сохраняющие распределение степеней вершин. При другом подходе, предлагаемом нами, используется пошаговый алгоритм, когда для отбора мотивов степени 1 в качестве нулевой гипотезы используются случайные графы, сохраняющие не только распределение степеней вершин, но и частоты неслучайных структурных мотивов размером . В этом случае структурная модель строится последовательно, начиная от мотивов размером 3 и далее, пошагово включая в структурную модель мотивы большего размера. Для генерации структурных моделей нами также используется подход, основанный на так называемых -сериях, реализованный в программной библиотеке Random Network Generator 26. -серия является вложенной структурой каждый следующий уровень 1 -распре деления содержит тот же объем информации об исходном графе, что и -распределение, но при этом также предоставляет о нем дополнительные сведения посредством включения в список ограничений более строгих правил генерации. Так, нулевой элемент последовательности, 0 -распределение, фиксирует самую грубую из возможных характеристик графа среднюю степень вершин, что дает наиболее слабое из правил генерации. Следующий элемент, 1 -распределение, сохраняет распределение степеней вершин более строгое условие, чем сохранение средней степени вершин. 2 -распределение сохраняет уже совместное распределение степеней вершин, т. е. число подграфов размером 2 другими словами, рбер между вершинами со степенями и . Таким образом, 2 -распределение обозначает попарную корреляцию степеней вершин, а также коэффициент ассортативности графа. 3 -распре деление сохраняет 3-совместное распределение степеней вершин, т. е. подграфов в виде замкнутого треугольника и клик, состоящих из трех вершин со степенями, и, что определяет коэффициент кластеризации, и т. д. 20 26. Здесь используются два варианта рандомизации графа 1 описанный выше алгоритм рандомизации графа с сохранением распределения степеней вершин и 2 алгоритм рандомизации графа с сохранением совместного распределения степеней вершин. В последнем варианте на каждом шаге Марковского процесса выполняются следующие операции. 1. Выбираем равновероятно одно ребро графа, . Далее выбираем равновероятно одну вершину в этом ребре. Пусть это будет . 2. Выбираем равновероятно другую вершину графа такая, что . Далее выбирается равновероятно соседняя вершина, инцидентная . Это дает второе ребро, . 3. Замена рбер в графе, . 4. Если, простой граф, то с заданной вероятностью принимается, иначе, . Такая процедура позволяет выбирать равномерно случайно все возможные элементы, имеющие заданное распределение степеней рбер и совместное распределение степеней вершин 27. Для определения критерия остановки используют различные подходы. Однако теоретические оценки дают слишком большие значения числа шагов, что практически трудно реализуемо для больших графов. В работе 28 предложен более практичный критерий остановки, который находится на основе сходимости распределения вероятностей ряда структурных характеристик графа глобальный коэффициент кластеризации, диаметр графа, максимальное собственное значение Лапласиана графа к стационарному распределению, т. е. если распределение структурных характеристик графа практически не меняется при достижении неко тором числа шагов, то процесс можно останавливать. В результате рекомендовано исполь зовать число шагов Марковского процесса, где число рбер в графе, а 5 30. Говоря о возможностях генерации случайных графов в целом, следует отметить, что Random Network Generator поддерживает работу с -серией вплоть до уровня 2, включая его расширения в виде 2.1 и 2.5 26. Эти уровни являются частными расширениями 2, полученными в результате добавления правил генерации в виде сохранения коэффициента кластеризации и спектра кластеризации исходного графа соответственно. Таким образом, Random Network Generator может применяться для пошаговой реконструкции структурных моделей согласно -серии. Система генерации структурных моделей построена по архитектуре клиент-сервер, где в качестве клиента выступает плагин-приложение системы визуализации графов Cytoscape 2931, а в качестве сервера удаленный вычислительный сервис с модульным подключением программных средств построения структурных моделей. Система Cytoscape это программная платформа с открытым исходным кодом для визуализации и анализа сложных биологических сетей с возможностью интеграции разного типа биоинформационных данных, таких как функциональная аннотация генов, уровень экспрессии генов и пр. Важной особенностью программной архитектуры Cytoscape является технология расширения функциональности системы путем подключения дополнительных модулей плагинов, созданных на языке Java сторонними разработчиками. Большая часть плагинов более 300 доступна на Cytoscape App Store, и их можно устанавливать с помощью менеджера приложений App Manager 32. Большая часть этих плагинов Cytoscape разработаны для решения различных задач биоинформатики в частности, загрузка биологических сетей из доступных баз данных, реконструкция биологических сетей на основе интеграции гетерогенной информации, визуализация, сравнение и анализ сетей, выявление функциональных модулей в сети, генерация атрибутов узлов сети с использованием доступных баз биологических данных, например базы данных по экспрессии генов, GO Gene Ontology аннотации и т. д. Система Cytoscape при реализации проекта дает возможность использовать этот функционал как для получения биологических сетей, так и для анализа структурных моделей. В рамках разрабатываемой системы, плагин-приложение является тонким клиентом, т. е. весь функционал по обработке загружаемых сетей ложится на удаленный вычислительный сервис. Плагин-приложение Cytoscape реализовано на языке Java, вычислительный сервис реализован на языке GoLang 33. Взаимодействие между клиентом и сервером реализовано посредством фреймворка gRPC 34 35 с применением протокола сериализации структурированных данных Protocol Buffers 36. При разработке интерфейса использовались основные компоненты библиотеки Java Swing JPanel, JScrollPane и JTree. В качестве основного элемента интерфейса используется древовидное представление текущей сессии работы с удаленным сервисом. В зависимости от выбранного пользователем элемента дерева, ему предлагается различный набор доступных опций. Например, при выборе узла верхнего уровня, соответствующего одному из доступных методов обработки исходной сети, пользователю предоставляется панель настройки параметров запускаемого алгоритма см. рисунок. Разработанная нами система позволяет асинхронно конструировать структурные модели заданных биологических сетей в виде случайных графов посредством программных библиотек Random Network Generator 26 и RNGmotifs, разработанной в ИЦиГ СО РАН на основе модификации пакета GTrie Scanner 37. Пользовательский интерфейс плагина Cytoscape обеспечивает загрузку биологической сети для анализа, формирование запроса на удаленный вычислительный сервер для реконструкции различных структурных моделей в соответствии с их спецификацией, визуализацию реконструированных структурных моделей и их сравнительный анализ в пакете Cytoscape. Целью вычислительного эксперимента является исследование того, как изменяется время вычислений при генерации различных структурных моделей в зависимости от структурных характеристик исходных биологических сетей. В качестве исходных данных были выбраны следующие биологические сети 1 сеть взаимодействия заболеваний человека 1 419, 2 738, построенная на основе данных об известных ассоциациях заболевание ген и указывает на общее генетическое происхождение многих заболеваний 38 2 сеть белок-белковых взаимодействий у дрожжей 2 361, 5 375 39 3 сеть белок-белковых взаимодействий в печени мыши для белков с циркадным изменением скорости трансляции 5 753, 98 813 40 4 сеть белок-белковых взаимодействий в печени мыши для белков с циркадным изменением скорости трансляции и повышенной скоростью трансляции в начале суток 0 2 702, 25 893 40. Сеть белок-белковых взаимодействий в печени мыши PPI была построена на основе базы данных IID Integrated Interactions Database, версия от 2017-04 41. Далее было выбрано подмножество белков, скорость трансляции которых в печени мыши имеет выраженное изменение в течение суток. С использованием этого подмножества взаимодействующих белков с циркадным изменением скорости трансляции была сформирована сеть белок-белковых взаимодействий 3 PIN 40. Если из белков, гены которых имеют выраженную суточную динамику трансляции, выбрать для каждого момента времени суток подмножества белков со скоростью трансляции в это время больше, чем среднесуточное значение, то мы получаем множество сетей белок-белковых взаимодействий или динамическую сеть белокбелковых взаимодействий PIN T, зависящую от времени суток 40. Таким образом сформирована сеть 4 PIN T0, которая является подмножеством сети 3. Исследование циркадных изменений динамической сети белок белковых взаимодействий PIN T имеет большое значение для выявления главных компонент структуры математической модели циркадного осциллятора. Используя разработанный нами Cytoscape плагин и реконструированную сеть была проведена генерация структурных случайных моделей различного уровня точности dk1.0 сохранение распределения степеней вершин, dk2.0 сохранение совместного распределения степеней вершин, т. е. распределения и корреляций степеней вершин, dk2.1 сохранение совместного распределения степеней вершин и коэффициента кластеризации и dk2.5 сохранение совместного распределения степеней вершин и спектра кластеризации, т. е. вероятности того, что два узла, соседних с узлом степени, будут соседями. Расчеты выполнялись на рабочей станции HP Z800 Xeon 2x X5570QC 2.93ГГц. Сравнительные результаты времени расчетов указанных биологических сетей представлены в таблице. Время вычислений реконструкции моделей биологических сетей, с и предсказание времени вычислений по структурным характеристикам сети Как показывают результаты вычислительного эксперимента, скорость сходимости может сильно различаться даже на сетях с сопоставимым количеством вершин и рбер. Для исследования зависимости времени расчетов от структуры сети нами были оценены различные характеристики сети размеры сети, распределение степеней вершин, коэффициенты кластеризации и ассортативности. Анализ показал, что распределение степеней вершин во всех использованных в вычислительном эксперименте сетях имеет зависимость, где и параметры распределения, которые были оценены для каждой сети с коэффициентом детерминации от 0,87 до 0,92 и уровнем значимости value 10 . Далее для предсказания времени вычисления каждой модели мы использовали метод пошаговой регрессии. Наиболее информативным показателем, учитывающим влияние структуры сети на логарифм времени вычислений, оказались характеристики распределения степеней вершин, в частности параметр . В таблице представлены результаты предсказания времени расчета с указанием уровня достоверности и коэффициента детерминации квадрат коэффициента корреляции между предсказанным и истинным значением времени рас чета. Предсказание времени выполнения запросов для вычисления структурных моделей биологических сетей важно для планирования вычислительных экспериментов. Безусловно, полученные результаты можно использовать только для сетей, имеющих указанную зависимость распределения степеней вершин. Тем не менее предварительные результаты показали перспективность такого рода исследования для этого класса биологических сетей. При этом накопление вариантов проведенных расчетов моделей для различных биологических сетей такого рода могут автоматически использоваться для уточнения предсказания. Разработана система построения структурных моделей биологических сетей в виде набора случайных графов, структурные закономерности которых совпадают со структурными закономерностями исходной биологической сети. При генерации структурных моделей в случайных графах могут быть зафиксированы следующие характеристики распределение степеней вершин, попарное распределение степеней вершин, средняя степень соседних вершин, коэффициент кластеризации, спектр кластеризации, частота заданных структурных мотивов различных размеров и т. д. Система построена по архитектуре клиент-сервер и состоит из плагина-приложения Cytoscape и удаленного вычислительного сервиса. Взаимодействие между клиентом и сервером реализовано посредством фреймворка gRPC с применением протокола сериализации структурированных данных Protocol Buffers. Система позволяет асинхронно конструировать структурные модели заданных биологических сетей в виде случайных графов посредством программных библиотек Random Network Generator и RNGmotifs, разработанной в ИЦиГ СО РАН на основе модификации пакета GTrie Scanner. Пользовательский интерфейс плагина Cytoscape обеспечивает загрузку биологической сети для анализа, формирование запроса на удаленный вычислительный сервер для реконструкции различных структурных моделей в соответствии с их спецификацией, визуализацию реконструированных структурных моделей и их сравнительный анализ в пакете Cytoscape. С использованием разработанной системы проведен вычислительный эксперимент по реконструкции структурных моделей ряда биологических сетей, для которых удалось построить алгоритм предсказания времени расчетов структурных моделей. "}
{"title": "КОМПЬЮТЕРНЫЙ АНАЛИЗ АЛЬТЕРНАТИВНОГО СПЛАЙСИНГА ГЕНОВ   В КУЛЬТУРАХ КЛЕТОК ГЛИОМ ПО ДАННЫМ RNA-SEQ ", "absract": "Современные постгеномные методы изучения экспрессии генов с помощью транскриптомного профилирования имеют большое значение для фундаментальных биомедицинских исследований в онкологии, поиска новых маркеров развития опухолей на культурах клеток глиом. Такие эксперименты требуют разработки новых компьютерных инструментов анализа объемных данных секвенирования. Цель представленного исследования – компьютерный поиск генов и их изоформ, нарушение экспрессии которых связано с развитием глиобластом, с помощью современных высокопроизводительных технологий секвенирования транскриптом и международных биомедицинских банков данных. Поиск генов – кандидатов для терапевтического воздействия в опухолях, в том числе отдельных изоформ генов, актуален в здравоохранении и современной высокотехнологичной медицине.  В данной работе представлены задачи биоинформатики, связанные с разработкой компьютерных конвейеров обработки транскриптомных данных, определения дифференциально экспрессирующихся генов, анализа альтернативного сплайсинга, описания категорий генных онтологий для найденных групп генов. Рассмотрены задачи автоматического поиска и описания функций генов в связи с раковыми заболеваниями, визуализации результатов  и разработки биомедицинских баз данных. Представлен прототип базы данных дифференциального альтернативного сплайсинга генов – «Дифференциальный альтернативный сплайсинг генов человека при вторичной глиобластоме (ДАСГГ)», с возможностью работы через веб-сайт, поиска уровней экспрессии отдельных изоформ в глиальной опухоли. : биоинформатика, транскриптомика, биомедицинская информатика, глиобластома, альтернативный сплайсинг, базы данных.  Работа была частично поддержана Министерством образования и науки РФ (28.12487.2018/12.1), разработка базы данных поддержана бюджетным проектом ИЦиГ СО РАН (№ 0324-2018-0019). Первичный послеоперационный материал был любезно предоставлен А. Л. Кривошапкиным и А. С. Гайтаном (Национальный медицинский исследовательский центр им. академика Е. Н. Мешалкина, Новосибирск).  Авторы благодарны Геннадию Владимировичу Васильеву за организацию транскриптомного секвенирования, Ирине Вадимовне Медведевой, Роману Олеговичу Бабенко и Антону Геннадьевичу Богомолову за помощь в разработке компьютерной базы данных. ", "text": "Исследование экспрессии генов в клетках глиобластомы, поиск генов кандидатов для терапевтического воздействия имеют несомненную актуальность в здравоохранении, современной высокотехнологичной медицине 1. Для такого сложного объекта, как опухоли мозга, требуется проведение новых исследований, опирающихся на современные клеточные технологии, технологии высокопроизводительного секвенирования, методы современной биоинформатики, использующие интеграцию имеющейся информации из международных баз и банков данных. Глиальные опухоли составляют большинство первичных опухолей центральной нервной системы у взрослых и включают целый спектр опухолей, различающихся по уровню клеточной дифференциации и злокачественности. Глиобластома является наиболее распространенной 60 от всех первичных опухолей и злокачественной выживаемость около 1 года после постановки диагноза первичной опухолью центральной нервной системы у взрослых 1 2. Глиобластома может развиваться de novo первичная или как конечный этап трансформации фибриллярных астроцитом II степень злокачественности согласно классификации ВОЗ либо анапластических астроцитом III степень злокачественности согласно классификации ВОЗ вторичная глиобластома 2. Первичная глиобластома в большинстве случаев встречается у лиц в возрасте старше 50 лет, и для нее характерен, как правило, короткий анамнез заболевания. Вторичная глиобластома чаще развивается в возрасте до 45 лет, трансформация в глиобластому может длиться от 1 до 10 лет. Злокачественные глиальные опухоли характеризуются ярким инвазивным фенотипом, отсутствием четких границ распространения опухоли и способностью к продолжению роста после хирургического удаления. Несмотря на анализ отдельных мутаций и генов, далеко не все транскрипты, часто встречающиеся в глиальных опухолях, функционально аннотированы. Таким образом, большую актуальность имеет поиск новых маркеров развития глиом, разработка биоинформационных методов анализа глиом, в том числе разработка компьютерных баз данных по экспериментам транскриптомного профилирования 3. Основные пути активации генов в опухолевых клетках были изучены ранее, в настоящее время необходимо более детальное исследование отдельных изоформ транскриптов, некодирующей РНК, которое может быть сделано с помощью современных компьютерных программ на основе технологий глубокого секвенирования 3 4. Секвенирование полного транскриптома RNA-seq с целью определения генов, ответственных за рост опухоли, на культурах клеток является современным молекулярно-биоло гическим методом исследования, послужившим основой данной работы. Биоинформационная часть исследования связана с использованием наиболее полных международных транскриптомных баз данных и аннотаций транскриптов, анализом отдельных изоформ генов для исследования глиобластомы. В данной работе выполнен перерасчет дифференциального альтернативного сплайсинга, с помощью конвейеров анализа данных 1. Рассмотрены отдельные изоформы генов с дифференциальной экспрессией в культурах клеток глиом и культурах здоровой ткани. Создан прототип компьютерной базы данных с возможностью поиска уровней экспрессии отдельных изоформ в глиальной опухоли. База содержит ссылки на международные ресурсы и базы данных генетической информации в частности OMIM. Подготовлена заявка на госрегистрацию базы данных Дифференциальный альтернативный сплайсинг генов человека при вторичной глиобластоме ДАСГГ Database Differential Alternative Splicing of human Genes in secondary Glioblastome DASGG, ИЦиГ СО РАН, Новосибирск, 2018. База данных доступна по запросу к авторам. Представленные в базе данные по дифференциальному альтернативному сплайсингу могут быть использованы в фундаментальных исследованиях по стволовым клеткам рака, а также в разработке диагностики глиом. Использовалась аннотация генома и транскриптома человека Ensembl . Отметим, что, помимо общей аннотации генома, существуют специализированные международные базы данных по экспрессии генов в различных тканях и органах включая микрочипы и транскриптомные данные GEO NCBI, в том числе содержащие данные по экспрессии в клетках опухолей различных типов The Cancer Gene Atlas, экспрессии генов в компартментах мозга Allen Brain Atlas, а также по транскриптомному профилированию опухолей, в том числе глиом и глиобластом . В работе использовались общие базы данных белковых взаимодействий, такие как HPRD, биохимических реакций KEGG, Interactome . Институтом Аллена разработана база Ivy Glioblastoma Atlas Project по данным пациентов, страдающих глиомой. Авторами этой базы данных ранее выделено 343 гена, специфичных для глиом в различных структурах мозга. По запросу Glioma в базе данных генов и фенотипов заболеваний OMIM Online Mendelian Inheritance in Man получен список генов, ассоциированных с глиомой по литературным данным . Таким образом, были получены базовые списки генов человека для анализа. В работе использовались данные транскриптомного секвенирования на клетках глиом и нормального мозга, полученные в ИЦиГ СО РАН в рамках завершенного проекта РФФИ в сотрудничестве с Национальным медицинским исследовательским центром имени академика Е. Н. Мешалкина, г. Новосибирск см. прилож.. Определение альтернативных вариантов изоформ генов по данным секвенирования представляет важную задачу биоинформатики. Альтернативный сплайсинг процесс, в ходе которого экзоны генов, вырезаемые из пре-мРНК, объединяются в различных комбинациях альтернативно, что порождает различные формы зрелой мРНК. Один ген может порождать не одну, а множество форм белка. Экзон одного варианта сплайсинга может оказаться интроном в альтернативном варианте. Поэтому молекулы мРНК, образованные в результате альтернативного сплайсинга, различаются набором экзонов, что приводит к образованию разных мРНК и, соответственно, разных белков одного первичного транскрипта. Сплайсинг гена может приводить к образованию разных изоформ белка, кодируемого этим геном 5. На рис. 1 схематически представлены варианты сплайсинга гена и образующиеся изоформы. Мутации генов в опухолевых клетках могут приводить к распространению нефункциональных изоформ белка, нарушению клеточной функции и пролиферации опухоли. Ранее считалось, что только мутации в кодирующей ДНК вызывают рак. В настоящее время показано, что изменения в альтернативном сплайсинге также провоцируют заболевание 4 развиваются соответствующие научные направления поиска специфических паттернов сплайсинга 3, исследования процессинга РНК 6. Существует несколько программ и конвейеров анализа данных сплайсинга. Нами разработан и применен конвейер по обработке данных РНК-секвенирования образцов глиом и здоровой ткани человека. Конвейер основан на использовании таких программ, как TopHat2 7, Cuffflinks 8, rMATS 9, Samtools 10, VCFtools 11, GOseq 12, и скриптов на языках программирования Perl, R и Bash. На первом этапе проводится картирование программой TopHat2 данных РНК-секвенирования на референсный геном человека GRCh38 с учетом экзон-интронной структуры рис. 2. На рис. 2 показаны этапы обработки данных оценка качества прочтений, картирование с помощью TopHat. Далее проводится оценка экспрессии генов и выявление случаев дифференциальной экспрессии между анализируемыми образцами при помощи программ Cufflinks 8. Составление списков геномных мутаций проводилось Samtools с последующим нахождением мутаций, встречающихся только в образцах глиомы, программами VCFTools. Найденные мутации сравнивались с мутациями глиомы из базы данных COSMIC 13. Случаи альтернативного сплайсинга предсказывались программой rMATS согласно инструкции, приведенной на сайте программы. Проводился поиск сверхпредставленных терминов генных онтологий GO интернет-ре сурсом DAVID и GOseq по спискам дифференциально экспрессирующихся генов. Полученные списки генов, ассоциированных с глиомой, сравнивались со списками генов, опосредующих развитие глиомы, из литературы. Конвейер реализован на языке программирования Bash под ОС Linux Redhat, использует многопоточность. На вход конвейера подаются данные секвенирования в формате fastq. Результат представляет собой набор файлов со следующей информацией экспрессия генов в каждом из анализируемых образцов, дифференциально экспрессирующиеся гены, случаи альтернативного сплайсинга, сверхпредставленные GO термины, полиморфизмы в каждом из анализируемых образцов, подтвержденные случаи ассоциации с глиомой дифференциально экспрессирующихся генов и полиморфизмов. В результате работы при сравнении тканей глиомы со здоровой тканью были найдены 8 284 случая дифференциальной экспрессии ДЭ. ДЭ гены оказались сверхпредставлены в процессах, связанных с межклеточным взаимодействием, клеточной гибелью, метаболизмом в клетке, генной экспрессией, что подтверждает связь выявленных случаев ДЭ с раковыми заболеваниями. На основе анализа базы данных OMIM и литературы выявлено 73 ДЭ гена, которые, как ранее показано, опосредуют развитие глиомы. Найдено 38 500 мутаций, специфичных глиоме, из которых более 3 000 представлены в базе данных COSMIC. Выявлено более 18 000 случаев альтернативного сплайсинга. При сравнении тканей глиомы со здоровой тканью были найдены более восьми тысяч случаев дифференциальной экспрессии. Выявлено 73 дифференциально экспрессирующихся гена, которые опосредуют развитие глиомы. Построена таблица категорий генных онтологий для генов со значимым дифференциальным сплайсингом в выборках клеток глиобластом и нормального мозга. Категории генных онтологий генов с дифференциальным альтернативным сплайсингом в исследованных выборках глиом, рассчитанные с помощью инструмента DAVID Категория Термин Число генов -value Корректированное значение GOTERMCCDIRECT Extracellular exosome 26 8,3E-7 1,0E-4 GOTERMCCDIRECT Focal adhesion 10 4,8E-6 2,9E-4 UPKEYWORDS Coiled coil 23 3,8E-5 2,4E-3 GOTERMBPDIRECT Intracellular protein transport 6 7,4E-4 1,8E-1 GOTERMCCDIRECT Brush border 4 9,3E-4 3,7E-2 INTERPRO Proteinase inhibitor I2, Kunitz, conserved site 3 2,2E-3 3,4E-1 INTERPRO Proteinase inhibitor I2, Kunitz metazoa 3 2,5E-3 2,1E-1 GOTERMCCDIRECT Membrane 11 3,2E-3 9,2E-2 SMART KU 3 3,3E-3 1,5E-1 KEGGPATHWAY Focal adhesion 5 4,0E-3 2,8E-1 INTERPRO E F-Hand 1, calciumbinding site 5 4,5E-3 2,5E-1 Таблица показывает связь категорий генных онтологий рассчитано по DAVID для 73 генов из списка с клеточной адгезией, мембраной, внеклеточными белками, что указывает на свойства пролиферации опухолей. Для анализа участия изоформ этих генов в развитии глиом был выполнен поиск опубликованной информации в GenBank, OMIM и PubMed. Подтверждение в литературе об их роли в развитии глиомы имеют 123 гена. В процессе анализа дифференциального сплайсинга были выявлены достоверные различия профилей сплайсинга в трех генах, связанных с возможной пролиферацией, между клетками нормального мозга и глиобластомы белок-прекурсор амилоида бета APP amyloid beta precursor protein, ген предрасположенности к раку CASC4 cancer susceptibility candidate 4 и известный онкоген транскрипционный фактор TP53. В частности, в гене TP53 наблюдалась некодирующая изоформа NR015381 с достоверно большей частотой в клетках глиобластомы. Короткая изоформа гена APP NM201413 высоко экспрессировалась в клетках глиобластомы, тогда как наиболее его длинная изоформа NM000484 специфически экспрессировалась в клетках нормального мозга. Для гена CASC4 его короткая изоформа NM177974 экспрессировалась в 6 раз выше в клетках глиобластомы, в то же время наиболее длинная изоформа NM138423 также имела высокий уровень экспрессии. Сверхэкспрессия CASC4 связана с повышенной экспрессией протоонкогена Her2 при раке яичника и молочной железы 11 12. В последние годы определены важные генетические мутации в глиомах. Ведущими мутациями в патогенезе злокачественных глиальных опухолей являются потеря гетерозиготности loss оf heterozygosity LOH в длинном плече хромосомы 10 LOH 10q, мутация гена PTEN 10q23.3, мутации в различных экзонах гена опухолевого супрессора p53, амплификация гена EGFR, делеция или инактивирующие мутации гена p16, а также гиперметилирование промотора гена MGMT. Эти мутации могут служить новым прогностическим фактором наряду с клиническими факторами прогноза и открывают новые перспективы и подходы в лечении GО 16. Последовательное изменение генов EGFRPTENAktmTOR является основным патогенетическим путем развития первичной глиобластомы 17. Амплификация гена EGFR встречается в 40 всех случаев первичных глиобластом и тесно связана с возрастом пациентов 18. Мутация гена TP53 p53 является основным событием, играющим роль в развитии вторичной глиобластомы 19. В ходе анализа дифференциальной экспрессии изоформ выявлены изоформы со статистически значимой разницей в экспрессии между культурой клеток нормального мозга и глиобластом. Ранее с помощью статистических подходов были выделены главные компоненты экспрессии изоформ гена APP в клетках нормального мозга и глиобластомы 1. N-APP связывает TNFRSF21, запускающую активацию каспазы и дегенерацию тел нейрональных клеток через каспазу-3 и аксонов через каспазу-6. На рис. 3 представлены варианты сплайсинга гена APP. Известно десять вариантов транскрипции см. рис. 3. Вариант транскрипции 1 представляет собой самый длинный транскрипт и кодирует самую длинную изоформу, также известную как PreA4 770 NM000484. Экзоны Вариант транскрипции 2 не имеет альтернативного экзона в рамке считывания по сравнению с вариантом 1. Данная изоформа, также известная как PreA4 751, имеет те же N и C-концы, но короче по сравнению с изоформой . Вариант транскрипции 3 не имеет альтернативного внутрикадрового сегмента по сравнению с вариантом 1. Полученная изоформа, также известная как PreA4 695, имеет те же N и C-концы, но короче по сравнению с изоформой . Вариант транскрипции 4 отличается в 5 UTR и кодирующей последовательности и не имеет альтернативного экзона в кадре по сравнению с вариантом 1. Данная изоформа имеет Экзоны более короткий и отличный N-конец и не имеет внутреннего сегмента по сравнению с изоформой . Вариант транскрипции 5 не имеет трех альтернативных экзонов в той же рамке считывания по сравнению с вариантом 1. Полученная изоформа имеет те же Nи C-концы, но короче по сравнению с изоформой . У варианта транскрипции 6 отсутствует альтернативный экзонов в той же рамке считывания по сравнению с вариантом 1. Полученная изоформа имеет те же Nи C-концы, но короче по сравнению с изоформой . Вариант транскрипции 7 отличается в 5 UTR и кодирующей последовательности и не имеет двух альтернативных экзонов в той же рамке считывания по сравнению с вариантом 1. Полученная изоформа короче на N-конце и не имеет внутреннего сегмента по сравнению с изоформой . Вариант транскрипции 8 не имеет альтернативного экзона в кадре по сравнению с вариантом 1. Полученная изоформа, также известная как L-APP752, имеет те же Nи C-концы, но короче по сравнению с изоформой . Для этой транскрипции нет полной расшифровки стенограммы. Вариант транскрипции 9 не имеет двух альтернативных экзонов в той же рамке считывания по сравнению с вариантом 1. Полученная изоформа, также известная как L-APP733, имеет те же Nи C-концы, но короче по сравнению с изоформой . Для этой транскрипции нет полной расшифровки стенограммы. Вариант транскрипции 10 не имеет трех альтернативных экзонов в кадре по сравнению с вариантом 1. Полученная изоформа, также известная как L-APP677, имеет те же Nи Cконцы, но короче по сравнению с изоформой . Для этой транскрипции нет полной расшифровки стенограммы. В качестве примера представлены диаграммы дифференциальной экспрессии изоформ APP и CDKN2A рис. 4 и 5. В ходе анализа экспрессии изоформ APP выявлено, что более короткие изоформы PreA4 751 и L-APP 752 больше экспрессируются в клетках глиом, нежели каноничная изоформа PreA4 770, которая больше экспрессируется в нормальных клетках мозга. Для гена CDKN2A характерна такая же картина, что для гена APP. Более короткие изоформы ENST00000371761 и ENST00000396148 экспрессируются выше в клетках глиом, в то время как самая длинная изоформа ENST00000372418 экспрессируется выше в нормальных клетках мозга. Отметим, что для TP53 весь спектр 37 видимых на наших данных изоформ из 43 известных изоформ, наблюдаемых в клетках глиобластом, отличался по уровню экспрессии от изоформ в нормальных клетках мозга. В частности, некодирующая изоформа NR015381 относится только к клеткам глиобластом. В настоящее время в открытом доступе находятся данные экспериментов секвенирования в опухолевых клетках, в том числе по различным типам глиом. Опубликованы статьи и материалы, содержащие информацию о генах, специфично экспрессирующихся в раковых клетках, о профилях метилирования и т. д. Эта информация нуждается в аккумулировании для дальнейшего использования в медицине. Ранее авторским коллективом была разработана компьютерная база данных BROG генов-мишеней онкогенов, определенных по данным экспериментов ChIP-seq включая транскрипционные факторы ER, MYC, TP53. В базе была представлена разметка сайтов связывания транскрипционных факторов данные о сайтах связывания были получены по открытым публикациям и ресурсам GEO NCBI. На рис. 6 представлен фрагмент интерфейса этой базы данных. Для написания собственного сайта была применена среда разработки WordPress. Сайт располагается по адресу httpgliomaicigsbras.ru. База пополнена данными по альтернативному сплайсингу, ссылками на международные ресурсы экспрессии генов в глиомах, системой навигации. В настоящее время идет патентование Заявка на получение свидетельства регистрации Базы данных Дифференциальный альтернативный сплайсинг генов человека при вторичной глиобластоме ДАСГГ Database Differential Alternative Splicing of human Genes in secondary Glioblastome DASGG. На рис. 7 показана структура сайта, представлены блоки содержащие информацию о научной работе, базы данных, публикации и контакты участников проекта. Структура сайта состоит из трех блоков. Первый блок посвящен информации о научной работе. Здесь можно ознакомиться с целями и задачами научного проекта. В Методах и подходах, использованных в ходе выполнения проекта подробно описана методика получения первичных культур, использованных в дальнейшем для RNA-Seq. Там же есть информация о компьютерном конвейере анализа данных секвенирования транскриптом, комплексе программ на языке Java для статистического анализа расположения генов на пространственных топологических доменах и известных частях хромосом, данных по экспрессии генов. На странице Демонстрация работы размещены изображения, сделанные в ИЦиГ СО РАН, часть которых была опубликована. В разделе Публикации представлен перечень статей, опубликованных в журналах и сборниках. В следующем блоке даны контакты участников проекта и ссылки на международные базы данных. Далее располагается база данных, находящаяся в свободном доступе. Здесь предоставлена информация о дифференциальной экспрессии генов. На рис. 8 представлен скриншот разработанной базы, показывающий уровни экспрессии генов в глиоме и здоровых клетках, и статистические параметры дифференциальной экспрессии. Также на фрагменте таблицы базы данных указаны идентификаторы Ensembl транскрипта, название гена, уровни экспрессии в выборках, статистическая достоверность различий. При помощи анализа данных современных высокопроизводительных технологий секвенирования транскриптом был выполнен компьютерный поиск генов, нарушение экспрессии которых связано с развитием глиобластом. Показана роль изоформ генов при развитии глиобластомы, дана функциональная аннотация 1723. Разработанный компьютерный конвейер может быть использован для решения аналогичных биомедицинских задач, основанных на обработке данных RNA-Seq 3 4. Исследование роли альтернативного сплайсинга при глиоме мозга на культурах клеток проводилось по данным RNA-seq, полученным в ИЦиГ СО РАН 1. Высокопроизводительное секвенирование полного транскриптома культуры клеток RNA-seq с целью определения генов, ответственных за рост опухоли, является современным методом исследования, который должен шире использоваться в медицинской практике 22 23. Работа по поиску маркеров развития глиом имеет большую практическую значимость для медицины. База данных ДАСГГ предназначена для медиков и исследователей, которые заинтересованы в получении информации об альтернативном сплайсинге при опухолях на первичных культурах клеток. Представленные данные могут быть использованы в фундаментальных исследованиях по стволовым клеткам глиом и в разработке диагностик. "}
{"title": "КОМПЬЮТЕРНАЯ БАЗА ДАННЫХ   ДЛЯ АНАЛИЗА ДИФФЕРЕНЦИАЛЬНО ЭКСПРЕССИРУЮЩИХСЯ ГЕНОВ    СВЯЗАННЫХ С АГРЕССИВНЫМ ПОВЕДЕНИЕМ    НА МОДЕЛЯХ ЛАБОРАТОРНЫХ ЖИВОТНЫХ  ", "absract": "Разработка и применение компьютерных средств анализа транскриптомных данных в модельных организмах животных представляет актуальную задачу биоинформатики. Задача исследования экспрессии генов современными методами высокопроизводительного секвенирования в отделах мозга лабораторных животных является исключительно важной для изучения генетических основ поведения в целом. Изучение генетических детерминант агрессивного поведения не только сохраняет актуальность для исследования молекулярных механизмов регуляции поведения, но и имеет широкую практическую составляющую при работе с животными, для решения задач агробиологии. Наследственная предрасположенность животных к агрессивному поведению приводит к появлению различий в строении головного мозга, и сравнение таких различий позволит найти как общие, так и специфичные механизмы регуляции поведения, способствующие проявлению агрессии в провоцирующих условиях среды. Представлены компьютерные программы анализа сплайсинга и прототип базы данных экспрессии генов  в отделах мозга лабораторных животных – серых крыс, селектированных по проявлению агрессивного поведения. Выполнена функциональная аннотация генов с повышенной и пониженной экспрессией в экспериментах на крысах, рассмотрены варианты изоформ и альтернативного сплайсинга этих генов.  : биоинформатика, транскриптомика, сплайсинг, дифференциальная экспрессия, лабораторные животные, генные онтологии, поведение, база данных.  Работа А. О. Брагина и И. В. Чадаевой поддержана РФФИ (проект № 18-34-00496 мол_а). Экспериментальные работы и выполнение транскриптомного секвенирования были поддержаны РНФ в 2014–2016 гг. Работа  с лабораторными животными поддержана грантом Минобрнауки РФ (№ RFMEFI62117X0015). Работа Ю. Л. Орлова была поддержана проектом Министерства образования РФ № 28.12487.2018/12.1. Авторы благодарны А. Л. Маркелю, Р. В. Кожемякиной и С. С. Ковалеву за помощь в работе, предоставление экспериментальных данных и научные консультации по базе данных. ", "text": "Задача исследования экспрессии генов на основе современных методов высокопроизводительного секвенирования в отделах мозга лабораторных животных является исключительно важной для исследования генетических основ поведения в целом, в том числе агрессивного поведения. Несмотря на огромный научный интерес, направленный на изучение различных психофизиологических механизмов, регулирующих поведение, многие механизмы, отвечающие за проявление агрессии, до сих пор мало изучены 1. Агрессия это активная негативная реакция организма на различные проявления внешней среды, один из механизмов борьбы за выживание, в то время как ручное, толерантное, в том числе к человеку, поведение являлось одним из главных направлений искусственного отбора животных в ходе их доместикации, или одомашнивания. Эти вопросы поднимались еще академиком Д. К. Беляевым, основавшим целое направление генетики по результатам работ проведена Беляевская конференция 2017, где широко обсуждались вопросы селекции животных 2. Исследование основ агрессивного и толерантного поведения при совместном содержании животных может быть применено для практических работ по звероводству, а также служит основой биомедицинских исследований. Изучение генетических детерминант агрессивного поведения в целом не только сохраняет актуальность в современном мире, но и имеет широкую практическую составляющую при работе с животными, в том числе в пушном звероводстве. На различных моделях животных см., например, 3 было показано, что одним из возможных последствий отбора по поведению является изменение ряда фенотипических признаков, в том числе окраса шерсти, что важно для исследования сельскохозяйственных животных, в частности норок и лис в пушном звероводстве. Выявление детерминант поведения важно и для животных мясных пород. Наследственная предрасположенность животных к агрессивному поведению приводит к появлению различий в строении головного мозга, и сравнение таких различий позволит найти как общие, так и специфичные механизмы регуляции поведения, способствующие проявлению агрессии в провоцирующих условиях среды. Модельные линии крыс являются удобными объектами для анализа факторов, которые влияют на поведение животных. Применение современных технологий высокопроизводительного секвенирования ДНК при работе с моделями лабораторных животных позволяет провести комплексное молекулярно-генетическое и физиологическое исследование 1 4 5. Селекция серых крыс, которая более 30 лет проводится в Институте цитологии и генетики СО РАН ИЦиГ СО РАН, создает уникальную основу для анализа генетических детерминант поведения. Для анализа генетических основ агрессивного поведения в ИЦиГ СО РАН были выведены две линии серых крыс, . Обе линии крыс в течение около 70 поколений селектировались по поведению по отношению к человеку тест на перчатку когда рука исследователя в защитной перчатке касается животного в клетке, с последующей видеофиксацией и численной оценкой поведения в баллах. В одну из этих линий в ходе селекции отбирали крыс по дружелюбному поведению по отношению к человеку и другим животным, в другую линию крыс по агрессивному поведению, оцениваемому по количественной шкале. Использование в исследованиях нескольких отделов мозга крыс вместе с применением секвенирования транскриптома позволило выявить ряд дифференциально экспрессирующихся генов у агрессивных и ручных неагрессивных крыс 4. В данной работе уточнены механизмы действия генов, представлена кластеризация и компьютерная база данных генов крысы с дифференциальной экспрессией. Экспериментальная часть исследования включала измерение уровней экспрессии с использованием ПЦР в реальном времени и на основе транскриптомного секвенирования. Проведена оценка экспрессии генов белков, связанных с работой дофамина и серотонина, в вентральной тегментальной области ВТО мозга таких крыс на основе РНК-профилирования. Были обнаружены значимые различия в экспрессии генов Th, Ddc, Drd2, Tph2, Htr1a, Htr1b, Htr5b, а также дофаминового Slc6a3 и серотонинового Slc6a4 транспортеров между агрессивными и неагрессивными крысами. Согласно статье 4, был проведен сравнительный транскриптомный анализ РНК из трех отделов мозга агрессивных и неагрессивных ручных крыс. В результате определены различия альтернативного сплайсинга некоторых генов синаптической регуляции, в том числе гена глутаматного ионотропного синапса Grin1. Было получено достоверное различие между пропорциями определенных изоформ транскриптов в нескольких генах, связанных с функционированием синапса, что исследователи связывают с особенностями поведения подопытных животных. Показано значение ферментов, усиливающих действие сплайсинга и приводящих к изменениям структуры РНК энхансеры NOVA12, FOX12, nSR100SRM4, а также веществ, обладающих противоположным эффектом сайленсеры PTB1, PTB2 4. Эксперименты выполнены на самцах серых крыс, прошедших селекцию на агрессивность агрессивные 10 и на прирученность ручные 12. Все крысы содержались в стандартных условиях вивария ИЦиГ СО РАН. Все манипуляции с крысами проводились в соответствии с международными правилами работы с экспериментальными животными. РНК-секвенирование образцов осуществлялось на платформе Illumina с использованием протокола NEBNext mRNA Library PrepReagent Set for Illumina NEB, USA. Библиотеки данных РНК-секвенирования крыс находятся в открытом доступе на сайте The European Nucleotide Archive под индексом ERP011250. В работе использовали 12 образцов нервной ткани образцы 2 повтора из 3-х отделов головного мозга агрессивных и ручных крыс гипоталамус, покрышка среднего мозга ПСМ и периакведуктум серого вещества ПСВ. Для каждой линии крыс анализировали по два повтора. Были рассмотрены гены, где отличия значения экспрессии fragments per kilobase of transcript per million mapped reads FPKM реплик определенного отдела мозга не превышали стандартного отклонения экспрессии, вычисленного по всем 12 образцам. Метод RNA-Seq является мощным инструментом, позволяющим определить активность генов в изучаемом образце. В данном исследовании образцами являлись ткани разных отделов головного мозга крыс гипоталамус, покрышка среднего мозга и периакведуктальное серое вещество. Образцы нервной ткани головного мозга крыс обеих линий были изъяты в соответствии со специализированной картой, представленной в Allen Mouse Brain Atlas . После препарирования образцы тканей мозга крыс обрабатывались в компании Геноаналитика Москва, где мРНК были экстрагированы с использованием Dynabeads mRNA Purification Kit Ambion. Библиотеки кДНК были получены с помощью инструментального набора Illumina США в соответствии с протоколом производителя и направлены на секвенирование. Параметры компьютерной фильтрации прочтений ДНК и картирования библиотек РНКсеквенирования крыс представлены в табл. 1. Статистика ридов библиотек РНК-секвенирования агрессивных и неагрессивных крыс Номер животного в эксперименте Линия крыс Число ридов, млн изначально после фильтрации картированных 2 неагрессивные 22,97 17,51 16,6 5 неагрессивные 22,01 17,13 16,32 8 агрессивные 22,5 17,33 16,56 11 агрессивные 20,15 15,41 14,68 Как можно видеть из табл. 1, изначально в библиотеках было по 2022 млн прочтений ДНК ридов. После фильтрации программой Trimmomatic было удалено около 23 ридов. Из оставшихся после фильтрации ридов около 95 было картировано на референсный геном крысы. Проведен анализ экспрессии генов крыс. Для компьютерного анализа данных РНК-сек венирования мозга крыс был задействован суперкомпьютер ССКЦ СО РАН. Фильтрованные программой Trimmomatic 6 чтения картировались программой TopHat2 6 на референсный геном RGSC Rnor5.0rn5 с последующей оценкой экспрессии программой Cufflinks 8. Уровень экспрессии генов оценивался в FPKM, что позволяет учитывать длину генов и общее количество картированных чтений ДНК. Индексы генов анализируемых белков, взаимодействующих с серотонином и дофаминов, брались из баз данных KEGG 9 и RefSeq 10. Для обработки конечных данных секвенирования были применены программы TopHat2 картирование на геном крысы и Cufflinks расчет уровней экспрессии генов 8. По данным экспрессии были определены дифференциально экспрессирующиеся гены. Разработан и применен конвейер по обработке данных РНК-секвенирования образцов клеток мозга рис. 1. Проводится оценка экспрессии генов и выявление случаев дифференциальной экспрессии между анализируемыми образцами при помощи программ Cufflinks, согласно методике, рекомендованной авторами. Составление списков геномных мутаций проводилось Samtools 11. Случаи альтернативного сплайсинга предсказывались программой rMATS, согласно приведенной на сайте программы инструкции 12. Проводился поиск сверхпредставленных терминов генных онтологий GO интернет-ресурсом DAVID и GOseq по спискам дифференциально экспрессирующихся генов. Полученные списки генов, сравнивались со списками генов, связанных с агрессивностью, из литературы. Конвейер реализован на языке программирования Bash под ОС Linux Redhat, использует многопоточность. На вход конвейера подаются данные секвенирования в формате fastq. Результат представляет собой набор файлов со следующей информацией экспрессия генов в каждом из анализируемых образцов, дифференциально экспрессирующиеся гены, случаи альтернативного сплайсинга, сверхпредставленные GO термины, полиморфизмы в каждом из анализируемых образцов, подтвержденные случаи ассоциации генов с заданным функциональным термином и полиморфизмов. При помощи секвенирования транскриптов удалось выявить различие уровней экспрессии генов при сравнении выборок образцов мозга ручных и агрессивных крыс, а также дифференциальный альтернативный сплайсинг для гена Grin1 табл. 2. Уровни экспрессии гена Grin1 в трех отделах мозга агрессивных и ручных крыс Отдел мозга Крысы агрессивные ручные 1 2 1 2 Гипоталамус 23,9613 14,7004 17,5862 12,1724 Вентральная тегментальная область 9,3537 21,3030 5,6566 7,5530 Периакведуктальное серое вещество 1,6186 4,6650 7,9608 15,5895 Согласно полученным данным, во всех рассмотренных отделах мозга прослеживается тенденция к более широкому размаху экспрессии у агрессивных крыс, чем у ручных. Наряду с этим показатели экспрессии в периакведуктальном сером веществе у агрессивных крыс значительно ниже, чем у дружелюбных, а в вентральной тегментальной области наблюдается обратная ситуация, с более высокими уровнями экспрессии у агрессивных крыс. В гипоталамусе такие явные различия не представлены. Разнородность показателей экспрессии в ВТО и ПСВ, предположительно, связана с особенностями функций данных отделов мозга. Гипоталамус регулирует нейроэндокринную деятельность мозга и ответственен за поддержание гомеостаза всего организма за исключением функции дыхания, сердечного ритма и кровяного давления. Кроме того, гипоталамус связан с большей частью отделов центральной нервной системы. Поэтому сходные уровни экспрессии гена Grin1 у агрессивных и ручных крыс в данном отделе мозга можно объяснить отсутствием патологий работы центральной нервной системы у этих животных. Таким образом, можно предположить, что проявление агрессивного или мирного поведения затрагивает гипоталамус в меньшей степени, нежели формирования мозга, вовлеченные в систему награждения, такие, как вентральная тегментальная область и периакведуктальное серое вещество. Второй представленный в табл. 2 отдел мозга вентральная тегментальная область. Она вовлечена в мезокортикальный и мезолимбический дофаминовые пути. Через ВТО проходят множественные нервные пути, ответственные за систему вознаграждения в поведении. Этот же отдел мозга участвует в формировании зависимости от никотина, героина, кокаина и метамфетамина. Отказ от перечисленных веществ вызывает тревогу, беспокойство и повышение агрессивности. По данным таблицы, экспрессия изучаемого гена в данном отделе мозга у агрессивных крыс в 1,72,8 раза выше, чем у ручных. На основе этого можно сделать предположение, что экспрессия гена Grin1, а следовательно, активность рецепторов NMDA и чувствительность к дофамину в вентральной тегментальной области будет выше у агрессивных крыс. Третьим отделом мозга, показавшим в ходе анализа тенденцию к различиям в уровнях экспрессии у ручных и агрессивных крыс, было периакведуктальное серое вещество. Данный участок головного мозга расположен в непосредственной близости от вентральной тегментальной области и, помимо других функций, участвует в передаче тепловых и болевых импульсов, связывая определенные участки таламуса и сенсорные окончания спинного мозга. Низкий уровень экспрессии гена, кодирующего синаптический рецептор, в данном отделе мозга может означать пониженную восприимчивость к боли и температуре окружающей среды. У агрессивных крыс, по данным табл. 2, показатель экспрессии гена Grin1 в 1,7 9,6 раза ниже, чем у дружелюбных по отношению к человеку. Путем анализа и обработки данных об альтернативном сплайсинге гена Grin1, представленных на сайте NCBI Reference Sequence Database, RefSeq, была составлена табл. 3. Изоформы гена Grin1 RefSeq RefSeqid Изоформа 3UTR Экзон 21 Экзон 5 NM001270606.1 5 короткая NM001270608.1 7 короткая NM001270602.1 1 длинная NM001270603.1 3 длинная NM001287423 9 короткая NM017010 2 длинная NM001270605.1 4 длинная NM001270610.1 8 короткая В табл. 3 все восемь изоформ гена Grin1 отсортированы по наличию или отсутствию экзона 5. 3UTR это 3 нетранслируемая область 3 untranslated region, которая является участком мРНК, выполняющим регуляторные функции. Мутации, затрагивающие данный участок, способны отразиться на экспрессии многих генов за счет особенностей связывания транспортных белков с 3UTR. Кроме того, данный отдел мРНК является заключительным после него идет полиаденилированный конец цепочки и терминирует синтез белка. Согласно типам альтернативного сплайсинга 1. Альтернативная селекция промотора 2. Альтернативный выбор сайтов расщепления полиаденилирования 3. Альтернативный сплайсинг с сохранением интрона 4. Кассетный экзон пропуск экзона, для гена Grin1 представлены такие типы сплайсинга, как пропуск экзона и альтернативный выбор сайта полиаденилирования. Таким образом, самый короткий транскрипционный вариант данного гена составит 3 813 оснований, а самый длинный 4 343 по данным httpncbi.nih.gov. При анализе изоформ гена Grin1 4 было установлено, что в гипоталамусе агрессивных крыс наиболее экспрессируемой является изоформа гена, которая представляет собой наиболее короткий транскрипт, а именно отсутствие экзонов 5 и 21, а также короткий вариант экзона 22. У неагрессивных ручных крыс эта изоформа экспрессировалась в среднем для всей выборки режиме, в то время как экспрессия изоформы с включенным экзоном 21 была повышена. Значения экспрессии генов белков, участвующих в работе дофамина, представлены в табл. 4. Видно что, гены ферментов, участвующих в синтезе дофамина, значимо выше экспрессируются у агрессивных крыс например, тирозин гидролаза . Экспрессия генов ферментов катаболизма дофамина незначительно выше у неагрессивных крыс. Экспрессия генов дофаминового транспортера статистически значимо выше у агрессивных крыс. Экспрессия гена дофаминового рецептора второго типа почти в два раза выше у агрессивных крыс, в то время как гены рецепторов дофамина первого, третьего, четвертого и пятого типов незначительно активнее экспрессируются у неагрессивных крыс. Было показано, что, гены ферментов синтеза серотонина активнее экспрессируются в ВТО мозга агрессивных крыс. Значимых различий экспрессии генов ферментов катаболизма серотонина между двумя линиями крыс не обнаружено. Ген серотонинового транспортера вдвое активнее экспрессируется у агрессивных крыс, экспрессия генов рецепторов, у них ниже. Экспрессия генов рецепторов, выше у агрессивных. Экспрессия генов ферментов метаболического пути синтеза и катаболизма дофамина в ВТО мозга крыс Функция Название гена Уровень экспрессии FPKM Неагрессивные Агрессивные Синтез дофамина Тирозин гидролаза NM012740 3,26 26,68 DOPA-декарбоксилаза NM012545 3,61 7,95 Катаболизм А NM033653 40 39 Катехол-О-метилтрансфераза NM012531 23,7 22,2 Дофаминовые рецепторы NM012546.3 1,75 1,21 NM012547.1 4,42 8,59 NM017140.2 0,17 0,17 NM012944.2 0,2 0,07 NM012768.1 1,82 1,44 Транспортер Дофаминовый транспортер NM012694 0,92 14,46 Найденные гены с дифференциальной экспрессией и дифференциальным альтернативным сплайсингом представлены в разработанной компьютерной базе данных. Рассмотрим некоторые их функции. Глутамат это аминокислота, важная для центральной нервной системы человека и других высших животных, поскольку позволяет проводить нервный импульс через специальные нейронные образования, которые называются синапсами. Рецепторы находятся на постсинаптической мембране и отвечают за соединение мембран синапса после улавливания веществ-активаторов, которые после секреции должны пройти синаптическую щель. NMDA рецепторы являются лиганд-зависимыми. Принцип их работы является нестандартным, поскольку, помимо необходимости улавливать один из активаторов-агонистов глицин или глутамин для проведения импульса необходимо присутствие ионов магния Mg . NMDA N-метил D-аспартат и GABA гамма-аминомасляный тип A рецепторы являются главными ингибиторными ионотропными нейротрансмиттерными рецепторами головного мозга млекопитающих. Их уникальность состоит в возможности одновременно связывать два агонистичных нейротрансмиттера L-глутамат и глицин вместе с осуществлением заряд-зависимой блокады ионами магния путем активации не-NMDA глутаматных рецепторов в синапсе 13 14. Эти рецепторы главным образом представлены в синапсах центральной нервной системы 15. Наличие возбуждающего постсинаптического потенциала ВПСП, появляющегося при активации рецептора NMDA, также способствует повышению концентрации ионов кальция в клетке. В свою очередь, ионы кальция могут действовать в качестве вторичного мессенджера в различных сигнальных путях. Этот процесс модулируется рядом эндогенных и экзогенных соединений и играет ключевую роль в широком диапазоне как физиологических память, так и патологических процессов. Для проведения анализа WGCNA на данных RNA-seq в образцах агрессивных и ручных крыс количество ридов, выровненных на ген, было подсчитано с помощью функции featureCounts в пакете Subread. Из выборки были исключены гены, на которые не выровнялись прочтения RNA-seq. В дальнейший анализ вошло 18 000 генов. Анализ дифференциальной экспрессии осуществлялся с помощью пакета DESeq2 пороговое значение 0,01. Дифференциальная экспрессия между образцами считалась для трех моделей 1 генотип 2 генотип отдел мозга 3 отдел мозга. В первом случае было идентифицировано 37 генов, экспрессия которых выше у ручных крыс, и 40 генов, экспрессия которых выше у агрессивных крыс. Анализ представленности терминов Gene Ontology и путей KEGG с помощью пакета limma показал, что у ручных крыс преобладают гены, участвующие в метаболизме сахаров, в то время как у агрессивных крыс гены, участвующие в метаболизме пуринов и при окислительном стрессе. Для каждой модели получено топ 20 дифференциально экспрессирующихся генов рис. 2, табл. 5, 6. Значимые генные онтологии для генов, экспрессия которых значимо выше либо у агрессивных, либо у ручных крыс Категория генной онтологии -value Агрессивные Catalytic activity 6,10E-04 Transition metal ion binding 6,19E-04 ATP-dependent DNA helicase activity 7,13E-04 Bicarbonate binding 1,47E-03 Carnitine O-acetyltransferase activity 1,47E-03 Deoxyguanosine kinase activity 1,47E-03 D-xylose 1-dehydrogenase NADP activity 1,47E-03 Ручные Monosaccharide binding 8,73E-05 Glucose binding 0,00016 Carbohydrate binding 0,000321 Fructose transmembrane transporter activity 0,001467 Значимые генные онтологии для генов, дифференциально экспрессирующихся между линиями крыс с учетом отделов мозга Категория генной онтологии -value Агрессивные Regulation of ion transport 1,19E-05 Plasma membrane part 1,40E-05 Synaptic transmission, GABAergic 0,000178 Main axon 0,000683 Ручные Regulation of parathyroid hormone secretion 6,24E-06 Oxidoreductase activity 1,25E-05 Regulation of endocrine process 7,49E-05 Regulation of developmental growth 0,000117 Positive regulation of cAMP biosynthetic process 0,000122 Во втором случае было найдено всего 439 дифференциально экспрессирующихся генов, а в третьем 383, при этом только 83 гена из второго списка не совпало с генами из третьего списка. Поэтому дифэкспрессию именно этих генов мы посчитали ассоциированной с агрессивным толерантным поведением у крыс. Пересечения списков генов, дифференциально экспрессирующихся только по генотипу и дифференциально экспрессирующихся по генотипу и по отделам мозга, не наблюдалось. GSEA Gene Set Enrichment Analysis показал, что эти гены активны при синаптической и гормональной регуляции . Таким образом, было выделено еще две группы генов, влияющих на агрессивное толерантное поведение. Анализ взвешенных сетей коэкспрессии генов осуществлялся с помощью пакета R WGCNA. После определения оптимального параметра 6 алгоритм построения WGCNA был использован, чтобы преобразовать коэффициент корреляции экспрессии между генами в коэффициент смежности. Затем на основе этого коэффициента считалось расхождение в топологической матрице перекрытия ТОМ. Используя рассчитанное расхождение, мы провели иерархическую кластеризацию. В результате было выделено 63 кластера коэкспрессии с количеством генов более 20 в каждом. Средняя связность коэкспрессии генов внутри модулей была больше 0,75. Высокая связность генов внутри модулей показывает значительную биологическую релевантность полученных модулей. Поэтому мы оценили, в каких кластерах коэкспрессируются дифференциально экспрессирующиеся гены. Из первой группы 47 генов попало в модуль darkseagreen3 и 12 в brown2. Согласно GSEA, эти модули отвечают за метаболические процессы и за процессинг и связывание РНК соответственно. Большая часть группы генов, экспрессия которых изменяется под влиянием генотипа и особенностей работы отделов мозга, представлена в модулях mediumorchid, brown, brown2. Модуль mediumorchid содержит гены, наиболее вероятно участвующие в проведении синаптических импульсов, а модуль brown гены, связанные с поведением и защитными механизмами в нейронах. а б Также для двух групп генов были построены ассоциативные сети с помощью программы ANDVisio с помощью раскладки в силовом поле 16. Субъединицы NR-2 и NR-3 имеют по несколько гомологов в результате альтернативного сплайсинга, приводящего к разнообразию продуктов транскрипции за счет выборочного удаления одного или нескольких экзонов из иРНК. Альтернативный сплайсинг, обеспечивающий разнообразие вариантов NR-2 и NR-3, обеспечивает и вариабельность работы синапса, а также может иметь определяющее значение для чувствительности рецептора, что, в свою очередь, влияет на скорость и качество проводимого через синапсы нервного импульса. Разработана база данных ГК-АСАП Дифференциальный альтернативный сплайсинг генов крыс, селектированных по агрессивному поведению, которая является компьютерной технологией в области системной биологии животных 17. База данных представляет варианты дифференциального альтернативного сплайсинга генов крыс, селекционированных на агрессивное поведение, полученных по данным экспериментов транскриптомного секвенирования. База данных разработана для экспериментаторов-селекционеров и исследователей, которые заинтересованы в получении информации о генах лабораторных животных серых крыс, и их взаимосвязи с поведением. Представлены варианты изоформ генов с различной экспрессией у крыс с агрессивным и толерантным поведением по отношению к человеку. База данных имеет графический веб-интерфейс, который предоставляет пользователям возможность проводить поиск интересующих образцов, планировать эксперименты и обеспечивает хранение данных о различных экспериментах и образцах генов, оптимизируя научно-исследовательский процесс в области молекулярно-биологических и генетических исследований лабораторных животных. База данных содержит информацию о транскрипте, об уровнях экспрессии данного транскрипта и значимости различий у агрессивных и неагрессивных крыс. Структура базы позволяет пополнять ее данными других транскриптомных экспериментов по изучению агрессии у крыс. База данных содержит уникальные данные об экспрессии, изоформах и дифференциальном альтернативном сплайсинге генов крыс, селектированных по агрессивному поведению, предоставляя комплементарную информацию к базе Маджин 18. Проведено исследование кластеризации генов. Исследования 13 показали, в частности, что NMDA-рецептор не является статичной составляющей синапса, появляющейся вместе с нервной клеткой, а производится в дендритах коротких отростках нейронов в эндоплазматической сети, после чего через аппарат Гольджи происходит его транспорт через синаптическую мембрану. Это свидетельствует, в первую очередь, о высокой пластичности и многофункциональности такой системы. При помощи секвенирования транскриптов удалось выявить различие уровней экспрессии генов при сравнении выборок образцов мозга ручных и агрессивных крыс, а также дифференциальный альтернативный сплайсинг для гена Grin1. При анализе изоформ гена Grin1 4 было установлено, что в гипоталамусе агрессивных крыс наиболее экспрессируемой является изоформа гена, которая представляет собой наиболее короткий транскрипт. У неагрессивных ручных крыс эта изоформа экспрессировалась в среднем для всей выборки режиме, в то время как экспрессия изоформы с включенным экзоном 21 была повышена. Работа представляет продолжение исследований поведения на моделях лабораторных мышей 19 20 и использует современные подходы биоинформатики для анализа транскриптомных данных 21 22. База данных экспрессии генов крыс по транскриптомным экспериментам развивает разработку базы данных RatDNA, построенную ранее по данным микрочипов 23. "}
{"title": "СЕМАНТИЧЕСКИЙ ПОДХОД   К МОДЕЛИРОВАНИЮ ФОНДА ОЦЕНОЧНЫХ СРЕДСТВ  ", "absract": "Фонд оценочных средств является составной частью нормативно-методического обеспечения системы оценки качества освоения студентом учебного материала. Онтологический подход к моделированию фонда оценочных средств позволяет формировать актуальные оценочные документы, которые учитывают не только всевозможные пожелания экзаменатора, но и степень усвоения различных компетенций и степень овладения различными профессиональными функциями.  В статье приведено описание онтологии, семантической и нечеткой моделей фонда оценочных средств. Описан алгоритм порождения шаблона оценочного документа, состоящий из трех этапов: сужение, ограничение  и определение. На каждом этапе генерируется соответствующая нечеткая модель, в рамках которой проверяется непротиворечивость заданного шаблона и выполнимость данного шаблона на имеющейся базе оценочных средств. Для формирования комплекта оценочных документов используется алгоритм CLOPE, позволяющий кластеризовать категорийные данные. : оценочный документ, комплект оценочных документов, фонд оценочных документов, онтология, семантическая модель, нечеткая модель. ", "text": "Каждое учебное заведение планирует, какими способами и средствами будут оцениваться результаты обучения и как будут достигнуты цели образовательной программы. Высшее учебное заведение обязано обеспечить разработку объективных процедур оценки уровня знаний и умений обучающихся. Первым этапом формирования фонда оценочных документов далее ФОС факультета является разработка ФОС по отдельным дисциплинам 1. ФОС по дисциплине представляет собой совокупность контролирующих материалов, предназначенных для измерения уровня достижения студентом установленных результатов обучения данной учебной дисциплины. К таким материалам традиционно относятся экзаменационные билеты, варианты контрольных работ, тесты и т. п. Особенностью образовательных стандартов нового поколения является применение компетентностного подхода при формировании учебного процесса. Понятие компетенция сложное и интегрированное, оно характеризует способность обучающегося применить все приобретенные навыки, умения и знания для решения задач в профессиональной и социальной областях 2. В связи с этим возникает необходимость формировать оценочные документы, позволяющие оценивать уровень освоения обучаемым различных компетенций. К таким материалам можно отнести рефераты, эссе, курсовые работы и т. п. Эти оценочные средства могут разрабатываться в рамках отдельных дисциплин и быть междисциплинарными. При планировании учебного процесса, необходимо учесть актуальные потребности рынка студентов с целью подготовки выпускника, способного успешно работать в профессиональной сфере. Исходя из этого в некоторых учебных заведениях темы выпускных квалификационных работ и дипломных проектов согласовываются с работодателями 3, а некоторые университеты заключают соглашения с различными компаниями для поддержания обратной связи 4. Таким образом, возникает необходимость в формировании оценочных документов, отвечающих требованиям различных профессиональных стандартов, а также требованиям потенциальных работодателей см, например, 5. Такой оценочный документ может формироваться из оценочных материалов отдельных модулей учебной дисциплины или нескольких дисциплин. В связи с постоянным развитием науки и техники структура и содержание учебных дисциплин, а также требования работодателей постоянно меняются. Следовательно, существует потребность в создании программной системы, работающей с постоянно пополняемой базой оценочных материалов. Данная программная система должна обладать возможностью автоматизированного порождения актуальных документов оценки, которые будут отвечать различным запросам экзаменаторов. Семантический подход к моделированию ФОС позволяет успешно справляться с этой задачей. Семантический подход используется в различных сферах и системах обучения, например для моделирования и управления учебной программой 6. Моделирование облегчает доступ к учебной программе и позволяет ее составителям просматривать общий учебный план и обеспечивать соответствие основным целям учебного учреждения. Учебная программа представляет собой структуру, где учебные единицы связаны с результатами и задачами обучения. Кроме того, семантическое моделирование учебной программы облегчает периодическую оценку и анализ соответствия стандартам и потребностям рынка, его можно использовать для обзора, оценки и улучшения программы путем определения ее основных элементов, связывания учебных единиц с задачами и результатами, а также между собой для определения последовательностей и предпосылок. Онтологии предметных областей история, география, программирование и др. и онтологии различных элементов обучения урок, способы оценивания, упражнения 7 позволяют более полно описать сферы учебной деятельности и извлечь необходимую информацию. Описание данных учащихся полезно для оценивания и персонализации. Персонализация в соответствии с профилем учащегося может включать в себя упорядочивание учебного материала и отслеживание его эффективности данные об оценках и пройденный материал 8. Семантическое моделирование также активно используется в оценивании качества освоения учебного материала учащимся. Система 9 представляет собой концептуальную карту, основанную на оценках, полученных студентами в процессе обучения. Эта карта используется в качестве инструмента для определения знаний студентов по пройденным темам. Онлайн-система оценивания OeLe 10 основана на онтологии, которая автоматически маркирует текстовые ответы учащихся на вопросы концептуального характера. Это делается путем сопоставления ответа ученика в форме карты понятий и онтологии предметной области. Помимо оценивания работы студентов, система OeLe также предоставляет информацию об эффективности освоения знаний учащимся, а также содержит отзывы преподавателей о студентах. Формализация предметной области Фонд оценочных средств факультета производилась на языке логики описаний 11 с применением методов семантического моделирования 12 и теории нечетких моделей 13 14. Центральным понятием в данной предметной области является понятие задание. Под мы понимаем минимальную составляющую единицу оценочного документа. Все задания делятся на и . Теоретические задания направлены на оценивание знаний студента. Практические задания направлены на оценивание умений и навыков студента. По своей конструкции делится на следующие виды, и . Вопрос формализуется в виде предложения или нескольких предложений естественного языка, которые хранятся в системе в виде строковой величины и являются единым неделимым объектом. хранится в системе в виде двух строковых величин текст вопроса и текст решения ответа. Текст решения ответа не доступен студентам и может быть использован только экзаменатором. Тестовое задание может содержать от 3 до 10 строковых величин вопрос, правильный ответ, неправильные ответы. по своей структуре похоже на, однако, в отличие от него, здесь оценка сложности см. ниже не является обязательной. Пример тема реферата, тема эссе и т. п. подразумевает набор инструкций, следуя которым нужно выполнить задание например, отчет о производственной практике. Задания также можно разделить по уровню сложности. На сегодняшний день в системе реализовано три уровня сложности, . В дальнейшем возможна настройка системы на более мелкую градацию сложности заданий. Задание должно быть привязано к учебному плану факультета к отдельному модулю учебного плана, модулю дисциплин, отдельной дисциплине или к отдельной теме дисциплины. Также задание может быть привязано к профессиональному стандарту или к отдельным его профессиональным функциям. Эта привязка не является обязательной например, если задание относится к общеобразовательной дисциплине. Задание должно быть привязано к некоторой компетенции или группе компетенций. Эту привязку можно производить либо непосредственно, либо автоматически через привязку к учебному плану. Таким образом, строится множество атомарных понятий предметной области, которое делится на следующие шесть классов, множество понятий, отражающих взаимосвязь с учебным планом множество понятий, отражающих взаимосвязь с множеством компетенций множество понятий, отражающих взаимосвязь с трудовыми стандартами. Каждое атомарное понятие мы воспринимаем как одноместный предикат, т. е. . Множество всех понятий данной предметной области строится согласно стандартному синтаксису, т. е. каждое понятие является булевой комбинацией атомарных понятий. В частности, нас будут интересовать формулы вида, ..., где,..., . Семантически эти формулы означают, что два задания относятся, например, к разным темам в рамках одной дисциплины или к разным дисциплинам в рамках одного модуля, или направлены на проверку разных компетенций и т. д. Для полного описания онтологии предметной области задается конечное множество аксиом . Мы рассматриваем аксиомы трех видов аксиомы общего-частного, аксиомы исключения и аксиомы полноты. Поясним более подробно смысл этих аксиом. . Классы понятий, и иерархически упорядочены, например если Задание относится к теме, то оно относится к дисциплине, а значит, относится к модулю . . Каждый из классов понятий, и является взаимоисключающим, например если задание является легким, то оно не может быть сложным. . Мы предполагаем, что работаем в полностью определенной предметной области. Следовательно, мы считаем, что каждое рассматриваемое Задание должно обладать хотя бы одним признаком из классов, и . Заметим, что задание может не обладать уровнем сложности класс, а также может не быть привязано к трудовому стандарту класс . Заметим, что множество образует онтологию предметной области которую, согласно традициям Логики Описаний, будем называть и является первой компонентой Базы Знаний предметной области . Второй компонентой Базы Знаний будем обозначать через является описанием конкретных Заданий. Рассмотрим конечное множество Заданий,..., . Каждое задание характеризуется наличием отсутствием тех или иных понятий из . Тогда понятие истинноназадании . Средствами Логики Описаний мы проверяем непротиворечивость и . Далее пару, и будем называть Базой Знаний предметной области . По мере появления в данной предметной области новых понятий например, новых профессиональных стандартов или новых заданий База Знаний будет расширяться. Однако общая структура Базы Знаний будет оставаться неизменной. Для проверки непротиворечивости запросов экзаменатора и для определения мощности множества всех оценочных документов, соответствующих запросу экзаменатора, мы используем нечеткую модель 15 предметной области . Эта модель строится на основе . Алгебраическую систему, будем называть предметной области, если . Упорядоченную тройку, назовем предметной области, порожденной моделью, если для любого понятия имеем . Значениями истинности предложений понятий в нечеткой модели являются числа из интервала 0,1, которые отражают статистику Базы Знаний. Более подробное описание свойств нечетких моделей можно найти в работах 16 17. Оценочный документ это набор заданий, который предоставляется студенту с целью проверки его знаний, умений или навыков. Традиционными оценочными документами являются экзаменационный билет, вариант контрольной работы, тест и т. п. В разрабатываемой системе реализована возможность формирования различных оценочных документов. Оценочный документ может быть сформирован для оценки внутри одной дисциплины или быть междисциплинарным, может быть направлен на проверку овладения той или иной компетентностью или трудовой функцией. Вид оценочного документа формирует, составляя . Формирование шаблона оценочного документа происходит в три этапа, и . Этап сужения направлен на формализацию цели проверки. На этом этапе экзаменатор определяет набор дисциплин или набор компетенций, или набор трудовых функций, на проверку которых направлен оценочный документ. В системе данный запрос формализуется в виде формулы ..., где,..., . Далее производится проверка формулы на выполнимость на модели . Описание алгоритма нахождения значения истинности бескванторного приложения на нечеткой модели можно найти в работе 18. Если оказывается, что 0,1, то делается вывод о неполноте базы знаний. В этом случае экзаменатору нужно либо пополнить базу знаний новыми заданиями, либо пересмотреть цель проверки. На втором этапе экзаменатор задает количество заданий в оценочном документе и накладывает ограничения на совместимость заданий. По умолчанию ставится следующее ограничение совместимости заданий,..., где количество заданий в одном документе. Это ограничение позволяет отслеживать, чтобы в одном оценочном документе не было повторяющихся заданий. По желанию экзаменатор может наложить более сильные ограничения. Например, . Общий вид формулы, задающей ограничения следующий,..., ..., . Для проверки этого ограничения строится модель, и соответствующая ей нечеткая модель . Так же, как на предыдущем этапе, требуется, чтобы значение истинности формулы,..., на модели превышало некоторый заданный порог, т. е.,..., где 0,1. На третьем, последнем этапе формирования шаблона оценочного документа определяется структура этого документа. На этом этапе экзаменатор имеет возможность задать тип, сложность заданий в оценочном документе и т. п. Например, Такое определение задается некоторой бескванторной формулой,..., в сигнатуре . Для проверки корректности определения структуры оценочного документа строится расширение модели на сигнатуру, т. е. модель, . Значение истинности формулы,...,..., на нечеткой модели показывает, сколько различных оценочных документов, соответствующих построенному шаблону, можно сгенерировать в рамках данной базы заданий. Заметим, что если,...,..., 0, то необходимо проверить данную формулу на логическую выполнимость. Если формула,...,..., невыполнима, то система делает вывод, что запрос экзаменатора некорректен и просит пересмотреть запрос. Часто нам приходится экзаменовать не одного студента, а группу студентов, поэтому есть необходимость формирования комплекта оценочных документов, соответствующих данному запросу. При этом необходимо, чтобы оценочные документы, входящие в один комплект, были уникальны, т. е. имели как можно меньше одинаковых заданий. Пусть множество всех оценочных документов, соответствующих заданному шаблону. Очевидно, что . Для формирования комплекта оценочных документов был выбран алгоритм кластеризации CLOPE 19, работающий на множестве документов . Его основным преимуществом является относительно высокая скорость для категорийных данных. Суть алгоритма заключается в разбиении на кластеры, при котором максимизируется специальная функция Profit, высчитываемая для каждого кластера . Эта функция зависит от количества уникальных заданий кластера и некоторого коэффициента чем больше этот коэффициент, тем ниже уровень сходства и тем больше кластеров будет сгенерировано. В результате работы алгоритма необходимо приблизиться к числу, равному количеству документов в комплекте. Для этого выполняется итеративная процедура. 1. На первой фазе происходит инициализация, формирующая начальное разбиение. Затем осуществляется повторный обход по документам от одного, до трех раз, и если изменений не произошло, то алгоритм прекращает свою работу. Оценочные документы для удобства хранятся в таблице. Происходит процедура считывания оценочных документов из таблицы, которые кладутся в соответствующий или новый кластер с максимальным значением Profit, . В результате в таблицу записывается пара ОД, номер кластера. 2. Вторая фаза алгоритма аналогична первой. Для каждого оценочного документа происходит поиск подходящего кластера путем максимизации опорной функции Profit, . При этом если номер нового кластера не совпадает с записью в таблице, то старое значение перезаписывается на новое. Эта фаза повторяется, пока есть какие-то изменения. В конце все пустые кластеры удаляются. Если полученное число кластеров равно или совсем немного отличается от требуемого не более чем на два, то считается, что требуемый результат был достигнут. Тем самым формируется итоговый комплект документов путем случайного выбора любого представителя из каждого класса одного или двух. В случае если отличие более чем на два, необходимо увеличить или уменьшить коэффициент, в зависимости от разницы и повторить процедуру снова. Данная работа посвящена семантическому моделированию фонда оценочных средств факультета, который является одним из компонентов образовательного процесса университета. В статье дается описание онтологии ФОС, основных атомных понятий предметной области, а также набора терминологических аксиом. Семантический подход позволяет создавать различные оценочные документы в рамках одной дисциплины, междисциплинарные, документы для проверки соответствия требованиям работодателя и т. д. Средства логики описаний и теории нечетких моделей используется для проверки согласованности запросов экзаменатора и базы знаний. Они также применяются в вычисления мощности набора всех оценочных документов, соответствующих запросу преподавателя. Реализованный алгоритм кластеризации CLOPE позволяет генерировать уникальные наборы, отвечающие одному запросу. "}
{"title": "МЕТОД ПРОВЕРКИ ГИПОТЕЗ   НА БАЗЕ СТАТИСТИЧЕСКОЙ ОБРАБОТКИ РАЗНОРОДНЫХ   ЭЛЕКТРОЭНЦЕФАЛОГРАФИЧЕСКИХ ДАННЫХ  ", "absract": "Предложен подход для автоматизации проверки гипотез на основе обработки разнородных ЭЭГ-данных. Подход базируется на наборе MATLAB-скриптов, использующих библиотеки EEGLAB, NeuroElf, Alphasim, spm8, Mediation toolbox, и программном пакете sLORETA. Разработанный инструментарий позволяет проводить унификацию ЭЭГ-записей, сделанных на различном оборудовании, восстановление утраченных данных, 3Dреконструкцию источников мозговой активности по исходным ЭЭГ-данным и медиационный анализ. ", "text": " В начале второго десятилетия XXI в. нейрофизиология уверенно перешла с уровня изучения анатомии мозга на уровень изучения мыслительных процессов, что обусловлено развитием как методов измерения, так и методов обработки данных. Наиболее популярные методы получения исходных данных магнитно-резонансная томография МРТ и электроэнцефалография ЭЭГ. МРТ обеспечивает выделение активных зон в мозгу по признаку повышения в них уровня кислорода с высоким пространственным разрешением порядка 1 мм 1. Методы ЭЭГ привлекательны тем, что нейронная активность регистрируется непосредствен но 2 в ЭЭГ измеряются колебания напряжения на поверхности головы, возникающие в результате ионного тока в нейронах мозга. При этом существуют хорошо зарекомендовавшие себя методы, реализованные, например, в пакете программ sLORETA 3, которые по снятым с поверхности головы ЭЭГ-сигналам определяют источники этих сигналов внутри мозга. Таким образом, методами ЭЭГ можно исследовать быстротекущие мозговые процес сы 4. В Лаборатории дифференциальной психофизиологии Института физиологии и фундаментальной медицины в течение последнего десятилетия активно проводятся исследования, включающие сбор ЭЭГ-данных. Накопленные значительные объемы экспериментальных данных позволяют повторно использовать эти данные для проверки новых гипотез. Однако, поскольку экспериментальная база как приборная, так и программная в течение этого времени несколько раз обновлялась, накопленные данные разнородны, и их обработка сопряжена с большим объемом рутинных ручных операций. Создание с нуля проприетарного программного обеспечения, автоматизирующего этот процесс, чрезвычайно трудоемко 5, поэтому остро стоит проблема поиска варианта переиспользования уже существующих открытых программных компонентов для обработки разнородных ЭЭГ-данных. В статье описан автоматизированный подход к проверке гипотез с использованием разнородных ЭЭГ-данных описываются программно-инструментальные средства получения экспериментальных данных, разработанные алгоритмы их предварительной обработки и унификации, способы восстановления, в том числе 3D реконструкции, и общая схема проверки гипотез методом медиационного анализа. Проверка гипотез проводится статистическими методами на основании данных, получаемых через обследование испытуемых. Данные включают результаты анкетирования испытуемого пол, возраст, социальное положение, национальность и т. д. и компьютерные записи, сделанные во время эксперимента. Для проведения эксперимента на голову пациента надевается специальный ЭЭГ-шлем, на котором расположены электроды, соединенные с электроэнцефалографом. На каждом электроде измеряется электрический потенциал, который записывается с частотой 1 кГц. За нулевой потенциал принимается потенциал электрода в районе темени. Эксперимент рис. 1 состоит в выполнении испытуемым элементарных тестовых заданий, называемых сначала на монитор, расположенный перед испытуемым, выводится картинка стимулирующее воздействие фотография человеческого лица, выражающего некоторое эмоциональное состояние, и текст с вариантами реакции список возможных действий с помощью клавиатуры испытуемый выбирает один из вариантов, после чего запускается следующая эпоха. Эксперимент проводится в автоматическом режиме. Выдачу стимулов и регистрацию реакции осуществляет программа управления экспериментом INQUISIT . Запись данных производится при помощи электроэнцефалографов компаний Neuroscan ЭЭГ-шлем имеет 118 электродов или Brain Products ЭЭГ-шлем имеет 128 электродов и соответствующего фирменного ПО. После проведения эксперимента с помощью прибора FASTRAK digitizer Polhemus измеряются координаты электродов ЭЭГ-шлема и так называемых референтных точек, которые характеризуют форму головы испытуемого. Местоположение референтных точек определяется по стандартизированной процедуре относительно ушей, носа и затылка 6. Таким образом, во время эксперимента создаются четыре файла файл с записью ЭЭГсигналов cnt-файл, содержащий метки начала эпох, файл протокола эксперимента с данными о стимуле, времени и типе реакции, файл координат электродов и файл координат референтных точек. Совместно с результатами анкетирования испытуемого эти четыре файла образуют исходный набор данных отдельного эксперимента, из которых собирается база данных. Из-за различий в оборудовании разное количество электродов собранная база данных существенно разнородна при использовании оборудования компании Neuroscan записывается 118 каналов, а при использовании оборудования компании BrainProducts 128. Совпадающих каналов только 98. Также различается и порядок записи каналов. Кроме того, из-за изменений во внутрилабораторных стандартах часть протоколов экспериментов записана в простом текстовом виде, а часть в html-формате. Файлы протоколов отличаются и по информационной структуре. Дополнительная сложность использования снятых данных обусловлена низким уровнем полезного сигнала мышечные напряжения в области головы скулы, глаза, язык и т. д. приводят к появлению так называемых артефактов паразитных импульсов, которые заглушают сигналы нейронной активности. Также недопустимое искажение сигнала может возникнуть и при плохом контакте датчика с поверхностью головы. Нарушение контакта может возникнуть как из-за некачественного крепления электрода лаборантом, так и из-за резких движений головой испытуемого. Подготовку ЭЭГ-данных к последующей обработке начинают с исключения артефактов. Несмотря на наличие автоматических средств удаления артефактов 7, исследователи предпочитают производить первичное удаление явно зашумленных участков и каналов вручную, поскольку на настоящий момент результаты ручной обработки оказываются точнее. Дальнейшая коррекция полученных ЭЭГ-данных проводится методом анализа независимых компонентов 8 в программном пакете EEGLAB toolbox, статистическая суть обработки приведена в 9. Обработанные с помощью EEGLAB данные сохраняются в бинарном set-файле. Формат set-файла ориентирован на пакет MATLAB, широко используемый научным сообществом для обработки цифровых сигналов 10. Во время обработки могут быть удалены существенные объемы данных после устранения артефактов может выясниться, что отсутствуют данные как о целых эпохах, так и об отдельных каналах. Потеря канала приводит к дополнительным нарушениям в однородности данных, что радикально усложняет последующую групповую обработку set-файлов. С другой стороны, исключение утраченного канала из остальных set-файлов с целью унификации влечет недопустимую потерю информативности всей выборки. Исходя из этих соображений, утраченные каналы восстанавливаются встроенной процедурой межканальной интерполяции EGGLAB. Предполагается, что восстановление делается во время устранения артефактов, в ручном режиме. Однако это чревато ошибками из-за человеческого фактора. Для автоматизации процедуры восстановления утраченных каналов был разработан алгоритм пакетного восстановления каналов по заданному образцу, который реализован в виде скрипта в пакете MATLAB. Для восстановления каналов также используется метод сферической сплайн-интерполяции, предоставляемый библиотекой eeglab. И хотя сам метод восстановления считается в целом приемлемым 11 при его использовании возникает ограничение на качество исходных данных количество утраченных каналов, поскольку в случае, если значительная часть каналов будет восстановлена интерполяцией, использование метода приведет к снижению значимости результатов корреляционного анализа. Для унификации форматов set-файлов, полученных на различном оборудовании Neuroscan и Brain Products, несовпадающие каналы исключаются из обработки 12, что обусловлено значительными искажениями, возникающими при интерполировании большого количества несовпадающих каналов около 20 от общего числа. Для автоматизации процесса унификации был предложен алгоритм рис. 2 пакетной обработки set-файлов в выбираемых пользователем двух корневых директориях с данными, полученными на оборудовании Neuroscan и Brain Products соответственно. Алгоритм формирует результаты во вновь создаваемых директориях. Порядок следования каналов определяется в соответствии с set-файлами из первой директории. Таким образом, сначала алгоритм фиксирует порядок следования каналов и определяет пересечение множеств каналов Neuroscan и Brain Products, а потом последовательно считываются set-файлы. Из очередного set-файла исключаются отсутствующие в пересечении каналы, и при необходимости изменяется порядок их следования. Алгоритм по унификации set-файлов реализован в виде MATLAB-скрипта и библиотеки EEGLAB. ЭЭГ оборудование регистрирует потенциалы на поверхности головы, в то время как исследовательский интерес представляют источники электрических сигналов, расположенные в головном мозге, локализация этих источников в функциональных областях коры головного мозга. Пространство, в котором производится поиск источников, задается трехмерной моделью мозга, основанной на так называемом атласе Талайрака 13. Определение координат и параметров источников электрической активности в головном мозге по ЭЭГ-данным или 3D-реконструкция производится на основе решения обратной задачи 14. Имеется множество методов 3D-реконструкции по записям электрической активности с поверхности головы, таких как MN минимальная норма, WMN взвешенная минимальная норма, Backus and Gilbert, and WROP weighted resolution optimization 15, 3D-моделирова ние на основе глубинных нейронных сетей 16 и др. В работе 3D-реконструкция проводилась программой sLORETA 3, использующей MN-метод. Выбор способа был обусловлен простотой использования пакета sLORETA при удовлетворительном качестве 3D-рекон струкции. Перед 3D-реконструкцией set-файлы преобразуются к входному формату sLORETA. Подготавливаются файлы с координатами электродов и реперных точек, а также данные о спектральной мощности сигналов, разбитые на эпохи и частотные диапазоны. Подготовка входных файлов в формате ASCII asc-файлов производится автоматически из set-файлов в соответствии с границами частотных диапазонов, задаваемыми пользователем. Обычно разбивка производится по пяти стандартным частотным диапазонам -ритм 14 Гц, -ритм 48 Гц, -ритм 812 Гц, -ритм 1235 Гц, -ритм 3545 Гц. Алгоритм подготовки входных данных для sLORETA реализован в виде MATLAB-скрипта на основе библиотеки EEGLAB. В результате работы пакет sLORETA формирует набор slor-файлов. Каждый slor-файл характеризует мозговую активность во время отдельного теста эпохи в выделенном частотном диапазоне. Slor-файл содержит воксельную модель мозга и амплитуды сигналов в каждом отдельном вокселе. Стандартный размер вокселя 5 5 5 мм. При этом мозг представлен трехмерным массивом 29 34 24 всего 23 664 вокселя. Для последующей обработки полученные файлы преобразуются в стандартный расширяемый NIFTI-формат, ориентированный на воксельное представление нейроизобра жений мозга 17. Преобразование ведется в пакетном режиме созданном MATLABскриптом с использованием библиотеки spm8 . Многоуровневый медиационный анализ рис. 3 18 основан на классической трехкомпонентной медиационной модели, в которой сначала средствами линейного регрессионного анализа определяется связь между независимой переменной и медиатором путь и связь между медиатором и зависимой переменной путь, а затем определяется медиационный эффект путь, т. е. влияние на, опосредованное как произведение регрессионных коэффициентов, полученных методом так называемого бутсрэппинга 19. Медиационный анализ проводится повоксельно, т. е. медиационный эффект вычисляется для каждого отдельного элемента воксельного представления мозга. Медиационный эффект может быть как положительным наблюдается одинаковый знак регрессионного коэффициента пути и пути, так и отрицательным путь и имеют противоположные знаки регрессионных коэффициентов. Перед проведением медиационного анализа было предложено унифицировать представление эксперимента. Для этого был разработан формат компактного представления протокола единичного эксперимента модельная матрица. Она задается двумерной матрицей, состоящей из пяти столбцов номер эпохи, два признака стимула, тип реакции, время реакции. Число строк модельной матрицы равно числу эпох в эксперименте. Алгоритм создания модельных матриц реализован расширяемым набором MATLABскриптов, обеспечивающих пакетную обработку протоколов в текстовом и html-форматах. Полученные в результате обработки протоколов модельные матрицы записываются на диск в виде mat-файлов пакета MATLAB, ориентированных на хранение данных. Повоксельное проведение медиационного анализа приводит к появлению ложно детек тируемых вокселей. Фильтрация ложно детектируемых вокселей производится на основании того, что при реакции у испытуемого активируются области мозга, по размеру превыша ющие размер единичного вокселя. Таким образом, после медиационного анализа отбрасы ваются единичные воксели и группы связанных вокселей так называемые кластеры неболь шого размера. Граничный размер кластера определяется функцией alphasim 20 из библиотеки Neuroelf на основании размера матрицы, содержащей воксельное представ ление мозга, и порога достоверности через симуляцию шума. Таким образом, реализованный пакет MATLAB скриптов производит унификацию про токолов, создает модельные матрицы, затем на основании данных о стимулах реакциях и воксельного представления мозга выявляет воксели-медиаторы, вычисляет граничный раз мер кластеров и в заключение исключает из рассмотрения единичные воксели и кластеры с размером меньше граничного. В результате получается набор воксельных моделей с обла стями, участвующими в выработке реакции, для каждого из исследуемых частотных диа пазонов. Координаты обнаруженных кластеров сопоставляются с картой функциональных зон мозга и служат объективной основой для интерпретации когнитивных процессов специали стами-нейрофизиологами, подтверждают или опровергают существующие гипотезы о харак тере нервной деятельности при социальном взаимодействии. Таким образом, разработаный комплекс программ рис. 4 включает компонент автомати ческого восстановления утраченных каналов, гомогенизацию ЭЭГ-файлов по составу и по рядку следования каналов, 3D-реконструкцию источников мозговой активности и медиа ционный анализ с выявлением воксельных кластеров, задействованных в выработке реакции на стимул. Разработанный пакет программ использовался при обработке экспериментов по социальному взаимодействию. Методика эмпирической проверки гипотезы приведена в 21 22. Единичный эксперимент включал 60 эпох. В качестве стимулов использовались фотографии мужских и женских лиц с тремя эмоциональными выражениями счастливое нейтральное агрессивное. В качестве реакции испытуемым предлагалось три варианта подружиться, уклониться от контакта, атаковать. Всего было обработано 43 эксперимента, из них 32 экспери мента проведены на оборудовании компании Neuroscan datформат протоколов и 11 на оборудовании Brain Products HTML-формат протоколов. При обработке отбраковано 20 каналов по причине низкого качества, которые затем были восстановлены автоматически. В процентном отношении это составило менее 0,5 от общего числа обрабатываемых каналов пиковое значение 2 восстановленных каналов у одного испытуемого. И если дополнительно учесть, что утраченные каналы восстанавливались интерполяционным методом, можно утверждать, что проведенная коррекция исходных данных незначительно повлияла на результаты последующей обработки. 3D-реконструкция проводилась по стандартным частотным диапазонам альфа бета гамма тета дельта. При этом в качестве временных интервалов, по которым определялась мозговая активность, использовался промежуток от предъявления стимула до фиксации реакции. Воксельное представление мозга задавалось матрицей размером 29 34 24 размер вокселя 5 5 5 мм. Использовался порог достоверности, равный 0,001. Граничный размер кластера составил 13 вокселей. Значение независимой переменной соответствующей стимулу для агрессивного выражения лица устанавливалось равным 1, для нейтрального 0, для счастливого минус 1. Значения зависимой переменной соответствующей реакции для случая атаковать устанавливалось равным 1, для уклониться от контакта 0, для подружиться минус 1. Результаты, полученные при практической апробации и пред ставляющие нейрофизиологический интерес, изложены в статье 23. Разработанные скрипты были частично использованы при исследовании нейрофизиологических различий у людей с коллективистской и индивидуалистской ориентацией. Предложен подход для автоматизации проверки гипотез на основе обработки разнородных ЭЭГ-данных. Подход включает унификацию ЭЭГ-записей, сделанных на различном оборудовании, восстановление утраченных данных, 3D-реконструкцию источников мозговой активности по исходным ЭЭГ-данным и проведение медиационного анализа. Реализация подхода базируется на наборе MATLAB-скриптов, использующих библиотеки EEGLAB, NeuroElf, Alphasim, spm8, Mediation toolbox, и программном пакете sLORETA. Созданный инструментарий апробирован при обработке данных нейрофизиологических экспериментов по социальному взаимодействию. В силу своей универсальности представленные скрипты, автоматизирующие статистическую обработку разнородных ЭЭГ-данных, могут использоваться для проверки широкого класса нейрофизиологических гипотез. "}
{"title": "АВТОМАТИЗАЦИЯ ПОСТРОЕНИЯ ТРЕХМЕРНЫХ   ГЕОЭЛЕКТРИЧЕСКИХ МОДЕЛЕЙ ДЛЯ МЕТОДА ЗОНДИРОВАНИЯ   СТАНОВЛЕНИЕМ ПОЛЯ В БЛИЖНЕЙ ЗОНЕ   НА ОСНОВЕ РЕЗУЛЬТАТОВ ОДНОМЕРНОЙ ИНВЕРСИИ ", "absract": "Предложен алгоритм автоматизации построения трехмерных геоэлектрических моделей для метода зондирования становлением поля в ближней зоне на основе результатов одномерной инверсии с целью расчета синтетических сигналов для трехмерных моделей, а также ускорения получения качественной оценки полевых материалов и сведения к минимуму ошибок интерпретации. Важной частью алгоритма является автоматическое формирование трехмерных расчетных сетей, необходимых для расчета синтетических сигналов в моделях. Результаты работы алгоритма представляют собой подготовленные трехмерные модели изучаемой среды с рассчитанным синтетическим электромагнитным сигналом. Алгоритм апробирован на данных электромагнитного мониторинга последствий землетрясения, произошедшего в 2003 г. в Республике Алтай.  : ВЭЗ, ЗСБ, GMSH, Modem3D, Geo3dBuilder, построение трехмерных моделей, трехмерная модель, геоэлектрическая модель, зондирование становлением поля в ближней зоне, диаграммы Вороного, CGAL, EMS, HTCondor, Condor. ", "text": " В настоящее время в области наземной геоэлектрики происходит усложнение объектов исследования, для решения научных и производственных задач недостаточно применять только одномерное моделирование сигналов становления электромагнитного поля в исследуемых средах. Причиной тому является возрастающее число необъяснимых или неверно истолкованных сигналов, в связи с чем возникла необходимость использовать более достоверный инструмент трехмерное моделирование сигналов становления электромагнитного поля, позволяющий отслеживать влияние трехмерных эффектов. В настоящее время уже существуют программные средства имитации сигналов в трехмерных средах Институт нефтегазовой геологии и геофизики им. А. А. Трофимука СО РАН использует для расчетов Modem3D 1, но остается непростой задача построения реалистичных трехмерных моделей. Для автоматизации построения таких моделей требуется хорошее стартовое приближение, в качестве которого в работе выступает трехмерная модель для выбранного пикета, соответствующая результатам одномерного моделирования для того же пикета. Процесс построения таких трехмерных моделей итеративный и занимает много времени, а также вызывает большое количество ошибок. Целью работы является уменьшение времени построения сложных трехмерных моделей для метода зондирования становлением поля в ближней зоне и уменьшение ошибок построения путем автоматизации расчетов моделирования и исключения человеческого фактора. Наземная электроразведка изучает геологическое строение земли, объединяя различные методы исследований объектов на основе их электрических и магнитных свойств. Сфера применения методов варьируется от поиска полезных ископаемых и картирования геологических разрезов до строительства, мониторинга дамб, а также изучения земных катастроф. На поверхности земли устанавливается аппаратура, регистрирующая изменения электрического и электромагнитного полей объектов. Полученные данные обрабатываются и интерпретируются в одномерную модель среды в каждой точке измерения. Наиболее популярными методами наземной электроразведки являются вертикальное электрическое зондирование ВЭЗ и зондирование становлением поля в ближней зоне ЗСБ. Исследования направлены на изучение геологических объектов, а также отслеживание их изменений в течение времени. Метод ВЭЗ основан на измерении напряжения электрического поля, созданного путем установки разнесенных электродов, питающих это поле. Построение трехмерных моделей для данного метода было предложено в работе А. А. Сафиуллиной 2. Другим ведущим методом наземной электроразведки является метод зондирования становлением поля в ближней зоне ЗСБ. Установка рис. 1 состоит из источника поля и приемников, представляющих собой незаземленные проволочные контуры, генераторная и измерительная петли. При достаточно большом разнесении петель глубина исследования может достигать 10 км, что позволяет использовать метод при картировании местности, поиске рудных месторождений, газа и нефти, мониторинге геологических объектов. Петли установки, используемые в исследовании, имеют форму квадрата и расположены соосно совпадают центы координат петель. Измерительная петля находится внутри генераторной. Размеры петель зависят от размера исследуемой области. Чем больше размер генераторной петли, тем больший на нее подается ток, что напрямую влияет на увеличение глубины исследования. Кроме того, увеличение тока на генераторных петлях провоцирует увеличение количества вихревых токов Фуко, которые, в свою очередь, влияют на наводку измерительных петель. Все существующие факторы приводят к одной глобальной пробле ме недостаточной точности измерения сигналов. На генераторную петлю подается ток, затем выключается источник. В земле образуются вихревые токи Фуко, которые регистрируются измерительной петлей зависимость напряжения от времени затухания. Полученные данные являются основой для трехмерного моделирования. Для метода ЗСБ предложен алгоритм автоматизации построения трехмерной расчетной сети с целью ускорения получения первого приближения моделей, сведения ошибок интерпретации к минимуму, а также расчета синтетических сигналов и их верификации. е Разработанный алгоритм для метода ЗСБ рис. 2 является развитием алгоритма, предложенного в работе А. А. Сафиуллиной, А. А. Власова 2, и позволяет решить три принципиальные задачи автоматическое построение первого приближения трехмерных моделей, составление для полученных моделей расчетной сети и оценка полученных результатов моделирования. Автоматическое построение трехмерных геоэлектрических моделей является важным этапом истолкования зарегистрированных сигналов ЗСБ, так как подготовка входных данных и построение из них трехмерных геоэлектрических моделей занимает у интерпретатора много времени. Разработанное программное средство Geo3DBuilder, использующее предложенный алгоритм, позволяет уменьшить время построения геоэлектрических трехмерных моделей, а также предотвращает ошибки, появляющиеся во время их ручного создания. Алгоритм апробирован на данных электромагнитного мониторинга последствий землетрясения, произошедшего в 2003 г. в Республике Алтай. Данные брались с установок в районе села Мухор-Тархата. обрабатывались и приводились в структурированный формат, описывающий будущую трехмерную модель. Подготовленный файл является основой для работы алгоритма. Данные из алгоритма считываются и переводятся во внутреннее представление, на основе которого происходит автоматическая генерация трехмерных моделей. Их обрабатывает генератор трехмерных моделей, который создает двумерную модель, отбрасывая координаты . Данная модель необходима для того, чтобы построить вокруг каждого пикета диаграммы Вороного 3 области, ближайшие к этому пикету относительно остальных и принадлежащие ему, что позволяет облегчить дальнейшие расчеты синтетического сигнала, при этом не сильно проигрывая в точности. В работе использовались наработки библиотеки CGAL средства построения двумерных диаграмм Вороного. Для удобства использования трехмерной модели, а также для дальнейших расчетов трехмерной сети в алгоритме используется Geo-разметка программного продукта GMSH . Программный продукт GMSH позволяет использовать готовый синтаксис описания трехмерных моделей, а также содержит в себе средства генерации двумерных и трехмерных расчетных сетей, необходимых для дальнейшего моделирования синтетического сигнала. Алгоритм сначала формирует трехмерные точки, каждой присваивается уникальный индекс и координаты, . Следует учесть, что точки с одинаковыми координатами объединяются в одну. Это необходимо для единой связности модели. В случае несвязности модели сигнал, проходящий в радиусе одного пикета, не зависит от сигнала другого пикета, что ничем не отличается от одномерного моделирования моделирования, зависящего только от координат мощностей слоев. Затем из точек строятся линии, содержащие координаты начальной и конечной точек. Полученная модель, состоящая из точек и линий, уже является трехмерной, но необходимо сформировать физические объемы, на основе которых будут производиться вычисления синтетических сигналов. Из полученных линий собираются контуры набор линий, идущих одна за другой в определенном порядке и замыкающих друг друга. Важно учесть направление линий, так как несколько контуров могут содержать различающиеся направления, но при этом иметь общие линии. Такая задача решается добавлением отрицательного направления линии в конкретном контуре. После получения контуров модели необходимо построить плоскости, содержащие контуры в основе, при этом учесть, что контуры могут совпадать в точности до линий, но иметь различные направления. Решение проблемы повторяющихся контуров приводит к избавлению от идентичных плоскостей и сохранению связности генерируемой модели. Из полученных плоскостей строятся уникальные контуры объемов, содержащие набор плоскостей, затем из контуров объемов формируются логические объемы. На основе логических объемов формируются физические, необходимые для расчета синтетических сигналов в них. Полученные трехмерные физические объемы являются финальной точкой генерации трехмерной модели рис. 3. Время, необходимое для ручного описания геометрии трехмерной модели, содержащей 4 пикета, и подбора параметров расчетной сети, занимает от 20 часов. В свою очередь, автоматическое построение этой же модели занимает до 10 минут, что существенно экономит время и исключает ошибки при описании геометрии. На следующем шаге полученная модель импортируется в ПО GMSH, где генерируется трехмерная расчетная сеть. Генерация производится встроенным в GMSH алгоритмом триангуляции Делоне, который позволяет создавать расчетную сеть, состоящую из тетраэдров. Плотность сети максимально высокая в центре координат исследуемого пикета и уменьшается в зависимости от увеличения радиуса области исследования. Рассчитывается при помощи полинома второй степени. Параметры полинома интерпретатор может редактировать на шаге создания сети. Для получения оптимальной расчетной сети рекомендуется использовать алгоритм оптимизации Netgen, но иногда он дает сбой, так как является экспериментальным. На выходе имеется модель, состоящая из тетраэдров, которая передается на вход в программное средство расчета синтетических сигналов Modem3D. Важной особенностью алгоритма является то, что интерпретатор на каждом шаге может изменять параметры как начальной модели, так и расчетной сети для интересуемой модели. Данная особенность алгоритма обусловлена тем, что он предлагает гибкий инструментарий для получения интересуемого результата. Эк Генерация трехмерных моделей производилась на основе данных электромагнитного мониторинга последствий землетрясения на юго-востоке села Мухор-Тархата рис. 4. Полигоном является участок 20 000 20 000 м, который содержит 4 пикета исследования. Каждый пикет представляют собой генераторную петлю размером 200 200 м и соосную измерительную петлю 100 100 м. Все петли одновитковые. Пикеты 10, 31, 32 расположены на равнине, пикет 1 в пойме притока реки Кокозек. Расстояние между пикетами варьируется от 500 до 1 000 м. На генераторные петли подавался ток в 1 А. В табл. 1 приведены данные одномерной инверсии для каждого исследуемого пикета. Экспериментальные данные хорошо согласуются с синтетическим сигналом одномерных моделей в пределах метрологической погрешности измерительной аппаратуры, поэтому далее результаты трехмерного моделирования трехмерная модель сравниваются с синтетическими сигналами одномерного моделирования рис. 5. Это позволяет сравнивать данные на более широком временном диапазоне и для трехмерного моделирования оценивать значения времени, при которых начинают влиять граничные условия. Результаты одномерной инверсии для 4 пикетов Пикет 1 Пикет 10 Пикет 31 Пикет 32 90 130 190 155 140 125 220 120 42 340 37 230 32 225 33 300 800 250 250 280 Для генерации синтетического сигнала используется программное обеспечение Mo dem3D, использующее метод конечных элементов 1. Для проверки достоверности результатов используется ПО EMS 4, которое позволяет производить моделирование синтетических сигналов ЗСБ для одномерных моделей. Расчетная сеть состояла из 1,5 млн тетраэдров. Расчеты производились при помощи разработанного в ИНГГ СО РАН решателя для Modem3D MG PCG . Задача состояла из 10 линейных и 120 логарифмических итераций и решалась на ЭВМ с Intel Core i5 2-го поколения. Расчеты сигналов для каждого пикета в среднем занимали около 20 часов в двухпоточном режиме и расходовали до 2,4 GB оперативной памяти. В результате сравнения результатов трехмерного и одномерного моделирования погрешность составила 1 в интервале времени от 0,3 до 35 мс для одномерного моделирования в каждом пикете рис. 6, что укладывается в метрологические характеристики измерительной аппаратуры 5 . Для построения модели на 12 пикетов была расширена предыдущая модель на 4 пикета. В табл. 2 приведены данные одномерной инверсии для каждого исследуемого пикета. Результаты одномерной инверсии для 12 пикетов Пикет 2 Пикет 4 Пикет 6 Пикет 11 100 140 150 145 180 120 115 130 35 300 28 210 32 280 45 30 1500 2000 2000 2000 Пикет 20 Пикет 21 Пикет 22 Пикет 30 100 130 130 150 90 130 110 120 38 230 300 290 25 210 19 270 1500 2000 2000 2000 Параметры установок и размер области исследования соответствовали модели на 4 пикета, так как имеют небольшой координатный разброс установок относительно друг друга. Модель состояла из 2,2 млн тетраэдров. Задача решалась на той же системе 180 часов в двухпоточном режиме при расходе памяти до 6 GB. Для параллельного решения нескольких задач использовалась Grid-система HTCondor, позволяющей использовать ресурсы ЭВМ, подключенных в единую локальную сеть. Полученные результаты рис. 7 показывают отклонение сигнала со временем, что нельзя наблюдать при одномерном моделировании, так как плотности сеток приблизительно одинаковые как в одномерных, так и в трехмерных моделях. Расхождение сигналов объясняется влиянием параметров модели соседних пикетов. Этот факт свидетельствует о том, что неправильно подобраны одномерные модели, и необходимо их скорректировать, либо о том, что невозможно истолковать зарегистрированные сигналы в рамках одномерных моделей, например, присутствуют наклонные границы пластов, или в пластах находятся посторонние объекты. Для корректного истолкования данных необходимо моделировать сигнал в более сложных двухмерных и трехмерных моделях. Разработанный алгоритм для метода зондирования становлением поля в ближней зоне позволяет в автоматическом режиме строить трехмерные геоэлектрические модели на основе результатов одномерной инверсии, тем самым ускоряя процесс получения оценки качества истолкования данных. Созданное программное средство Geo3DBuilder позволяет генерировать геометрию трехмерных моделей, а также подбор плотности расчетной сети. Интерпретатор использует Geo3DBuilder для настройки входных параметров модели, а уже в построенных моделях корректирует параметры расчетной сети. Применение алгоритма сводит к минимуму участие человека, что исключает появление ошибок интерпретатора, а также уменьшает время, необходимое на построения этих моделей. Интерпретатор оценивает качество моделирования и подбирает параметры расчетной сети, изменяя коэффициенты полинома и размеры моделей. Кроме того, интерпретатор сам определяет, какой погрешности ему необходимо добиться и сколько он может уделить времени на расчеты. Следующим шагом развития направления исследований будет получение моделей, более приближенных к реальным условиям. Эта цель будет достигаться путем создания моделей с наклонными границами, что позволит сделать более плавные переходы внутри одного пласта между пикетами. "}
{"title": "ИСПОЛЬЗОВАНИЕ ГОРИЗОНТАЛЬНО МАСШТАБИРУЕМОЙ   ИНФРАСТРУКТУРЫ ПРИ ПОИСКЕ СХОДСТВА   В ГЕНОМНЫХ ДАННЫХ ЭКОСИСТЕМ", "absract": "Рассмотрена проблема выявления генетического сходства при анализе баз данных (БД) геномов организмов. Такая проблема возникает с развитием методов метагеномики, сравнительной геномики, технологий высокопроизводительного секвенирования ДНК, а также инструментов оценки и прогнозирования состояния экосистем. Для быстрого сравнения геномов с целью выявления повторяющихся наборов нуклеотидов разработана специализированная компьютерная система. Из-за большого объема данных, возникающих при обработке исходной информации, осуществлен переход к нереляционным БД, как к более гибким и масштабируемым. В качестве основы подхода использованы распределенная нереляционная БД MongoDB и алгоритм обработки данных Winnowing. При использовании нереляционной БД для выявления генетического сходства предложен вариант представления отпечатков структурных вариаций геномов в виде «ключ – значение». Выполнена программная реализация разработанной модели. Проведены вычислительные эксперименты: 1) загрузка данных в БД с использованием одной  и трех шард (серверов, где хранятся данные и осуществляются поиск и обработка информации); 2) поиск совпадений выбранных наборов нуклеотидов с БД геномов с использованием одной и трех шард; 3) расчет скорости поиска геномов в БД; 4) расчет скорости загрузки геномов в БД. Результатом экспериментов стало подтверждение возможности использования предложенного способа поиска генетического сходства. Продолжение работы может быть в направлениях: 1) решения задачи об определении момента, когда необходимо добавлять узел к кластеру при возрастании рассматриваемого количества выбранных наборов нуклеотидов и увеличении числа геномов  в БД организмов; 2) практического наполнения создаваемой БД как можно большим количеством реальных геномов организмов; 3) исследования геномных нарушений с целью оценки вероятности генетических отклонений  на этапе распознавания потенциально возможного неблагоприятного развития организма. : сравнение геномов, большие данные, нереляционные базы данных, алгоритмы поиска повторений, биоинформатика. ", "text": "Изучение структурно-функциональной организации живых организмов продолжает оставаться актуальным направлением, развивающимся на стыке биологии и информатики 1. В этой связи использование компьютерных технологий при исследовании геномов см., например, 25 получило широкое распространение в мире. В числе современных крупных геномных проектов несколько БД ENSEMBL совместный проект организаций EMBL-EBI Германия и Sanger Centre Великобритания с целью создания программной системы для автоматического создания аннотаций геномов эукариотов. Проект ENSEMBL ориентирован на соответствие следующим критериям точный, автоматический анализ данных генома аннотации, основанные на текущих, своевременно обновляемых данных доступность полученных данных через Интернет. GenBank БД нуклеотидных последовательностей, которая поддерживается NCBI Национальным центром биотехнологической информации США. Крупнейшая интегрированная поисковая система ENTREZ, которая создана и поддерживается NCBI, используется для анализа нуклеотидных и аминокислотных последовательностей, библиографии PubMed, полных геномов Genomes, а также трехмерных структур белков MMDB. При этом поиск данных о ДНК и белках не ограничивается только ресурсами GenBank, но распространяется и на другие доступные по сети хранилища информации. International Nucleotide Sequence Database Collaboration объединяет три крупнейшие коллекции нуклеотидных последовательностей EMBL-EBI и GenBank NCBI и DDBJ Япония. Информационный ресурс KEGG Kyoto Encyclopedia of Genes and Genomes создается Институтом химических исследований Kyoto University, Japan. Эта база знаний имеет обширные возможности для работы со всеми крупными мировыми информационными ресурсами. Обновление KEGG происходит ежедневно. Существует ряд геномных браузеров, в том числе NCBI, UCSC Genome Browser, ENSEMBL. Эти браузеры используются для получения и визуализации детальной справочной информации о геномах. Разработанная же авторами специализированная система предназначена для обработки справочной информации, а именно для быстрого сравнения геномов организмов с целью выявления повторяющихся наборов нуклеотидов. В связи с развитием технологий высокопроизводительного секвенирования ДНК продолжается рост объема геномной информации в мире. Таким образом, несмотря на развитие международных БД и браузеров, остается важной задача сравнения протяженных геномных последовательностей, процессинга данных, поиска совпадений. К настоящему времени предложены специальные форматы геномных данных например, FASTA, для поиска сходств в определенных классах геномных последовательностей разработаны компьютерные средства например, BLAST, идет работа над переносом рабочих процессов аппаратной оптимизации быстрого поиска геномных данных на виртуальные мощности облаков 6. Нельзя не упомянуть вклад российских специалистов в разработку компьютерных методов решения задач метагеномики, сравнительной геномики, определения полиморфизмов, скрининга мутаций, транскриптомного профилирования и т. д. например, 79. Данное исследование посвящено решению задачи сравнения выбранных наборов нуклеотидов с геномами организмов в реально существующем и постоянно актуализирующемся информационном ресурсе. Для этого необходимо сравнить содержащиеся в БД геномы организмов G с выбранными наборами нуклеотидов N в виде символьных последовательностей произвольной длины. В работе источником элементов используемой БД являлась KEGG GENOME, включающая расшифрованные представления около пяти тысяч организмов, находящиеся в свободном доступе. В настоящее время объем данных этого информационного ресурса можно оценить приблизительно в пять ТБ, что представляет технический вызов для существующих вычислительных мощностей. В связи с большим объемом данных, возникающим при обработке исходной информации, был осуществлен переход от реляционных БД к нереляционным как к более гибким и масс штабируемым. Такой путь решения подобных проблем был обоснован в работе 10, в том числе для поиска нуклеотидных полиморфизмов и сходства геномных последовательностей 11. В этом случае необходим инструментарий, позволяющий осуществлять поиск в горизонтально масштабируемой информационной системе далее ИС с возрастающими ресурсами в процессе развития. Данная ИС должна характеризоваться достаточной эластичностью, т. е. способностью к расширению, без существенных инвестиций в инфраструктуру ИС, а также доработку программного обеспечения и алгоритмов. Один из вариантов решения данной задачи это использование структуры хранения данных и разработка поискового механизма на основе средств нереляционной распределенной БД MongoDB и алгоритма Winnowing 1214. В статье представлены результаты, ориентированные на реализацию такого подхода для сравнения геномов и поиска отклонений в их структуре. Распределенная ИС, созданная в работе на основе использования семи серверов, включает нереляционную БД MongoDB. Три сервера UbuntuSlaveA, UbuntuSlaveB, UbuntuSlaveC отвечают за хранение данных. На серверах находятся две распределенные БД база данных нуклеотидных последовательностей и БД организмов. Три сервера UbuntuSlaveD, Ubuntu SlaveE, UbuntuSlaveF это управляющие сервера, отвечающие за запись данных и их хранение на серверах UbuntuSlaveA, UbuntuSlaveB, UbuntuSlaveC. Сервер UbuntuMaster это управляющий сервер, который предназначен для управления всем кластером, созданным с использованием технологии MongoDB. На рис. 1 представлен персональный компьютер пользователя, с которого осуществляются первоначальная загрузка данных для формирования БД геномов организмов и БД нуклеотидных последовательностей, а также последующие запросы к созданным БД. Данные о геномах, полученные из ENSEMBL, представляли собой наборы нуклеотидов, например, для мыши типа CTAAAGTATA TATGAGTAAA CTTGGTCTGA CAGTTACCAA TGCTTAATCA GTGAGGCACC... и т. п. В этом же виде они переносились в создаваемую в работе вторичную БД, со структурой, соответствующей описанной выше информационной системе. В исследованиях жизнедеятельности организмов, входящих в экосистемы различного уровня, используется представление о сходстве объектов например, 15. В литературе встречается достаточно много вариантов поиска сходства текстов, которые основаны на -граммах например, 16. Методы поиска, использующие -граммы, основаны на создании отпечатков документов, которые позволяют идентифицировать части при попарном сравнении символьных последовательностей. Подробный обзор сравнения алгоритмов с точки зрения производительности выполнен в работе 13. Одним из алгоритмов, который основан на применении -грамм, является алгоритм Winnowing 12. Пример применения алгоритма Winnowing для решения задачи сравнения текстов рассмотрен в работе 14. Показано, что выбранная -грамма помещается в таблицу БД в виде триады и представляется записями как минимум в двух реляционно-связанных таблицах. Выполненный анализ демонстрирует высокую производительность при росте количества сравниваемых документов, но, как следствие, возникают скоростные ограничения в процессе использования реляционной мо дели. В качестве решения проблемы производительности в работе предложена нереляционная модель типа, где хеш подстроки граммы документа выступает в качестве ключа, а значение представляет собой двумерную таблицу, содержащую значения для всех документов, имеющих совпадающую символьную последовательность. Таким образом, для поиска используется только одно ключевое значение, представленное значением хеш-функции от граммы. Благодаря этому возникает возможность выполнения параллельных запросов к нескольким узлам кластера одновременно. Описанная модель была положена в основу структуры БД и протестирована в ряде экспериментов, результаты которых представлены ниже. Проведены четыре эксперимента по оценке следующих характеристик 1 скорость загрузки геномов организмов и выбранных наборов нуклеотидов в БД MongoDB на одном компьютере в сравнении со случаем, когда БД распределена между тремя компьютерами в кластере 2 зависимость скорости загрузки от размера выбранного набора нуклеотидов 3 скорость загрузки геномов организмов на один компьютер в сравнении со случаем, когда БД распределена между тремя компьютерами в кластере 4 скорость сравнения геномов организмов с БД выбранных наборов нуклеотидов на одном компьютере в сравнении со случаем, когда БД распределена между тремя компьютерами в кластере. Применимость подхода оценивалась через два параметра. Первый параметр это масштабируемость инфраструктуры, а второй скорость работы. Скорость работы распределенной ИС оценивалась при сравнении выбранного набора нуклеотидов с геномами организмов по времени загрузки последних в БД. Объем данных, использованных в экспериментах, составлял порядка 20 Гб. Оценка масштабирования инфраструктуры выполнялась при построении прототипа ИС с использованием различных конфигураций. Были протестированы конфигурации без разделения записей по индексу, а также с разделением записи по индексу между одной шардой и тремя. Шарды это сервера, где хранятся данные и осуществляются поиск и обработка информации. При тестировании ПО на всех конфигурациях не потребовалось изменения программного обеспечения, что позволяет утверждать, что прототип ИС может работать при разделении БД между неограниченным количеством рабочих станций. Данное свойство придает распределенной ИС эластичность при росте объема данных. Первый эксперимент был предназначен для оценки скорости загрузки массива геномов организмов в БД. Данная операция не является критической для поисковой системы. Средняя скорость загрузки для различных конфигураций мсКБ текста без шард 76,2 3 шарды 17,9. Зависимость скорости загрузки от размера геномов организмов показана на графиках, которые представлены на верхней панели рис. 2. При загрузке данных производится обновление индексов. Производительность операции добавления данных зависит от объема уже загруженной информации. Из этих графиков видно, что время загрузки документов уменьшается в зависимости от количества шард в кластере. Из графиков нижней панели рис. 2 следует, что зависимость относительного увеличения времени, требуемого на загрузку, от объема ужe загруженных геномов организмов близка к линейной. Также видно, что скорость поиска уменьшается. Отсюда можно сделать вывод, что скорость работы информационной системы с тремя шардами выше, чем с одной. Увеличение количества узлов хранения с одного до трех дает возможность оценки относительной скорости загрузки, показывающей меньший рост при увеличении числа узлов хранения. Это позволяет утверждать, что с точки зрения загрузки данных система является горизонтально масштабируемой. На графике, расположенном в средней панели рис. 2, видно, что в момент перераспределения индекса по шардам скорость загрузки геномов организмов в БД уменьшается стрелкой показан момент перераспределения. Целью второго эксперимента была оценка скорости поиска по БД геномов организмов. Для проведения оценки массив из геномов организмов был загружен в БД MongoDB, которая была установлена на загруженные ранее архитектуры. При осуществлении поиска случайным образом из списка всех рассматриваемых наборов нуклеотидов были выбраны некоторые с определенными нарушениями в порядке нуклеотидов и выполнено сравнение отобранных вариантов с геномами заполненной БД. Результатом поиска было совпадение набора хешей. Эксперимент оценивал не качество, а скорость поиска. Графики зависимости времени поиска от размера приведены на рис. 2 нижняя часть. Средняя скорость поиска мсКБ составила без шард 121,8 3 шарды 72,3. Из этого можно сделать вывод о том, что средняя скорость загрузки без использования распределенной инфраструктуры как минимум в два раза выше, чем при хранении данных в распределенных узлах. Результаты экспериментов свидетельствуют о принципиальной пригодности разработанной модели для поиска сходства в созданной БД, заполненной реальной информацией о геномах. Оценка скорости работы созданной модели, говорит о ее приемлемости с точки зрения производительности для поиска сходства геномных последовательностей организмов и, как следствие, дает возможность выявлять отклонения в развитии на ранних этапах диагностики. Алгоритм, основанный на использовании -грамм, в процессе экспериментов с созданной программной платформой показал достаточно хорошие результаты при поиске сходства наборов нуклеотидов в БД геномов. Разработанная программная модель позволила протестировать алгоритм Winnowing и распределить отпечатки геномов организмов и выбранных наборов нуклеотидов по кластеру в нереляционной БД MongoDB. Разработанный программный комплекс позволил провести эксперименты, которые способствуют выработке новых стратегий и алгоритмов по улучшению поиска выбранных наборов нуклеотидов в геномах организмов. Оценим объем данных, которые возникнут в геномике при развитии постгеномных технологий секвенирования. Международный проект 1 000 геномов уже привел к секвенированию порядка 100 000 индивидуальных геномов, и рост продолжается. Если оценить размер генома человека в 3 ГБ без вспомогательной информации и аннотации, и население планеты в 7 миллиардов, то получим порядка 210 тысяч петабайт информации. Рост геномной информации по секвенированию геномов лабораторных животных крыс и мышей как результат экспериментов в биомедицине, при тестировании фармпрепаратов, приводит к росту БД различных организмов. Так, например, следует отметить важность охарактеризованных ресурсов и системы быстрого поиска в них для развития средств мониторинга сообществ гидробионтов в водных экосистемах. Модели водных экосистем нового пятого поколения содержат в качестве основополагающих внутренних параметров геномные характеристики видов планктона 17. Вышесказанное делает актуальным продолжение работы в нескольких направлениях. Первое направление это решение задачи об определении момента, когда необходимо добавлять узел к кластеру при возрастании рассматриваемого количества выбранных наборов нуклеотидов и увеличении числа геномов в БД организмов. Второе это практическое наполнение БД как можно большим количеством реальных геномов организмов. Использование полученных результатов в междисциплинарных геномных системных исследованиях позволило бы говорить о детализации и развитии модели в перспективном плане. Третье это исследование геномных нарушений с целью оценки вероятности генетических отклонений на этапе распознавания потенциально возможного неблагоприятного развития организма. При индустриальном использовании БД геномов человека, животных и растений, в сотрудничестве со специалистами-генетиками, вышесказанное выглядит все реальнее с учетом продолжающегося бума исследований в данной области 18. . Авторы благодарны коллективу, выпускающему журнал, за внимание к работе и ценные советы. "}
{"title": "ОБ ОПЫТЕ МИГРАЦИИ ПРИЛОЖЕНИЙ  НА СВОБОДНО РАСПРОСТРАНЯЕМОЕ ПРОГРАММНОЕ ОБЕСПЕЧЕНИЕ  С ОТКРЫТЫМ КОДОМ ", "absract": "Важной проблемой современного программирования является поддержка и сопровождение наследственного программного обеспечения (ПО). Функциональность приложений, написанных в старых окружениях, ценна и попрежнему актуальна. Устаревшее ПО не позволяет использовать их на современных машинах и развивать в дальнейшем. В работе описан опыт миграции на примере двух приложений – Архива академика А. П. Ершова и системы «Библиотека», которые используются в ИСИ СО РАН не один десяток лет. В качестве платформы с открытым кодом для создания новых приложений был выбран CMF Drupal, который значительно облегчает разработку и перенос модели данных. Миграция включает в себя реинжиниринг приложения с сохранением бизнес-логики, модели данных, а также перенос самих данных. : миграция, база данных, модель данных, реинжиниринг, drupal, ms sql server, fox pro, mysql, postgresql. ", "text": "Многие научные организации столкнулись с необходимостью поддержки большого количества информационных систем, разработанных в течение последних двух десятков лет с использованием проприетарного программного обеспечения. Такие системы, как правило, создавались с помощью грантов или с использованием спонсорской помощи компаний, предоставляющих программное обеспечение ПО окружения серверные платформы, СУБД, системы программирования, интернет-серверы. Гранты закончились, и ресурсов на обновление ПО окружения больше нет, а приложения используются по сей день и работают на устаревшем оборудовании, в устаревшем окружении, в то время как своей актуальности они не потеряли и требуют дальнейшего развития и сопровождения. В связи с этим становится актуальной задача миграции с проприетарного ПО на свободное. В данной статье будет описан метод такой миграции на опыте двух проектов Архива академика А. П. Ершова и библиотечной системы Библиотека. Определим, что мы будем понимать под миграцией приложений. Миграция от англ. приложений процедура перевода программных продуктов исходного кода и структуры базы данных с одной платформы технологии на другую чаще всего из устаревшей в более современную . В противоположность миграции данных из одного хранилища в другое с одной аппаратной платформы на другую, из одной СУБД в другую, в данной статье речь пойдет именно о миграции приложения в целом. Причин миграции может быть множество. 1. Экономическая причина. Стоимость лицензии от мировых лидеров производителей самых популярных СУБД Oracle и Microsoft велика. А в связи с новой экономической политикой компаний продавать лицензии только на год, причем указывается стоимость лицензии на один процессор, т. е. в случае 4-процессорного сервера обычная конфигурация стоимость увеличивается в 4 раза, платить такую цену за СУБД под силу только крупным компаниям. Но, как показывает опыт, крупные компании тоже не всегда идут на это. Так, например, компания Яндекс в период с 2012 по 2016 г. планомерно мигрировала все свои сервисы на свободно распространяемую СУБД PostgreSQL . Заметим, что ПО с открытым кодом не всегда бывает бесплатным компании, предоставляющие собственные сборки, строят свой бизнес на продаже и поддержке собственных сборок. И все же стоимость такой поддержки не сравнима с ценами, установившимися в связи с новой лицензионной политики мировых брендов ПО. 2. Политическая причина. Зачастую именно политическая причина играет важную роль в принятии решения о миграции, если речь идет о приложениях, имеющих национальное значение. Уже упомянутая компания Яндекс приняла решение о миграции с Oracle еще в 2012 г., до объявления санкций и связанной с ними политикой импортозамещения . Политическая ситуация была названа руководством одной из причин миграции. 3. Вопросы безопасности. Как ни странно, даже компании, предоставляющие решения в области безопасности, предпочитают использовать свободно распространяемое ПО с открытым кодом. Разработчиками ПО в open source контрибуторами являются и отдельные энтузиасты, и целые группы разработчиков, и компании. Политика же контрибуции модулей при разработке открытого ПО обычно такова, что модуль при добавлении подвергается многократному аудиту и ревизии, и если в нем присутствовал бы вредоносный код или просто уязвимость, они были бы выявлены на ранней стадии из-за широкого применения пользователями, которые одновременно являются и разработчиками. Обнаруженные в процессе эксплуатации уязвимости исправляются очень быстро выпуском обновлений безопасности, зачастую в течение нескольких часов с момента обнаружения, в то время как в случае проприетарного ПО известны случаи, когда уязвимость не устранялась в течение длительного времени, пока о ней не становилось известно большому количеству пользователей. Что касается ОС для серверных платформ, выбор открытого ПО Ubuntu, CentOS, Debian, Fedora, FreeBSD давно признан предпочтительным с точки зрения безопасности. 4. Выход свободного ПО на качественно новый уровень. Еще совсем недавно свободно распространяемые продукты, такие, например, как операционные системы Linux, использовались либо исключительно разработчиками ПО, либо только на серверных платформах. Сейчас благодаря Wine, Open Office, Linux Mint пользователи, не являющиеся специалистами в области IT, могут даже не заметить, что на их персональном компьютере установлена Linux, а не Windows. Что касается платформ для разработки веб-приложений, многие системы, начинавшиеся двадцать лет назад как системы управления содержимым сайтов CMS Content Management System переросли в платформы frameworks для разработки CMS. За двадцать лет они проделали путь от нехитрых конструкторов для построения сайтов до фреймворков, содержащих десятки тысяч библиотечных модулей с функциональностью, которая может потребоваться при разработке собственных CMS и веб-приложений. 5. Поддержка. При правильном выборе свободного ПО пользователь получает не только само ПО, но и бесплатную круглосуточную поддержку от членов сообщества, работающих с этим ПО. Поскольку круг пользователей очень широк, вопрос, который может возникнуть у одного из них, скорее всего, уже возникал не у одного десятка пользователей, и на форумах сообщества найдется не только формулировка вопроса, но и решение проблемы. 6. Рефакторинг кода. Неотъемлемым свойством жизненного цикла приложения является развитие. По мере добавления все новых и новых возможностей, а также роста объема данных первоначально спроектированная архитектура приложения перестает удовлетворять современным требованиям. Приложение начинает работать медленно, понижается его отказоустойчивость. Миграция приложения является хорошим поводом для пересмотра функциональных модулей системы, его архитектуры и рефакторинга кода. Миграция приложений, безусловно, требует затрат и человеческих ресурсов. Даже если речь идет о миграции на другую СУБД с сохранением кода приложения и структуры базы данных, это может стать долгим и трудоемким процессом, поскольку оказывается, что SQLзапросы и хранимые процедуры не переносятся один в один из СУБД в СУБД. Более того, даже если речь идет о миграции от версии к версии одной СУБД, задача может оказаться нелегкой и потребовать изучения бизнес-логики самого приложения и переписывания части его кода. Если же в рамках миграции требуется также и полное переписывание кода приложения в другую технологию, процесс может растянуться на годы. Поэтому миграция приложения это, прежде всего, вынужденная мера, на которую приходится идти, чтобы сохранить возможность дальнейшей эксплуатации приложения. Но, как мы покажем далее, даже миграция с полным переписыванием кода вручную требует значительно меньших трудозатрат, чем требовалось на этапе создания исходного приложения. Очевидно, объясняется это тем, что при миграции мы имеем дело с уже сформулированной бизнес-логикой приложения и готовой моделью данных, к тому же проверенными годами эксплуатации. Кроме того, тщательный подход к выбору платформы для миграции позволяет использовать богатый арсенал готовых библиотечных модулей для воссоздания функциональности приложения на новой платформе. И здесь самое время рассказать о выборе платформы Drupal. Для осуществления миграции была выбрана свободно распространяемая платформа Drupal, которая активно развивается с 2001 г. Первоначально развиваемая как CMS, впоследствии Drupal стала позиционироваться как CMF framework платформа. По данным на январь 2018 г., Drupal включает в себя более 39 000 модулей, что сильно ускоряет разработку приложений. Drupal поддерживает все популярные СУБД, отлично справляется с большими проектами, хорошо документирован. Платформа Drupal поддерживается широким сообществом разработчиков в мире и в России в том числе. Кроме того, выбор Drupal был также обусловлен тем, что в Институте систем информатики имени А. П. Ершова СО РАН уже был накоплен значительный опыт работы с этой платформой. В период с 2005 г. по настоящее время сотрудниками института реализовано около 30 веб-проектов на этой платформе. Из недостатков можно отметить подход Drupal к структуре базы данных. В базе данных Drupal хранятся не только данные приложения, но и сама система управления приложением, поэтому создавать структуру базы данных произвольно нельзя она формируется модулями ядра Drupal и модулями третьих сторон. Работать с базой данных напрямую достаточно сложно и не рекомендуется. Другим недостатком Drupal является то, что, несмотря на жесткую модерацию модулей, некоторые из них могут вести себя некорректно при определенных условиях либо больше не поддерживаются разработчиками. В рамках изучения методов миграции на свободное ПО требовалось выполнить миграцию приложений, разработанных несколько десятилетий назад в ИСИ СО РАН, а именно Архива академика А. П. Ершова 1 2 и системы Библиотека 3. Миграция включает в себя следующие работы, которые могут быть выполнены как поэтапно, так и параллельно 1 воссоздание структуры приложения с сохранением по возможности модели данных 2 воссоздание бизнес-логики приложения для различных ролей пользователей, включая неавторизованных пользователей 3 организация рабочих мест для авторизованных пользователей 4 разработка дополнительных возможностей для повышения удобства использования приложений 5 тестирование и отладка на тестовом пуле данных 6 перенос данных на новое приложение. Электронный архив академика А. П. Ершова 4 проект ИСИ СО РАН, выполненный при поддержке Microsoft Research. Проект был начат в 2000 г. и реализован в технологиях Microsoft MS SQL Server, .Net, Microsoft Windows Server, IIS. После кончины академика А. П. Ершова остался уникальный архив 5. Это более 500 папок с документами, отражающими жизненный путь академика и историю развития информатики в России 69. В настоящее время архив включает в себя следующие коллекции документов архив А. П. Ершова, архив С. С. Лаврова, архив ИСИ СО РАН, архив ВНТК Старт. В архиве содержится следующая информация документы 42 386 изображения документов 156 033 описанные персоналии 6 431 сведения об организациях 3 047. В архиве реализованы два вида просмотра документов папки и листы, как собирал их сам А. П. Ершов, и разбиение по темам и группам, как распределили их архивисты рис. 1, 2. Система Библиотека разработана Я. М. Курляндчиком в начале 1980-х гг. на БЭСМ-6, затем была перенесена на ПК с использованием средств MS DOS и FoxPro 10. Система используется до настоящего времени в Мемориальной библиотеке А. П. Ершова для хранения, управления фондами, обработки и публикации новых поступлений в библиотеку. Система Библиотека представляет собой десктопное однопользовательское приложение 3. И база данных, и само приложение находятся на одном компьютере, который представляет собой и рабочее место библиотекаря, и рабочее место читателя. Система написана не в архитектуре клиент-сервер. Это означает, в частности, что она не предоставляет возможности доступа к приложению с другого компьютера. Фактически, база данных представляет собой набор файлов, управляемых специально разработанной системой 11. В системе содержатся следующие данные журналы 722 15 955 номеров описания 54 646 персоналии читателей 114. Объекты, с которыми работает Библиотека, периодические журналы и непериодические описания издания рис. 3. Каталог периодических изданий представляет собой список названий журналов. Выпуски журналов представлены таблицей, символом помечены номера, находящиеся на руках рис. 4. Описания хранятся в массивах по 1 000 элементов. Каждый массив это файл с таблицей FoxPro. В описании указываются вид, язык, авторы, УДК, ББК, редактор, редакция, серия, год, название, количество страниц, источник, выпуск, том, ISSN и другие свойства описываемого фонда библиотеки. Перед тем как приступить к миграции приложения Библиотека, был изучен и обобщен опыт построения библиотечных систем . Для сохранности данных приложения миграцию не следует проводить из работающего приложения. Непосредственно перед осуществлением миграции приложения пришлось осуществить аппаратную миграцию работающего приложения как есть, а именно создать виртуальную машину с окружением, необходимым для запуска исходного приложения, затем скопировать данные приложения и запустить эмулировать приложение в современном окружении. С этой целью для приложения Библиотека была создана виртуальная машина, что позволило осуществить удаленный доступ к копии исходного приложения. Для приложения Архив академика А. П. Ершова была скопирована база данных на виртуальную машину с СУБД MS SQL SERVER. Только после этого стало возможным приступить к первому этапу разработки приложения воссозданию модели данных. Требовалось проанализировать исходную модель данных и полностью воссоздать ее на платформе Drupal. Работа состояла из нескольких этапов 1 создание типов сущностей 2 создание словарей таксономии 3 настройка связей между сущностями и терминами таксономий 4 разграничение уровня доступа для пользователей. В случае с системой Библиотека требовалось не просто воссоздать модель данных, но и формализовать ее, поскольку все данные в системе были строковыми и хранились нерационально. Как говорилось ранее, Drupal не позволяет напрямую работать с базой данных. При миграции каждой сущности для Drupal нужно указывать сразу все связи этой сущности с другими, после чего Drupal распределит их по таблицам в базе данных. Это очень удобно для пользователей приложений, чтобы заполнять данные о конкретной сущности, но вызывает сложности при миграции. По этой причине очень полезным оказался фреймворк Migrate, который позволяет писать собственные модули для миграции рис. 5. Migrate поддерживает миграцию из всех популярных CMS и БД в Drupal, а также между версиями Drupal. Каждый модуль это расширение класса Migrate на языке PHP. Для каждого типа сущности был написан модуль, который преобразует извлеченные данные и записывает их в соответствующие поля сущностей Drupal. Миграции запускаются поочередно, итеративно, в зависимости от модели данных. Есть возможность тестирования миграций включение миграции на небольшом объеме данных, остановка миграции, откат изменений, вызванных конкретной миграцией. Во время миграции приложений пришлось столкнуться с определенными сложностями, которые были вызваны структурой исходных данных, а также особенностями самого метода миграции. В архиве А. П. Ершова данные, относящиеся к одной сущности, зачастую хранились в разных таблицах, такие таблицы приходилось отыскивать для каждой сущности и соединять операцией JOIN. В системе Библиотека все данные были строковые, т. е. не подразумевали использование словарей, типизации. Пришлось определить типы данных и на их основе составить словари для связей. В системе Библиотека после миграции возникло больше количество дубликатов сущностей. Дублировались сущности, которые библиотекарь вводил с ошибками или используя разные варианты написания и сокращения. После миграции были написаны скрипты на языке PHP, которые позволили объединить дубликаты сущностей и восстановить связи между ними. Платформа Drupal может работать только с кодировкой UTF-8. Архив А. П. Ершова работал в среде MS SQL, где использовалась стандартная кодировка Windows CP1251. В системе Библиотека использовалась DOS кодировка CP866. Были написаны функции, декодирующие данные из исходных кодировок в UTF-8 перед записью в базу данных. По итогам работы предложенный метод миграции был исследован и рекомендуется для использования в дальнейшем. Благодаря поддержке словарей таксономии на уровне ядра Drupal отлично подходит для систем со сложной моделью данных, с большим количеством сущностей и связей между ними архивы, библиотеки, каталоги. Ввиду высоких требований Drupal к аппаратным ресурсам следует с осторожностью принимать решение о применении предложенного метода для миграции высоконагруженных систем с большим количеством одновременных пользователей. Предложенный метод показал весомое снижение трудозатрат на написание приложения. Исходное приложение Архив академика А. П. Ершова разрабатывалось командой из четырех разработчиков на протяжении нескольких лет, в то время как разработка на Drupal заняла несколько месяцев у одного разработчика. Дальнейшее ведение проектов архивист либо библиотекарь может осуществлять самостоятельно, не прибегая к помощи разработчика. Поскольку платформа Drupal широко распространена и поддерживается мощным сообществом, в том числе в России, найти разработчика для поддержки, сопровождения и дальнейшего развития проекта не составляет проблемы. В рамках миграции по каждому приложению были выполнены следующие задачи воссоздана модель данных исходного приложения в окружении Drupal разработаны веб-приложения с набором тестовых данных, создан интерфейс для пользователей и редакторов, настроены права доступа для пользователей проведено тестирование новых приложений на выборке данных разработаны механизмы для миграции данных исходных приложений в БД новых приложений с воспроизведением модели данных осуществлен ряд итераций для миграции данных приложение Архив академика А. П. Ершова находится в работе два года, доступно по адресу httpershov.iis.nsk.su приложение Библиотека в настоящий момент находится в стадии тестовых испытаний. "}
{"title": "РАЗРАБОТКА И РЕАЛИЗАЦИЯ АЛГОРИТМОВ РАЗРЕШЕНИЯ КОНФЛИКТОВ   ПО ДОСТУПУ К ПАМЯТИ В ДИНАМИЧЕСКОМ КОМПИЛЯТОРЕ JAVA   ДЛЯ ПРОЦЕССОРА «ЭЛЬБРУС»  ", "absract": "Рассмотрены особенности разработки алгоритмов разрешения конфликтов по доступу к памяти и их реализация в динамическом компиляторе Java для отечественной платформы «Эльбрус». Эти алгоритмы позволяют существенно расширить возможности планировщика инструкций – ключевой оптимизации VLIW-процессоров.  В работе исследуются статические и динамические подходы к анализу зависимостей по памяти, и приводится сравнение эффективности реализованных алгоритмов на основе стандартной тестовой сюиты SpecJVM2008. : Эльбрус, Java, JIT-компилятор, планировщик инструкций, оптимизации компилятора. ", "text": "В настоящее время идет активное развитие Российской электроники, в том числе и процессоров. Так, процессоры Эльбрус, разработанные на основе архитектуры Very Long Instruction Word VLIW, призваны заменить зарубежные аналоги в отраслях, где ключевым критерием является безопасность, например, в работе государственных организаций. Одна из важных задач, которая всегда встает перед разработчиками нового процессора, это задача адаптации уже разработанного программного обеспечения под новый процессор. Для ее решения необходимо разработать для этого процессора компиляторы и виртуальные машины популярных языков программирования. Одним из примеров таких языков является Java кросс-платформенный язык, в котором программы преобразуются в архитектурно независимый байт-код, а затем исполняются при помощи виртуальной Java-машины JVM. Идея работы JVM заключается в том, чтобы интерпретировать методы, которые используются в программе не очень часто, и компилировать в машинный код часто встречающиеся методы. При этом компилятор должен обеспечивать качество кода с помощью встроенных методов оптимизации. Как и на любом процессоре с архитектурой VLIW, важной оптимизирующей компонентой компилятора является планировщик инструкций. В текущей версии компилятора Java для процессора Эльбрус используется суперблоковый планировщик инструкций 1, позволяющий выбрать сразу несколько базовых блоков и запланировать операции внутри них так, как если бы планирование происходило в одном блоке. Зачастую при планировании возникает ситуация, когда одна инструкция должна быть исполнена раньше другой, в таких случаях речь идет о между инструкциями. Если не получается точно определить, есть ли зависимость между какой-либо парой инструкций, то необходимо предполагать ее наличие, чтобы не допустить ошибку выполнения программы. Одним из видов зависимости является, когда операции загрузка-запись и запись-запись могут указывать на один и тот же участок памяти в программе. В предыдущей реализации JVM для процессора Эльбрус любая пара вышеупомянутых обращений к памяти считалась зависимой, что отрицательно сказывалось на возможностях планирования 2. Целью данной работы являлся анализ алгоритмов разрешения конфликтов по доступу к памяти и их реализация в JVM на процессоре Эльбрус. В работе анализируются существующие в настоящее время алгоритмы и способы их адаптации к JVM, а также описываются новые алгоритмы, разработанные с учетом особенностей JVM и процессора Эльбрус. В заключение приводится сравнение производительности реализованных алгоритмов. Java это типизированный объектно-ориентированный язык, разработанный компанией Sun Microsystems. Исходные коды на Java транслируются в .classфайлы, содержащие специальный байт-код, благодаря которому обеспечивается кроссплатформенность, такие файлы могут быть исполнены на любой архитектуре, для которой реализована JVM. Для исполнения байт-кода JVM на процессоре Эльбрус включает в себя интерпретатор и JIT-компилятор. Интерпретатор исполняет один байт-код за другим, не применяя при этом сложных оптимизаций, он используется для реализации методов, исполняющихся не очень часто. JIT-компилятор, в свою очередь, анализирует и оптимизирует сразу весь метод, в результате чего получается более оптимальный код. Так как сам процесс компиляции является ресурсоемким, он обычно применяется к часто исполняющимся методам 3. Ключевая особенность процессоров Эльбрус состоит в том, что они построены на VLIW-архитектуре, позволяющей за один такт процессора выполнять сразу несколько инструкций. Эти инструкции исполняются параллельно, а распределение работ между ними задается во время компиляции. Такой подход существенно упрощает устройство процессора и позволяет увеличить количество вычислительных модулей, однако усложняет работу компилятора 4. За один такт процессор выполняет одну . Такая команда может содержать несколько операций сложения, вычитания, умножения, деления, операций загрузки и записи и др. Задача планирования заключается в том, чтобы выбрать последовательность выполнения инструкций, минимизировав при этом сумму времени исполнения операций и времени простоя 5. Для ее решения нужно разместить все инструкции в наименьшее количество широких команд, соблюдая при этом минимальные задержки по готовности результатов. Ключевым понятием при планировании является определение . Базовый блок это последовательность инструкций, имеющая одну точку входа, одну точку выхода и не содержащая инструкций передачи управления ранее точки выхода 6. Один из вариантов реализации планировщика заключается в том, чтобы производить планирование инструкций только внутри базовых блоков. Проблема такого подхода заключается в том, что зачастую код содержит небольшие блоки, внутри которых недостаточное количество инструкций, для того чтобы выполнить эффективную упаковку кода. Один из способов решения этой проблемы заключается в том, чтобы производить . это последовательность базовых блоков, содержащая только одну точку входа и сколько угодно точек выхода 7. Используемый в JIT-компи ляторе суперблоковый планировщик был разработан с учетом особенностей JVM для процессора Эльбрус 1. Суперблоковый планировщик это итеративный алгоритм, каждая итерация которого выглядит следующим образом выбрать еще не запланированный суперблок построить граф зависимостей между инструкциями в суперблоке выбрать порядок выполнения инструкций и разместить их по широким командам. Одним из ключевых понятий алгоритмов планирования инструкций является граф зависимостей это взвешенный ориентированный граф, описывающий зависимости между инструкциями 8. Множество вершин такого графа совпадает со множеством инструкций, для которых производится планирование. Ребро, с весом в графе указывает, что инструкция должна быть исполнена раньше инструкции хотя бы на тактов. Если равно 0, значит, инструкции и могут быть исполнены в одной широкой команде. Тем не менее надо учитывать, что в некоторых случаях порядок инструкций в широкой команде важен, и инструкция все равно должна быть исполнена раньше инструкции . Можно выделить три ключевых вида зависимостей между инструкциями возникают, когда операции чтения и записи значения в регистр должны следовать друг за другом в определенном порядке возникают, когда операции загрузки и записи в память должны следовать друг за другом в определенном порядке возникают, когда необходимо выполнить какую-то инструкцию гарантированно до или после перехода в другой блок. Чем меньше ребер окажется в итоговом графе зависимостей, тем больше будет в результате возможностей для планирования. Зависимости по данным определяются однозначно и не могут быть упрощены. Количество зависимостей по управлению может быть уменьшено путем вставки дополнительного кода, восстанавливающего состояния регистров на выходах из суперблока. На данный момент эта оптимизация уже реализована в JVM для Эльбруса. Таким образом, с точки зрения уменьшения количества зависимостей наибольший интерес представляют зависимости по памяти. Если удастся доказать, что две инструкции обращаются к разным участкам памяти, то можно говорить о том, что они независимы 9. Рассмотрим два основных подхода к анализу зависимостей по доступу к памяти и . Статический подход заключается в том, чтобы производить проверку зависимости двух операций обращения к памяти во время компиляции метода, и в соответствии с результатом проверки либо добавлять ребро в графе зависимостей, либо не добавлять. Идея динамического подхода, в свою очередь, заключается в том, чтобы производить такую проверку во время исполнения метода. В таком случае нам необходимо генерировать код для обоих исходов проверки 10. Одной из ключевых особенностей языка Java является отсутствие указателей, благодаря чему представляется возможным выполнить анализ по ти пам статический подход к анализу зависимостей по памяти при помощи сравнения типов загружаемых и записываемых элементов 11. В высокоуровневом представлении компилятора хранится дополнительная информация об объектах, в частности о классах, к которым эти объекты относятся. Здесь важно отметить, что из-за наличия в языке Java виртуального полиморфизма на этапе компиляции мы не можем достоверно знать, принадлежит в действительности объект к данном классу или к одному из его наследников. Передав информацию о классах объектов в низкоуровневое представление, мы получаем возможность определять, к каким классам относятся загружаемые и записываемые элементы на этапе построения графа зависимостей Здесь неважно, является эта операция обращением к полю некоторого объекта или обращением к индексу массива. В первом случае речь будет идти о классе, к полю которого мы обращаемся, во втором о классе массива. Если класс объекта, из которого идет загрузка, является наследником или предком класса объекта, в который производится запись, то возможно, что эти объекты совпадают, и соответствующие операции могут указывать на один и тот же адрес. В этом случае нам необходимо использовать другие методы анализа зависимостей. Если же это не так, т. е. ни один из этих классов не является наследником другого, то можно утверждать, что операции обращения к памяти являются независимыми, и не добавлять между ними ребро в графе зависимостей. Также анализ особенностей языка Java показал, что в результате наследования классов типы полей объектов не могут быть изменены. Тем самым мы можем анализировать по типам операции чтения и записи не только на основе объектов, из которых происходит загрузка, но и на основе типов непосредственно загружаемых объектов например, классов полей при обращении к полю объекта. В этом случае нам даже не нужно смотреть на иерархию классов, достаточно просто сравнивать, совпадает ли класс загружаемого объекта с классом записываемого. Если классы отличаются между собой, то операции гарантированно являются независимыми. Самый простой способ сгенерировать динамическую проверку это добавить блок, в котором производится сравнение на равенство двух адресов чтения и записи, и создать код для обоих возможных случаев выполнения программы один для случая равенства адресов и другой для случая неравенства. При таком подходе надо учитывать, что проверка будет производиться во время исполнения программы, поэтому генерировать такие проверки для всех пар операций слишком ресурсоемко. Обычно проверки создаются только для наиболее горячих участков кода, а именно для циклов. Если адреса в операциях обращения к памяти не зависят от номера итерации цикла, то можно сделать блок с проверкой перед циклом и создать два варианта цикла оптимизированный, в котором все операции чтения и записи между собой не пересекаются, и неоптимизированный, в котором операции чтения и записи считаются пересекающимися, если обратное не было доказано при помощи статических алгоритмов разрешения конфликтов по доступу к памяти. Если в цикле есть несколько операций чтения и записи, то нужно добавить проверку для всех таких пар и делать переход на оптимизированную версию цикла только в случае, если никакие из них не являются пересекающимися. Как правило, в реальных программах адреса операций чтения и записи в цикле зависят от номера итерации, поэтому для эффективной работы динамической проверки нужен более сложный анализ, для которого необходимо, чтобы цикл имел канонический вид, а именно содержал ровно одну индуктивную переменную индуктивная переменная изменялась на каждом шаге на некоторую константу, известную на этапе компиляции не имел других точек входа кроме головы цикла не имел других точек выхода кроме хвоста цикла. В таких циклах инструкции обращения к памяти в массивах можно представить в виде Для получения такого представления необходимо определить, каким образом получается адрес обращения к памяти. Для этого мы находим предыдущую операцию, в которой происходило определение регистра, соответствующего адресу, и в зависимости от типа операции изменяем базу, множитель и смещение. Далее процедура повторяется для базы, пока мы не дойдем до операции, из которой нельзя будет однозначно выразить новые значения базы и смещения это может быть, например, загрузка из памяти или результат вызова функции. Когда такое представление будет получено для каждой инструкции обращения к памяти в цикле, мы можем проводить статический анализ для соответствующих операций, а именно если для каких-то двух операций базы и множители совпадают, а смещения различаются, то мы можем утверждать, что они указывают на разную память. Несовершенство такого подхода заключается в том, что часто базы, с которых происходит загрузка, различаются например, два массива передаются в функцию в качестве аргументов, и в этом случае мы ничего не можем сказать о зависимости между ними. Для преодоления этой проблемы перед циклом выполняется динамическая проверка. Мы составляем список используемых в цикле баз массивов, а перед циклом вставляем дополнительный проверочный блок. В этом блоке сравниваются между собой базы используемых в цикле массивов, и если базы всех массивов отличаются друг от друга, то делается переход на предварительно сгенерированную оптимизированную версию цикла. В противном случае делается переход на неоптимизированную версию 12. Преимущество описанного подхода состоит в том, что при планировании нашей оптимизированной версии цикла мы можем полагать, что никакие базы между собой не пересекаются, и, соответственно, если адреса двух инструкций определяются через две разных базы, то они гарантированно являются независимыми. Архитектура процессора Эльбрус предоставляет специальное устройство для динамического разрешения зависимостей по памяти. Принцип работы устройства основывается на разбиении начальной инструкции чтения на две и . Обе инструкции содержат три аргумента, два из которых определяют адрес загрузки, а третий обозначает регистр, в который будет записан результат чтения. Инструкция выполняет обычную загрузку из памяти и добавляет адрес, с которого произошла загрузка, в специальную таблицу процессора. Любая последующая операция записи с этого адреса удаляет соответствующую строчку из таблицы. Инструкция проверяет наличие данного адреса в таблице. Если адрес в таблице есть, то значение загруженного ранее регистра актуально, и указанный в качестве аргумента адрес просто удаляется из таблицы. Если же такого адреса в таблице нет, значит, данные по нему были перезаписаны, в таком случае загрузка производится заново, как при обычной операции чтения. Кроме того, в последнем случае выставляется специальный флаг, по которому впоследствии это можно сделать. Благодаря этому мы можем выносить за инструкции записи не только загрузку, но и зависимые от нее операции, и если эти зависимые инструкции были произведены с неправильным значением загруженного регистра, то мы можем исполнить их снова. Такие зависимые операции называются . Для эффективного использования соответствующих команд Эльбруса необходимо внести определенные изменения в вышеприведенный алгоритм суперблокового планирования. Модифицированная версия планировщика выглядит следующим образом 13 выбрать еще не запланированный суперблок разбить каждую инструкцию чтения на и построить граф зависимостей, полагая инструкции независимыми по отношению к инструкциям записи спланировать инструкции в выбранном суперблоке, убрав лишние инструкции добавить компенсационный код. Несмотря на то что идея алгоритма достаточно простая, есть несколько важных моментов, которые нужно учитывать при реализации алгоритма. Особенность инструкции на Эльбрусе заключается в том, что она не может быть спекулятивной, а значит, в результате должна остаться в исходном блоке, что необходимо отдельно учитывать при построении графа зависимостей. Кроме того, в JVM на Эльбрусе используются, т. е. может быть сделана загрузка с нулевого адреса и только потом произведена проверка на то, удалось ли сделать такую загрузку. Чтобы избежать загрузки с нулевого адреса, неявная проверка переносится между инструкциями и . Также определяемый в инструкции регистр добавляется в в качестве дополнительного аргумента, чтобы при распределении регистров между ними на то же место не был назначен другой регистр. Была разработана эвристика, которая не дает выносить инструкции слишком высоко от начального места, это позволяет уменьшить количество срабатываний инструкции и сократить давление на регистры, чтобы избежать ситуации, когда нам приходится выгружать часть регистрового файла на стек. Чтобы корректно сгенерировать компенсационный код, для каждой операции необходимо поддерживать набор регистров, значения которых от нее зависят. Важно заметить, что нельзя переносить зависимости от использования к определению регистра за инструкцию, так как в этом случае не получится восстановить начальные значения регистров для того, чтобы исполнить их снова. Алгоритмы, описанные в этой статье, были реализованы в динамическом компиляторе с языка Java для VLIW-процессора Эльбрус. Компилятор с реализованными оптимизациями был проверен на следующих стандартных тестах SpecJVM98 SpecJVM2008 SpecJBB2005 Dacapo JCK JCTF. Все тесты были пройдены успешно. Также была произведена оценка полученного ускорения за счет реализованных оптимизаций на стандартной тестовой сюите SpecJVM2008. Тесты SpecJVM2008 включают в себя следующие бенчмарки Compress алгоритм сжатия LZW Signverify алгоритм подписи и проверки на основе протоколов MD5withRSA, SHA1withRSA, SHA1withDSA и SHA256withRSA Mpegaudio декодирование формата mp3 Scimrak SOR метод релаксации Якоби Scimrak Monte Carlo интегрирование методом Монте-Карло Scimrak LU LU-разложение матрицы Xml.Validation валидация xml-документов по xml-схеме. Следует заметить, что тесты Scimark кроме Monte Carlo в SpecJVM2008 включены в small и large версии. В первом случае все данные, которыми оперирует программа, помещаются в кеш процессора, во втором размеры матриц и массивов подобраны таким образом, что их необходимо загружать из оперативной памяти. Результаты сравнения производительности приведены на рисунке Статья является логическим продолжением работы 1 над улучшением показателей упаковки кода и, как следствие, ускорением работы JIT-компилятора Java на процессоре Эльбрус. Разработанные и описанные в статье оптимизации открывают большие возможности для добавления ряда других важных улучшений компилятора. В частности, это конвейеризация циклов и динамическая проверка существования исключений в цикле, которые невозможны без реализации рассмотренных выше алгоритмов. Кроме того, планируется перенести описанные алгоритмы и на другие JIT-компиляторы для процессора Эльбрус, а именно, C и JavaScript. "}
{"title": "БИНАРНЫЕ ОПЕРАЦИИ В ИНФОРМАЦИОННОЙ СИСТЕМЕ   «МОЛЕКУЛЯРНАЯ СПЕКТРОСКОПИЯ» ", "absract": "Представлен подход, использованный при разработке и реализации модуля, выполняющего бинарные операции над данными в ИС «Молекулярная спектроскопия». Приводится формализация бинарных операций над наборами спектроскопических данных с учетом особенностей предметной области. Описываются алгоритм действий  и интерфейс пользователя для проведения бинарных операций – единые для имеющихся баз данных по различным веществам и нескольким типам спектроскопических данных. : структуры данных, количественная спектроскопия, бинарные операции, базы данных. ", "text": "Основным способом представления широкой общественности результатов научной деятельности являются публикаций в научных изданиях. При небольшом объеме численных данных, полученных в ходе исследования, они публикуются непосредственно в статье в виде таблиц или графиков. В случае если объем численных данных велик для публикации в статье, такие данные публикуют в сети Интернет, размещая файлы, например, на FTP-серверах. Современные исследования по молекулярной спектроскопии высокого разрешения в области состояний молекул и характеристик спектральных переходов дают постоянно растущие объемы численных данных благодаря совершенствованию как измерительного оборудования, так и вычислительной техники. Таким образом, результаты экспериментальных работ содержат значения параметров от десятков и сотен до десятков тысяч спектральных переходов или состояний молекулы 1 2. Теоретические расчетные работы могут содержать характеристики нескольких миллиардов переходов 3 4. В информационной системе ИС Молекулярная спектроскопия ведется накопление численных значений данных, публикуемых исследователями в статьях 58. Совокупность извлеченных из опубликованных материалов численных значений спектроскопических данных будем называть набором данных. В отдельных статьях, как правило, представляются данные по свойствам лишь одной молекулы или небольшой группы молекул. Зачастую приводятся только часть набора параметров спектральных линий или исследования в узком спектральном диапазоне. Однако исследователям из прикладных областей, использующим необходимые спектральные параметры, например, в расчетах радиационных или климатических моделей, требуются данные в достаточно широком спектральном диапазоне. Это приводит к необходимости формирования составных наборов данных путем комбинирования данных из различных источников. Среди составных наборов можно выделить экспертные наборы, предоставляющие достоверные, согласованные и наиболее полные данные как по перечню спектральных параметров, так и по спектральному диапазону 9. Процесс создания таких наборов можно разделить на два вида действий отбор данных с помощью условий в пределах одного набора данных и объединение отобранных данных в новый составной набор данных. Формирование составных наборов данных процесс трудоемкий, но часть действий можно автоматизировать с помощью информационных технологий. Действия по выборке части данных из конкретного источника, удовлетворяющих наложенным ограничениям, были автоматизированы созданным в рамках ИС Молекулярная спектроскопия модулем унарные операции 10. Для создания составного экспертного источника данных из отобранных частей исходных источников необходим механизм их объединения, позволяющий учитывать как формализуемые ограничения предметной области, так и принимаемые экспертами решения, не поддающиеся алгоритмизации. Подробно структура данных молекулярной спектроскопии, над наборами которых производятся манипуляции, была рассмотрена нами в работе 10. Здесь лишь коротко напомним, что набор данных представим в виде таблицы независимо от способа хранения, и имеются, продиктованные особенностями предметной области. 1. Во всех наборах данных есть две обязательные части набор квантовых чисел и набор некоторых физических величин. В зависимости от спектроскопической задачи обязательной физической величиной является уровень энергии или частота спектрального перехода. Остальные физические величины могут отсутствовать совсем либо иметь пустоты в отдельных строках. 2. Значения квантовых чисел в каждой строке таблицы является уникальным идентификатором, который однозначно определяет, к какому уровню энергии или спектральному переходу относятся значения набора физических величин, представленных в этой строке таблицы, согласно используемой модели молекулы. Сравнение строк производится только по набору значений квантовых чисел, который мы рассматриваем как единый элемент идентификатор. Два идентификатора равны, если равны между собой все соответствующие квантовые числа. Остальные физические характеристики имеют приближенные значения в силу неточности самих моделей или измерений в эксперименте. Таким образом, все строки в одном наборе данных должны быть с различными уникальными идентификаторами как в исходных наборах, так и в результирующем наборе. 3. Операндами в бинарных операциях являются только канонические наборы данных, в которых квантовые числа удовлетворяют ограничениям на состояние и правилам отбора определяют допустимые сочетания квантовых чисел верхнего и нижнего состояния. Операции производятся над данными, относящимися к одному типу спектроскопических задач прямая обратная и одному веществу 11. 4. В исходных и результирующем наборах данных может быть только по одной колонке с данными по конкретной спектральной характеристике физической величине. Рассмотрим три операции над парой наборов данных по аналогии с теорией множеств объединение, пересечение и разность. Эти операции являются манипуляциями с данными, т. е. действиями, не изменяющими сами значения данных. наборов данных дает множество строк одного набора данных, не имеющих пары по набору значений квантовых чисел во втором наборе данных. наборов данных, позволяет соединять в единый набор строки из двух разных наборов независимо от наличия совпадений по набору значений квантовых чисел. С помощью наборов данных, можно выбрать строки из двух наборов с совпадающими наборами значений квантовых чисел. Специфика предметной области приводит к особому процессу выполнения некоторых операций. Так, в операции разности результат однозначен и может быть получен автоматически, так как среди отобранных строк набора данных не может быть строк с одинаковыми наборами значений квантовых чисел. В то время как в операциях объединения и пересечения имеет место, где могут быть строки с совпадающими наборами значений квантовых чисел, но из разных наборов данных. Согласно принятым нами правилам результирующий набор данных должен содержать только канонические данные 11, т. е. среди прочих условий не иметь строк с совпадающими наборами значений квантовых чисел. Выбор строк, которые попадут в результирующий набор данных, может произвести только пользователь системы эксперт на основании имеющихся у него неформализуемых знаний. Это и есть неавтоматизированная часть операций манипулирования наборами данных. Таким образом, в операциях объединения и пересечения автоматически выполняется формирование промежуточного результата с выбранными из разных источников строками и создание нового набора данных с сохранением в него строк, отобранных экспертом. Для описания сути бинарных операций нам удобно использовать термины теории множеств. Обозначим набор данных по конкретному веществу, как, где спектральные переходы, профили спектральных линий, уровни энергии молекулы тип спектроскопической задачи, а это множество строк набора данных. Согласно теории множеств при выполнении операций пересечения, объединения и разности производится сравнение элементов по их значениям, однако в нашей предметной области строка в наборе данных не является элементарным объектом с одним значением. Каждая строка набора данных имеет сложную структуру, для описания которой можно применить кортежи из алгебры кортежей 12. Тогда элемент множества набора данных можно представить кортежем, элементы которого разделены по смыслу на две части, как упоминалось ранее, где,..., кортеж, содержащий значения квантовых чисел из предметной области, уникальная комбинация которых идентификатор в пределах набора данных однозначно идентифицирует,..., кортеж, содержащий численные значения физических величин, набор которых зависит от спектроскопической задачи, описывающих свойства -го спектрального перехода или состояния молекулы, число физических характеристик. Операция пересечение двух наборов данных производится построчно на основе сравнения идентификаторов. Выбираются строки с одинаковыми идентификаторами из обоих наборов данных, прочие строки в результат операции не попадают. Промежуточный результат может содержать по два значения одной и той же физической величины, соответствующих одному идентификатору. Так как в нашей информационной системе принято, что одному идентификатору должно соответствовать по одному значению каждой физической величины, то далее пользователь должен выбрать, какое значение физической величины включать в результат. Пусть 1, и 2, два исходных набора данных. Их пересечение можно расписать следующим образом 1 2 3, где и, а,..., . С помощью записи мы обозначили, что эксперт, производящий операцию, делает выбор между и, основываясь на имеющихся у него неформализуемых знаниях. Операция объединение двух наборов данных проводится, как и операция пересечения, на основе сопоставления идентификаторов строк. Выбираются все строки из первого набора данных, а затем к ним добавляются строки из второго набора данных. Из получившегося промежуточного результата в итоговый набор данных попадают строки с несовпадающими идентификаторами. Значения физических величин в строках с совпадающими идентификаторами могут быть включены в результирующий набор данных в зависимости от выбора пользователя либо все из первого набора данных, либо все из второго набора данных. Допускается объединение наборов данных независимо от заполненности строк, т. е. с возможностью образования пропусков в данных отсутствие значений физических величин. Пусть имеется два набора данных 1, 2, . Тогда их объединение можно записать так 1 2 3, где содержит строки, удовлетворяющие следующим условиям,..., при и,..., при и,..., при и . Операция разность наборов данных 1 и 2 аналогична разности дополнению в теории множеств. Так же как и операция пересечения, она выполняется на основе сравнения идентификаторов. Разность множества 1 и множества 2 это множество, содержащее в себе элементы множества 1, но не входящие в 2 . Обозначается 1 без 2, 1 2 или 1 2 . Мы будем использовать последний вариант обозначения для записи операции разности наборов данных. В результате может получиться пустой набор данных, часть 1 или полностью 1 . 1, 2, 1 2 3, где и . Обзор интерфейсов в информационной системе Молекулярная спектроскопия для проведения автоматических операций не требующих участия пользователя был представлен в работах 10 13. Здесь рассмотрим интерфейс той части ИС, которая относится к выполнению неавтоматизированного этапа операций объединение и пересечение. После выбора двух источников данных, над которыми будут производиться манипуляции, пользователь делает выбор операции и параметров ее выполнения рис. 1. В качестве дополнительной информации при принятии решения эксперт может воспользоваться имеющейся в системе характеристикой разупорядочения между выбранными наборами данных. В операции выбор эксперта сводится к указанию, что сделать со всеми строками с совпадающими наборами значений квантовых чисел. Их можно все взять из одного или другого набора данных либо не брать их в результирующий набор данных вообще. Поэтому промежуточный результат операции не отображается, а сразу выдается окончательный результат. В операции эксперт имеет возможность детальной обработки промежуточного результата. Он может указать, из какого источника брать данные по конкретной спектральной линии или спектральной полосе в целом рис. 2. Название источника данных и значения конкретных параметров спектральной линии, взятых из него, подсвечиваются одним цветом. Полученный результат сохраняется как новый набор данных рис. 3. Такая реализация позволяет сохранять результат детальной обработки в отдельном наборе данных и использовать его потом в других операциях, тем самым уменьшается количество потенциальных ошибок, когда пользователь в при первой обработке промежуточного результата выбрал одно, а при повторной выбрал другое. Детальная обработка пересекающейся части по строкам и по спектральным полосам имеется только в операции пересечения. В рамках информационной системы Молекулярная спектроскопия создан модуль позволяющий формировать составные наборы данных, путем их комбинирования из различных источников. Это позволяет создавать составные экспертные наборы данных, учитывая как формализуемые ограничения предметной области, так и принимаемые экспертами решения, не поддающиеся алгоритмизации. Одно из направлений дальнейших исследований определение критериев для автоматического формирования рекомендаций для эксперта по выбору окончательного результата полуавтоматической части операций. "}
{"title": "КОЛЛАБОРАТИВНАЯ ФИЛЬТРАЦИЯ ДЛЯ ПОСТРОЕНИЯ РЕКОМЕНДАЦИЙ   НА ОСНОВЕ ДАННЫХ О ЗАКАЗАХ ", "absract": "Рассматривается возможность применения методов коллаборативной фильтрации в процессе создания рекомендательной системы на основе данных о заказах документов из библиотечного фонда. Приводится сравнительный экспериментальный анализ трех методов коллаборативной фильтрации: на основе документов, на основе пользователей и на основе гибридного метода, являющегося комбинацией первых двух методов. : рекомендательная система, коллаборативная фильтрация, унарные данные, бинарные данные. Работа выполнена при частичной поддержке фонда РФФИ (проект № 18-07-01457). ", "text": "Рекомендательные системы открывают новые возможности навигации в процессе информационного поиска. Очевидно, что одной из областей их применения могут быть библиотечные фонды 1. Учет поведения пользователей для ранжирования документов, с которыми они взаимодействуют, ведет к установлению новых взаимосвязей между этими документами, выходящих за пределы традиционной рубрикации и ключевых слов. Такой учет позволяет связывать документы из смежных областей знания в условиях, когда в них используется различная терминология. В рамках данной работы рассматривалась возможность применения методов коллаборативной фильтрации для создания рекомендательной системы на основе данных о заказах документов в электронном каталоге Научно-технической библиотеки Томского политехнического университета НТБ ТПУ. Задачи, поставленные в рамках исследования 1 предварительная оценка качества рекомендаций на основе документов и на основе пользователей по сравнению с базовым методом без персонализации 2 оценка качества работы гибридной рекомендательной системы, объединяющей описанные выше методы 3 подбор некоторых параметров будущей системы. В работе использовались данные о заказах читателей НТБ ТПУ за 2015 г., представленные в виде таблицы из двух столбцов в первом столбце содержатся идентификаторы пользователей, зашифрованные с помощью хеш-функции для обеспечения анонимности, а во втором идентификаторы документов. В качестве документа может выступать любой объект, библиографическое описание которого присутствует в электронном каталоге книга, статья, цифровой носитель и т. д.. Каждая строка отражает факт заказа читателем документа без указания времени заказа. Строго говоря, описанные данные являются унарными. Это означает, что мы знаем лишь о положительном отклике пользователя факте заказа. При этом мы не знаем, насколько высоко пользователь оценил данный документ рейтинги неизвестны, а также не обладаем сведениями об отрицательном отклике. Если пользователь не заказал конкретный документ, то причин может быть несколько данный документ не является релевантным документ релевантен, известен пользователю и, следовательно, не должен быть рекомендован документ релевантен, неизвестен пользователю. Очевидно, при построении рекомендаций необходимы документы последней группы. Однако выделить их на основе имеющихся данных не представляется возможным. Для создания тестовой выборки при оценке качества работы рекомендательной системы мы вынуждены использовать допущение, что все документы, которые не были заказаны, являются нерелевантными. Технически это означает замену всех неопределенных значений на нули и переход от унарного типа данных к бинарному 3. Если пользователь заказывал документ, то на пересечении соответствующих строки и столбца стоит единица, в противном случае ноль. Такой подход позволяет формировать группу нерелевантных документов для проверки без оценки пользователем каждого документа в коллекции, что, как правило, невозможно. Дополнительно в работе был задействован набор данных под названием MSWeb, предоставляемый в рамках используемого инструментария. Данные получены путем выборочного анализа лог-файлов сайта www.microsoft.com. Они представляют собой записи об обращениях к различным областям сайта анонимных пользователей, выбранных случайным образом, и также приведены к бинарному виду. Временной период одна неделя в феврале 1998 г. В роли документа выступает область сайта. Набор данных MSWeb является вспомогательным, его использование в данной работе обусловлено стремлением выделить особенности данных о заказах НТБ. Для того чтобы исключить из работы пользователей и документы, о которых слишком мало информации, были применены следующие фильтры в указанном порядке 1 исключение документов, которые были заказаны менее чем 4-мя пользователями 2 исключение пользователей, которые заказали менее 4-х документов. Описанная фильтрация позволяет существенно сократить объем данных для работы табл. 1. Кроме того, она позволяет составлять тестовую выборку из тех пользователей, кто заказал 4 и более документов. Это означает, что мы можем строить рекомендации на основе трех документов и иметь как минимум один документ для проверки. Количественное описание данных Данные До фильтрации После фильтрации НТБ MSWeb НТБ MSWeb Записи о заказах просмотрах 98 341 98 653 51 513 57 497 Уникальные пользователи 9 619 32 710 4 786 9 544 Уникальные документы 37 718 285 3764 231 В работе была использована библиотека 2 для вычислительной среды R project. С помощью данной библиотеки для исходных данных были построены следующие варианты рекомендательных систем 1 рекомендации по популярности 2 коллаборативная фильтрация на основе документов, 3 коллаборативная фильтрация на основе пользователей, 4 гибридный подход . Первый способ, при котором всем пользователям рекомендуются наиболее популярные документы, был использован в качестве базового метода для сравнения. Рекомендации, полученные с его помощью, не являются персонализированными. Модели на основе сходства документов используют предположение, что похожие между собой документы будут оцениваться пользователями сходным образом. Таким образом, производится вычисление меры схожести для каждой пары документов, и задействуются те документы, для которых значения меры наибольшие. Модели на основе пользователей базируются на аналогичной идее похожие между собой пользователи оценивают документы приблизительно одинаково. Для того чтобы спрогнозировать оценку данным пользователем конкретного документа, можно привлечь оценки других пользователей, похожих на данного пользователя 3. Количество похожих документов или пользователей может варьироваться. В данной работе оно задается с помощью значения параметра . Гибридный метод подразумевает комбинацию двух списков рекомендаций с заданными весовыми коэффициентами. В данной работе комбинировались два варианта коллаборативной фильтрации на основе документов и на основе пользователей. Для оценки того, насколько документы или пользователи похожи между собой, были использованы следующие меры 1 коэффициент Жаккара 4 2 мера Дайса 5 3 косинусная мера 3 4 коэффициент корреляции Пирсона 3. Данные, используемые в работе, были случайным образом разбиты на обучающую 70 пользователей и тестовую 30 выборки. Для пользователей из тестовой выборки, в свою очередь, производилось разделение документов. Для каждого пользователя были выбраны по три документа, на основе которых строились рекомендации. Размер списка рекомендаций описывается параметром . Полученные рекомендации сравнивались с остальными скрытыми документами пользователя. По результатам сравнения были вычислены оценки качества работы системы. Качество рекомендаций оценивалось с помощью показателей, традиционно используемых для оценки качества информационного поиска полноты, точности и -меры 6. Результаты применения различных мер схожести для построения рекомендаций на основе документов можно проиллюстрировать с помощью так называемых кривых полнота-точ ность рис. 1. Как видно из рис. 1, коэффициент Жаккара и мера Дайса дают очень близкие результаты, тогда как коэффициент Пирсона им несколько проигрывает. Значения полноты и точности для косинусной меры настолько малы, что вся кривая выглядит как одна точка рядом с началом координат. Такая аномалия проявляется за счет особенностей реализации построения рекомендаций с помощью косинусной меры в библиотеке . Использование данной меры схожести приводит к тому, что слишком многие документы получают максимально возможное значение меры схожести. В случае, когда для некоторого документа количество максимально схожих с ним документов больше значения параметра, выбор ближайших соседей становится проблематичным. Используемый инструментарий в этом случае возвращает пустое множество вместо списка рекомендаций. Таким образом, рекомендации на основе косинусной меры были сформированы менее чем для 4 пользователей тестовой выборки. Для оставшихся пользователей были приняты нулевые значения показателей полноты и точности. Для вычисления сходства между пользователями использовались уже перечисленные меры схожести рис. 2. Лучшие результаты для данных НТБ ТПУ показала косинусная мера, которой незначительно уступает коэффициент Жаккара. Иллюстрация того, как на качество рекомендаций влияет количество ближайших соседей, приведена на гистограмме рис. 3. Из рассмотренных значений параметров рекомендательной системы наиболее качественные рекомендации дает использование параметра 50 в сочетании с косинусной мерой. По результатам аналогичного анализа метода построения рекомендаций на основе документов параметр был выбран равным 30. В табл. 2 приведены показатели качества для двух вариантов коллаборативной фильтрации. Оценки качества для списка из 10 рекомендаций Мера сходства Рекомендации основанные на документах IBCF, 30 основанные на пользователях UBCF, 50 точность полнота F-мера точность полнота -мера Жаккара 10,85 18,75 13,74 15,15 27,01 19,41 Пирсона 10,46 18,33 13,32 14,53 24,27 18,18 Косинусная 0,65 0,18 0,28 15,58 27,06 19,78 Дайса 10,84 18,73 13,73 14,26 24,28 17,97 В результате проведенных экспериментов для рекомендаций на основе документов был выбран коэффициент Жаккара, а для рекомендаций на основе пользователей косинусная мера. При этом результаты метода на основе пользователей заметно превосходят качество рекомендаций на основе документов. При создании гибридного подхода были использованы два метода построение рекомендаций на основе пользователей с применением косинусной меры и на основе документов с использованием коэффициента Жаккара. Пропорция для комбинирования методов задавалась с помощью параметра 1 . Зависимость -меры от параметра проиллюстрирована на рис. 4. Среди рассмотренных значений лучшим оказалось значение 0,925. При этом достигнутое значение -меры превосходит значение, полученное методом на основе пользователей. Таким образом, комбинация превосходит по качеству каждый метод в отдельности. В табл. 3 приведены оценки качества рекомендаций рассмотренных выше подходов. Для всех методов параметр 10. Значения показателей заметно различаются для двух наборов. Набор данных MSWeb можно назвать более предсказуемым, поскольку он позволяет добиться более высоких показателей качества значение -меры достигает 27,47 . Набор данных НТБ ТПУ показывает более скромные результаты, но при этом он характеризуется значительной разницей между рекомендациями по популярности и коллаборативной фильтрацией. Выигрыш в -мере для гибридного метода составляет всего 1,5 от значения для метода на основе пользователей, в то же время он является значительно более трудоемким табл. 4. Сравнение качества рекомендаций для описанных подходов 10, Показатель качества По популярности На основе документов коэф. Жаккара, 30 На основе пользователей косинусная мера, 50 Гибридный метод 0,925 НТБ MSWeb НТБ MSWeb НТБ MSWeb НТБ MSWeb Точность 3,79 16,16 10,85 17,46 15,58 17,27 15,84 18,50 Полнота 4,78 57,63 18,75 64,37 27,06 65,19 27,43 68,60 -мера 4,23 25,24 13,74 27,47 19,78 27,31 20,08 29,14 Среднее время на итерацию вычислений Рекомендации Время, с моделирование формирование рекомендаций Всего По популярности 0,004 3,59 3,594 На основе документов 2467,38 2,58 2469,96 На основе пользователей 0,007 59,36 59,367 Гибридный метод 13529,17 848,61 14377,79 Метод, основанный на документах, требует значительно больше времени для моделирования. Это связано с особенностями данного подхода, а также с реализацией данного алгоритма в библиотеке . Поскольку количество документов в нашем случае значительно, матрица схожести имеет большую размерность, что затрудняет вычисления. При этом время формирования рекомендаций для пользователей значительно меньше, чем для подхода на основе пользователей. Что касается гибридного метода, выигрыш в качестве, который он обеспечивает, вряд ли может компенсировать его временные затраты. Проведенные эксперименты позволяют утверждать о возможности построения рекомендательной системы методами коллаборативной фильтрации на основе данных о заказах НТБ ТПУ. Использование подхода, основанного на пользователях, позволило добиться более качественных рекомендаций по сравнению с базовым методом рекомендациями по популярности, а также по сравнению с рекомендациями на основе документов. Гибридный подход с использованием двух методов коллаборативной фильтрации позволил несколько улучшить показатели качества, но при этом потребовал значительного времени как на этапе моделирования, так и на этапе формирования рекомендаций. В рамках дальнейшей работы планируется исследовать возможности сбора более качественной информации о предпочтениях пользователей например, в виде рейтингов документов, а также оценить возможности привлечения информации из библиографических описаний документов, хранящихся в фонде библиотеки. "}
{"title": "СИСТЕМА АНАЛИЗА И ВИЗУАЛИЗАЦИИ   ДЛЯ КРОСС-ЯЗЫКОВОЙ ИДЕНТИФИКАЦИИ   АВТОРОВ НАУЧНЫХ ПУБЛИКАЦИЙ  ", "absract": "Представлена система разрешения неоднозначности авторства статей на английском языке с использованием русскоязычных источников данных. Система позволяет находить и исправлять ошибки в определении авторства научных публикаций, что может улучшить результаты поиска статей определенного автора и подсчета индекса цитируемости. В качестве исходного хранилища публикаций использовалась база link.springer.com, для получения достоверной информации об авторах и их статьях использовалась научная электронная библиотека eLIBRARY.ru. Система предоставляет интерактивную визуализацию результатов и возможность редактирования для повышения качества экспертного анализа. Подходы, используемые в данной системе, применимы для разрешения неоднозначности авторства публикаций из различных библиографических баз данных. : разрешение неоднозначности авторства, кросс-языковая идентификация сущностей, обработка естественного языка, интерактивная визуализация, кластеризация. ", "text": "Многие научные цифровые библиотеки, такие как DBLP, PubMed, Springer и др., предоставляют функции, которые облегчают исследования целых коллекций документов. Такие системы дают доступ к миллионам библиографических записей, и на данный момент являются важнейшим источником информации для академического сообщества, так как они позволяют производить централизованный поиск публикаций. Одной из проблем, возникающих при поиске публикаций определенного автора, является то, что такие системы не свободны от ошибок идентификации авторов. Эти ошибки могут быть двух типов публикации двух разных персон присваиваются одной персоне или публикации одной персоны распределяются по нескольким разным персонам. От подобного рода ошибок не свободно большинство библиографических систем, в том числе VIAF, SCOPUS и др. Например, на сайте Scopus представлено пять авторов с разными вариантами написания фамилии Непомнящий. При этом публикациям реальной персоны В. А. Непомнящий, сотрудник ИСИ СО РАН соответствовали публикации четырех из них, и все они имели различные идентификаторы. Помимо того, что данные ошибки затрудняют поиск статей, относящихся к определенному автору, они могут влиять на такую важную характеристику работы ученых, как индексы цитируемости. Причин возникновения ошибок достаточно много множественные варианты транслитерации с русского языка на английский, ошибки автоматических систем по наполнению библиографических баз данных, невнимательность пользователей. Наиболее точно решает проблему установления авторства публикаций экспертный анализ. Эксперты могут идентифицировать автора неизвестного документа или определить принадлежность произведения другому автору при помощи характерных языковых особенностей, стиля автора. Однако экспертный анализ трудоемкий процесс, поэтому разрабатываются системы для автоматизации определения авторства документов. В таких системах применяются подходы из теории распознавания образов, математической статистики и теории вероятностей, алгоритмы нейронных сетей, кластерного анализа и др. К сожалению, автоматическое разрешение неоднозначности не дает стопроцентной точности, и в любом случае требуется вмешательство эксперта. Задача эксперта усложняется тем, что количество документов в коллекции, для которой необходим анализ, может достигать нескольких сотен или даже тысяч. Для упрощения восприятия результатов анализа применяется интерактивная визуализация информации в виде графов, матриц смежности, диаграмм и т. п. Такое представление коллекции документов и полученных результатов значительно ускоряет процесс экспертного анализа. Задача, в которой все публикации даны на одном языке например, на английском достаточно хорошо изучена существуют решения, которые работают в условия неполноты и разнородности данных и показывают высокую точность результатов 1 2. Однако задача кроссязыковой идентификации сущностей в частности, данных на английском и русском языках является достаточно новой и требует детального изучения. В работах 3 4 описаны эксперименты по кросс-языковой идентификации сущностей при помощи Открытого архива СО РАН на основе исчерпывающей информации о местах работы авторов. Хотя результаты были достаточно обнадеживающими, основной проблемой был локальный характер этого архива, поскольку он касался только сотрудников СО РАН. Таким образом, возник вопрос, с каким более крупным русскоязычным источником можно провести подобные эксперименты. В качестве такого экспериментального источника данных была выбрана научная электронная библиотека eLIBRARY.ru, которая содержит большое количество подтвержденных записей о публикациях российских ученых. В данной статье описана система анализа и визуализации публикаций на естественном языке для автоматизации процесса устранения неоднозначности авторства научных публикаций рис. 1. Система производит идентификацию авторов коллекции статей на основании извлекаемых метаданных и текста публикации, а также предоставляет интерактивную визуализацию для упрощения интерпретации полученных результатов и анализа коллекции. В качестве исходного хранилища публикаций использовалась база link.springer.com . По фамилии, имени и отчеству ФИО на русском языке из данного хранилища извлекается коллекция статей на английском языке. Часть данных о статье, в том числе текст публикации, может отсутствовать. В качестве источника достоверной информации об авторах и их статьях использовалась Научная электронная библиотека eLIBRARY.ru. Большая часть информации в ней представлена на русском языке. Для решения проблемы идентификации авторства коллекции документов из хранилища link.springer.com требуется сопоставить статьи из хранилища link.springer.com со статьями из eLIBRARY.ru произвести разделение набора научных статей, соответствующих одному или нескольким авторам, на набор непересекающихся множеств, где каждому множеству соответствует один автор данных научных публикаций произвести визуализацию полученных результатов. Как известно, существует проблема неоднозначности транслитерации имен авторов с русского языка на английский язык. Как упоминалось ранее, в системе Scopus хранятся публикации В. А. Непомнящего, отнесенные к разным авторам, имена которых представлены как Nepomniaschy, V.A. Nepomnyashchii, V.A. Nepomnyaschy. Генерация всех возможных транслитераций не представляется возможной, так как реальные данные могут не подчиняться правилам транслитерации букв. Однако чем больше будет покрытие вариантов, тем больше данных будет доступно при поиске. В ранних работах использовались транслитерации, полученные лишь по одному из имеющихся стандартов или по обращению на языковые ресурсы для переводов текста, такие как translate.google.com . Данные подходы покрывают малое количество вариантов транслитерации. В текущей работе были изучены различные транслитерации букв русского алфавита, используемые в стандартах зарубежных стран и Российской Федерации ГОСТ 7.79-2000, ГОСТ 16876-71 и пр. 5, а также транслитерации, используемые в обиходе пользователей сети Интернет . На основании выделенных транслитераций отдельных букв была реализована генерация всех возможных транслитераций имени автора на русском языке. С каждым именем сопоставляются различные варианты сокращений, так как не всегда в хранилище возможно найти статьи по полному имени автора. По всем вариантам транслитерации производится обращение к базе данных Springer. Также осуществляется обращение к eLIBRARY.ru по изначально предложенным экспертом ФИО на русском языке. В результате получения входных данных исходными параметрами статей из хранилища link.springer.com являются название статьи список авторов список мест работы для каждого автора дата публикации название журнала список тем, затронутых в публикации список ключевых слов текст публикации в формате pdf. В результате получения входных данных исходными параметрами статей из eLIBRARY.ru являются название статьи список авторов информация об издании, в котором была опубликована статья. Сопоставление происходит по доступным параметрам следующим образом пусть статья из link.springer.com, статья из eLIBRARY.ru если название статьи совпадает с названием статьи полностью, без учета разделительных символов, регистра и знаков препинания, то считается, что иначе производится стемминг названий и, и считается коэффициент совпадения названия как доля совпадающих слов в данных названиях коэффициент соавторства данных статей принимается равным доле совпадающих авторов если сумма двух данных коэффициентов превышает пороговое значение, то считается, что . Если название публикации и список авторов указаны в eLIBRARY на русском языке, сравнить их вышеуказанным способом не получится. В таком случае в сравнении использовались результаты машинного перевода названия и списка авторов с русского языка на английский. В качестве инструмента для машинного перевода использовалась система Яндекс.Переводчик. Иногда среди данных о публикации из link.springer.com доступна информация об издании, в котором был опубликован оригинал статьи на русском языке, включающая в себя номер выпуска, номера страниц и дату публикации. В таком случае производится сравнение этой информации с данными eLIBRARY. В результате такого сопоставления формируются группы статей, которые принадлежат одному автору, найденному в электронной библиотеке eLIBRARY.ru, а также группа статей, которые не были распознаны. Для оценки качества сопоставления проведены эксперименты на данных сотрудников ИСИ СО РАН. В выборку были включены 25 сотрудников института, чьи публикации содержатся в системе link.springer.com. Средний процент числа публикаций авторов, распознанных системой, составил 79, при этом количество публикаций, которые не принадлежат автору, но были отнесены в его группу, близко к нулю. Основной причиной, по которой система не может определить принадлежность статьи ее автору, является неполнота данных. Для улучшения результатов к группе статей, которые не были распознаны, применяется алгоритм подсчета близости и группировки статей, описанный далее. Алгоритм кластеризации статей, не сгруппированных на ранних этапах, заключается в попарном сравнении статей и объединении групп в случае, если коэффициент схожести статей превышает заданный порог. Более формальное описание алгоритма приведено ниже. Пусть множество статей, полученных после сопоставления публикаций из Springer с публикациями из eLIBRARY.ru, где номер группы. При этом группа, где 1 группа публикаций, для которых не было найдено сопоставление. Тогда применяется следующий алгоритм, 1 1, При объединении групп происходит проверка на то, что обе эти группы не были изначально сформированы на этапе сопоставления со статьями из eLIBRARY.ru. В данном случае объединения не происходит, так как эти группы соответствуют статьям различных авторов, указанным в eLIBRARY.ru. Асимптотика данного алгоритма . Для улучшения данной асимптотики была применена структура данных Система непересекающихся множеств 6. С ее помощью асимптотика операции объединения групп уменьшается до 1, следовательно, весь алгоритм имеет асимптотику . Для подсчета близости научных статей из хранилища link.springer.com используются все полученные через API данные, чтобы сократить влияние неполноты данных на результаты идентификации. Сравнение каждого из параметров формирует свой коэффициент, который суммируется в итоговый. Далее, пусть и различные статьи, полученные из хранилища link.springer.com. если название статьи совпадает с названием статьи полностью, без учета разделительных символов, регистра и знаков препинания, то считается, что коэффициент совпадения названий равен максимальному значению 1.0 иначе производится стемминг названий и, и считается коэффициент совпадения названий как доля совпадающих слов в данных названиях. Коэффициент соавторства статей принимается равным доле совпадающих авторов. Для производятся следующие шаги приведение пары имен к одинаковому формату например, если одно имя является полным, а во втором отсутствует отчество автора, то из первого удаляется отчество таким же образом обрабатывается ситуация с сокращениями имен производится сравнение имен с помощью алгоритма сравнения строк. По результату сравнения двух приведенных к одному формату имен авторов не всегда можно сразу сказать, являются ли эти строки ФИО одного и того же человека. Это обусловлено тем, что транслитерации имени одного человека могут достаточно сильно различаться, либо, наоборот, люди могут являться полными тезками. Для того чтобы уменьшить количество ошибок при сравнении, используется полученная информация о местах работы авторов. В случае если место работы совпадает, коэффициент сравнения имен авторов увеличивается, так как более вероятно, что это один и тот же человек. статей подсчитывается аналогично коэффициенту соавторства, т. е. они принимаются равными доле совпадающих терминов. Данный коэффициент является небольшим добавочным коэффициентом и призван улучшить сопоставление документов в соответствии с гипотезой о том, что если между датами публикаций прошло не очень много времени, то вероятность того, что они принадлежат одному автору выше, чем у тех документов, которые были приняты в печать с довольно продолжительным разрывом во времени если между датами публикаций статьи и статьи разница менее 5 лет, то коэффициент принимается равным 0.1 иначе, если между датами публикаций статьи и статьи разница более 25 лет, то коэффициент принимается равным 0.1. Еще один добавочный коэффициент, основанный на эвристике, это если названия журналов статей и совпадают, то коэффициент принимается равным 0.1. Для подсчета коэффициента сходства текстов на естественном языке они представляются в виде векторов в многомерном пространстве. Тогда мера близости между ними определяется как косинусное расстояние. Для улучшения качества сравнения текстов на естественном языке, а также уменьшения размерности векторного представления текстов производится их предобработка 7, в которую входят удаление стоп-слов и стемминг. Для построения векторного представления текстов в ранних работах использовался алгоритм мешка слов bag of words с применением TF-IDF меры 8. TF-IDF статистическая мера, показывающая важность слова в контексте набора документов. Наибольший показатель будет иметь слово, которое часто встречается в документе, но редко встречается во всей коллекции. Также были проведены эксперименты по векторизации текстов на естественном языке с применением инструмента word2vec . Это программный инструмент анализа семантики естественных языков, представляющий собой технологию, которая основана на дистрибутивной семантике и векторном представлении слов. Векторное представление слов основывается на контекстной близости близкие векторы будут иметь слова, имеющие похожий смысл. Векторные репрезентации слов, полученные в результате работы word2vec, обладают следующим свойством смысл имеют только расстояния между векторами, а не сами векторы. При сложении векторов двух слов получается вектор слова, который показывает нечто общее между исходными. Однако увеличение количества слагаемых быстро приводит к потере какого-либо ценного результата, поэтому нельзя описать основную идею документа простой суммой векторов всех слов, которыми представлен текст. Одним из вариантов векторного представления текста является представление, в котором каждый элемент соответствует некоторой тематике. Перечислив достаточное количество возможных тематик текста, можно посчитать количество слов в тексте, соответствующих каждой тематике, и получить семантический вектор текста вектор, каждый элемент которого обозначает отношение данного текста к той или иной тематике. Таким образом, для построения семантического вектора текста необходимо описать достаточное количество кластеров, отражающих тематику и стиль текста. С помощью алгоритма кластеризации все слова разбиваются на заданное число кластеров, и, если количество кластеров будет достаточно большим, можно ожидать, что каждый кластер будет указывать на достаточно узкую тематику текста, а точнее, на узкий признак тематики или стиля. Каждое слово имеет отношение ко многим кластерам к каким-то больше, к каким-то меньше. Поэтому вычисляется семантический вектор слова вектор, зависящий от расстояния от слова до центра соответствующего кластера в полученном векторном пространстве. После этого, для того чтобы получить семантический вектор текста, необходимо сложить все векторы слов, которые составляют текст. Для улучшения результатов необходимо отбросить все слова-шумы, расстояние от которых до центров кластеров не превышает пороговое значение, а также нормировать полученный семантический вектор текста количеством входящих в него слов. Для обучения алгоритма word2vec была использована модель, построенная на части дампа сайта wikipedia.org за 2014 г. Данная модель содержит приблизительно двести тысяч векторных представлений слов. На основании этой модели были произведены кластеризация на 100 кластеров с помощью алгоритма k-means, реализованного в библиотеке Accord.Net, и подсчет векторного представления текстов по описанному выше алгоритму. В качестве выборки для тестирования алгоритмов векторного представления текстов были использованы тексты на естественном языке, полученные при обращении в хранилище link.springer.com по имени Быстров Александр Васильевич. В результате получено 10 документов, 2 из которых не содержали текста, поэтому сравнение было произведено по тем 8 документам, которые имели текст публикации. Ниже представлены матрицы схожести данных текстов, построенные на основании меры TF-IDF и алгоритмов word2vec табл. 1, 2. Матрица смежности, полученная при сравнении текстовых данных TF-IDF мерой 1.0000 0.0101 0.0073 0.0103 0.1167 0.0084 0.0068 0.0100 0.0101 1.0000 0.0162 0.4791 0.0164 0.1977 0.0327 0.2201 0.0073 0.0162 1.0000 0.0157 0.0206 0.0120 0.0252 0.0204 0.0103 0.4791 0.0157 1.0000 0.0373 0.1679 0.0248 0.2957 0.1167 0.0164 0.0206 0.0373 1.0000 0.0113 0.0344 0.0168 0.0084 0.1977 0.0120 0.1679 0.0113 1.0000 0.0205 0.1296 0.0068 0.0327 0.0252 0.0248 0.0344 0.0205 1.0000 0.0262 0.0100 0.2201 0.0204 0.2957 0.0168 0.1296 0.0262 1.0000 Матрица смежности, полученная при сравнении текстовых данных word2vec 1.0000 0.9477 0.9211 0.9426 0.9681 0.9484 0.9448 0.9388 0.9477 1.0000 0.9258 0.9925 0.9613 0.9757 0.9630 0.9768 0.9211 0.9258 1.0000 0.9294 0.9493 0.9216 0.9118 0.9165 0.9426 0.9925 0.9294 1.0000 0.9620 0.9774 0.9633 0.9846 0.9681 0.9613 0.9493 0.9620 1.0000 0.9571 0.9594 0.9534 0.9484 0.9757 0.9216 0.9774 0.9571 1.0000 0.9659 0.9803 0.9448 0.9630 0.9118 0.9633 0.9594 0.9659 1.0000 0.9618 0.9388 0.9768 0.9165 0.9846 0.9534 0.9803 0.9618 1.0000 Как видно из таблиц, результаты, полученные на основании алгоритма word2vec, являются плохо разделимыми. Такое возможно из-за недостаточно точно обученной модели. Для использования более крупных моделей требуется больше вычислительных мощностей и времени, что неприменимо в данной системе, когда эксперту необходимо взаимодействовать с ней и изменять параметры группировки по ходу работы. Добавление в систему модуля кластеризации статей, не распознанных на этапе сравнения с публикациями из eLIBRARY, позволило улучшить результат идентификации авторства статей до 92 . Следует отметить, что получение стопроцентной точности автоматической идентификации представляется маловероятным, при этом экспертный анализ позволяет достичь гораздо более высоких результатов, но отличается высокой трудоемкостью. Таким образом, стоит признать наиболее оптимальным вариант полуавтоматической обработки данных о публикациях с целью установления авторства. При этом необходимо представлять результаты автоматической идентификации в удобном для эксперта формате, чтобы упростить и ускорить процесс экспертного анализа. Количество документов в коллекции, для которых необходимо произвести атрибуцию, может достигать десятков, а то и сотен. Анализировать полученные результаты в виде текстовых данных затруднительно, эксперт может потратить большое количество времени. Поэтому для упрощения понимания результатов и взаимодействия пользователя с системой используется визуализация информации. В разработанной системе пользователю предлагается рассмотрение результатов на различных уровнях. Такая методика применяется во многих системах она позволяет взглянуть на результаты с разных сторон например, на результаты в целом и на внутреннее представление объектов. Это также позволяет производить более тонкую настройку инструмента пользователем, поскольку он может исключить из рассмотрения ненужные признаки или выделить признаки, вносящие наибольший вклад в целевую функцию. В главном меню пользователю предлагается ввести ФИО искомого автора и запустить программу. Также есть возможность просмотреть все генерируемые транслитерации и сокращения для данного имени на русском языке. В текстовом поле отображается текущий статус работы системы, ведется логирование всех действий. Первый уровень визуализация групп объектов по сущности автору. Это позволяет сразу взглянуть на итоговые результаты и внести коррективы. В качестве визуализации предлагается круговая диаграмма, в которой каждая доля показывает выделенную алгоритмом анализа группу рис. 2. Размер долей в круговой диаграмме прямо пропорционален количеству документов из коллекции, которые система определила в данную группу. На этом уровне пользователю предлагается просмотр краткого текстового описания группы документов, которое появляется после нажатия на долю круговой диаграммы. Также доступны тонкие настройки параметров группировки, такие как использование различных параметров в целевой функции и порог целевой функции. При изменении данных параметров система автоматически пересчитывает результаты, что добавляет визуализации интерактивный характер. Также эксперту доступно редактирование полученных результатов. В диалоге рис. 3 можно изменять группы публикаций с помощью переноса статей из одной группы в другую. При нажатии кнопки Показать детальнее открывается следующий уровень визуализации визуализация отдельной группы статей, а при нажатии кнопки Сохранить результаты пользователь может выбрать путь для сохранения данных, а также информации о текущем разбиении. Следующий уровень представления внутреннее представление сформированной группы документов рис. 4. На этом уровне коллекция представлена в виде матрицы смежности документов, попавших в данную группу. Коэффициенты схожести отображены в виде окружностей, радиус которых зависит от веса коэффициента. При нажатии на определенную точку она выделяется красным цветом, появляется текстовое описание пары документов, а также развернутое пояснение полученного коэффициента. В случае если документ был отнесен к данной группе на этапе кросс-языковой идентификации с библиотекой eLIBRARY.ru, окружность изначально имеет зеленый цвет, а информация об авторе, указанном в eLIBRARY.ru, добавляется в краткое текстовое описание. При нажатии кнопки Соавторство открывается очередной уровень визуализации, представляющий соавторов научных публикаций в виде матрицы рис. 5. Данный уровень помогает искать так называемые выбросы в группе такие публикации, которые в действительности не принадлежат данному автору, в отличие от остальных. Например, эксперт точно знает группу ученых, вместе с которыми публиковался данный человек, а значит, может точно определить, что некоторые статьи в этом наборе лишние. Для этого предусмотрено выделение интересующей эксперта статьи, и по нажатию кнопки Убрать из группы текущая статья будет перемещена из группы. Система либо автоматически распределит эту публикацию в другую группу, либо создаст новую группу, содержащую эту статью. Помимо перечисленного, пользователю системы предлагается для изучения распределение научных статей автора по году публикации рис. 6. Оно отображается при нажатии кнопки По годам и также может помочь при поиске научных публикаций, не принадлежащих данному автору. В статье представлена система анализа и визуализации для разрешения неоднозначности авторства англоязычных статей хранилища link.springer.com при помощи сопоставления с русскоязычным источником данных elibrary.ru. Реализованная система генерирует множество вариантов транслитераций имен авторов использует в качестве источника достоверных данных на русском и английском языках электронную библиотеку научных публикаций eLIBRARY.ru на основании извлекаемых метаданных и текста публикации идентифицирует авторов исходной коллекции документов показала результат распознавания 92 протестирована на выборке авторов из ИСИ СО РАН предоставляет интерактивную визуализацию для упрощения интерпретации полученных результатов и анализа коллекции. В дальнейшем планируется добавить дополнительные виды визуализации, помогающие не только искать выбросы в полученных группах, но и точнее настраивать алгоритм кластеризации и анализировать полученные группы, например, изменение тематики с течением времени. Также планируется расширить систему для использования различных англои русскоязычных баз данных, предоставляющих информацию о публикациях. "}
{"title": "MEDILUX – СЕРВИС ИНТЕЛЛЕКТУАЛЬНОГО ФОРМИРОВАНИЯ   РАСПИСАНИЯ ПОСЕЩЕНИЙ МЕДИЦИНСКИХ УЧРЕЖДЕНИЙ", "absract": "Предложен новый вид обслуживания – «интеллектуальная регистратура»: в мобильном приложении обеспечена возможность выбора сотрудников медицинского учреждения, далее происходит анализ графика работы выбранного врача и свободного времени пользователя при помощи алгоритмов программирования в ограничениях  с целью определения наилучшего времени записи на прием. База знаний о свободном времени пользователя формируется на основе задач, которые агрегируются с мобильного устройства и популярных сервисов по управлению задачами. Для случая, если пользователь не знает, к кому обратиться, продукт снабжен «умным» чатом, в котором можно описать проблему. Текст отправится на сервер, где произойдет синтаксический разбор и семантическое сопоставление с конкретной специальностью врача. В базе данных хранится информация обо всех посещениях  и врачебных выписках (электронная медицинская карта), что позволяет, например, напоминать пользователю  о необходимости принятия медикаментов. Практическая ценность продукта заключается в автоматизации бизнес-процесса «прием пациентов», что приводит к экономии времени пациентов, обеспечению высокой доступности услуг и оптимизации трудовых затрат  в медучреждениях. : регистратура, программирование, мобильное, приложение, чат, запись, прием. ", "text": "В настоящее время проблема качества медицинского обслуживания стала предметом внимания властей и средств массовой информации, поскольку уровень развития здравоохранения говорит о развитии государства в целом. Бизнес-процесс прием пациентов является отличным примером, так как пока еще посещение поликлиники требует много усилий и связано с негативными последствиями, такими как 1 жалобы пациентов из-за недоступности медицинской помощи 2 перекрестное инфицирование из-за скопления пациентов в одном месте 3 самолечение и, как следствие, увеличение материальных затрат на лечение пациентов с осложнениями 4 периодические стрессовые ситуации, связанные с работой, у персонала медицинских учреждений 5 падение рейтинга и имиджа, что является существенной проблемой для негосударственных медицинских учреждений. Анализ возможных источников проблемы дал понять, что к вопросу следует подходить с нескольких сторон. Возможные факторы и причины 1 кадровая проблема отсутствие должного количества врачей 2 нежелание врачей работать в государственных медицинских учреждениях 3 отсутствие должного взаимодействия между подразделениями медицинской организации и четких алгоритмов работы каждого подразделения 4 ограничение информированности населения о возможности получения медицинской помощи, несвоевременные обращения, необходимость для пациентов в лишних посещениях запись, чтобы узнать или спросить 5 избыточные временные затраты на оформление медицинских документов, дублирование информации, растущая отчетность. Исходя из перечисленных проблем можно сделать вывод, что не существует универсального решения даже для такого, казалось бы, малого звена в функционировании медицинского учреждения, как бизнес-процесс прием пациентов. Частично помочь пациентам может клиент-серверное решение, где в качестве клиента будет выступать мобильное приложение, предоставляющее пользователям электронную медицинскую карту, электронную регистратуру и электронный чат с врачами. Данное решение не ново, но предлагаемый сервис отличается от прочих тем, что способен удобные дату и время приема как для конечного пользователя, так и для лечащего врача. Помимо этого, в сервисе предлагается интеллектуальный чат, в котором пользователь сможет получить общую информацию или советы в режиме реального вре мени. Таким образом, сервис нацелен на анализ повседневного ритма и рабочего графика с последующей возможностью и в медицинские учреждения. Мобильное приложение будет выступать интеллектуальным звеном-помощником между пациентами и поликлиниками. В работе предложен новый вид обслуживания интеллектуальный прием пациентов в мобильном приложении имеется возможность выбора сотрудников медицинского учреждения, далее происходит анализ графика работы выбранного врача и свободного времени пользователя при помощи алгоритмов программирования в ограничениях с целью определения наилучшего времени записи на прием. База знаний о свободном времени пользователя формируется на основе задач, которые агрегируются с мобильного устройства и популярных сервисов по управлению задачами Trello, Google Tasks, Wunderlist, Apple Reminders и др.. Для случая, если пользователь не знает, к кому обратиться, продукт снабжен умным чатом, в котором можно описать проблему. Текст отправится на сервер, где произойдет синтаксический разбор и семантическое сопоставление с конкретной специальностью врача. В базе данных хранится информация обо всех посещениях и врачебных выписках электронная медицинская карта, что позволяет, к примеру, напоминать пользователю о необходимости принять медикаменты. Практическая ценность продукта заключается в бизнес-процесса прием пациентов, что приводит к времени пациентов, обеспечению услуг и трудовых затрат в медицинских учреждениях. Клиентская часть выполнена нативными средствами на языке Swift 4.0 с использованием среды разработки Xcode. Основной архитектурой для всех модулей приложения взят VIPER View-Interactor-Presenter-Entity-Router. Соблюдены принципы SOLID 1 и SOA, что позволяет в дальнейшем без трудностей расширять функциональные возможности приложения 2. Дизайн выполнен с соблюдением Human Interface Guidelines от компании Apple, что предоставляет пользователям привычный UX-дизайн рис. 1. а б Серверная часть реализована на языке Java 8 с использованием среды разработки IntelliJ IDEA. За архитектурную основу взят стиль REST Representational state transfer в этой архитектуре данные передаются без дополнительных слоев, что делает ее менее ресурсоемкой в сравнении с SOAP или XML-RPC, здесь не нужно анализировать запрос, чтобы понять его природу и транслировать данные из одного формата в другой. В качестве базы данных выбран PostgreSQL 10. Очевидно, что возможных решений вариантов для приема может быть несколько, и здесь мы имеем дело с комбинаторной задачей, которую для удобства можно записать в виде задачи удовлетворения ограничений Constraint satisfaction problem, CSP 3 4. В нашем случае CSP включает в себя 1 variables переменные 2 domains набор возможных значений 3 constraints список ограничений. Правил всего два для каждой переменной мы задаем набор возможных значений переменным могут быть присвоены любые значения, а не только 1 или 0 истина или ложь 5 а также у нас есть список ограничений, которым удовлетворяют исходные переменные. Для нас решением задачи удовлетворения ограничений будет нахождение всех возможных значений, которые могут принимать переменные, с учетом существующих ограничений 6. Термин время для приема следует разбить и рассматривать данную модель, как совокупность дня и конкретного времени. Выделим шесть переменных множество возможных значений времени, когда лечащий врач может принять пациента множество возможных дней для пациента множество общих значений времени, когда запись неосуществима например, ночное время множество значений времени, когда пользователь не может посетить врача множество строится на основе значений времени, указанных в заметках множество дополнительных значений времени, которое определяется на основании рабочего графика, предпочтительного времени и других подобных факторов, выбранных пользователем в мобильном приложении множество вычисляемых переменных-ограничений например, если в заметках указана геолокация мест, то мы можем вычислить время, за которое пользователь доберется от текущего местоположения до цели, тем самым мы получим дополнительные ограничения. Зададим ограничения, которые будем накладывать на переменные, чтобы получить актуальное множество решений, . Программирование в ограничениях подразумевает собой использование декларативной формы программирования, что в отличие от императивного стиля позволяет нам в разы упростить задачу нам нужно лишь описать проблему в общем случае, а всеми вычислениями и поиском решений будет заниматься так называемый решатель Solver, который и содержит эффективные алгоритмы вычислений. К сожалению, исчерпывающих обзоров теории удовлетворения ограничений на русском языке нет, однако имеются публикации, которые освещают отдельные аспекты данной предметной области 8 9. После того как решатель вычислил множество значений времени, которые удовлетворяют нашим условиям и ограничениям 7, мы можем показать это множество пользователю, после чего осуществить запись на прием в медицинское учреждение. Рассмотрим одну из основных функций приложения запись на прием рис. 2. С помо щью функции запись на прием пользователь попадает на экран, на котором расположены 1 текстовое поле что вас беспокоит именно здесь пользователь может описать причину обращения, указать симптомы или другую информацию для врача 2 поле выбора в какой больнице предоставляется список доступных медицинских учреждений, в которые интегрирован данный сервис 3 поле выбора к какому врачу список доступных врачей для выбранной поликли ники 4 поле напомнить заранее при выбранном значении пользователь будет уведомлен о предстоящем визите заранее, посредством push-нотификации на мобильное устройство или почту 5 поле интеллектуальное определение времени приема при невыбранном значении пользователь может самостоятельно связаться с медицинским учреждением и согласовать время приема. Если все-таки пациент выбрал интеллектуальное определение времени, то на сервер отправляются задачи, которые были интегрированы с мобильного устройства и различных сервисов для планирования, а также отправляется множество выбранных пользователем предпочтительных дат для приема. На сервере происходит сопоставление информации, полученной с клиента, с графиком выбранного врача. Далее, на том же сервере, решатель Solver находит решение задачи программирования в ограничениях и отправляет их обратно клиенту, где пользователь может выбрать наиболее подходящий вариант. После выбора информация вновь отправляется на сервер, откуда попадает в медицинское учреждение, уведомляя тем самым врача о новой записи. История с интеллектуальным чатом представляет собой творческую задачу. На данном этапе реализован простой синтаксический разбор текста, с последующим разбиением на лексемы, которые сопоставляются с семантическими командами рис. 3. Подводя итоги, можно сказать, что готовый продукт действительно является интеллектуальным помощником и промежуточным звеном между пациентами и медицинскими учреждениями. Теперь запись на прием становится простой и доступной для абсолютного большинства людей. Разработанный сервис особенно удобен для людей, у которых рабочий день не нормирован им присущ плотный график с частыми форс-мажорными ситуациями, из-за чего данный сегмент зачастую пользуется сервисами-планировщиками, которые, в свою очередь, можно интегрировать с разработанным сервисом Medilux, что приведет к более точному определению наилучшего времени записи на прием. Помимо прочего, интеллектуальный чат в приложении способствует сокращению обращений в поликлиники с целью быстрых вопросов или консультаций теперь можно получить ответы которые согласованы со специалистами на большинство вопросов, не выходя из дома. Электронная медицинская карта с полной историей записей избавляет от бумажной волокиты и позволяет напоминать пользователю о необходимости принять медицинские препараты через push-нотификации на мобильное устройство. Сервис Medilux готов составить конкуренцию уже существующим сервисам в данной области. Разработанный продукт отличается уникальными особенностями, которые имеют векторы для развития, что приведет к более точным результатам определения времени записи на прием и расширению словарного запаса интеллектуального чата. "}
{"title": "РАЗРАБОТКА СЕРВИСА ЗАДАНИЯ СЦЕНАРИЕВ ПРЕДЪЯВЛЕНИЯ СТИМУЛОВ   С ИСПОЛЬЗОВАНИЕМ МОДЕЛЬНО-ОРИЕНТИРОВАННОГО ПОДХОДА   ", "absract": "Современная физиология не может обойтись без методов количественного анализа данных. Необходимым условием для использования математической статистики, анализа сигналов и машинного обучения является на личие должным образом собранных, размеченных и подготовленных данных. С возможностью совместной обра ботки данных, собранных в разных условиях и в рамках разных протоколов экспериментов, появилась потреб ность в наличии структурированной метаинформации. В настоящее время существует множество программных  систем, позволяющих создавать, редактировать и запускать сценарии представления стимулов. Их проблемой  является сложность использования реализованного сценария как в рамках других систем, так и для аннотиро вания данных, полученных экспериментально. Целью работы является разработка сервиса, позволяющего зада вать сценарии представления стимулов с помощью графического интерфейса с возможностью сохранять мета информацию эксперимента в независимом от платформы формате и исполнять в закрытых системах.  В предлагаемом решении используется модельно-ориентированный подход. В основе платформенно-независимой  модели лежит открытый формат эксперимента PsychoPy. Для исполнения полученного сценария используется  платформа Neurobs Presentation. С помощью преобразования общей модели сценария эксперимента в модель  платформы и описания синтаксической структуры предметно-ориентированного языка Presentation автоматически  формируется программный код. Реализация данного подхода может быть расширена для других систем пред ставления стимулов. : модельно-ориентированный подход, кодогенерация, предметно-ориентированный язык, система предъявления стимулов. ", "text": "Количественный анализ данных является важным методом исследований в современной инструментальной физиологии. Высокой прогностической и диагностической значимостью обладают данные биоэлектрической активности головного мозга. Анализ данных количе ственной электроэнцефалографии кЭЭГ является перспективным направлением для приме нения математической обработки. В кЭЭГ используются такие параметры, как амплитуда, мощность, спектр, когерентность внутрии межполушарных взаимодействий и другие ха рактеристики осцилляторной активности головного мозга 1. Регистрация показателей может происходить в состоянии спокойного бодрствования с открытыми или закрытыми гла зами, при выполнении функциональных проб или когнитивных заданий. При создании экс перимента необходимо учитывать такие аспекты, как содержание и структура сценария, взаимодействие и синхронизация с аппаратными компонентами, формат выходных данных. В настоящее время существует ряд программных систем, позволяющих создавать, редак тировать и воспроизводить сценарии предъявления стимулов Cedrus SuperLab, Milli second Software Inquisit, Mitsar Psytask, Neurobs Presentation, Nottingham University PsychoPy, OkazoLab EventIDE, Psychology Software Tools E-Prime и др.. Большинство систем платные и позволяют сохранять сценарий либо в виде программы на собственном языке создания сценариев, либо в закрытом формате. Системы, в которых способом создания сценария является написание программы, обладают широкими возможностями исполне ния, но сложны для изучения и применения. Проблемой платных систем также является ограничение возможностей использования реализованного сценария как в рамках других си стем, так и для аннотирования данных, полученных экспериментально. Целью работы является разработка сервиса, позволяющего задавать сценарии предъявле ния стимулов с помощью графического интерфейса с возможностью сохранять метаинфор мацию о сценарии эксперимента в независимом от платформы формате и исполнять в систе мах с собственным языком описания сценариев. В предлагаемом решении используется модельно-ориентированный подход. В основе платформенно-независимой модели лежит открытый формат эксперимента системы PsychoPy. Для исполнения полученного сценария была выбрана платформа Neurobs Pre sentation. С помощью преобразования платформенно-независимой модели в модель языка Presentation и описания его синтаксической структуры автоматически формируется про граммный код. Реализация данного подхода может быть расширена для исполнения разрабо танного сценария в других системах предъявления стимулов с собственным скриптовым языком. Рассмотрим особенности создания, редактирования и сохранения данных экспериментов для систем задания сценариев предъявления стимулов табл. 1. Создание сценария эксперимента может происходить двумя способами с помощью собственного скриптового языка системы Presentation, Inquisit или с помощью графического интерфейса, функциональность которого иногда дополняют языком общего назначения или его расширением. Язык Inquisit похож на язык разметки и является декларативным. Он представляет собой набор именованных элементов стимулы, тестовые пробы, последовательности стимулов и т. п. и выражений присваивания для их параметров. Кроме констант, списков и ссылок на другие элементы, значениями параметров могут быть выражения арифметические, присваивающие и условные. Таким образом, потенциальная сложность языка может заключаться в описаниях параметров. В языке Presentation выделяются декларативная Scenario Description Language, SDL и процедурная Presentation Control Language, PCL части. Кроме того, в заголовке скрипта Presentation задаются настройки сценария Header. Декларативная часть языка позволяет описать набор элементов эксперимента и их параметров. В процедурной части есть возможность задать порядок предъявления элементов SDL, используя общие конструкции переменные, контейнеры, условия и циклы. Язык для описания сценариев Psytask включает в себя списки стимулов и проб, список предъявления проб и команд, обработку ответной реакции. Набор стимулов ограничен Обзор форматов, используемых основными системами предъявления стимулов Система Лицензия Способ задания сценария Формат сценария выходных данных E-Prime Комм. Графический интерфейс E-Studio, дополнительная функциональность реализуется с помощью языка E-Basic на основе Visual Basic формат для хранения и редактирования в E-Studio формат для исполнения в E-Run Inquisit Комм. Редактор для языка Inquisit текстовый файл скрипта EventIDE Комм. Графический интерфейс есть возможность использования XAML для графических элементов, дополнительная функциональность реализуется с помощью расширения языка C формат EventIDE Presentation Комм. Редактор языка Presentation и графический интерфейс для дополнительных настроек текстовый файл скрипта PsychoPy О. Графический интерфейс PsychoPy Builder редактор Python PsychoPy Coder файл формата XML, соответствующий XSD эксперимента файл программы на Python сериализованный Python объект Psytask Пр. Графический интерфейс загрузка файла сценария текстовый файл скрипта запись в базу данных SuperLab Комм. Графический интерфейс формат SuperLab Особенности систем предъявления стимулов с графическим интерфейсом Система Графическое представление последовательности предъявления Полнота графического интерфейса Универсальность системы E-Prime EventIDE PsychoPy Psytask SuperLab несколькими форматами, порядок показа линейный, без возможности рандомизации, за счет чего язык понятен и хорошо подходит для создания простых сценариев. Более универсаль ные предметно-ориентированные языки Inquisit, Presentation включают в себя понятия раз ных уровней от уровня предметной области функциональная проба до особенностей реализации цвет шрифта. Вместе с особенностями порядка предъявления стимулов рандо мизацией и обработкой реакции исследуемого такие языки будут достаточно сложными для людей, не знакомых с программированием. При создании сценариев с помощью графического интерфейса существующие системы используют формы для задания параметров. Кроме того, некоторые системы используют ви зуальное представление последовательности стимулов в виде потока работ PsychoPy, ориентированного графа EventIDE или древовидной структуры E-Prime . Системы E-Prime и EventIDE расширяют функциональность графического интерфейса с помощью расширений для языков общего назначения Visual Basic и C. Особенности графических систем предъявления стимулов показаны в табл. 2. Под полнотой понимается возможность задания любого реализуемого в системе сценария с помощью графического интерфейса без использования языка программирования. Универсальными названы системы со встроенной рандомизацией и возможностью проектировать нелинейные сценарии Сценарий в платных системах сохраняется в закрытом формате и может исполняться только внутри системы. В случае, когда сценарий является скриптом, его можно редактиро вать как текст. Форматы выходных данных чаще всего представляют собой набор значений delimiter separated values и хорошо подходят только для анализа показателей в рамках одно го исследования. Исполнение реализованного в определенной системе сценария невозможно без ручного переноса информации в другую систему. Различные аспекты сценария оформление стиму лов, настройки последовательности и времени предъявления, аппаратные особенности, фор мат вывода и пр. в большинстве случаев собраны вместе, затрудняя тем самым изучение и применение системы для создания и изменения сценариев. Кроме того, полезная для дальнейшей обработки данных метаинформация о сценарии эксперимента не может быть напрямую получена из закрытого формата эксперимента и из скрипта сценария. Для решения задачи платформенно-независимой разработки сценариев с использованием возможностей существующих систем предъявления стимулов графический интерфейс и функциональность и обеспечением модульной интеграции между ними наиболее целесо образно применить модельно-ориентированный подход 2 3. С архитектурой, управляемой моделями Model Driven Architecture, MDA, связывают стандарт MDA, разрабатываемый консорциумом Object Management Group с 2000 г. Со гласно методологии MDA модели являются главными элементами процесса разработки. Для конструирования программного приложения должна быть построена подробная, формально точная модель, из которой потом может быть автоматически получен исполняемый про граммный код. Под моделью понимается выборочное ограниченное представление некото рой системы, форма и содержание которого могут быть выражены с помощью набора понятий концептов. Для описания модели могут быть использованы различные нотации и форматы. Метамодель определяет абстрактный синтаксис языка моделирования. По стандарту Метаобъектного средства Meta-Object Facility, MOF различают четыре уровня моделирования M0M3. Языком описания верхнего уровня часто является Unified Modeling Language UML . В процессе модельно-ориентированной разработки можно выделить следующие шаги 4 1 создание модели предметной области, независимой от платформы Platform Indepen dent Model, PIM 2 создание модели платформы Platform Specific Model, PSM, которая определяет спе цифику конкретной реализации 3 преобразование PIM PSM, с помощью которой с каждым формальным понятием мо дели предметной области сопоставляется его реализация 4 генерирование необходимых артефактов. К каждому из шагов 13 можно возвращаться, расширяя модель. При этом изменения уже существующих элементов повлекут за собой изменения на следующих стадиях. В настоящее время существуют инструменты для применения стандарта OMG MDA . В работе использовалась свободно распространяемая система Eclipse Modeling Framework EMF 5. Проект EMF представляет собой платформу для моделирования с возможностью генерирования программного кода для создания инструментов и приложений на основе структурированной модели данных. В качестве модели верхнего уровня в EMF используется язык Ecore 6, который похож на UML, но формально не является расширением. Рассмотрим задачу разработки сценариев с точки зрения модельно-ориентированного подхода. На рис. 1 показаны разные уровни моделирования для платформенно-независимых PIM и платформенно-зависимых PSM моделей сценария эксперимента. В качестве модели верх него уровня в обоих случаях выступает Ecore. В терминах Ecore может быть описан физио логический эксперимент и эксперимент, реализованный в системе Presentation, которая вы ступает в качестве платформы. На уровне модели могут находиться сценарии конкретных экспериментов например, GoNoGo Task. В общей модели экземпляром эксперимента может быть его представление в виде потока работ, а в платформенно-зависимой скрипт языка Presentation. В качестве основы для платформенно-независимой модели была использована XML схема эксперимента системы PsychoPy . В соответствии со схемой сохраняются получаемые с помощью PsychoPy Builder эксперименты, при этом она достаточно общая и не содержит информации о деталях реализации. С помощью инструмента EMF была получена Ecore мо дель, соответствующая схеме на рис. 2. Платформенно-зависимая модель языка Presentation создавалась с помощью редактора Ecore моделей. Она содержит понятия языка, соответствующие его синтаксическим конст рукциям. На рис. 2. показаны концепты моделей верхнего уровня для описания структуры скрипта, выраженных с помощью Ecore. Работу системы можно представить в виде преобразований моделей рис. 3 1 получение экземпляра сценария 1 2 представление экземпляра сценария в виде экземпляра Ecore модели 1 2 3 преобразование платформенно-независимой модели к модели платформы Presentation 4 генерирование скрипта для исполнения на Presentation 3 4. Получение экземпляра сценария 1 происходит с помощью графического редактора PsychoPy. Далее, файл сценария в формате XML преобразуется к экземпляру обобщенной модели в формате Ecore с помощью сгенерированного Java кода. Преобразование 2 3 экземпляра обобщенной модели эксперимента в экземпляр модели эксперимента Presentation происходит на уровне M1. Для этого задается трансформация для моделей уровня M2. В предлагаемой реализации используется язык преобразования моделей Epsilon 7. Он выбран в силу того, что позволяет задавать трансформации Ecore-моделей и может запускаться в качестве независимого программного модуля. Трансформация пред ставляет собой набор правил, описывающих соответствие элементов обобщенной модели элементам платформы Presentation. Запуск преобразования начинается с корня XML-доку мента и рекурсивно вызывается для вложенных элементов с помощью механизма ленивого правила 8. Получение исходного кода происходит с помощью инструмента EMFText 9. На основе модели абстрактного синтаксиса и описания конкретного синтаксиса он позволяет получить ANTLR -парсер, кодогенератор и редактор для предметно-ориентированного языка рис. 4. Модель абстрактного синтаксиса представляется в формате Ecore. Модель конкретного син таксиса выражается с помощью файла в формате .cs, содержащего описание токенов, стилей подсветки для редактора и правил грамматики в форме Бэкуса-Науэра, где в качестве слу жебных символов используются элементы модели абстрактного синтаксиса и их атрибуты. Сервис представляет собой консольное приложение, написанное на языке Java и позво ляющее запустить цепочку преобразований исходного экземпляра сценария эксперимента, полученного с помощью интерфейса PsychoPy, в текст скрипта для исполнения на Presentation. На основе модельно-ориентированного подхода разработан сервис задания сценариев предъявления стимулов для физиологических экспериментов. Показана работоспособность данного подхода с помощью преобразования модели эксперимента в модель платформы и описания синтаксической структуры предметно-ориентированного языка Presentation гене рируется программный код. Полученный в результате запуска экземпляр модели сценария эксперимента может быть использован в качестве структурированного источника метадан ных о сценарии эксперимента. Таким образом, была осуществлена интеграция графического интерфейса PsychoPy и функциональных возможностей Presentation с помощью модельно ориентированного подхода. Использованный подход позволил организовать взаимодействие между различными сис темами за счет информации, выраженной в платформенно-независимой модели. Установле но, что для его применения к системам необходима информация о структуре сценария и ста бильность данной структуры для разных версий. Такие условия выполняются для систем с предметно-ориентированным языком создания сценариев. Применение подхода к системам с закрытым форматом не представляется возможным без получения дополнительной инфор мации. В дальнейшем планируется 1 расширение подхода для других систем предъявления стимулов, позволяющих зада вать сценарии с помощью предметно-ориентированного языка 2 реализация обратной трансформации получение экземпляров независимой от платфор мы модели на основе написанных скриптов Presentation, для чего нужно реализовать обрат ную трансформацию PSM PIM 3 добавление нового уровня моделирования для типовых функциональных проб закры тые и открытые глаза, классические протоколы. "}
{"title": "МЕТОДИКА ПОВЫШЕНИЯ ПРОИЗВОДИТЕЛЬНОСТИ   НЕБОЛЬШИХ ИНФОРМАЦИОННЫХ СИСТЕМ   ЗА СЧЕТ ОПТИМАЛЬНОЙ РЕСТРУКТУРИЗАЦИИ ДАННЫХ   НА ОСНОВЕ МНОГОМОДАЛЬНОГО РАСПРЕДЕЛЕНИЯ АТРИБУТОВ ", "absract": "Рассматривается системный подход к повышению производительности небольших информационных систем за счет оптимальной реструктуризации табличных структур данных. Авторами сформулирована задача оптимизации количества информационных блоков, необходимых для выполнения группы запросов на считывание информации, предложена целевая функция и структурные ограничения. Проанализирована невозможность использования грубых методов поиска оптимального решения. Предложена методика многомодального распределения атрибутов в зависимости от частоты появления в группе запросов. Проведен эксперимент, подтверждающий эффективность разработанной методики для небольших информационных систем. : система поддержки принятия решений, оптимизация, структуры данных, базы данных, системный анализ.", "text": "Большинство многопользовательских информационных веб-систем выделяется такими требованиями, как оперативное взаимодействие с пользователем 1. Эффективное исполнение данного требования зависит не только от аппаратной составляющей, включающей в себя серверное оборудование и линии связи, но и от реализации программных компонентов, среди которых программное приложение, реализованное с применением веб-технологий и система управления базой данных СУБД. В статье рассмотрена методика повышения производительности информационной системы, за счет уменьшения среднего времени выполнения группы запросов на чтение информации базы данных. От структуры данных, способах ее физического размещения на жестких дисках зависит количество обращений к дисковым накопителям, которые сопровождаются соответствующими прерываниями и задержками по времени 2. Важным понятием при рассмотрении вопроса физической организации баз данных является понятие блока. Блок это минимальный адресуемый элемент внешней памяти, с помощью которого осуществляется обмен информацией между оперативной и внешней памятью. Запись и чтение блоков осуществляется через буферную часть оперативной памяти. Для организации каждого файла базы данных в зависимости от его размера во внешней памяти выделяется от одного до блоков, где размещаются записи. В одном блоке могут разместиться все записи или в нескольких блоках одна запись, или в одном блоке одна запись. От этого будет зависеть время считывания и записи элементов файла. Записи в блоках размещаются плотно, без промежутков, последовательно. В блоке часть памяти отводится под служебную информацию относительный адрес свободных участков памяти, указатели на следующий блок и т. д. Для хранения поступающих данных, которые должны размещаться в одном блоке, заполненном уже полностью, выделяется дополнительный блок памяти в области переполнения записи, организованной в виде одного блока, где записи связываются указателями в одну цепь. Таким образом, на скорость поиска влияют объем блока в байтах, объем файла, количество записей в блоке файла, количество записей в блоке индекса, количество блоков в файле, доля резервной части блока, число полей в записи, размер записи в байтах 2. Процесс построения оптимальной модели данных информационной системы включает оптимальное вертикальное распределение таблиц базы данных по блокам на дисковом накопителе. Основным критерием оптимизации модели данных информационной системы является минимальный размер строки таблицы реляционной базы данных, позволяющий в одном блоке хранить больше данных и, как следствие, минимизировать количество операций чтения блоков данных с жесткого диска при выполнении запросов к базе данных. Это достигается за счет уменьшения объема данных, побочно участвующих в запросе 3. В рамках методики предлагается разделить таблицы базы данных на несколько сущностей, связанных отношением один к одному. В соответствии с принципами блочного хранения данных в СУБД каждая таблица будет храниться в отдельном наборе блоков. При выполнении запроса на чтение информации СУБД считывает блоки данных с жесткого диска в оперативную память каждой таблицы, атрибуты которой участвуют в запросе. Задача повышения производительности информационной системы сводится к поиску оптимального разделения табличных структур базы данных с учетом конкретной группы запросов на чтение информации, выявленной статистически в рамках жизненного цикла БД 4. Для формализации задачи рассмотрим множества и параметры, влияющие на скорость обработки запросов на чтение информации к исследуемой таблице базы данных. 1. Целочисленный параметр, равный количеству атрибутов в исследуемой таблице. 2. Вектор типов данных 1, которые поддерживаются конкретной выбранной СУБД. Элемент вектора занимаемый элементом типа размер данных в байтах памяти. 3. Набор атрибутов столбцов таблицы, который задан бинарной матрицей, элемент которой равен единице, если столбец таблицы имеет тип, 1,..., 1,..., . 4. Множество, представляющее группу запросов 1, на чтение информации из таблицы базы данных, элемент множества кортеж из двух элементов, где числовой параметр, равный частоте появления запроса за выбранный период времени, 1, бинарный вектор, размерность которого равна количеству атрибутов таблицы . 1, если атрибут таблицы участвует в запросе, и 0 в противном случае. количество запросов в статистической выборке, выявленной в рамках жизненного цикла БД. 5. Множество индексов, характеризующихся набором полей таблицы, по которым построен индекс 1, . Элемент множества 1, бинарный вектор, размерность которого равна количеству атрибутов таблицы, 1, если атрибут таблицы участвует в индексе, и 0 в противном случае. 6. Хранимые процедуры и функции 1, характеризующиеся набором полей, используемых в теле хранимой процедуры или функции. Элемент множества 1, бинарный вектор, размерность которого равна количеству атрибутов таблицы, 1, если атрибут таблицы участвует в теле хранимой процедуры или функции, и 0 в противном случае. 7. Множество триггеров базы данных 1, характеризующихся набором полей таблицы, используемых в теле триггера. Элемент множества 1, бинарный вектор, размерность которого равна количеству атрибутов таблицы, 1, если атрибут таблицы участвует в теле триггера, и 0 в противном случае., Множество запросов к рассматриваемой таблице обрабатывается СУБД за время, . Временные затраты, можно представить в виде суммы временных затрат на чтение блоков данных таблиц, участвующих в запросах, и остальных временных затрат, к которым относятся временные затраты на выполнение плана обработки запроса, на передачу информации и т. д., . В рамках методики предлагается уменьшить слагаемое, влияющее на общее время выполнения запроса, . Временные затраты, в общем виде зависят от количества операций чтения блоков данных таблиц с жесткого диска. Пусть временная задержка, связанная со считыванием одного блока данных равна, тогда, где, число информационных блоков, которые необходимо считать с жесткого диска в кэш СУБД для дальнейшего выполнения запроса к таблице, заданной бинарной матрицей . Кэш СУБД находится в оперативной памяти вычислительного устройства. Функция, вычисляется как отношение, где количество строк в рассматриваемой таблице фиксированный размер блока данных выбранной СУБД в большинстве СУБД он равен 8Кб, величина, характеризующая дисковое пространство, занимаемое одной строкой таблицы в байтах, . Здесь, количество памяти, занимаемое служебными отметками СУБД для строки, считываемое при выполнении запроса, количество памяти, занимаемое атрибутами таблицы в строке, считываемое при выполнении запроса . Параметры и остаются неизменными. Так как временную задержку, связанную со считыванием одного блока данных, допускается считать постоянной величиной, на сумму временных затрат на чтение блоков данных таблицы, влияет количество блоков, необходимое для считывания, которое вычисляется как функция, . Подставим в формулу, формулу функции, . Функция, определяющая количество блоков, необходимых для считывания с жесткого диска в оперативную память при выполнении множества запросов к рассматриваемой таблице, ., В рамках методики предлагается разделить рассматриваемую таблицу на 1 дочерних таблиц, связанных с родительской отношением один к одному, 11. Введем следующую переменную 1, если-йатрибутнужновыделитьв-ютаблицу, 0 впротивномслучае. Переменные представляют собой бинарную матрицу для таблицы реляционной базы данных размерностью, где количество атрибутов таблицы. Строки матрицы соответствуют таблицам, на которые разбивается родительская таблица, а столбцы соответствуют их атрибутам. Количество блоков, которое необходимо считать с жесткого диска для выполнения множества запросов к таблице, вычисляется как функция, равная сумме блоков, которые необходимо считать с жесткого диска для выполнения множества запросов к каждой из дочерних таблиц. Максимальное количество дочерних таблиц равно числу атрибутов родительской таблицы и равно ., где, если 0, 0 впротивномслучае. 1,..., 1,..., 1,..., . Параметры и являются постоянными, функция, характеризующая количество информации, которая занимает одну строку дочерней таблицы в байтах, функция, характеризующая дисковое пространство, занимаемое служебными отметками СУБД в строке дочерней таблицы в байтах. Следовательно, задача повышения производительности системы сводится к поиску такого разделения таблицы на дочерние, при котором сумма блоков, которые необходимо считать в кэш СУБД для выполнения множества запросов, минимально. Целевая функция, min, где, если 0, 0 впротивномслучае. 1,..., 1,..., 1,..., . При структурных ограничениях 1 каждый атрибут родительской таблицы может присутствовать только в одной дочерней таблице 1, 1,..., 1,..., 2 атрибуты таблицы, используемые при построении индексов, должны принадлежать хотя бы одной дочерней таблице, 1,..., 0, 1,..., 1,..., 3 атрибуты таблицы, используемые в теле хранимых процедур или функций, должны принадлежать хотя бы одной дочерней таблице, 1,..., 0, 1,..., 1,..., 4 атрибуты таблицы, используемые в работе триггеров исследуемой таблицы, должны принадлежать хотя бы одной дочерней таблице, 1,..., 0, 1,..., 1,..., 5 отношение количества физических блоков данных, необходимого для хранения данных рассматриваемой таблицы до применения методики, к количеству блоков, необходимому для хранения данных в дочерних таблицах, полученных после применения методики, не должно превышать заданного параметра 01 Целевая функция не линейна, а также не линейны ограничения. Переменная бинарная матрица размерностью . Представим переменную в виде машинного слова длиной . Следовательно, количество возможных комбинаций переменной определяется как 2 . Исходя из этого задача обладает экспоненциальной сложностью и является трудной 5 6. Для решения задачи разработана методика, основанная на многомодальном распределении атрибутов исследуемой таблицы по критерию появления их в группе запросов на чтение информации. Для получения оптимального разбиения исследуемой таблицы с числом атрибутов, равным, необходимо выполнить следующие действия. 1. Получить для каждого атрибута значение частоты его появления в группе запросов к базе данных. Вектор частот появлений атрибутов исследуемой таблицы в группе запро сов, где 1, 1,..., . 2. Отсортировать атрибуты по частоте их появления в группе запросов 1, . 3. Сформировать группы атрибутов с одинаковой частотой. Получим разбиение конечного множества .,..., в котором ..., 1, где, если, 1, 1, . 4. Получить разбиение множества групп атрибутов. Получим разбиение конечного множества .,..., в котором ..., 1, где, 1, 1 . коэффициент, характеризующий количество разбиений множества групп атрибутов, 1, . Варьируя параметр 1, мы можем получать решения, эффективность которых оценивается при помощи выведенной в рамках исследования целевой функции. Для анализа эффективности полученной методики были выделены исходные данные и базовые множества. 1. Параметр 16, характеризующий количество столбцов в таблице пп Наименование столбца Тип данных СУБД 1 Id bigint 2 Attr1 nchar10 3 Attr2 nchar10 4 Attr3 nchar10 5 Attr4 nchar10 6 Attr5 nchar10 7 Attr6 nchar10 8 Attr7 nchar10 9 Attr8 nchar10 10 Attr9 nchar10 11 Attr10 nchar10 12 Attr11 nchar10 13 Attr12 nchar10 14 Attr13 nchar10 15 Attr14 nchar10 16 KeyForSearch nchar10 2. Множество типов данных, которые поддерживаются конкретной выбранной СУБД MS SQL 2012. Задано вектором, характеризующим занимаемое типом данных дисковое пространство в байтах, 4, 8, 20 количество типов данных СУБД уменьшено для компактности. Множество типов данных СУБД MS SQL 2012 может быть представлено в виде таблицы пп Наименование типа данных Занимаемое дисковое пространство, байты 1 int 4 2 bigint 8 3 nchar10 20 3. Набор атрибутов столбцов таблицы 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 4. Множество, представляющее группу запросов на получение информации из базы данных, состоящее из 3 элементов пп Количество запросов, поступивших на сервер за выбранный период времени Бинарный вектор атрибутов, участвующих в запросе 1 10 0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,1 2 20 1,1,1,1,1,1,0,0,1,1,0,1,1,1,0,1 3 5 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1 Для проведения эксперимента были исключены ограничения в виде индексов, триггеров и хранимых процедур, а также был исключен коэффициент дополнительного использования памяти. Это позволило продемонстрировать преимущества предлагаемой методики над традиционным подходом. В результате применения методики было предложено разделить исследуемую таблицу на четыре дочерних таблицы A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 A11 A12 A13 A14 A15 A16 T1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 T2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 T3 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 T4 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 Полученное решение было проверено статистически на всей группе запросов. Для повышения достоверности экспериментов были выполнены все 35 запросов на чтение информации. Это позволило получить сведения о запросах, которые после применения методики стали выполняться быстрее, а также выделить подмножество медленных запросов. Результаты экспериментов, а также суммарное время выполнения группы запросов представлены в виде таблицы Количество строк в исследуемой таблице Время выполнения группы запросов к исследуемой таблице, мс Время выполнения группы запросов к таблицам после разделения на дочерние, мс 300 000 28 312 23 021 600 000 59 521 48 271 1 200 000 130 485 107 363 2 400 000 311 223 279 491 Эффективность применения методики представлена на рисунке. а б В результате проведенного исследования была сформулирована проблема повышения производительности информационной системы за счет реструктуризации табличных структур данных. Получено ее описание в теоретико-множественном представлении. Сформулированы целевая функция и ограничения. Предложен подход к нахождению субоптимального разбиения исследуемой табличной структуры на дочерние путем многомодального распределения атрибутов по частоте их появлений в запросах на чтение информации. Предложенная методика особенно актуальна для таблиц БД, которые используют небольшие информационные системы. Полученные результаты могут быть использованы при проектировании отечественных СУБД. Дальнейшие исследования в этой области связаны с разработкой методик оптимальной реорганизации табличных структур данных для крупных информационных систем. Открытая апробация методики реализуется в виде веб-системы, в которой любой исследователь может ввести сведения о своей БД и получить рекомендуемое оптимальное разделение таблиц. "}
{"title": "РАЗРАБОТКА ЯДРА ОНТОЛОГИЧЕСКОЙ МОДЕЛИ,   НАСТРАИВАЕМОЙ ПОД ПРЕДМЕТНУЮ ОБЛАСТЬ  ", "absract": "Статья посвящена разработке ядра онтологической модели в виде программной системы, настраиваемой под конкретную предметную область. Работа основана на теоретико-модельном подходе к представлению знаний. Для представления знаний используются фрагменты атомарных диаграмм алгебраических систем и нечеткие модели. Программная система разбита на модули. Базовые модули реализуют функциональность, необходимую для любой онтологической модели. Например, проверку на непротиворечивость хранящихся знаний. Расширение функциональности происходит через создание новых модулей и их добавление в систему. В работе приведен обзор существующих программных решений в области разработки онтологий и онтологических моделей. Описана структура ядра онтологической модели, приведена архитектура программного решения. ", "text": " При создании современных систем поддержки принятия решений возникает задача моделирования реальности. Часто в качестве инструмента для моделирования используются онтологические модели. Создание для каждой новой предметной области онтологической модели является трудоемкой задачей. В данной работе описывается разработка ядра онтологической модели, настраиваемой под конкретную предметную область. Ядро онтологической модели состоит из семи модулей базы знаний, модуля сбора информации, модуля обработки информации, модуля визуализации, модуля аналитической обработки, модуля порождения новых знаний и модуля конвертации. Современным интеллектуальным системам для работы необходима некоторая формализация реального мира. Одним из видов такой формализации является построение онтологической модели. Прежде чем перейти к онтологической модели следует остановиться на понятии онтологии. В инженерии знаний под онтологией понимают общее описание основных понятий предметной области и того, как они между собой связаны. Для более конкретного описания предметной области используется онтологическая модель. Она содержит информацию об отдельных объектах, событиях и процессах предметной области. Вся информация записывается в терминах, заданных онтологией 1. Среди отечественных исследований, посвященных онтологическому моделированию, можно выделить следующие работы. Коллективом под руководством Д. Е. Пальчунова была разработана программная система Diagnostic Panel 2, предназначенная для помощи врачам в постановке диагноза и составлении плана лечения пациента. В основе Diagnostic Panel лежит онтологическая модель предметной области Деформации позвоночника и дегенеративные заболевания позвоночника. Представление знаний, извлеченных из текстов естественного языка, осуществлено на основе прецедентного подхода. Прецедентный подход, в свою очередь, основан на теоретико-модельных методах формализации предметных областей. Знания, представленные в системе, обрабатываются с использованием методов анализа формальных понятий. В работах 35 коллектив под руководством А. С. Клещева предложил подход к формализации медицинских предметных областей при помощи онтологий. В рамках данного подхода решение предполагаемый диагноз представлено в виде набора истинных гипотез и соответствующих причинно-следственных связей, описывающих все наблюдаемые признаки. На основе исследования была разработана онтология общей медицинской диагностики, онтология офтальмологии, база знаний заболеваний и лекарственных средств 68. В настоящее время много работ публикуется на тему совместного применения логического вывода и онтологий. В работе 9 описана программная система, помогающая экспертам предметной области в поиске противоречий в онтологии. В основе разработанной программной системы лежит машина логического вывода. В 10 было проведено исследование на тему использования логического вывода и онтологий для решения задач кризисного управления и реагирования. В представленной программной системе для построения цепочек рассуждений использовалась машина логического вывода и онтология на языке OWL DL. В работе 11 логический вывод применяется для нахождения смысловых ошибок в документах сети Интернет. В исследовании 12 машина логического вывода применяется для проверки согласованности онтологической модели. Для разработки ядра онтологической модели был выбран теоретико-модельный подход к представлению знаний, в частности 4-уровневая структура представления знаний 1315. В выбранном подходе знания представляются в виде четырех уровней 1 онтология 2 общие знания 3 прецеденты 4 вероятностные знания. Данный подход позволяет, в первую очередь, интегрировать знания, извлеченные из разных источников с различным уровнем достоверности и авторитетности и, во-вторых, при порождении новых знаний использовать всю информацию, от единичных фактов до знаний о связях между понятиями предметной области. Более подробное описание использования теоретико-модельного подхода к построению онтологических моделей содержится в работах 13 14. В статьях рассматриваются проблемы представления знаний, разработки методов интеграции знаний, извлеченных из разных источников, и порождения новых знаний. Решение было представлено на примере построения онтологической модели предметной области Деформации позвоночника и дегенеративные заболевания позвоночника на основе интеграции знаний, представленных в различных медицинских документах Международной классификации болезней, справочниках по лекарствам, нормативных документах Минздрава, монографиях и статьях по данной области медицины, историях болезней пациентов. В статье 16 представлен теоретико-модельный подход к извлечению знаний из текстов естественного языка, а именно знаний о смысле ключевых понятий заданной предметной области. Для этого используются разработанные ранее методы представления знаний, извлеченных из текстов, в виде набора конечных фрагментов атомарных диаграмм алгебраических систем, методы интеграции атомарных диаграмм и порождения таким способом нового онтологического знания, ранее в явном виде не сформулированного. В работе 17 рассматривается задача нахождения ассоциативных правил с использованием теоретико-модельных методов, анализа формальных понятий, аксиоматизируемых классов, создания онтологической модели. Предложена концепция ядра онтологической модели в виде программной системы, настраиваемой под конкретную предметную область. При создании программной системы используется модульный подход вся функциональность модели разделена на модули для каждого модуля описан интерфейс, который он должен реализовывать расширение функциональности происходит путем добавления нового модуля к системе. Данный подход позволяет разработать набор базовых модулей, применимых в любой онтологической модели независимо от предметной области. Функциональная расширяемость через добавление новых модулей позволяет адаптировать ядро онтологической модели к конкретной предметной области. Программная система состоит из семи модулей 1 база знаний 2 модуль сбора информации 3 модуль обработки информации 4 модуль визуализации 5 модуль аналитической обработки 6 модуль порождения новых знаний 7 модуль конвертации. Реализация модулей 57 планируется в дальнейшем. Модуль База знаний представляет собой 4-уровневую онтологическую модель и хранилище источников. Вся информация перед добавлением в онтологическую модель помещается в хранилище источников. После каждого извлечения и добавления знаний в онтологическую модель исходный источник копируется в хранилище, сохраняются данные о его достоверности и новизне. Для формализации знаний в онтологической модели был выбран язык логики описания DL, в частности фрагмент логики SROIQ логика ALCI, не содержащая символа импликации, иерархии ролей и ограничений мощности. В программной системе модель представлена в виде файлов в формате OWL 2. Хранилище источников представлено в виде таблицы реляционной базы данных в качестве базы данных использовалась PostgreSQL. В таблице хранится следующая информация об источнике file ссылка на файл source url адрес источника sourcetype вид источника полуструктурированный сайт owl файл rdf файл xml файл format формат текст owl rdf xml, knowledgetype знания какого вида можно извлечь из источника онтологические общие знания прецеденты status состояние источника загружен обработан источник обновился, но не загружен updateperiod период обновления файла updatedat дата последнего обновления файла. В различных задачах инженерии знаний часто возникает ситуация, когда предметная область представлена текстами естественного языка. Такая ситуация часто встречается в бизнес-анализе, при организации поиска информации, извлечении знаний из Интернета, определении точного смысла предложений, описании контекста и т. д. Сначала мы имеем текст естественного языка, описывающий данную предметную область. На основе этого текста мы получаем теорию предметной области. Согласно теории предметной области мы строим модель предметной области. Модуль сбора информации и модуль обработки информации предназначены для выполнения данной задачи в полуавтоматическом режиме. Модуль сбора информации предназначен для наполнения хранилища источников неструктурированной и структурированной информацией из внешних источников. Модуль выполняет следующие функции сбор текстовых и медийных данных из Интернета сайты социальные сети подключение к сторонним базам данных Подключение к сторонним онтологиям в формате owl, rdf сбор данных из внутренних информационных систем сбор информации, полученной от пользователя, путем ручного ввода. Здесь содержатся подключаемые подмодули для извлечения знаний из хранилища источников и их добавления в онтологическую модель. Для каждого из источников следует реализовать свой подмодуль. Все подмодули имеют единый интерфейс. Для текстов на естественном языке существует в виде подмодуля алгоритм обработки естественного языка. Данный модуль предназначен для визуализации для пользователя знаний из онтологической модели. В частности, в виде графа, таблицы, отчета. Визуализация в виде графа представлена средствами редактора Protg. Модуль аналитической обработки предназначен для хранения онтологической модели в согласованном и непротиворечивом состоянии. Модуль реализует следующие функции логический вывод проверка на непротиворечивость Данный модуль предназначен для порождения новых вероятностных и оценочных знаний. Работа содержащихся в этом модуле алгоритмов основана на интеграции уже имеющихся знаний, представленных в онтологической модели. Реализует модуль следующие функции кластеризация знаний классификация знаний выявление зависимостей поиск закономерностей. С помощью алгоритмов, содержащихся в данном модуле, можно переводить формулы логики описания, описывающие онтологические знания, в формулы логики предикатов конвертировать OWL-файлы в формат RDF. В системе представлены следующие виды конвертации из OWL в RDF из RDF в OWL из OWL в Логику описания из Логики описания в OWL из Логики предикатов в Логику описания из Логики описания в Логику предикатов из OWL в Логику предикатов из Логики предикатов в OWL. В работе был предложен подход к разработке ядра онтологической модели в виде программной системы, настраиваемой под конкретную предметную область. Было проведено исследование основных методов и способов создания онтологических моделей. На основе исследования в качестве основного подхода разработки был выбран теоретико-модельный подход. Программная система разбита на функциональные модули. Каждый модуль решает одну поставленную задачу. С помощью добавления новых модулей можно расширять функциональность программной системы. Базовые модули позволяют решать задачи общие для всех предметных областей проверка на непротиворечивость, логический вывод новых знаний из существующих, классификация и кластеризация данных. В дальнейшем планируется 1 завершить реализацию модуля аналитической обработки, модуля порождения новых знаний и модуля конвертации 2 к базовым модулям добавить модуль преобразования текстов естественного языка во фрагменты атомарных диаграмм и модуль пополнения базы знаний при помощи запросов к поисковым системам. "}
{"title": "ПОДХОД К ПОСТРОЕНИЮ РАСШИРЕННЫХ   ТЕМАТИЧЕСКИХ МОДЕЛЕЙ ТЕКСТОВ НА РУССКОМ ЯЗЫКЕ ", "absract": "Представлен новый подход для получения расширенных тематических моделей текстов научных статей  на русском языке. Такие модели лучше интерпретируются пользователями и точнее описывают предметную область документа, чем модели, состоящие только из униграмм (отдельных слов). На основе предложенного подхода была разработана система, в результате работы которой для каждого документа предоставляется набор содержащихся в нем тем с указанными вероятностями, ключевыми словами и фразами для каждой темы. Предложенный в статье подход может быть полезен при построении рекомендательных систем и систем автореферирования. : тематические модели, обработка текста, извлечение ключевых слов, извлечение многословных терминов, определение темы текста. ", "text": "В современном мире непрерывно производятся огромные объемы электронной информации. Значительную ее часть составляют тексты на естественном языке. В связи с этим становится все более актуальной задача автоматической обработки таких текстов с целью извлечения из них структурированных данных, пригодных для дальнейшего использования в машинном анализе. Одним из современных инструментов обработки естественного языка являются тематические модели. Тематическое моделирование заключается в построении модели некоторой коллекции текстовых документов. В такой модели каждая тема представляется дискретным распределением вероятностей слов, а документы дискретным распределением вероятностей тем 1. Следует обратить внимание на то, что нельзя смешивать понятия тематического моделирования и тематической классификации. Основное отличие состоит в том, что при определении тем текстов отсутствует какая-либо информация о темах неизвестно ни их количество, ни их содержание что подразумевается под каждой темой. Для классификации же необходимы априорные знания о структуре классов. В этом смысле процесс тематического моделирования больше похож на кластеризацию, чем на классификацию. Однако ни классификация, ни кластеризация не справляются с синонимией и полисемией, в отличие от тематического моделирования. А, как известно, важнейшим препятствием при создании систем автоматической обработки текстов является лексическая неоднозначность. Так, в тематической модели слова, являющиеся синонимами, с большой вероятностью попадут в одну и ту же тему, так как зачастую они используются в одинаковом контексте. В то же время омонимы слова одинаковые по написанию, но имеющие разное значение с большой вероятностью будут отнесены к разным темам, так как обычно контексты их использования не совпадают. В данной статье описан новый подход для получения расширенных тематических моделей текстов научных статей на русском языке. Под расширенной моделью здесь понимается тематическая модель, содержащая помимо однословных терминов термины, состоящие из нескольких слов также называемые многословными терминами или ключевыми фразами. Такие модели лучше интерпретируются пользователем и точнее описывают предметную область документа, чем модели, состоящие только из униграмм отдельных слов. Тематическое моделирование построение тематической модели некоторой коллекции текстовых документов. Тематическая модель представляет собой описание коллекции с помощью тематик, использующихся в документах этой коллекции, и определяет слова, относящиеся к каждой из тематик 1. Вероятностная тематическая модель представляет каждую тему как дискретное распределение на множестве слов, а документ как дискретное распределение на множестве тем 2. Одной из разновидностей тематических моделей являются тематические модели, выявляющие ключевые фразы термины предметной области. Под ключевой фразой в данной работе подразумевается устойчивая последовательность слов -грамма, имеющая определенную семантику в контексте заданной предметной области, относящаяся к одной из выявленных в тексте тем и обладающая значительной частотой встречаемости по сравнению с другими -граммами. Пусть задана некоторая коллекция документов, тогда множество всех встречающихся в данной коллекции терминов слов или -грамм. Каждый документ представляется в виде последовательности терминов,..., длиной, при этом каждый термин может встретиться в документе несколько раз. Предполагается, что существует некоторое множество тем, причем каждое вхождение термина связано с некоторой темой . Коллекция документов рассматривается как множество троек, выбранных случайно и независимо из дискретного распределения, заданного на конечном множестве . При этом документы и термины являются наблюдаемыми переменными, а тема скрытой переменной. Гипотеза о том, что элементы выборки независимы, эквивалентна предположению мешка слов порядок слов в тексте документа не имеет значения, и тематику можно выявить даже при произвольной перестановке терминов в тексте. В этом случае каждый документ можно представить как подмножество, в котором в соответствие с каждым элементом поставлено количество вхождений термина в документ . Согласно определению условной вероятности, формуле полной вероятности и гипотезе условной независимости . Тогда задача построения тематической коллекции документов заключается в нахождении для известной коллекции множества всех использующихся в ней тем, а также для каждого по распределению слов по документам восстановить распределения тем в документе и слов по темам . В настоящее время тематические модели находят применение в самых различных областях. К примеру, в 3 авторы используют тематическое моделирование с помощью алгоритма Latent Dirichlet Allocation LDA на отзывах пользователей для создания персонализированных медицинских рекомендаций. В работе 4 авторы используют тематическую модель, включающую в себя авторов, тексты и цитирования, для библиографического анализа. Также тематическое моделирование применяется в обучении в работе 5 авторы предлагают использовать тематическое моделирование для упрощения оценки учителем письменных работ учеников. Помимо этого, тематическое моделирование применяется для анализа данных социальных сетей 68, для многоязычного информационного поиска 9, выявления трендов в новостных потоках или научных публикациях 10, для автоматического присвоения тегов веб-страницам 11, в рекомендательных системах, учитывающих контекст 12, в анализе террористической активности в сети Интернет 13 и мн. др. Современные требования к тематическим моделям довольно разнообразны. Основное из них заключается в том, что тематические модели должны хорошо поддаваться интерпретации, конечному пользователю должны быть понятны причины выделения определенных тем в тексте и структура самих тем. Эта особенность является главным преимуществом тематических моделей перед набирающими популярность нейронными сетями. Кроме того, часто требуется, чтобы тематические модели учитывали разнородные данные, выявляли динамику тем во времени, автоматически разделяли темы на подтемы, использовали не только отдельные ключевые слова, но и многословные термины и т. д. Основными подходами к тематическому моделированию являются алгоритмы PLSA Probabilistic Latent Semantic Analysis, вероятностный латентный семантический анализ, LDA Latent Dirichlet Allocation, латентное размещение Дирихле и библиотека ARTM Additive Regularization for Topic Modeling, аддитивная регуляризация тематических моделей. PLSA вероятностная тематическая модель представления текста на естественном языке. Модель называется латентной, так как предполагает введение скрытого латентного параметра, являющегося темой. Впервые описана Томасом Хофманном в 1999 г. 14. LDA модель, позволяющая объяснять результаты наблюдений с помощью неявных групп, благодаря чему возможно выявление причин сходства некоторых частей данных. Например, если наблюдениями являются слова, собранные в документы, утверждается, что каждый документ представляет собой смесь небольшого количества тем и появление каждого слова связано с одной из тем документа 15. ARTM является обобщением большого числа алгоритмов тематического моделирования, позволяет комбинировать регуляризаторы, тем самым комбинируя тематические модели. При таком подходе PLSA представляет собой тематическую модель без регуляризаторов, а LDA тематическую модель, в которой каждая тема сглажена одним и тем же регуляризатором Дирихле. Модель ARTM в предложена 2014 г. 16. В настоящее время ARTM приобретает все большую популярность благодаря своей универсальности и гибкости настройки параметров моделей. Как уже говорилось, основным требованием к тематическим моделям является их интерпретируемость. При этом в большинстве алгоритмов тематического моделирования в качестве терминов используются только слова, а не -граммы. В то же время для человека использование ключевых фраз для обозначения тем может упростить интерпретацию выявленной темы и разрешить возможную неоднозначность. При этом стоит заметить, что в русском языке задача извлечения ключевых фраз является гораздо более сложной, чем, например, в английском. Это связано с тем, что русский язык флективный, т. е. каждое слово в речи может быть представлено множеством различных словоформ. Обычные алгоритмы извлечения ключевых фраз, основанные на относительной частоте встречаемости -грамм в документах, показывают низкий уровень точности извлечения. Каждую словоформу такие алгоритмы воспринимают как различные термины, и из-за этого частота встречаемости снижается в несколько раз. Существует несколько основных подходов к решению данной проблемы. Во-первых, для распознавания словоформ можно использовать словари, содержащие все возможные формы слова 17. Очевидно, что в этом случае точность определения будет высокой для имеющихся в словаре слов. Однако очевидно, что применимость словарных алгоритмов ограничена предметной областью словаря. Другой подход к этой задаче использование лексико-синтаксических шаблонов 18 19. В 18 описана стратегия распознавания в заданном тексте фрагментов, соответствующих заданному лексико-синтаксическому шаблону, предложен язык записи шаблонов, позволяющий задавать лексические и грамматические свойства входящих в него элементов. В статье 19 приводится описание системы с возможностью ручной настройки видов шаблонов для извлечения словосочетаний с помощью набора морфологических признаков. К сожалению, основными недостатками методов, основанных на шаблонах, является их большая трудоемкость. Проблему многословных терминов можно обойти, если использовать стемминг нахождение основы слова или лемматизацию приведение слова к его начальной форме. Однако тогда возникает проблема с восстановлением изначальных словосочетаний так, биграмма будет после стемминга выглядеть как тематическ моделировании, а после лемматизации как тематический моделирование. Очевидно, такие биграммы не могут быть использованы в качестве ключевых фраз в научной статье или на веб-странице, и для дальнейшего использования нужно преобразовать их в изначальное словосочетание. Для решения проблемы согласования словосочетаний применялись лексико-синтаксиче ские шаблоны. Исследование многословных ключевых терминов, выбранных для статей авторами, позволило составить базовый набор шаблонов. Мы не можем утверждать, что этот набор является полным, так как для составления полного набора шаблонов понадобилось бы привлечь экспертов-лингвистов с целью проведения дополнительного исследования. По этой причине вопрос о полноте набора шаблонов терминов пока остается открытым. Однако предусмотрено возможное расширение набора шаблонов, и в случае увеличения их количества потребуются лишь минимальные изменения в модуле согласования словосочетаний. Выделенные шаблоны удобно записать при помощи логики предикатов первого порядка. Рассмотрим словарь множество слов коллекции документов. Пусть,...,..., множество прилагательных из,...,..., множество существительных из . Для морфологических признаков введем следующие обозначения, содержит информацию о категории рода мужской, женский, средний, о категории числа единственное, множественное, о категории падежа именительный, родительный, дательный, винительный, творительный, предложный. Далее введем четырехместные предикаты, для прилагательных и, для существительных. Теперь шаблоны многословных терминов можно записать в виде формул исчисления предикатов, т. е. в случае согласованных словосочетаний будут истинны следующие шаблоны. 1., . Например, линейное уравнение. 2., . Например, разработка системы. 3., . Например, гипотеза условной независимости. 4., . Например, вероятностная тематическая модель. 5., . Например, определение тематики документа. 6., . Например, общая теория относительности. 7., . Например, умножение столбиком. 8., . Например, решение методом прогонки. Обобщение шаблонов 1 и 4 можно переписать в виде, . Обобщение шаблонов 2 и 5 запишем в виде, . Был разработан модуль согласования словосочетаний на основе вышеперечисленных шаблонов, использующий для извлечения морфологической информации программу Mystem . На вход модулю подаются лемматизированные словосочетания, которые сопоставляются с каждым шаблоном из набора. После определения требуемого шаблона словосочетание приводится в согласованный вид путем преобразования зависимых слов в форму, обусловленную формой главного слова и видом связи в словосочетании. Данный модуль показывает приемлемые результаты, а набор модулей покрывает значительную часть используемых в качестве ключевых фраз многословных терминов. Для улучшения результатов работы можно использовать как расширение набора шаблонов, так и дополнительные способы согласования. Основным недостатком текущей версии модуля является невозможность построения словосочетаний, в которых существительные находятся во множественном числе. Для решения данной проблемы в дальнейшем планируется использовать модуль поиска начальной формы из базового подхода, модифицировав его для поиска всех вариантов заданного лемматизированного словосочетания, а затем применить морфологический анализатор для определения нужного числа существительного. Также к недостаткам модуля можно отнести несовершенство изменения формы слов с точки зрения лингвистики. В русском языке множество исключений, например, слова, оканчивающиеся на -мя время, пламя и др. не относятся к первому, второму или третьему склонению, а склоняются смешанным способом, причем при склонении к корню добавляется -ен времени, пламени. Этот вид исключений был учтен в разработанной программе, однако, чтобы учесть все варианты исключений, встречающихся в русском языке, потребуется участие эксперта-лингвиста. Для лемматизации текста и построения морфологического словаря коллекции документов используется программа Mystem. Программа лемматизирует слова, используя анализ контекста для снятия лексической неоднозначности, а также предоставляет морфологическую информацию часть речи, род, число, падеж, склонение и др. для каждого слова. Программа распространяется бесплатно для некоммерческого использования. Выбор методов тематического моделирования объясняется наличием определенных особенностей. Для сравнения некоторые из них приведены в табл. 1. Сравнение методов тематического моделирования Название метода Увеличение количества параметров модели с ростом числа документов Применимость к большим наборам данных Использование многословных терминов Единственность и устойчивость решения PLSA да, есть линейная зависимость нет нет нет LDA нет да нет нет ARTM нет да нет да Также для выбора базового алгоритма построения униграммных тематических моделей был проведен ряд экспериментов. Была подготовлена коллекция текстов научных статей на русском языке на основе выложенных в открытом доступе архивов журналов Программные продукты и системы, Сибирский психологический журнал и Cloud of Science . Статьи очищены от формул, таблиц, рисунков и библиографических ссылок, аннотация и ключевые слова были удалены. Размер коллекции составляет более двухсот шестидесяти текстов. Для оценки результатов были выбраны следующие метрики, реализованные в библиотеке BigARTM и описанные в работе 20 перплексия, разреженность матриц и, доля фоновых слов, мощность ядер тем, чистота ядер тем, контрастность ядер тем. Первоначальные эксперименты выявили, что LDA показывает значительно худшие результаты перплексии по сравнению с PLSA и ARTM. В связи с этим дальнейшее сравнение проводилось только для двух последних алгоритмов при числе проходов по коллекции 100. Результаты представлены в табл. 2. Сравнение алгоритмов PLSA и ARTM Метрика PLSA ARTM Перплексия 754.784 751.888 Разреженность матрицы 0.769 0.769 Разреженность матрицы 0.000 0.635 Доля фоновых слов 0.059 0.050 Средняя чистота ядер тем 0.370 0.364 Средняя контрастность ядер тем 0.787 0.788 Средняя мощность ядер тем 2085.000 2085.600 По результатам эксперимента, приведенным в табл. 2, можно увидеть, что ARTM показывает аналогичные либо лучшие результаты по сравнению с PLSA для всех метрик, за исключением средней чистоты ядер, где ухудшение незначительно. В совокупности с особенностями алгоритмов, приведенными в табл. 1, было принято решение использовать в качестве алгоритма построения униграммных тематических моделей алгоритм ARTM в реализации библиотеки BigARTM 16. Для извлечения многословных терминов из текстов используется адаптированный алгоритм извлечения ключевых слов Turbotopics. Суть оригинального алгоритма Turbotopics, описанного в работе 21, обобщенно состоит в следующем. Первоначально строится униграммная модель текста при помощи алгоритма LDA. Затем производится расширение модели многословными терминами. Для каждого отдельного ключевого слова, полученного при помощи LDA, или уже добавленной фразы осуществляется проверка в исходном тексте на наличие соседних слов, которые с высокой вероятностью будут предшествовать в тексте или следовать за ним. Пара таких найденных слов, или, считается многословным термином и добавляется к списку ключевых фраз. Данный алгоритм был разработан для применения в текстах на английском языке на основе алгоритма построения тематических моделей LDA и показал довольно хорошие результаты. Поэтому в данной работе он был адаптирован для работы с русскими текстами с использованием алгоритма ARTM библиотеки BigARTM. Для определения списка ключевых слов для каждого документа изначально предполагалось использовать список наиболее часто встречающихся терминов однои многословных для каждой темы, к которой относится данный документ. Однако этот подход привел к тому, что из документа извлекались ключевые слова темы, а не самой статьи для различных документов списки ключевых слов были очень похожи, а термины, которые должны быть ключевыми исходя из текста статьи, не попадали в список из-за низкой частоты встречаемости. Для решения данной проблемы было предложено использовать TF-IDF статистическую меру, оценивающую важность каждого слова для документа, в котором оно встречается 22. Наибольшее значение TF-IDF будут иметь слова, которые часто встречаются в данном документе, но редко встречаются в остальных документах коллекции. В рамках исследования была разработана система, позволяющая строить расширенные тематические модели, включающие многословные термины, для коллекций научных статей на русском языке. Система написана на языке Python 3 с использованием библиотеки BigARTM. Используемые в системе алгоритмы из этой библиотеки были настроены таким образом, чтобы получить оптимальные результаты относительно различных метрик перплексия, разреженность и др. при использовании текстов научных статей на русском языке. Обобщенная схема работы системы представлена ниже. Далее приведено подробное описание процесса построения расширенной тематической модели и извлечения ключевых фраз разработанной системой. Опишем схему работы системы как последовательность шагов. На вход системе подается коллекция документов в формате .txt. Каждый документ должен быть представлен одним файлом, все документы помещены в одну директорию, путь к которой передается программе в качестве параметра. В модуле предобработки текста каждый документ очищается от специальных символов отличных от кириллических и латинских букв, из документа удаляются стоп-слова, все слова приводятся к нижнему регистру. Далее строится корпус коллекции в формате последовательного Vowpal Wabbit. Производится вызов программы Mystem, на вход которой подается файл с построенным на предыдущем этапе работы корпусом. Результатом работы является файл лемматизированного корпуса формат, аналогичный полученному ранее корпусу, только каждое слово заменено его начальной формой, а также файл морфологического словаря, где каждой строке соответствует слово и описывающая его морфологическая информация. На лемматизированном корпусе производится поиск ключевых слов и -грамм с помощью алгоритма Turbotopics. Найденные алгоритмом Turbotopics -граммы преобразуются из лемматизированного вида в согласованный с использованием шаблонов, описанных выше, и морфологического словаря, полученного на шаге 2. Для лемматизированного корпуса строится тематическая модель коллекции документов с использованием алгоритма ARTM. Параметры алгоритма можно подобрать автоматически или использовать заранее вычисленные так как подбор параметров задача весьма трудоемкая и занимает значительное время. Полученная на шаге 5 тематическая модель расширяется с помощью многословных терминов, извлеченных из коллекции на шаге 3 и согласованных на шаге 4. Для каждого документа строится словарь TF-IDF с каждым словом в лемматизированном документе сопоставляется значение меры TF-IDF. Слова в словаре сортируются по убыванию значения меры. На основе матрицы распределения тем по документам с каждым документом сопоставляется набор присутствующих в нем тем и их вероятностей учитываются только темы, вероятность появления которых в данном документе превышает порог 1, где количество тем в модели. После этого сравниваются два множества первые слов из отсортированного словаря TF-IDF и первые слов и словосочетаний для каждой темы, отсортированных по вероятности встретить этот термин в документе. Итоговыми ключевыми словами для темы документа будет пересечение этих множеств. и могут настраиваться по умолчанию эти значения равны 100 и 300 соответственно. Такие значения параметров были подобраны эмпирическим путем, чтобы каждому документу в среднем соответствовало порядка 510 ключевых слов и фраз. Результатом работы программы является текстовый файл, содержащий следующую информацию название исходного документа список тем, для каждой из которых указана вероятность содержания ее в тексте как десятичная дробь от 0 до 1 список ключевых слов и фраз для каждой темы. Также для пользователя доступен файл с описанием тем, где с каждой темой сопоставлено множество слов и словосочетаний с наибольшей вероятностью для этой темы. Поскольку невозможно автоматически оценить интерпретируемость тем и приемлемость извлеченных ключевых фраз, результаты были оценены вручную. Далее приведены несколько примеров работы алгоритма для различных публикаций разной направленности. Некоторые из наиболее частотных слов и фраз для первых пяти тем расширенной тематической модели коллекции, представлены в табл. 3. Расширенная тематическая модель коллекции научных статей Тема Расширенная тематическая модель Тема 1 алгоритм, решение, задача, значение, вершина, значение параметра, время распознавания, класс объекта, обработка информации, алгоритм поиска, вершина графа, изображение объекта, граница решения, задача поиска, граф решения Тема 2 метод, данные, алгоритм, классификация, текст, слово, классификатор, обучение, значение параметра, класс объекта, множество признака, представление текста, процесс обучения, метод классификации, построение модели, задача классификации, качество классификации, обучение классификатора, классификация текста Тема 3 человек, ребенок, психологический, группа, отношение, стратегия восприятия, процесс формирования, образ мира, группа испытуемая, уровень развития, респондент группы, развитие ребенка Тема 4 система, управление, процесс, модель, требование, разработка, система управления, орган управления, процесс разработки, модель прогнозирования, критерий эффективности проекта, этап прогнозирования, критерий эффективности, эффективность проекта Тема 5 исследование, отношение, испытуемый, элемент, диагностический, результат исследования, значение параметра, удовлетворенность отношения, процесс формирования, поиск решения, вид деятельности, группа испытуемая, удовлетворенность брака, формирование религиозности По представленным в табл. 3 результатам можно отметить, что темы из разных предметных областей технические науки и психология очень хорошо различимы в тематической модели. При этом граница между более узкими темами не настолько четкая если тема 4 довольно хорошо интерпретируется как отдельная предметная область, связанная с управлением проектами и процессом разработки, темы 1 и 2 связаны с классификацией и распознаванием, а темы 3 и 5 с психологической диагностикой. При этом важно заметить, что в теме 5 многословные термины удовлетворенность отношения, формирование религиозности и т. д. улучшают интерпретируемость темы как относящуюся к психологии, тогда как термины исследование, испытуемый являются более общими. В табл. 4 представлены извлеченные программой ключевые слова и фразы для нескольких научных публикаций. Ключевые слова и фразы Название статьи Извлеченные ключевые слова и фразы 1 Алгоритм детектирования объектов на фотоснимках с низким качеством изображения объект, класс, изображение, набор, автокодировщик, обучение, объект, класс, набор, изображение, слой, пиксел 2 Проектирование интерфейса программного обеспечения с использованием элементов искусственного интеллекта программный, пользователь, система управления, уровень развития, нечеткий, интерфейс, характеристика, эксперт, система управления 3 Родительское отношение как фактор формирования религиозности личности ребенок, отношение, родитель, формирование, религиозность, религиозный, религия, семья, родительский, решение задачи 4 Прогнозирование платежеспособности клиентов банка на основе методов машинного обучения и марковских цепей прогнозирование, состояние, клиент, классификатор, ак, заемщик, решение задачи, дерево решения 5 Разработка системы хранения ансамблей нейросетевых моделей данные, модель, набор, ансамбль, ряд, преобразование, хранение, нейросетевой, оценка качества, процесс формирования, классификация текста Можно утверждать, что извлеченные ключевые слова и фразы соответствуют содержанию статей и хорошо определяют предметную область исследований. При этом можно заметить, что в некоторых случаях они дают большее представление о содержании публикации, чем ее название например, ключевая фраза дерево решения дает понять, что в качестве алгоритма машинного обучения в четвертой статье использовались деревья решений, а ключевая фраза классификация текста в статье 5 указывает, что ансамбли нейросетевых моделей здесь использовались для классификации текста а не только изображений, например. Тематические модели позволяют автоматически систематизировать большие коллекции текстовых документов на естественном языке, повышают эффективность информационного поиска. В ходе данного исследования была разработана система построения тематических моделей и извлечения ключевых слов и фраз для текстов научных статей на русском языке. Для проведения экспериментов была подготовлена коллекция очищенных текстов научных статей на русском языке из размещенных в открытом доступе журналов . Разработанная система способна строить расширенные тематические модели, включающие, помимо униграмм, словосочетания в согласованном виде. Для каждого документа предоставляется набор содержащихся в нем тем с указанными вероятностями и ключевыми словами и фразами для каждой темы. Благодаря расширению тематической модели многословными терминами темы хорошо интерпретируются. Извлекаемые ключевые слова и фразы соответствуют содержанию документа. Предложенный в статье подход может быть полезен при построении рекомендательных систем и систем автореферирования. "}
{"title": "МАТЕМАТИЧЕСКОЕ ОБОСНОВАНИЕ   НОВОГО ЭЛЕКТРОМАГНИТНОГО ЗОНДА С ТОРОИДАЛЬНЫМИ КАТУШКАМИ  ДЛЯ ВЫСОКОРАЗРЕШАЮЩЕГО КАРОТАЖА   НЕФТЕГАЗОВЫХ СКВАЖИН ", "absract": "Представленная работа посвящена обоснованию нового электромагнитного зонда для каротажа нефтегазовых скважин на основе компьютерного моделирования. Получено решение прямой задачи электромагнитного каротажа для тороидального источника в цилиндрически-слоистой геоэлектрической модели. Разработаны комплексы алгоритмов и компьютерных программ для анализа сигналов электромагнитного зонда с тороидальными катушками в пространственно неоднородных анизотропных средах. Путем масштабного компьютерного моделирования выполнено обоснование оптимальной конфигурации зондовой системы и исследованы ее возможности изучения макроанизотропных свойств геологических сред. : компьютерное моделирование, прямая задача, геоэлектрическая модель, анизотропная среда, электромагнитный каротаж, зонд с тороидальными катушками.", "text": "В последнее десятилетие существенно расширился круг задач промысловой геофизики, что обусловлено в первую очередь вовлечением в разработку глубокопогруженных залежей углеводородов сложного геологического строения. Это требует применения новых эффективных способов их изучения и, следовательно, создания новых методов геофизических исследований в нефтегазовых скважинах. Разработка геофизических приборов начинается с изучением его возможностей, определением оптимальных параметров конфигурации и анализом результатов путем масштабного компьютерного моделирования. Опыт конструирования приборов нового типа показал, что для успешной аппаратурной разработки необходимо создание ее программно-алгоритмический базы, позволяющей учесть конструктивные особенности и реалистичные модели сред, и составляющей основу интерпретационно-мето дического обеспечения в дальнейшем. Представленная работа посвящена разработке алгоритмов и компьютерных программ быстрого численного моделирования электромагнитных полей применительно к обоснованию конфигурации нового электромагнитного зонда с тороидальными катушками для высокоразрешающего каротажа скважин. Одной из основных электрофизических характеристик, по которой определяется флюидонасыщение пласта, является удельная электропроводность УЭП. На определение пространственного распределения УЭП вокруг скважины ориентированы методы электрического и электромагнитного каротажа. При этом огромное внимание уделяется изучению анизотропии, которая сильно проявляется в осадочных горных породах. Как правило, используют одноосную анизотропию УЭП. В этом случае среда описывается двумя параметрами УЭП вдоль и поперек напластования, т. е. различают горизонтальную и вертикальную УЭП. Традиционные методы электрокаротажа не зависят от вертикальной УЭП. Для изучения электрической анизотропии используют многокомпонентные измерения 121, характеризующиеся сложной аппаратурной реализацией и обладающие рядом недостатков при использовании их в обработке. Для нового прибора предлагается следующая система возбуждения-наблюдения 2226 многокатушечный зонд на металлическом корпусе с тороидальными генераторными и приемными катушками, а также датчиками тока рис. 1. Используются две генераторные катушки, которые питаются гармонически изменяющимся во времени током. Тороидальная катушка на металлическом корпусе возбуждает ток, протекающий вдоль корпуса. Любая из измеряемых компонент электромагнитного поля зависит от вертикальной и горизонтальной УЭП. Данная система позволяет реализовать два режима возбуждения-наблюдения. Первый, суммарный токи в генераторных катушках равны и имеют один знак, и второй, дифференциальный токи в генераторных катушках противоположны по знаку. При этом проводятся измерения абсолютных и или относительных характеристик электромагнитного поля с последующим определением тензора УЭП. Зондовая система реализуется двумя генераторными катушками и набором приемных, число которых ограничивается размером зонда. Например, использование трехкатушечного зонда две генераторные и одна приемная катушки позволяет регистрировать как минимум три электромагнитных отклика, в то время как в традиционных каротажных системах регистрируется один-два. Использование различных частот и дополнительных приемных катушек позволит существенно увеличить число независимых измерений. Обобщая основную идею, укажем, что в суммарном режиме, измеряя абсолютные и относительные характеристики электромагнитного поля, можно определить компоненты тензора УЭП. В дифференциальном режиме диаграммы позволяют детально расчленять разрез по вертикали, выделяя границы пластов и зоны трещиноватости. При этом радиальная глубинность обеспечивается, во-первых, измерением электромагнитных откликов, слабо зависящих от корпуса прибора и бурового раствора, во-вторых, совместной инверсией полного набора данных измерений. Предлагаемый каротажный зонд обладает существенными преимуществами высокий уровень измеряемого сигнала за счет значительной плотности тока на корпусе высокое вертикальное и радиальное разрешение детальное расчленение разреза определение горизонтальной УЭП и коэффициента электрической анизотропии выделение интервалов зон трещиноватости компактная зондовая система. Целью данной работы является анализ измеряемых сигналов для выявления оптимальной конфигурации электромагнитного зонда с тороидальными катушками по результатам компьютерного моделирования. В настоящее время разработан комплекс базовых алгоритмов математического моделирования и анализа электромагнитных сигналов в радиально-слоистых анизотропных средах. Алгоритмы обеспечили полномасштабный анализ измеряемых сигналов для последующего выявления оптимальной конфигурации электромагнитного зонда. Проведенный анализ источников измеряемых сигналов показал, что при возбуждении тороидальной катушкой на металлическом корпусе в среде возникает переменное электрическое поле, имеющее как горизонтальную, так и вертикальную компоненты. Это определяет зависимость измеряемых электромагнитных сигналов от горизонтального и вертикального удельного электрического сопротивления УЭС пласта. Пространственное распределение источников измеряемых сигналов указывает на значительную глубинность и локальность исследований. Это обеспечивает разрабатываемому электромагнитному зонду высокое вертикальное и радиальное разрешение. Проведенное компьютерное моделирование и сравнительный анализ электромагнитных характеристик подтверждают, что измерения являются независимыми и есть их однозначная связь с УЭС пласта. Отмечается высокий уровень и широкий динамический диапазон измеряемых сигналов. Для обоснования параметров зонда с тороидальными катушками выберем модель однородного по вертикали пласта рис. 2. В этом случае модель среды является одномерной цилиндрически-слоистой. Внутренний цилиндр первый слой имитирует металлический корпус прибора, второй слой скважину, внешний слой пласт. Между скважиной и пластом может находиться зона проникновения фильтрата бурового раствора в пласт. Она может быть неоднородной и описывается одним или несколькими цилиндрическими слоями. Будем предполагать, что мощность пласта гораздо больше длины зонда и толщины скин-слоя. В этом случае влиянием вмещающей пласт среды, а также конечными размерами корпуса прибора по вертикали можно пренебречь. Такое упрощение позволит нам достаточно легко оценить реальные уровни измеряемых сигналов, установить их основные зависимости от параметров пласта и скважины, а в последующем оценить их чувствительность к параметрам модели, в том числе к влиянию корпуса прибора. Пусть ток в источнике изменяется по гармоническому закону . Здесь круговая частота 1с, время с. Частота Гц связана с круговой соотношением 2 . Источник поля в виде тороидальной катушки вдали от нее формально можно описать круговым магнитным током 27. Будем использовать цилиндрическую систему координат, ось которой совпадает с осью скважины и направлена вниз. В решении задачи об электромагнитном поле тороидальной катушки будем использовать метод, основанный на представлении поля произвольного гармонического источника в виде суммы нормального и аномального полей, а также на преобразовании Фурье электромагнитного поля по вертикальной координате 28 29. Пусть источник электромагнитного поля расположен в слое с номером . Представим поля в м слое в виде суммы двух слагаемых, . 1 Здесь, электрическое и магнитное поля стороннего источника в однородной изотропной среде с параметрами го слоя первичные поля, аномальные поля. Векторы, а также полные поля в м слое, подчиняются уравнениям Макс велла 2 . 3 Здесь плотность магнитного тока. Тензор проводимости 0 0 0 0 0 0 . 1 1, ., горизонтальная и вертикальная УЭП -го цилиндрического слоя, коэффициент электрической анизотропии -го слоя. На границах сред 1, 1 касательные компоненты полей непрерывны, что можно записать в следующем виде . 4 Индексом обозначена тангенциальная или вертикальная -компонента электромагнитного поля 1, 0, . Согласно 24, определение полного электромагнитного поля распадается на две независимые задачи 1 определение первичного поля, подчиняющегося уравнениям 2 2 определение полей, 1, связанных однородными уравнениями 3 и неоднородными граничными условиями 4. Рассмотрим решение первой задачи. Расписывая покомпонентно уравнения 2 и учитывая, что круговой магнитный ток имеет только тангенциальную компоненту 0,0, получим следующую систему для определения электромагнитного поля 1 . 5 Выражение для плотности стороннего магнитного тока . 6, координаты источника, точка наблюдения, магнитный момент, дельта-функция Дирака. Таким образом, при возбуждении поля круговым магнитным током ненулевыми являются только компоненты, и . Ввиду осевой симметрии источника электромагнитное поле не зависит от координаты . Определим Фурье-образы компонент поля по координате следующими соотноше ниями, . 1, 2 7 С помощью преобразования Фурье из уравнений 5 получим 1 . 8 Из системы 8 получаем уравнение для Фурье-образа вертикальной компоненты электрического поля 1 1 . 9 Здесь, . Также из уравнений 8 получаем, что компоненты, выражаются через производную следующим образом . 10 Чтобы привести дифференциальное уравнение 9 к алгебраическому виду, воспользуемся преобразованием Ханкеля 30, ., 11 Здесь и далее верхний индекс означает Ханкель-образ. функция Бесселя нулевого порядка. Используя свойства преобразования Ханкеля 30 и выражение для стороннего тока 6, из уравнения 9 находим, откуда с помощью обратного преобразования Ханкеля, используя табличные интегралы 31, определяем, ., 12 Здесь, модифицированные функции Бесселя первого и второго рода нулевого и первого порядков. С помощью 10 из формулы 12 получаем выражение для тангенциальной компоненты магнитного поля и радиальной компоненты электрического поля, 13, ., 14 Формулы 13, 14 понадобятся для решения второй задачи. Обратное преобразование Фурье выражений 1214 дает следующие формулы для определения первичных полей, cos, 15, cos, 16, sin ., 17 Рассмотрим вторую задачу. Аналогично первой получаем следующее уравнение для определения Фурье-образа вертикальной компоненты электрического поля 1 0. 18 Компоненты, выражаются через производную с помощью формул . 19 Общее решение уравнения 18 имеет вид . 20 Здесь, неизвестные коэффициенты. С учетом конечности поля в нуле и убывания его на бесконечности . 21 Используя непрерывность компонент, на границе 4, а также зависимости 13, 14, 19 и 21, получим систему линейных уравнений для определения коэффициентов и . 22 Матрица системы, вектор неизвестных коэффициентов и правая часть системы записываются в виде 23 0 ... 0 ... ..., ... ... 0 ... 0 24 Здесь . Для определения электромагнитного поля в произвольной точке среды необходимо решить систему 22, воспользоваться представлением через коэффициенты и 21 и выражениями для, 19, а затем выполнить обратное преобразование Фурье 7 по переменной . В результате получим 1 cos, 25 1 cos, 26 1 sin . 27 Если источник и приемник находятся в одном слое, к полученным значениям полей 2527 необходимо прибавить первичные поля 1517 с параметрами -го слоя. Измеряемыми сигналами являются э.д.с. в приемной катушке и плотность тока на корпусе прибора. Определим моменты, необходимые при расчетах величины измеряемых сигналов. По закону Фарадея э.д.с. в приемном контуре выражается через нормальную к контуру компоненту магнитного поля следующим образом . Если площадь, ограниченная приемным контуром, мала в пределах контура величина изменяется мало, то . Для э.д.с. в приемной катушке 28 Здесь э.д.с. в одном витке катушки, длины окружностей источника радиусом и приемника радиусом, число витков генераторной и приемной катушек соответственно, площади витков генераторной и приемной катушек соответственно магнитная проницаемость сердечника приемной катушки. В выражении для стороннего тока 6 была указана магнитная проницаемость слоя с источником скважины . В реальных тороидальных катушках применяются магнитные материалы, усиливающие сигнал. Учитывая, что магнитная проницаемость бурового раствора равна магнитной проницаемости вакуума 4 10Гнм, получаем, что величина измеряемого сигнала должна быть умножена на относительную магнитную проницаемость в источнике . Окончательно . 29 амплитуда силы тока в источнике, относительные магнитные проницаемости в генераторной и приемной катушках. Таким образом, для вычисления э.д.с. в приемном контуре введен момент Ам. 30 Аналогично определяем момент для вычисления плотности тока, текущего по корпусу прибора, 31 Ам. 32 Здесь УЭП корпуса. Для анализа сигналов зонда с тороидальными катушками использовалась цилиндрическислоистая модель среды, включающая корпус прибора, скважину и пласт. УЭС корпуса прибора 10 Ом м, радиус корпуса 0,05 м, УЭС бурового раствора 2 Ом м, радиус скважины 0,108 м. Когда исследовалась зависимость сигналов от УЭС бурового раствора, он менялся от 0,01 до 10 Ом м. При исследовании зависимости от радиуса скважины его диапазон составил 0,060,15 м. В вычислениях использовались единичные моменты генераторной катушки и приемного датчика. Отметим также, что амплитуда плотности тока обратно пропорциональна УЭС корпуса скважинного прибора, а амплитуда э.д.с. от него не зависит при УЭС металла менее 10 Ом м. Необходимость создания компактной зондовой системы обусловила выбор для анализа длин зондов от 0,2 до 1,2 м. Диапазон исследуемых частот составил 5500 КГц для обеспечения достаточного проникновения электромагнитного поля в неизмененную часть пласта. Генераторная тороидальная катушка порождает в среде вихревое электромагнитное поле, служащее вторичным источником измеряемых сигналов. Пусть вертикальные координаты двух генераторных катушек равны 0,6 и 0,6 м. Режим возбуждения суммарный. На рис. 3 показано пространственное распределение реальной и мнимой частей плотности вихревого тока в пластах с УЭС 5 Ом м на частоте 50 КГц. Возбуждаемый в среде вихревой ток имеет как горизонтальную, так и вертикальную компоненты. Это обеспечивает зависимость измеряемых электромагнитных сигналов от горизонтального и вертикального УЭС пласта. О глубине проникновения электромагнитного поля в среду можно судить по нормированным амплитудам реальной и мнимой частей плотности вихревого тока показаны цветом. Нормировка проводилась на значение плотности вихревого тока на стенке скважины. В радиальном направлении амплитуда тока затухает примерно на порядок. Поведение вихревого тока значительно различается для реальной и мнимой частей. Это указывает на необходимость измерения обеих составляющих сигнала, что будет обеспечивать высокое пространственное разрешение скважинного прибора. Пространственное распределение источников измеряемых сигналов указывает на достаточную для практики глубинность и локальность исследований. На рис. 4 приведено распределение реальных и мнимых частей плотности тока и э.д.с. в зависимости от длины зонда и частоты. Для реальной части плотности тока на корпусе наблюдается повышение уровня сигнала при увеличении как длины зонда, так и частоты. Зависимость измеряемого сигнала от обоих параметров высокая. Для мнимой части отмечается повышение уровня сигнала при уменьшении длины и увеличении частоты. В области низких частот сигнал слабо зависит от длины зонда. Уровень сигнала реальной части э.д.с. в приемной катушке повышается с уменьшением длины зонда и увеличением частоты. Зависимость измеряемого сигнала от обоих параметров значительная. Уровень сигнала мнимой части э.д.с. повышается с увеличением частоты. Измеряемый сигнал слабо зависит от длины зонда, при этом в области низких частот зависимости практически нет. Измеряемые амплитуды плотности тока и э.д.с. характеризуются высоким уровнем и имеют большой динамический диапазон. Измеряемые сигналы сильно зависят от частоты, что указывает на преобладание частотного зондирования. При этом с повышением частоты зависимость сигналов от длины зонда увеличивается. Проведенный анализ указывает на возможность выбора дискретного набора длин двухкатушечных зондов и операционных частот для макета прибора. На рис. 5, 6 показано влияние скважины на измеряемые сигналы. На рис. 5 приведены зависимости амплитуды плотности тока и э.д.с. от УЭС бурового раствора для двухкатушечных зондов на частоте 50 КГц. Зависимость измеряемых характеристик от УЭС бурового раствора менее 1 Ом м для зондов длиной 0,4-1,2 м слабая. Сильнее всего от УЭС бурово го раствора зависит короткий зонд длиной 0,2 м. Для УЭС от 1 до 10 Ом м изменение сигналов составляет около 20 . На рис. 6 приведены зависимости сигналов от радиуса скважины. Изменение сигналов составляет 1015 для диапазона радиусов от 0,06 до 0,15 м. В целом отмечается слабая зависимость измеряемых характеристик от УЭС бурового раствора и ее отсутствие в скважинах с биополимерным и глинистым растворами. Влияние возрастает при увеличении частоты и уменьшении длины зонда. Зависимость измеряемых характеристик от радиуса скважины практически отсутствует при частотном и наблюдается при геометрическом зондировании. Влияние параметров скважины приводит к необходимости их учета, в частности путем внесения соответствующих поправок. На рис. 7 приведены зависимости сигналов от УЭС пласта для двухкатушечного зонда длиной 0,6 м. Уровень измеряемых сигналов возрастает с увеличением частоты. Для УЭС от 1 до 200 Ом м сигналы на низкой частоте уменьшаются примерно в 20 раз, на высокой на порядок. Во всем диапазоне УЭС отмечается выраженное частотное зондирование. В более проводящей среде преобладает геометрическое зондирование. На рис. 8 приведены зависимости сигналов от горизонтального УЭС коэффициент электрической анизотропии 1-4 для двухкатушечного зонда длина 0,6 м, частота 50 КГц. Уровень измеряемых сигналов уменьшается с увеличением коэффициента анизотропии. На рис. 9 приведены зависимости сигналов от коэффициента электрической анизотропии для двухкатушечного зонда длиной 0,6 м на частоте 50 КГц. Измеряемые характеристики однозначно связаны с коэффициентом электрической анизотропии пласта. В целом представленные зависимости указывают на однозначную связь измеряемых характеристик с параметрами пласта. Следует отметить высокий уровень и широкий динамический диапазон измеряемых сигналов. Частотное зондирование преобладает во всем диапазоне УЭС пласта. Геометрическое зондирование возможно в проводящих средах. Разработан комплекс базовых алгоритмов компьютерного моделирования и анализа электромагнитных сигналов в радиально-слоистых анизотропных средах с целью изучения пространственного распределения УЭС горных пород и их электрической анизотропии с помощью нового зонда с тороидальными катушками. Алгоритмы обеспечили полномасштабный анализ измеряемых сигналов для последующего выбора оптимальной конфигурации электромагнитного зонда. С использованием созданного алгоритмического инструментария сделаны следующие основные выводы. Проведенный анализ источников измеряемых сигналов показал, что при возбуждении тороидальной катушкой на металлическом корпусе в среде возникает переменное электрическое поле, имеющее как горизонтальную, так и вертикальную компоненты. Это определяет зависимость измеряемых электромагнитных сигналов от горизонтального и вертикального УЭС пласта. Пространственное распределение источников измеряемых сигналов указывает на значительную глубинность и локальность исследований. Это обеспечивает разрабатываемому электромагнитному зонду высокое вертикальное и радиальное разрешение. УЭС корпуса оказывает влияние на амплитуду плотности тока. Его уменьшение приводит к пропорциональному УЭС корпуса возрастанию уровня сигнала. Зависимость амплитуды э.д.с от УЭС корпуса незначительная. Уровень измеряемых сигналов может быть существенно повышен за счет увеличения моментов генераторной и приемной катушек. Их предполагаемый диапазон составляет первые единицы первые сотни соответствующих единиц. Отмечается зависимость измеряемых характеристик от УЭС бурового раствора для высоких частот и коротких зондов. В диапазоне значений УЭС 0,12 Ом м зависимость измеряемых характеристик и их составляющих ослаблена. Зависимость измеряемых характеристик от радиуса скважины слабая при частотном зондировании и наблюдается при геометрическом зондировании. Влияние на измеряемые сигналы радиуса скважины меньше, чем УЭС бурового раствора. Проведенные компьютерное моделирование и сравнительный анализ электромагнитных характеристик подтверждают, что измерения являются независимыми и однозначно связаны с УЭС пласта. Отмечается высокий уровень и значительный динамический диапазон измеряемых сигналов. Преобладает частотное зондирование. Геометрическое зондирование воз можно в проводящих средах. "}
{"title": "ИССЛЕДОВАНИЕ ПРОИЗВОДИТЕЛЬНОСТИ ПРИЛОЖЕНИЙ БАЗ ДАННЫХ:  ТРАНЗАКЦИОННАЯ МОДЕЛЬ И АРХИТЕКТУРА ИМИТАЦИОННОЙ СИСТЕМЫ ", "absract": "Высокий уровень изменчивости программного и технического обеспечения информационных систем требует получения оценок их производительности за ограниченные сроки на любых стадиях их жизненного цикла. В статье рассматривается унифицированный процесс обработки данных в клиент-серверном приложении, которое взаимодействует с базой данных, состоящей из стандартных компонентов. Формальная модель процесса представлена одноканальной системой массового обслуживания с входящим потоком требований, интегрирующим элементарные потоки, каждый из которых ассоциируется с определенным транзакционным классом. Излагаются актуальные вопросы реализации модели и приводятся результаты имитационных экспериментов, отражающие продолжительность отклика системы на задаваемую рабочую нагрузку. : оценка производительности, время отклика, клиент-серверная система, имитационное моделирование, система массового обслуживания. ", "text": "Любое многопользовательское приложение баз данных ПБД, реализованное в клиентсерверной архитектуре, в процессе своего создания или после очередной модернизации должно подвергаться нагрузочному тестированию, главная цель которого установление фактических значений производительности для заданных параметров рабочей нагрузки, показательной для той предметной области, где ПБД эксплуатируется. Среди используемых сегодня показателей производительности, таких как доступность, загруженность, пропуск ная способность и продолжительность отклика 1 2, последний показатель считается основным. Качество проводимого тестирования во многом определяется тем, насколько адекватно тестовая среда воспроизводит функционирование ПБД, инфраструктуру информационной системы и саму рабочую нагрузку. В подавляющем большинстве случаев 310 тестовая среда представлена системами массового обслуживания, с разной степенью детализации и точности, отражающих процессы обработки данных в ПБД. Несмотря на большое число исследований, выполненных в этой области, на практике эти модели не получили широкого распространения ввиду недостаточной точности их предсказательных возможностей 3, что можно объяснить следующими обстоятельствами. В основе всех моделей лежат транзакции, представляющие собой запросы к базе данных, и некоторый алгоритм, в соответствии с которым транзакции выполняются той или иной серверной системой управления базой данных СУБД. При этом номенклатура разновидностей классов, типов транзакций может быть сколь угодно большой и варьироваться от одной предметной области к другой в достаточно широких пределах. То же самое относится к интенсивностям входящих транзакционных потоков, меняющихся с течением времени. При этом лишь небольшая часть классов транзакций отличается действительно высокими интенсивностями. Большинство из них инициируются эпизодически и могут не оказывать серьезного влияния на производительность ПБД, если задан и поддерживается, например, корректный регламент обслуживания таких транзакций. Отсюда одна из задач, возникающая при моделировании процессов обработки данных, локализация и формализация транзакций, характеризующихся наивысшей интенсивностью. Два других обстоятельствах, сказывающихся на качестве моделирования, высокие степени неоднозначности и изменчивости среды, которая призвана обеспечить выполнение транзакций. В последнее время наметилась тенденция к стремлению максимально оградить пользователя от участия в процессах, связанных с обработкой транзакций. По сути, разработчики СУБД инкапсулировали соответствующие алгоритмы и используемые структуры данных и исключили возможность заранее предугадать, насколько быстро и когда будет выполнена конкретная транзакция. В этом проявляется неоднозначность. Относительно изменчивости отметим следующее. Переход к очередным версиям СУБД или средам разработки прикладного программного обеспечения, если они существенным образом затронули технологии работы с транзакциями, могут свести к нулю и полученные ранее результаты моделирования, и сделать некорректными сами модели. Все перечисленное делает актуальным построение таких моделей, структура которых, во-первых, представлена неизменяемыми и в то же время существенными элементами, определяющими производительность, и, во-вторых, в состоянии воспроизвести и реальную промышленную нагрузку в виде потоков разнородных транзакций, и саму среду выполнения. Настоящая работа направлена на решение обозначенных выше задач. Основной резуль тат формирование рамочной модели, имитирующей процессы обработки данных в многопользовательских приложениях с централизованной базой данных. Модель должна позволять получить оценку продолжительности отклика клиент-серверной системы для заданных интенсивностей входящих потоков требований SQL-запросов и мощностей отношений баз данных. За время непродолжительной эволюции, насчитывающей несколько десятков лет, сформировались представления о том, какой должна быть эффективная организация архитектура ПБД. Архитектура, по сути, рамочно задает максимальные возможности системы, в том числе и предельные характеристики ее производительности. Возьмем за основу клиентсерверную архитектуру, ставшую сегодня де-факто стандартом для ПБД, и выделим в ней те элементы, которые будут существенно влиять на значения, принимаемые показателями производительности. Последние будут перечислены позднее. Клиент-серверная архитектура в зависимости от выбранного метода доступа может быть реализована в трех потенциальных вариантах отсоединенного доступа, прямого доступа и некоторой комбинации первых двух. На сегодняшний день отсоединенный режим считается наиболее предпочтительным по сравнению с режимом прямого доступа, так как позволяет получить значительный выигрыш в скорости выполнения запросов за счет сокращения времени блокировок ресурсов. Поэтому будем на него ориентироваться в дальнейшем. Отсоединенный доступ предполагает, что клиентское приложение соединяется с базой данных на непродолжительное время только для получения или записи информации и использует собственную подсхему для представления данных. Элементы такой архитектуры показаны на рис. 1. Функции двустороннего обмена и передачи запросов реализует поставщик данных. Определившись с базовыми элементами и конфигурацией моделируемой системы ПБД, покажем далее, что будет пониматься под производительностью. Большинство исследователей и практиков обоснованно считает 110, что производительность это время продолжительность отклика системы на запросы, поступающие от пользователей этой системой. Продолжительность в зависимости от структуры запросов и нагрузки на сервер может варьироваться в достаточно широких пределах от нескольких миллисекунд до часов. ПБД включает большое число разновидностей классов запросов, которые инициируются и выполняются в случайные моменты времени . Для описания входных потоков требований, каждый из которых ассоциируется с запросом, необходимо знать законы распределений случайных величин, образующих множество, . Продолжительность выполнения отдельного -го запроса также будет представлять собой случайную величину с неизвестным законом распределения. Логично для представленной архитектуры ПБД в качестве показателей производительности использовать ряд оценок распределений среднее время выполнения каждого класса категории запроса к БД, а также вероятность того, что эта продолжительность с заданной надежностью не выйдет за определенные границы, где дисперсия случайной величины предельное значение вероятности. Последний показатель дает возможность учесть разброс значений относительно . Это требование вытекает из практики. Мало кого устроит, например, если 30 запросов о состоянии банковского счета будет выполняться с продолжительностью 20 и более секунд. Это, конечно, условные цифры. Тем не менее заметим, что значения элементов множеств и могут рассматриваться в качестве требований к информационной системе ИС. Одна из главных сложностей построения моделей и последующего моделирования процессов обработки данных в ПБД многообразие конфигураций потенциальных запросов, которые могут присутствовать в программах, и, как одно из следствий, трудности с нахождеСУБД База данных БД нием частотных распределений . В действительности же массовые запросы, к которым будем относить запросы с наиболее высокими значениями входных интенсивностей, отличает стандартная конфигурация, вытекающая из стандартной архитектуры приложений, а также стандартной организации баз данных, представленной типизированными структурами. Поскольку в вопросе унификации массовых запросов типизация структур БД не менее важна, чем выбор архитектуры, изложим соображения и решения, касающиеся одной из возможных типизаций. Будем при этом руководствоваться назначением БД, которая призвана регистрировать факты, и способом, которым это делает СУБД. Факты это привязанные ко времени взаимодействия, устанавливающиеся между объектами, из которых состоят предметные области. Факты фиксируются в документах и в базах данных могут размещаться либо в документальных структурах, либо в слабых сущностях. Использование документальных структур более предпочтительно, так как исключается необходимость в дублировании однозначных атрибутов, характеризующих документы. В отличие от фактов, информация об объектах содержится в справочных структурах. Одним из признаков последних является присутствие в них семантических сведений либо ссылок на таковые, если используются семантические объекты. Если не углубляться в дальнейшую типизацию, которая несущественна для задач, решаемых в настоящей работе, структурную часть базы данных в своей основе составляют справочные и документальные структуры. Продемонстрируем сказанное на небольшом примере организации структур, содержащих данные об отметках, получаемых студентами в ходе сдачи ими экзаменов рис. 2. Возьмем за основу экзаменационную ведомость. Логическая модель документа представлена двумя документальными структурами Examinationrecord listHead и ExaminationrecordlistDetails, а также справочниками, которые поставляют семантику для записей документальных структур. Корректная работа с документом в информационной системе по умолчанию предполагает, что в произвольный момент времени доступ к документу имеет один и только один пользователь. В противном случае всегда есть риск получения рассогласованных данных. Отсюда элементарными, типичными и одновременно массовыми операциями, выполняемыми в ПБД, будут операции на получение чтение и корректировку запись данных, сосредоточенных в документальных структурах. Продемонстрируем общую структуру запросов, производящих чтение и запись данных рис. 3. DocumentHead заголовочная структура DocumentDetail содержательная структура Личности Дисциплины Отметки Подразделения Первая часть запроса обеспечивает получение данных из заголовочной таблицы структуры, вторая из содержательной. За ссылку на конкретный документ отвечает параметр и переменная Iddoc, которой предварительно присваивается значение идентификационного кода документа. Противоположный запрос, предназначенный уже для записи данных, может либо ограничиться инструкциями UPDATE и DELETE, если данные только обновлялись, либо включать два подзапроса один на удаление DELETE и один на вставку данных INSERT. Последний вариант может оказаться более эффективным с точки зрения производительности выполнения, так как количество записей, сосредоточенных в одном документе, в основном варьируется в незначительных пределах и в редких случаях превышает 100 единиц. Таким образом, каждому классу документа можно поставить в соответствие по одному стандартному запросу один на чтение данных, другой на запись. Присутствие входного потока требований в виде запросов, поступающих на сервер прибор обслуживания в случайные моменты времени, и необходимость в оценке продолжительности выполнения обслуживания этих запросов свидетельствуют в пользу применения в качестве математической модели исследуемого процесса системы массового обслуживания СМО. Согласно документации, описывающей организацию и функционирование таких распространенных СУБД, как ORACLE и MS SQL, СМО включает встроенную очередь с дисциплиной обслуживания FIFO первый пришел первым обслужен. Входящий поток требований представлен совокупностью локальных потоков, каждый из которых соответствует му запросному классу рис. 4. Применительно к каждому локальному потоку если брать в расчет характерный для конкретной предметной области временной интервал можно с высокой степенью уверенности утверждать, что поток обладает всеми признаками простейшего пуассоновского потока ординарностью, стационарностью и отсутствием последействия. Несмотря на то что в общем случае, это нестационарный пуассоновский процесс, характеризующийся совокупностью, соответствующих различным временным интервалам, для исследования производительности ПБД будем принимать в расчет интервал времени с максимальной интенсивностью. DocumentHead., Ref. DocumentHead Ref1 Refn DocumentHead.IddocIddoc DocumentDetail, Ref. DocumentDetail Ref1 Refn DocumentDetail.IddocIddoc Зная, можно получить количество запросов, которые будут поступать на сервер в течение заданного интервала времени. Но для имитации процесса обработки данных необходимы данные другого рода моменты времени поступления требований. Воспользуемся стандартным преобразованием, согласно которому, если входной поток является простейшим, то вероятность моментов времени поступления требований можно найти на основании экспоненциального распределения 1 . Тогда, интервал времени между поступлениями требований составит 1ln1, где случайное число, равномерно распределенное в интервале 0, 1. Поскольку 1 также равномерно распределенное число в том же интервале, можно произвести замену 1 на Неизвестной величиной в представленной модели окажутся случайные величины, законы распределения которых предстоит найти в ходе имитационных экспериментов с этой моделью. Как уже было замечено, одна из особенностей современных клиент-серверных СУБД состоит в максимальной степени их закрытости, что затрудняет организацию и проведение имитационных экспериментов. Закрытость, в частности, проявляется в том, что СУБД берут на себя полное управление дисциплиной и постановкой запросов в очередь. Поэтому задать время старта очередного запроса, что требуется условиями эксперимента, не прибегая к каким-то нестандартным программным решениям, крайне проблематично. Решить возникшее затруднение можно двумя способами либо запустить отдельные экземпляры приложений, включающих текст самого запроса и оператор, инициирующий выполнение запроса, либо воспользоваться потоками, обеспечивающими параллельное выполнение программ. В обоих случаях суммарное число и экземпляров, и потоков будет равно количеству запросов. В настоящей работе был реализован второй способ. Покажем принципиальное различие в использовании однопоточной и многопоточной архитектур программной системы, имитирующей поступление и выполнение запросов в ПБД рис. 5. Пусть и случайные моменты времени поступления на сервер запросов и соответственно, начало, а, завершение выполнения этих запросов. Если продолжительность выполнения запроса которая также является случайной величиной меньше, то, приостановив выполнение программы на, можно имиОчередь База данных тировать посредством какой-либо из команд используемого языка моделирования старт запроса . В противном случае время старта запроса будет всегда больше или равно, так как команда, инициирующая старт, не может быть выполнена до тех пор, пока не завершится выполнение команды, запускающей . В однопоточном программном коде все команды выполняются строго последовательно. Использование потоков позволяет избежать возникновения вынужденной задержки старта очередного запроса. Каждый запрос может быть выполнен в собственном потоке, и тогда всегда . Обратим внимание на то, что в силу наличия серверной очереди время старта очередного запроса это время, когда запрос поступил на сервер и занял место в очереди на выполнение. Ниже приводится текст программы на языке C листинг 1, имитирующей выполнение случайной последовательности запросов инкапсулированных в транзакции в потоках, со всеми необходимыми пояснениями. Моделирующая система разработана в среде Microsoft Visual Studio 2017 c использованием ADO.NET и СУБД MS SQL 2012. Листинг 1 foreach DataRowView GG in DV deltaT intGGDeltaT Thread.SleepdeltaT ThparCickle new Threadnew ParameterizedThreadStartThreadProc ListofParametrsLoP new ListofParametrsstringGGNamesp, parCickle, intGGAmmountrecords, charGGParametersYN ThparCickle.StartLoP parCickle 1 Старт запросов в однопоточном приложении Старт запросов в многопоточном приложении public static void ThreadProcObject Paramets DateTime start string strConn, startQuery, namesp Random Rand new Random ListofParametrsLoP new ListofParametrs LoP ListofParametrs Paramets namesp string LoP.Namesp int ammountrecords intLoP.Ammountrecords char parametersYN charLoP.ParametersYN inttransactionnumber int LoP.Nomertransaction strConn Data SourceISEInitial CatalogUniversityIntegrated SecurityTrue Connection Timeout200 PoolingFalse Asynchronous ProcessingTrue MultipleActiveResultsetstrue SqlTransaction myTransaction SqlConnection sqlCon SqlCommand sqlCom sqlCon new SqlConnectionstrConn sqlCon.Open myTransaction sqlCon.BeginTransactionConvert.ToStringtransactionnumber sqlCom new SqlCommand sqlCom.Connection sqlCon sqlCom.CommandText namesp sqlCom.CommandType CommandType.StoredProcedure sqlCom.CommandTimeout 0 if parametersYNY sqlCom.Parameters.AddWithValueIddoc,Rand.Next1,ammountrecords sqlCom.Transaction myTransaction sqlCom.ExecuteNonQuery sqlCom.Transaction.Commit sqlCom.Connection.Close Перед началом моделирования пользователь, посредством диалогового окна рис. 6, выбирает из списка хранимых процедур, содержащих откомпилированные тексты запросов, те из них, которые будут участвовать в эксперименте, и задает интенсивность их появления . Инициация начала эксперимента посредством нажатия кнопки старт приводит к выполнению модуля, который рассчитывает моменты времени поступления запросов на сервер. Полученные данные записываются в экземпляр GG класса DataRowView, который представляет собой последовательный список. Далее, в цикле на величину, определенную как разность между моментами времени старта смежных запросов, организуется задержка в основном потоке и создается отдельный параметризированный поток, которому передается имя процедуры, запускающей на выполнение очередной запрос. Инструкция создает такой поток, а метод этого потока, принимая набор входных параметров класс запроса, признак обращения к документальным или справочным таблицам и ряд других, перечисленных в структуре, инициирует выполнение запроса, посредством метода В теле метода выполняются следующие действия. Cначала создается набор инструментов, необходимых для выполнения запроса в потоке, а затем, с помощью инструкции, выполняется сам запрос Упомянутые инструменты это команды на создание и открытие соединения с базой данных и, а также инструкция myTransaction sqlCon.BeginTransactionConvert. ToStringtransactionnumber, создающая и запускающая внутри открытого соединения транзакцию. Имя хранимой процедуры присваивается свойству CommandText экземпляра sqlCom. Моменты времени начала и завершения выполнения транзакции запроса фиксируются средствами, предоставляемыми утилитой, входящей в пакет поставки MS SQL. Разработанная и реализованная модель обработки запросов для системы, состоящей из централизованной базы данных и клиентских приложений, позволяет решать многие задачи, связанные с организацией информационных систем и поиском эффективных механизмов управления последними. Ограничимся исследованием характеристик случайной величины, представляющей собой продолжительность времени обработки запроса, принадлежащего к классу документальных запросов. Одна из задач, решаемых в ходе экспериментов, получение распределений для различных дискретных значений и мощностей документальных структур . Везде далее значение будет соответствовать количеству записей, которые содержатся в заголовочной структуре. Количество записей, размещенных в содержательной структуре, составит 10 одной записи заголовочной структуры соответствует 10 записей содержательной В качестве характерного периода для индекс будем далее опускать примем промежуток времени продолжительностью в один час 3 600 000 мс, который характерен для достаточного большого числа предметных областей образовательных, почтовых, медицинских, банковских, торговых и многих других. Эксперименты показали следующее. 1. Ни один из возможных теоретических законов распределения случайной величины нормальное или логнормальное распределения не может быть использован для аппроксимации экспериментальных данных. Так, например, для 510 и 510 проверка по критерию Пирсона на соответствие нормальному закону показала, что 11367 0,95 13 5,89, где доверительный интервал, число степеней свободы. Для логнормального распределения 6392 0,95 12 5,23 . Вид полученных кривых рис. 7 также не соответствует экспоненциальному закону распределения продолжительности времени обслуживания, который фигурирует, например, в 3 6. Справедливости ради стоит заметить, что на первый план выходят не законы распределения времени обслуживания заявок, а перечисленные ранее характеристики таких распределений, участвующие в формировании критериев производительности ПБД, а также наборы управляющих параметров, которые в состоянии улучшить значения этих критериев. 2. нелинейно зависит от рис. 8. Это характерно только для тех диапазонов и, которые менялись в процессе экспериментов 510,1,2510, 510,1,2510 . Логарифмический рост среднего времени выполнения запросов объясним двумя моментами способностью СУБД параллельно выполнять часть запросов и тем, что суммарная продолжительность обслуживания всех запросов для всех значений ни разу не вышла за пределы 1 ч 3 600 000 мс. Существенное увеличение от 210 и выше приводило к зависанию сервера и соответственно к его неспособности обрабатывать поступающие заявки. Очевидно, что нахождение предельных параметров производительности клиент-сервер ных приложений одна из актуальных практических задач, которая может решаться посредством использования разработанной имитационной системы. 3. В связи с ростом накладных расходов операционной системы на поддержку программных потоков возрастание влекущее за собой увеличение общего числа потоков приводило к нарастанию запаздываний фактических моментов времени старта транзакций рис. 9 по отношению к расчетному времени, которое находилось для заданных потокам выделяется память, и требуется время, необходимое для их создания, управления и завершения 11 12. Эксперименты выполнялись на компьютере со следующими характеристиками процес сор IntelR Core TM i5-2400, CPU 3.1GHz, число ядер 4, объем оперативной памяти 4 ГБ. Использование вычислительной системы с более высокими характеристиками увеличивало корректную границу, в пределах которой транзакции стартовали в строго расчетное время. Можно заключить, что началу экспериментов с моделируемой системой должно предшествовать определение предельного значения для используемого вычислительного оборудования, при котором время старта последней транзакции не превысит 3 600 000 мс. Невыполнение данного условия говорит о необходимости выбора более производительного оборудования или использования иных, непоточных вычислительных моделей. Цель работы состояла в построении адекватной и по возможности простой модели, отражающей существенные аспекты клиент-серверного взаимодействия в приложениях баз данных и позволяющей за ограниченные сроки для заданных входных условий получать оценки производительности таких систем. Проведенные эксперименты показали пригодность модели для решения поставленной задачи, одновременно обнаружив сложности в ее реализации, связанные с ограниченной возможностью вычислительной системы, состоящей из одного или двух компьютеров, имитировать работу реальной вычислительной среды, включающей сервер баз данных и сколь угодно большое число клиентов. Возможности разработанной и реализованной в виде программного стенда модели не ограничиваются исследованием производительности ПБД. Перечислим задачи, которые актуальны и требуют решения исследование максимальных предельных возможностей программно-технической си стемы, реализующей функции приложений баз данных управление входными потоками требований, направленное на минимизацию продолжительности отклика системы конфигурирование параметров среды выполнения таких как блокировки, индексы, буферы, дисциплина очереди и т. д. под требуемые значения показателей производитель ности. "}
{"title": "МЕТОД ПОВЫШЕНИЯ РОБАСТНЫХ СВОЙСТВ   ЛИНЕЙНОЙ ЗАМКНУТОЙ СИСТЕМЫ В УСЛОВИЯХ   СТРУКТУРНО-ПАРАМЕТРИЧЕСКОЙ НЕОПРЕДЕЛ ННОСТИ ОПИСАНИЯ   ПЕРЕДАТОЧНОЙ ФУНКЦИИ ОБЪЕКТА УПРАВЛЕНИЯ  ", "absract": "Для линейных систем управления, состоящих из объекта управления со структурно-параметрической неопределенностью в описании и модального регулятора, обоснована мера робастных свойств устойчивости и качества управления. Разработан алгоритм вариации настроек модального регулятора, последовательно повышающий меру робастности замкнутой системы. Предложенный алгоритм может быть реализован на ЭВМ. : робастность, модальный регулятор, структурно-параметрическая неопределенность.  Далее предполагается, что операторы  и  взаимно простые, т. е. не имеют общих нулей.  ", "text": "Классическая постановка задачи синтеза модального регулятора может быть сформулирована следующим образом. Линейный одномерный динамический объект управления назначается дифференциальным уравнением -го порядка, записанным в операторной форме, 1 здесь входной управляющий сигнал, выходной управляемый сигнал, непрерывное время и дифференциальные операторы . Здесь и далее под записью понимается полиномиальный оператор в степени, где постоянные коэффициенты, оператор дифференцирования по времени . Полиномиальному оператору соответствует алгебраический полином, где переменная преобразования Лапласа. Оператор и соответствующий полином будем называть точечным, подразумевая, что в пространстве коэффициентов данному оператору соответствует точка. Качество управления назначается ограниченной односвязной областью, определяющей допустимое расположение полюсов передаточной функции ПФ на комплексной плоскости . Предполагается, что область расположена слева от мнимой оси. В технологии синтеза модального регулятора описанной в работе 1 регулятор ищется в виде дифференциального уравнения -го порядка, 1, 2 здесь заданный эталонный сигнал. В результате ПФ замкнутой системы имеет вид, 3 Известно, что для объекта управления, заданного дифференциальным уравнением -го порядка, любое заданное расположение полюсов ПФ 3 можно обеспечить динамическим регулятором 2 порядка 1 и выше 2. Коэффициенты регулятора находятся из уравнения 2 1, 1, 1, 1, 4 где за 2 1, принят характеристический полином эталонной системы. Полином 2 1, выбирается произвольным образом при условии, что все множество его корней 2 1, 0, лежит внутри области, т. е. выполняется int . 5 Приравнивая коэффициенты при одинаковых степенях переменной в левой и правой частях уравнения 4, получаем систему линейных алгебраических уравнений, где матрица, 1,2 1, 1,2 1, составленная из коэффициентов полиномов, и, объекта 1 по правилу 0, 0, при 1,2 1, 1, 1, и при 1, 1,2 1, искомый вектор коэффициентов регулятора 2 далее иногда будет удобно представлять его состоящим из двух векторов, и, тогда вектор символически записывать в виде, вектор, составленный из коэффициентов полиномов 2 1, и, 1, 1,2 1. Подобная задача синтеза регулятора и последующего анализа качества управления усложняется, если в описании объекта присутствует неопределенность. Будем выделять неопределенность объекта, связанную с неопределенностью коэффициентов дифференциального уравнения 1 параметрическая неопределенность, и неопределенность, связанную с неточностью задания порядка дифференциального уравнения структурная неопределенность. Проблема синтеза регулятора и анализа качества управления в условиях структурнопараметрической неопределенности описания в объекте достаточно широко представлена в литературе. Можно выделить два главных направления, в рамках которых решается такая задача 1 принцип исключения нуля 2 методы теории . Принцип исключения нуля впервые сформулирован в работах 4 5. Обобщениям принципа исключения нуля на различные случаи, а также разработке на их основе вычислительных методик проверки робастной устойчивости и качества управления посвящено большое количество статей, например, 69, а также 3. Следует отметить, что критерии, предложенные в перечисленных работах за исключением статьи 3 требуют, чтобы количество нулей и полюсов в ПФ замкнутой системы было конечно, и, более того, заранее известно, что делает данные критерии пригодными для исследования в условиях параметрической неопределенности, но противоречит понятию структурной неопределенности. Кроме того, задача синтеза регулятора заданного динамического порядка, оптимального с точки зрения робастных свойств устойчивости и робастного качества управления для замкнутой системы остается нерешенной. Методы теории, представленные в работах 1013 и др., позволяют формулировать достаточное условие робастной устойчивости при наличии структурно-параметрической неопределенности описания, однако существенным недостатком таких критериев является использование метрики операторов, что сильно ограничивает классы операторов, для которых выполняются условия этих критериев. В настоящей статье развиваются результаты, полученные нами в 3. В указанной работе введена функция которую можно рассматривать в качестве меры робастных свойств, позволяющая сравнивать свойства робастности замкнутых систем, состоящих из одного объекта управления, но с разными настройками регулятора. В данной статье разрабатывается алгоритм вариации настроек регулятора заданного порядка, последовательно повышающий меру робастности замкнутой системы. Объект управления со структурно-параметрической неопределенностью будем задавать в виде, 6 здесь, семейства множества дифференциальных операторов, 1, 1, 1, . Далее предполагаем, что области, и в 6 связны. В записи 6 подразумевается, что пара, описывает ту часть объекта управления, для которой уже выполняются свойства устойчивости и качества управления, заданного областью т. е. предполагается, что для всех операторов из множеств, и, выполняются int, int, 7 где и обозначены множества нулей всех дифференциальных операторов, и, соответственно. Очевидно, регулировать следует только оставшуюся часть объекта управления т. е. операторы, в этом смысле пара, далее будет именоваться структурными возмущениями, а, основной динамикой подлежащей регулированию. Для объекта 6 регулятор 2 порядка 1 будем рассчитывать по классической схеме синтеза, изложенной в предыдущем разделе в качестве точечного объекта управления 1 примем, где операторы, и, принадлежат основной динамике объекта 6. Замыкая объект 6 рассчитанным регулятором, получим ПФ, 1, 1, 1, . Знаменатель ПФ является характеристическим полиномом замкнутой системы 2 1, 1, 1, . С учетом определений операторов, и, в 6 получим окончательное выражение для 2 1, 2 1, 2 1, e 2 1, 1, 1, e e, 1, . 8 Следуя статье 3, для семейства полиномов 8 введем новое множество функций, определенных следующим образом каждый элемент 2 1, множества 8 разделим на полином, получим новый элемент 2 1, 2 1, или, в развернутом виде, 2 1, 2 1, 1, 1, 1, 1, . Множество элементов 2 1, обозначим за 2 1, таким образом 2 1, 2 1, 2 1, 1, 1, 1, 1, . 9 Как следует из определения 9, семейство 2 1, представляет собой множество дробных функций 2 1, каждая из которых имеет в общем случае 2 1 нулей и полюсов. В этом смысле будем говорить, что и семейство 2 1, имеет 2 1 нулей и полюсов. В соответствии с условием 7, все полюса дробных функций 2 1, лежат внутри области . Пусть из множества функций 2 1, найдется хотя бы одна такая, что все ее нули лежат внутри области, тогда потеря количества нулей функции 2 1, находящихся внутри области, происходит только в следующих случаях 1 при вариациях векторов, в 6 часть нулей и полюсов функции 2 1, в 9 совпадает поскольку совпадающие нули и полюса находятся внутри области, то их сокращение не повлияет на вариацию аргумента функции 2 1, 2 при переходе хотя бы одного нуля функции 2 1, через границу области . Пусть 1 все множество нулей семейства полиномов, лежит внутри области 2 семейство функций 9 содержит хотя бы одну такую, что все ее нули лежат внутри . Тогда для того, чтобы все множество нулей функций 9 лежало внутри области, достаточно, чтобы выполнялось условие 0, где введены обозначения min, 10, 11 min 2 1, 1, 1, 1, max 1, max, . Доказательство данного утверждения следует из результатов, изложенных в статье 3. Утверждение 1 формулирует достаточное условие робастной устойчивости и робастного качества управления для 8. Функция может служить в качестве оценки свойств робастного качества управления. Расчет функции для каждой точки границы области сводится к решению задач поиска экстремумов функций с ограничениями на векторы варьируемых параметров, заданных областями, и . Указанная задача поиска условного экстремума функций решается методом неопределенных множителей Лагранжа. В настоящей работе мы воспользуемся свободой в выборе расположения нулей эталона 2 1, ограниченной условием 5 с целью максимизации . Ниже излагается алгоритм поиска вектора коэффициентов регулятора 2, максимизирующего значение . Рассмотрим процедуру повышения как итерационный процесс обозначим за номер итерации алгоритма. Для удобства изложения номер итерации будем указывать в качестве первого из аргументов векторов и функций например, вектор, полином, функции, и т. д. далее будут записаны как, и, соответственно. Вектору соответствует характеристический полином эталона,2 1, который определяется формулой,2 1, 1, 1, 12 где, и, полиномы, принадлежащие основной динамике объекта управления 6. На вариации вектора будем накладывать условие int, 13 здесь за обозначено множество нулей полинома,2 1, . Требование выполнения условия 13 на каждой итерации алгоритма является существенным, поскольку в противном случае нельзя гарантировать выполнения всех условий утверждения 1. На начальной итерации 0 алгоритма вектор 0 рассчитывается по формуле 12 для заданного полинома 0,2 1, выбираемого из условия 13. Для 0 по формулам 10 и 11 определяются 0, и 0. На очередной -й итерации алгоритма будем искать вектор такой, что 1 после подстановки его коэффициентов в 12 для,2 1, выполняется 13 2 выполняется 1 . 14 Обозначим за все множество точек границы, в которых функция 1, принимает минимальное значение argmin 1, . Предполагая, что число таких точек на границе на -й итерации алгоритма конечно, множество может быть переписано в виде argmin 1, 1, . Для каждой точки найдем нормированный обобщенный градиент функции 1, по обозначим его за, если, если min, если min 0, если min 0, если 1, 0, и 0, и 0, если 1, 0, или 0, ил и 0 Re, Re, Im, Im, Re, Re, Im, Im, 1, 1,2 1, 1, Re, Im, . Множество обобщенных градиентов, вычисленных для всех точек множества обозначим как, . Индексное множество разделим на два подмножества, . В случае если не пусто, из множества формируем два множества, . Множества и определяют направления градиентов и антиградиентов для функции 1, в точках множества . Пусть существует вектор такой, что выполняются условия, 0, 15 тогда вектор определяет направление возрастания функции 1, во всех точках минимума разумеется, за исключением тех точек, где градиент обращается в ноль. Проблема построения поиска вектора, обеспечивающего выполнение условий 15, может быть решена одним из алгоритмов построения фазового портрета например, алгоритмом Гаусса Зайделя, изложенным в 14. Если существует, вектор будем искать в виде 1, 0, 16 где за обозначен модуль вектора, параметр, определяющий величину шага алгоритма вдоль выбранного направления . Шаг будем выбирать из условий 13 и 14 к вопросу выбора такого мы еще вернемся. Случай означает, что во всех точках множества градиент функции 1, по либо не определен, либо равен нулю . В этом случае в 16 в качестве вектора последовательно выбираются векторы ортонормированного базиса в . Условия останова алгоритма 16 1 не существует не найден вектор, являющийся решением задачи 15 2 выполнение условий достижения локального максимума функции, по параметру хотя бы в одной из точек множества, 0, 0, . 17 Здесь использованы обозначения min, если 0, 0, если 0, если 0, 0, если 0, 1 1 1 1, 1 1, 1 1 1 1, 2 1 2 1, 1 min, если 0, 0, если 0, если 0, 0, если 0, здесь и производные функций и по переменной 1 1, 1 1 . Если ни одно из перечисленных условий останова не выполняется, определяется шаг алгоритма 16. По смыслу поиск такого удовлетворяющего условиям 13 и 14 состоит из 2-х этапов. Этап 1. Определяется открытый интервал обозначим его за 0, 0, где за обозначено такое значение параметра в 16, при котором нули полинома,2 1, в 12 выходят на границу области . Искомое значение если оно существует определяется формулой min, 18 здесь за обозначено положительное решение системы уравнений Re 1,2 1, Re 1,2 2, 0, Im 1,2 1, Im 1,2 2, 0, 19 в 19 введено обозначение 1 1 1,2 2, за 1,2 1 обозначены компоненты вектора . Решение переопределенной системы уравнений 19 относительно параметра существует только при условии Re 1,2 2, Re 1,2 1, 1 Im 1,2 2, Im 1,2 1, 20 при этом значение определяется выражением Re 1,2 1, если Re 1,2 2, 0, Re 1,2 2, Im 1,2 1, если Im,2 2, 0, Im 1,2 2, 21 Если значение 21 отрицательно или такого значения вообще не существует, значит, не существует такого положительного значения в 16, при котором нули полинома,2 1, выходят на границу области в точке . Таким образом, в качестве в выражении 18 можно принять любое сколь угодно большое значение. Прежде чем перейти ко второму этапу процедуры нахождения отметим, что вектор являющийся решением задачи 15 соответствует общему направлению возрастания функции 1, во всех точках множества и, возможно, убывания в других точках границы . Следовательно, в силу непрерывной зависимости функции от вектора а значит, и от, существуют такие значения 0, при которых функция возрастает. Этап 2. Внутри интервала ищется такой вложенный интервал с закрытыми границами 0, что для выполняется условие 14. Значение может быть найдено одним из методов прямого поиска экстремума функции на заданном интервале . Приведенные рассуждения можно рассматривать как нестрогое доказательство изложенного ниже алгоритма. Для работы алгоритма необходимо задать параметры алгоритма и выполнить следующие предварительные расчеты 1 задать число, определяющее максимально допустимое число точек минимума функции на границе области, и число, определяющее величину зазора при решении задачи 15 2 в качестве начальной итерации 0 задать характеристический полином эталона 2 1, удовлетворяющий условию 13, и по классической схеме синтеза модального регулятора рассчитать вектор 0 . Шаг 1. Расчет функций, и по формулам 10, 11. Проверка условия, 22 если данное условие выполнено, переход на шаг 2, в противном случае переход на шаг 9 с формулировкой превышение допустимого числа точек минимума функции, на . Шаг 2. Формирование множеств, и индексных множеств, . Шаг 3. Проверка условия . Если данное условие выполнено переход на шаг 5, в противном случае переход на шаг 4. Шаг 4. В качестве выбирается любой ранее не выбиравшийся вектор ортонормированного базиса в выбранный вектор вместе с векторами, выбранными на предыдущих итерациях запоминаются. В том случае если такой вектор есть, переход на шаг 6 если таких векторов нет, переход на шаг 9 с формулировкой достигнут локальный максимум функции . Шаг 5. Формируются множества, и решается задача 15. В случае если вектор, являющийся решением задачи 15, не найден, переход на шаг 6 в противном случае на шаг 9 с формулировкой достигнут локальный максимум функции . Шаг 6. Вектор ищется в виде выражения 16. Проверяются условия 17. Если условия 17 не выполнены, переход на шаг 7, в противном случае переход на шаг 9 с формулировкой достигнут локальный максимум функции . Шаг 7. По формулам 18 и 19 определяется интервал, внутри которого затем ищется такое значение, при котором выполняется условие 14 методами прямого поиска экстремума функции на заданном интервале. Если искомое значение не найдено, переход на шаг 4. Шаг 8. Принять 1 и перейти на шаг 1. Шаг 9. Останов. Данный алгоритм обеспечивает нахождение такого вектора настроек регулятора 2, при котором функция 10 достигает своего локального максимума при условии, что ни на одной из итераций алгоритма не нарушается условие 22. В настоящей статье разработан алгоритм вариации настроек модального регулятора 2, последовательно повышающий меру робастности 10 замкнутой системы. Алгоритм не требует точного знания операторов структурных возмущений достаточно знания функции, определенной выражением 11. Данный алгоритм может быть реализован на ЭВМ. Изложенные результаты можно рассматривать как методику повышения робастных свойств для систем, состоящих из линейного объекта управления, содержащего структурнопараметрическую неопределенность в модели объекта, и модального регулятора. "}
{"title": "ИСПОЛЬЗУЮТ ЛИ РОССИЙСКИЕ УЧЕНЫЕ   СОВРЕМЕННЫЕ ТЕХНОЛОГИИ НАУЧНЫХ КОММУНИКАЦИЙ", "absract": "Веб-технологии и социальные сети качественно изменили систему научных коммуникаций. Насколько  успешно российские ученые ими пользуются? Это исследование состоит из двух частей. В первой были изучены персональные сайты (при их наличии) действительных членов и членов-корреспондентов Российской академии наук. Во второй – степень проникновения социальной сети ResearchGate в российские научные организации. Оказалось, что около половины выдающихся ученых имеют свой персональный сайт на русском языке, но из них более 90 % не имеют сайта на английском. Также более 90 % ученых не размещают на своих сайтах ссылки  на полные тексты статей и не зарегистрированы в ResearchGate. : персональный веб-сайт, социальная сеть, ResearchGate, РАН, библиография.  Например, mathnet.ru, scholar.google.com, arxiv.org и др. ", "text": "После принятия майских указов Президента РФ в 2012 г. наметился устойчивый рост количества российских публикаций в международных индексах цитирования Web of Sciences и Scopus 1. Однако при этом наукометрические исследования фиксируют, что у российских ученых показатели цитируемости остаются меньше среднемировых. Это косвенно свидетельствует о пока еще недостаточно тесной интеграции российской науки в мировую, в том числе о низкой эффективности использования современных технологий продвижения результатов научно-исследовательской деятельности в среде Интернет. Одной из таких технологий является персональный веб-сайт ученого, который содержит биографию, контактные данные, сведения об основной области исследований, библиография, полные тексты публикаций и лекций. Другим часто используемым каналом распространения являются репозитории публикаций открытого доступа. Еще одним постоянно усиливающимся каналом продвижения являются социальные сети упоминания о новых научных результатах все чаще можно встретить в Facebook и Twitter. Однако наиболее высокую популярность у ученых имеют специализированные научные социальные сети, такие как Academia.edu, ResearchGate, Mendeley. ResearchGate предоставляет широкий спектр возможностей для продвижения научных результатов, дискуссий и особенно популярна в среде российских исследователей. В данной работе мы, оставляя за скобками вопросы эффективности этих каналов, изучим, насколько активно они применяются российскими учеными. В первой части были исследованы персональные веб-сайты, разделы и страницы выдающихся ученых, расположенные как на отдельном домене, так и на сайтах их организаций. Хотя существуют и другие каналы представления трудов ученого в Интернете, однако персональные веб-сайты предлагают наиболее гибкие возможности размещения информации контактные данные, биография образование, опыт работы, город проживания, награды и степени, область интересов, участие в конференциях, курсы лекций или презентации с конференций. Во второй части статьи предметом изучения будет степень присутствия результатов российских исследований в научной социальной сети ResearchGate. Для этого будет сделана оценка доли отечественных организаций, ученых и их публикаций, которые отражаются в этой базе данных. Анализ проведем в разрезе областей наук и географических регионов, что позволит выявить сильные и слабые сегменты отечественной науки в задачах продвижения научных результатов. В качестве объектов исследования были взяты веб-сайты академиков и членов-кор респондентов РАН, РАМН и РАСХН трех академий, которые в 20132014 гг. были объединены в одну во время очередного этапа научной реформы. Эта выборка в несколько тысяч человек из сотен тысяч российских ученых хоть и не очень большая, но достаточно репрезентативная. Кроме того, в нее входят наиболее выдающиеся представители российской науки, а значит, их результаты наиболее востребованы в информационном пространстве. Были сформулированы следующие вопросы для изучения Каковы основные характеристики пол, возраст, специальность, отделение, академия ученых, которые имеют персональные веб-сайты Насколько много информации содержит персональный веб-сайт ученого, позволяет ли ознакомиться с его библиографией, основными интересами и текстами публикаций На первом этапе были составлены общие списки академиков и членов-корреспондентов РАН, РАМН и РАСХН, опубликованные в русскоязычной Википедии в январе-марте 2016 г. далее словом ученый мы называем академиков и членов-корреспондентов из этого списка. Итоговый список содержал 1 843 человека табл. 1, для каждого из которых были выгружены из Википедии следующие поля ФИО ученого, дата рождения, дата избрания, специальность, степень, звание академик или член-корреспондент, наименование отделения академии, к которому он относится, признак наличия персональной страницы в Википедии. К сожалению, эти данные оказались неполными для РАМН и РАСХН в большинстве случаев отсутствовала дата избрания, а также специальность ученого. В таких случаях специальность мы указывали согласно ученой степени, а год избрания уточнялся по другим источникам. Далее все ученые объединялись в общий список, в котором были сформированы предметные группы табл. 2. Следующим этапом стал поиск персонального веб-сайта академиков и членов-коррес пондентов из списка. Критерием отбора служило нахождение ссылки на сайт на первой странице поисковой выдачи Google по запросу ФИО ученого, другими словами, видимость этого сайта. Следует заметить, что рассматривались только сайты, которые создавались самими учеными, к которым они имели доступ и могли актуализировать информацию в любое время. Поэтому из результатов позднее были убраны ресурсы справочно-энциклопедического Распределение ученых по региональным отделениям и академиям Отделения РАМН РАН РАСХН Всего Дальний Восток 5 38 3 46 Сибирь 36 127 12 175 Урал 7 75 5 87 Центр 374 895 266 1535 Предметные группы и соответствующие им степени ученых Предметная группа Обозначение Степень Физика и математика ph.-math. д. ф.-м. н. История hist д. и. н. Экономика eco д. э. н. Общественно-гуманитарные науки other д. иск. н., д. к. н., д. пол. н., д. психол. н., д. соц. н., д. фил. н., д. филос. н., д. ю. н. Сельскохозяйственные науки agro д. с.-х. н. Биология bio д. б. н. Химия chem д. х. н. Науки о Земле geo д. г. н., д. г.-м. н. Медицина med д. м. н., д. в. н., д. фармацевт. н. Технические науки tech д. т. н. характера . Для каждого найденного персонального веб-сайта или веб-страницы методом de-visu отмечалось наличие на ней английской версии, библиографии и полных текстов публикаций. Любопытно, что всего 2 сайтов ученых оказались расположенными на отдельных доменах, тогда как остальные находятся на доменах институтов, в которых работают ученые. Прежде всего отметим распределение по половому признаку 1 747 95 всех ученых мужчины, и лишь 96 5 женщины. Однако если рассмотреть процентное соотношение по академиям, то можно заметить, что в РАМН 9 39 ученых женщины, РАН 3 38, РАСХН 7 19. Такой низкий процент присутствия женщин-ученых среди академиков и членов-корреспондентов не является неожиданностью, поскольку ранее было показано, что чем выше степень и звание рассматриваются, тем выше гендерное неравенство и ниже доля женщин 27. Возрастное распределение оказалось следующим 2 ученых в возрасте от 37 до 50 лет, 12 от 51 до 60, 29 от 61 до 70, 33 от 71 до 80, 21 от 81 до 90, 2 ученых старше 90 лет. Результаты показали, что 978 53 ученых из 1 843 имеют персональный веб-сайт, в то время как у 865 47 он отсутствует. При этом лишь 20 2 ученых имеют сайт на отдельном домене, а 13 1,3 страницу с данными в формате pdf. В табл. 3 представлено распределение доли наличия веб-сайтов, а также английской версии сайта, библиографии и полных текстов публикаций на нем по отделениям. Как можно заметить, наиболее активным отделением по наличию персональных сайтов и их контента является Сибирское отделение. Это может быть связано с проведением в 2008 и 2010 гг. конкурса сайтов научных институтов . Одним из его критериев было наличие на сайте института персональных страниц ученых, а также публикаций и научно-популярных статей сотрудников. Конкурсные баллы начислялись за наличие англоязычной версии не только главной страницы и страницы с контактами, но и всех внутренних страниц, включая информацию о сотрудниках. Вероятно, это подтолкнуло институты СО РАН к размещению более детальной информации о своей деятельности. Наличие у членов РАН персональных сайтов и сведений о публикациях Региональные отделения РАН Всего членов РАН Сайт Библиография Полные тексты трудов русскоязычный англоязычный Дальний Восток 46 43 20 0 7 8 5 5 Сибирь 175 64 112 5 15 26 72 6 17 Урал 87 43 38 2 5 12 25 3 6 Центр 1 535 53 808 3 82 15 441 3 98 Любопытным оказалось распределение ученых, имеющих сайты, по предметным областям рис. 1. Среди лидеров оказались историки 89, представители общественно-гумани тарных наук 87 . Средние показатели продемонстрированы в областях Физика и математика 60, Химия 60 и Технические науки 51 . Самый низкий показатель у представителей сельскохозяйственных наук 23 . Совершенно не радует фактор доступности персональных сайтов для зарубежных пользователей лишь 10 найденных веб-сайтов имеют английскую версию. Примечательно, что самый большой показатель наличия английской версии сайта у представителей общественногуманитарных наук без истории и экономики. При этом историки, несмотря на наибольшую долю наличия сайта, имеют только 3,2 сайтов с английской версией. У химиков, математиков и физиков более высокие показатели 7,1 и 5,2 соответственно, хотя по доле веб-сайтов уступают историческим наукам. Представители сельскохозяйственных наук имеют наименьший процент наличия сайтов, а английской версии не содержит ни один из них. Также и ученые РАМН практически не имеют англий ской версии на своих веб-сайтах 0,6, а на Дальнем Востоке этот показатель равен 0. Рассматривая региональный срез рис. 2, отметим, что распределение меняется и в зависимости от предметной области. Так, стабильно высокие показатели наличия русскоязычного сайта имеют общественно-гуманитарные науки и науки о Земле. Однако наблюдаются провалы в некоторых региональных отделениях в биологии Урал, Центр, химических науках Сибирь и Дальний Восток, экономике Урал, физико-математических Дальний Восток и технических Дальний Восток и Урал науках. Для ознакомления с работами ученого необходимо, чтобы на сайте были размещены его труды в виде библиографического списка или, что гораздо лучше, в виде полных текстов публикаций. Оказалось, что библиографический список содержат 55 сайтов распределение по областям наук показано на рис. 3, однако чаще всего это не полный список, а перечисление основных трудов без указания ссылок на полные тексты. Еще один печальный результат исследования состоит в том, что полные тексты публикаций были найдены только на 4 веб-сайтов в виде ссылки на сторонние ресурсы, либо ссылки на скачивание документа. Если рассмотреть распределение по наукам, то самый большой показатель 18 имеют общественно-гуманитарные и исторические науки, а у сельскохозяйственных наук полные тексты публикаций отсутствуют. Также ученые исторических и общественно-гуманитарных наук, за исключением экономики, чаще других имеют страницу в Википедии. В свою очередь, страницы ученых медицинских и сельскохозяйственных наук встречаются реже 33,6 и 16,8 соответственно. При рассмотрении ученых РАН на наличие статьи в Википедии и веб-сайта было выявлено, что каждый академик РАН имеет персональную страницу в Википедии рис. 4, 5. Это говорит о большой системной работе по созданию этих страниц. Интересно и то, что 70 академиков РАН имеют и сайт, и страницу в Википедии. Наблюдается закономерность члены-корреспонденты в каждой академии отстают по этому показателю от академиков почти в 2 раза. Рассматривая связь между наличием у ученого сайта и его возрастом, на рис. 6 можно заметить нисходящий тренд, указывающий на то, что чем старше ученый, тем реже у него есть персональный сайт. Более ярко он выражен у членов-корреспондентов РАН. Испанские ученые приходят к выводу, что маленький процент наличия сайта у европейских ученых обосновывается именно тем, что возраст большинства из них выше 60 лет, поэтому для них освоение новых технологий коммуникаций может вызывать сложности 5 6. Более того, имея высокую репутацию в научном сообществе, они могут не придавать этому особого значения. Вероятно, схожие причины имеются и в нашем случае. Сравним результаты нашего исследования с похожим исследованием, в котором испанские ученые рассматривали 5 6 аналогичные вопросы применительно к выборке высоко цитируемых европейских ученых табл. 4. Размеры этих выборок практически одинаковы, в обоих случаях рассматриваются выдающиеся ученые, хотя критерии их отбора отличались. Сравнение с аналогичным исследованием европейских высоко цитируемых ученых EHC European Highly Cited Показатель РАН EHС чел. чел. Общее количество 1 876 1 498 Количество женщин 98 5 73 5 Наличие персонального сайта 994 53 1030 69 Сайт только на родном языке 888 97 98 9 Сайт только на английском языке 0 811 На сайте есть оба языка 106 153 Наличие библиографии 552 55 40 Наличие полных текстов публикаций 127 12 509 47 В целом видно, что европейские ученые лучше используют новые формы научных коммуникаций персональные веб-сайты встречаются у них на 16 чаще. С другой стороны, не поддаются сравнению другие два показателя наличие англоязычной версии сайтов и возможность ознакомиться с полными текстами публикаций, которые находятся на уровне 12 от числа ученых, имеющих персональный сайт, и 7 от всех рассматриваемых ученых. Иными словами, более 90 российских выдающихся ученых не используют возможности персональных сайтов для ознакомления коллег с результатами своей деятельности. Если сравнить распределение по наукам, то общественно-гуманитарные науки, за исключением экономики, имеют наибольшую долю наличия веб-сайтов. В европейском же исследовании среди лидеров оказываются ученые из областей экономических и технических наук. Еще одним каналом продвижения научных публикаций, рассматриваемых в этой работе, являются научные социальные сети. Мы сконцентрировались на социальной сети Research Gate, как наиболее популярной среди российских исследователей и предоставляющей наиболее интересный функционал и возможности детализации для нашего исследования. В данном случае целесообразно будет отказаться от конкретной выборки ученых и рассмотреть все данные о российских исследованиях. В отличие от первой части, здесь уже появляется возможность получить все данные из одной системы и составить полноценную картину. В пользовательском режиме ResearchGate для каждой зарегистрированной организации доступны данные об исследователях и их публикациях. Важно, что их регистрация в системе возможна только с согласия самих ученых. Фактически это означает, что чем больше процент зарегистрированных от организации пользователей, тем более активно ее сотрудники пользуются современными средствами коммуникации. Авторам настоящего исследования не удалось обнаружить официальной базы данных российских научных организаций, поэтому в качестве основы был использован каталог организаций, зарегистрированных в eLibrary.ru. Для анализа показателей организации в Re searchGate в качестве опорных данных количества исследователей в организации и числа их публикаций также использовались показатели этой системы на начало 2017 г. К сожалению, ResearchGate, несмотря на многочисленные просьбы научного сообщества, пока не предоставляет API для извлечения данных сторонними пользователями. Для сбора показателей был реализован алгоритм, который в автоматическом режиме извлекал значения целевых параметров, эмулируя работу обычного веб-пользователя рис. 7. Необходимо отметить, что определенную сложность представлял собой процесс сопоставления организаций в исходной базе данных и базе ResearchGate, так как в последней названия часто заметно отличались от официальных. Сопоставление проводилось в полуавтоматическом режиме выбором подходящего варианта из списка наиболее похожих, отсортированного по увеличению расстояния Левенштейна между парами наименований 7. Алгоритм сбора данных мог осуществлять свою работу регулярно, выполняя мониторинг изменений российского присутствия в научной социальной сети. Однако в ноябре-декабре 2016 г. компания ResearchGate произвела масштабные изменения в структуре научных организаций, переведя значительную часть академических научных организаций в разряд подразделений Российской академии наук, что закрыло возможность для корректного мониторинга и анализа этих данных как отдельных научных единиц. Это стало большой неожиданностью, и нам не удалось найти рационального объяснения этим изменениям. Последующие результаты и выводы сделаны на основании сведений, которые были получены до описанных модификаций, в мае-сентябре 2016 г. Для начала рассмотрим долю организаций, зарегистрированных в ResearchGate в географическом разрезе сгруппированы по федеральным округам рис. 8. Ожидаемо среди лидеров оказались округа с наиболее сильно развитыми научными центрами. Но даже для этих округов данные об организациях в ResearchGate удалось обнаружить менее чем в половине случаев. А в Северо-Кавказском федеральном округе в ResearchGate зарегистрирована лишь каждая девятая организация. Оказалось, что в среднем в этой социальной сети представлены данные примерно о каждой четвертой научной организации в России. Еще более важными представляются показатель средней вовлеченности авторов и доля размещенных публикаций рис. 9. Для этих целей данные из ResearchGate были сопоставлены с данными по количеству авторов и публикаций соответствующей организации в eLibrary.ru. Хотя распределение по округам почти не изменилось, сами показатели оказались заметно ниже не более 12 авторов разместили информацию о себе не более 8,2 публикаций присутствует в ResearchGate. Необходимо отметить, что, так как использовались данные об общем количестве авторов и публикаций в БД eLibrary, трудно ожидать, что соответствующие показатели в Research Gate, обеспеченные социальной активностью преимущественно молодых исследователей в последние несколько лет, могут к ним приблизиться. При этом показательной является общая динамика роста количества зарегистрированных российских пользователей этой социальной сети и размещенных ими публикаций. За период с мая по сентябрь 2016 г. Количество пользователей выросло с 48 794 до 49 744, что позволяет оценивать годовой прирост в 6, а количество публикаций с 258 710 до 292 563, в годовом выражении рост мог составить более 35 . Эти цифры позволяют говорить о высоком интересе российских ученых к продвижению результатов своих исследований в общем и к этой социальной сети в част ности. Проведенное исследование позволяет прийти к следующим выводам российские организаций и ученые слабо используют научные социальные сети для размещения своих результатов наиболее высокие показатели у исследователей Москвы, Санкт-Петербурга, Центрального и Сибирского федеральных округов разработчики сети ResearchGate ведут весьма неустойчивую политику управления мастер-данными, что приводит к невозможности более использовать эту систему в качестве наукометрического источника данных. Отсутствие персональных веб-сайтов у 47 выдающихся российских ученых членов Российской академии наук может быть связано с отсутствием данной возможности на сайте института или же недостаточным для ученого функционалом. Наши европейские коллеги также отмечают, что выдающиеся ученые нередко находятся в зрелом возрасте, что само по себе может быть барьером к использованию новых технологий научных коммуникаций. От себя добавим, что может создаться ложное впечатление, что ученый с мировым именем вообще не нуждается в персональном сайте. И это действительно так, если рассматривать сайт лишь как средство продвижения своих результатов. Однако современная система научных коммуникаций выстраивается именно вокруг сетевых технологий, и отсутствие в этом новом научно-информационном пространстве важных узлов а именно их создание является признаком выдающихся ученых негативно отражается на его качестве. Если говорить о действительно современных технологиях научных коммуникаций, то персональные сайты уже едва ли можно отнести к таковым. Последние 5 лет активно развиваются научные социальные сети, предлагающие новые инструменты для взаимодействия. В дополнение к институциональным репозиториям IR institutional repositories, по сути являющимся электронными библиотеками, появляются CRIS-системы current research information system. Эти системы полноценные базы данных, содержащие разнообразные сведения о научной активности отдельных ученых и целых организаций. Безусловно, будущее научных коммуникаций за этими системами. Однако для их внедрения необходимо понимание текущей ситуации и отношения российских ученых к современным технологиям. Наше исследование показало, что ситуация далека от оптимальной. Примерно 9 из 10 выдающихся ученых не имеют персонального сайта на английском языке, а на русскоязычном сайте если он есть не предоставляют ссылки на полные тексты своих трудов. Примерно на том же уровне находится использование научной социальной сети ResearchGate. Как следует из нашего сравнительного анализа, по этим параметрам наши ученые заметно уступают европейским. У авторов этой статьи есть основания полагать, что другие уязвимые места российской науки низкая цитируемость и недостаточное участие в международных коллаборациях могут быть следствием в том числе и недостаточного использования современных технологий научной коммуникации. Поэтому считаем необходимым интенсифицировать процессы их внедрения в научных организациях, что поможет молодым специалистам установить плодотворные связи, а состоявшимся ученым выйти на новый уровень в научной карьере. "}
{"title": "МАТЕМАТИЧЕСКОЕ МОДЕЛИРОВАНИЕ   УПРУГОПЛАСТИЧЕСКИХ ДЕФОРМАЦИЙ ДЛЯ ЗАДАЧ ОБРАЗОВАНИЯ  И ЭВОЛЮЦИИ ГЕОЛОГИЧЕСКИХ ТРЕЩИН    ", "absract": " Представлена математическая модель упругопластических сред с учетом фазовых переходов между твердым телом, жидкостью и газом. Также учтен процесс откола вещества от газовой фазы. Сформулирован один из подходов к записи уравнения состояния упругопластических сред, выписаны основные инварианты, используемые для построения уравнения состояния. Представлены результаты математического моделирования геологических деформаций, приводящих к образованию трещин. : гидроразрыв пласта, упругопластичная среда, математическая модель, метод Годунова, адаптивные и подвижные сетки.", "text": "Задача определения геометрии трещины гидроразрыва пласта ГРП является ключевой при разработке дизайна ГРП. При проведении ГРП осуществляется закачка жидкости гидроразрыва в продуктивный пласт, ограниченный малопроницаемыми пластами. Трещина ГРП по мере закачки жидкости гидроразрыва растет в размерах, при этом наблюдается несколько качественно различных этапов в поведении трещины ГРП. На первом этапе проведения процесса гидравлического разрыва пласта происходит формирование зародыша будущей трещины, для чего в скважину спускается так называемый перфоратор далее производится отстрел зарядов, формирующих отверстия заданного диаметра в стенке скважины и в прискважинной области. После проведения перфорации производится серия тестов, часто объединяемых общим названием мини-ГРП. На этапе мини-ГРП в продуктивном пласте создается трещина некоторых размеров и формы путем нагнетания жидкости ГРП в перфорационные отверстия, при этом ведется тщательная запись поведения графика давления и ряда других параметров приборами, установленными в соответствующих местах наземного оборудования. В некоторых случаях используются забойные приборы для измерения параметров мини-ГРП например, давления и температуры. По характеру изменения давления во время проведения миниГРП делается оценка параметров пласта определение коэффициента утечек, минимальное напряжение закрытия трещины и ряд других. Если после некоторого времени закачки жидкости выключить насосы и предоставить систему самой себе, то будет наблюдаться постепенная утечка жидкости в пласт. Этот процесс может проходить с различной интенсивностью, зависящей от добавок, содержащихся в жидкости ГРП, и от проницаемости пласта. После того как трещина мини-ГРП закроется, а все необходимые параметры теста мини-ГРП будут записаны, производится подготовка дизайна основного ГРП с учетом измеренных параметров. Целью дизайна ГРП является формирование так называемого расписания закачки таблицы с концентрациями закачиваемых агентов, расходами и рядом других контролируемых параметров. По сформированному расписанию начинается закачка основного ГРП с повторным открытием уже сформированной трещины. На последних этапах вместе с жидкостью ГРП производится закачка расклинивающего агента proppant, который предотвращает смыкание стенок трещины после остановки закачки. В технологии ГРП используется основное соотношение теории фильтрации закон Дарси. Данное соотношение связывает расход жидкости, фильтрующейся через проницаемый пласт, с градиентом давления, проницаемостью пород, вязкостью флюидов и площадью притока флюидов. Целью проведения операции ГРП является создание формы и размеров пропированной трещины ГРП, которые позволили бы увеличить площадь притока пластовых флюидов и объем добываемого флюида в единицу времени. Из приведенного описания технологии ГРП можно понять, что размеры трещины контролируются сразу несколькими параметрами прочностью трещиностойкостью пород, вязкостью жидкости ГРП и скоростью фильтрации жидкости в пласт. При определенной скорости утечек давление, создаваемое жидкостью ГРП, может становиться недостаточным для увеличения размеров трещины. Кроме того, непроницаемые пласты, ограничивающие продуктивный пласт, обладают прочностными характеристиками, отличными от аналогичных характеристик продуктивного пласта. В то же время сжимающие напряжения, действующие в покрышке и подошве продуктивного пласта, как правило, превосходят напряжения в продуктивном пласте трещина не может неограниченно расти в высоту из-за действия напряжений в покрышке и подошве продуктивного пласта. Из анализа системы напряжений, действующих на пласт, можно понять, что характер распределения этих напряжений зависит от принятых допущений о свойствах материалов, а также качества экспериментальных данных, описывающих геометрию слагающих пластов сейсмические исследования. При допущениях об изотропном слоисто-анизотропном материале и параллельном горизонтальном залегании пластов постоянной толщины, распределение напряжений будет таким, что трещина ГРП будет располагаться преимущественно в вертикальной плоскости. Однако в случае геологического строения, осложненного наличием пластов с переменной мощностью, разломов и большими углами падения пластов, может формироваться такое напряженное состояние, которое будет приводить к значительному искривлению плоскости трещины. Решение плоской задачи о деформации прямоугольной области с трещиной, нагруженной давлением на ее берегах, было получено в работах Ю. П. Желтова и С. А. Христиановича 1, Г. И. Баренблатта 2 и др. Последовательный обзор первоначальных решений с ясной системой обозначений и подробным объяснением физических допущений для рассматриваемой плоской задачи приведен в сборнике А. Ю. Ишлинского 3. Среди работ последнего времени, которые следует выделить в контексте задачи, решаемой в данной работе, можно от метить решения, полученные в 4. Нельзя не упомянуть многочисленные решения зарубежных авторов 5, которые были получены независимо от работ отечественных ученых. Общим местом для всех решений является допущение о плоской деформации горизонтального сечения вертикальной трещины. В литературе принято обозначать модели такого класса аббревиатурой KGD по первым буквам фамилий авторов Khristianovich Geerstma de Klerk. Альтернативным взглядом на решение плоской задачи о росте трещины ГРП является класс моделей, обозначаемых аббревиатурой PKN Perkins Kern Nordgren. В данном классе моделей рассматривается вертикальное сечение вертикальной же трещины ГРП. Интересной особенностью данного класса моделей является допущение о том, что трещина останавливает свой рост в высоту, когда подвижный фронт трещины достигает покрышки и подошвы продуктивного пласта, в котором и формируется трещина ГРП. Дальнейший рост объема трещины типа PKN происходит за счет роста в длину. Более сложные модели P3D, Planar-3D предполагают, что фронт трещины может проникать на некоторую глубину в ограничивающие пласты. Целью данной работы является решение плоской задачи о росте трещины типа KGD, однако некоторые выводы являются более общими, чем это предполагается в исходной модели KGD. Следует отметить, что в первоначальных моделях использовал ся целый ряд очень сильных допущений трещина остается плоской все время процесса ГРП, утечки жидкости ГРП в пласт отсутствуют, пласт считается однородным и изотропным, напряжения на границах прямоугольной области являются однородными и т. п. Допущение о том, что трещина остается плоской, прямо следует из условий симметрии задачи. Общей особенностью всех упомянутых решений является использование так называемых интегральных уравнений. В частности, решение о перемещении точек, расположенных на берегах трещины, получают путем совместного решения уравнения смазки уравнение Рейнольдса и интегрального уравнения связи между перемещениями и давлением на стенки трещины. Упомянутое интегральное уравнение получают путем того или иного обобщения классической задачи теории упругости о точечной силе, приложенной к упругому полупространству задача Буссинеска. Теоретические решения плоской задачи теории упругости для областей с трещинами приведены в работах Мусхелишвили 6, где представлен подробный вывод соответствующих интегральных уравнений с привлечением ТФКП. Поскольку задача о росте трещины ГРП предполагает рассмотрение физических процессов из различных разделов физики теория трещин, теория фильтрации, гидродинамика и т. д., то получение даже простейшего аналитического решения является очень полезным в теоретических работах по ГРП. Тем не менее, в работах последнего времени основной упор делается на численные решения задачи о росте трещины ГРП. Наиболее удачное численное решение для трещин типа KGD было получено Жаном Дероше Jean Desroches и Марком Терцилином Marc Thiercelin после разработки кода Loramec 7. Многие решения плоской задачи сравнивались именно с решением Loramec. Отметим, что код Loramec позволил смоделировать характер деформации берегов трещины вблизи ее кончика. Вообще говоря, распределение деформаций и давления в кончике трещины ГРП является определяющим для корректной количественной оценки. Более того, известно, что подвижный фронт жидкости ГРП отстает от подвижного фронта растущей трещины, при этом образуется так называемый fluid lag сухой кончик трещины, преимущественно заполненной жидкостью ГРП. На существование лага указывалось ещ в работе 1, однако изучение влияния лага было выполнено в работе 8, а первые численные решения получены с помощью кода Loramec. Отдельно следует упомянуть, что для лабораторной количественной проверки решений Loramec была изготовлена специальная лабораторная установка. Этот факт является особенно интересным, поскольку большинство моделей ГРП не могут быть проверены в условиях лабораторного эксперимента из-за чрезвычайно сложной физики решаемой связанной задачи. В частности, прогиб стенок трещины типа KGD, а также распределение давления по длине трещины подробно рассмотрены в 9 10. Изучение этих работ показывает, что распределение прогибов стенок трещины вблизи кончика трещины подчиняется очень сложным физическим закономерностям, поэтому привлекаются различные асимптотические приближения решения либо используется достаточно мелкая расчетная сетка вблизи кончика трещины ГРП. Теоретический интерес представляет расчет геометрии трещины ГРП, распространяющейся в слоисто-неоднородном пласте при наличии такой системы напряжений на границах прямоугольной области, при которой трещина может искривляться. Кроме того, исследование поведения кончика трещины ГРП численными методами требует привлечения достаточно подробной расчетной сетки, как это было показано в работах 710. Для того чтобы избежать адаптивного перестроения сетки в подвижном кончике трещины, была предложена автомодельная формулировка соответствующих уравнений в подвижной системе координат, расположенной в кончике прямолинейно распространяющейся трещины. При этом все переменные были представлены в безразмерной форме. К сожалению, применение интегральных уравнений для областей, заполненных неоднородным материалом, вызывает большие теоретические сложности 11, поэтому для приемлемой точности решения требуется привлечение конечно-элементной формулировки. Наиболее полная кончено-элементная постановка задачи о росте трещины типа KGD при наличии эффектов фильтрации жидкости ГРП в пласт выполнена в работе 12. В качестве условия на кончике трещины рассматривается специальная формулировка для действующих в кончике сил когезионного сцепления материала, удовлетворяющая условию Г. И. Баренблатта о плавном смыкании берегов трещины. В теоретических расчетах использование такой формулировки предполагает либо выбор изначально мелкой сетки, либо привлечение адаптивной сетки, либо специальной автомодельной формулировки уравнений по аналогии с 7 8. Целью настоящей работы является привлечение механизмов адаптивной подвижной сетки для моделирования роста трещин ГРП. Рассмотрим упрощенную постановку задачи, которая раскрывает основные сложности моделирования с применением адаптивных сеток. Система координат, граничные условия и исходная сетка показаны на рис. 1. Квадратная область с размерами 10 10 м находится в условиях плоской деформации. На границе 5 м перемещения в направлении отсутствуют. На границе 5 м задано давление 25 МПа. Вертикальный зародыш трещины длиной 1 м расположен в начале координат 0. Две равные и противоположные силы 12,5 МН приложены в начале координат к противоположным берегам зародыша будущей трещины. По всей области задано начальное напряжение 25 МПа. Остальные силы и напряжения в начальный момент времени равны нулю. Материал среды обладает модельной трещиностойкостью 500 м . С момента 0 силы, приложенные в начале координат, постепенно возрастают, вызывая рост трещины. При достижении определенной величины нагрузки происходит прирост длины трещины вследствие превышения интенсивности напряжений в кончике трещиностойкости материала, при этом осуществляется адаптивное перестроение сетки с ее измельчением в области кончика трещины. Для анализа используется упрощенный алгоритм, в основе которого лежит VCCT virtual crack closure technique, который хорошо опи сан в 13. Предложенные в литературе методы адаптивного перестроения сеток в применении к задачам гидроразрыва пласта не позволяют моделировать трещины, способные искривляться в поле действующих напряжений и сил. Учитывая относительно сложную физику процесса ГРП, требуются достаточно эффективные формулировки системы уравнений и алгоритмы перестроения адаптивных подвижных сеток, которые позволили бы стабилизировать расчет и сократить расчетное время. Например, из анализа рис. 2 видно, что даже в условиях симметричного нагружения закрепления может происходить искривление траектории трещины, что, очевидно, вызвано ошибками округления при адаптивном перестроении сетки, а не физическими эффектами перераспределения напряжений. Таким образом, можно констатировать, что даже простейшие расчеты динамики трещин с применением современных универсальных симуляторов напряженно-деформированного состояния необходимо проводить с большой осторожностью, поскольку алгоритмы адаптивного перестроения расчетных сеток могут давать ошибочные решения. Проблема выбора эффективного алгоритма генерации адаптивных подвижных сеток особенно актуальна для задач гидроразрыва пласта, поскольку в мире практически не существует лабораторных установок для проверки численных решений по всему спектру рассматриваемых физических эффектов ГРП. Для эффективного моделирования роста трещин ГРП необходимо так подобрать физикоматематическую формулировку основных законов сохранения, уравнений состояния, начальных и граничных условий и уравнений, отвечающих за генерацию расчетных сеток, чтобы обусловить перестроение подвижных сеток на каждом шаге вычислительного процесса. Этому условию удовлетворяет подход, предложенный в 14, который применялся для решения задач о сварке взрывом. Отличительной особенностью этого подхода является применение динамических уравнений равновесия многофазной упругой среды, которые лучше подходят для численного решения задач с применением параллельных вычислений. Следует отметить, что динамические уравнения равновесия пороупругопластической среды применялись в работах В. Н. Николаевского 15, однако уравнения равновесия были записаны в смешанной форме Эйлер Лагранж, что сразу определяло характер решения и ограничивало возможности метода. Настоящая работа посвящена подбору модельного уравнения состояния для описания процесса сварки взрывом с учетом трехфазности модели и является обобщением формулировок уравнения состояния и условий их корректности, которые выработались в результате оригинальных вычислительных экспериментов и их сравнения с экспериментом на задаче о сварке взрывом металлических пластин 14 16, а также на задачах о разрушении материала 17. Оказалось, что созданная математическая модель естественным образом может быть расширена на задачи об образовании трещин в геологической среде, что также исследуется в настоящей работе. В общем виде условие корректности уравнения состояния можно сформулировать в виде интервала допустимых значений для термодинамического потенциала функции энтропии. Достижение нижней границы такого интервала свидетельствует о достижении больших отрицательных величин нормальных напряжений, что фактически является условием разрушения материала или отколом. На верхней границе такого интервала достигаются большие касательные напряжения, что свидетельствует о необходимости перестройки структуры материала, и для этого вводятся пластические деформации, которые уменьшают девиатор несимметричного тензора напряжений, таким образом, происходит разгрузка. При дальнейшем уменьшении роли девиатора тензора напряжений осуществляется переход к гидродинамической модели и корректировка эффективной скорости звука, возникающей благодаря росту энтропии. Напряженное состояние упругой среды зависит от деформации, которой эта среда под вергалась и от ее теплового состояния, описываемого термодинамической переменной температурой или энтропией . Для определения напряжений по заданным деформациям используется уравнение состояния среды с энергетическими затратами, потребными для осуществления этих деформаций. Деформация описывается при помощи отображения координат, составляющих среду материальных точек из начального состояния в деформированное. Начальные координаты, носят название лагранжевых. Возникшее при деформации искажение координатной сетки задается так называемой матрицей дисторсии, т. е. якобианом отображения, . Для вычислений нам удобно рассматривать сингулярный вид матрицы дисторсии. Выполним в какой-либо точке нашей среды в рассматриваемый момент времени сингулярное разложение для матрицы 0 0 0 0 . 0 0 Мы будем использовать такой вид далее. Уравнение состояния среды это выражение зависимости внутренней энергии на единицу объема и на единицу массы, от тензора деформации и от термодинамического параметра энтропии, . При адиабатическом 0 изменении полный дифференциал матрицы дисторсии есть, из которого следует формула Мурнагана для тензора напряжений Пиола Кирхгофа . Если среда изотропная, а именно такие среды мы и будем рассматривать, то энергетические затраты на деформацию можно выразить через инварианты симметрической матрицы, которой присваивается название тензор деформации. Это позволяет сформулировать общий вид уравнения состояния для моделирования широкого круга упругопластических сред. Для формулировки и исследования уравнения состояния нам оказалось удобнее использовать вместо матрицы ее квадратный корень . В этом случае уравнение состояния мы можем записать в виде, . Здесь матрица может быть представлена в виде . Тензор напряжений вычисляется по формуле, . Следует отметить, что при изучении вращений системы координат тензор удобно представить в виде шарового тензора и девиатора тензора с нулевым следом 1 1 tr tr, 3 3 где 1tr, 3 1tr . 3 В наших математических моделях мы использовали более простой вид уравнения состояния вида и сделали три допущения. 1. Будем предполагать аддитивность по инвариантам уравнения состояния. Это допущение вполне обоснованно, так как каждый инвариант формулируется для описания определенного свойства упругопластического материала, а уравнение состояния в этом случае формулируется в виде суперпозиции рассматриваемых свойств. 2. Термодинамическую переменную мы будем рассматривать отдельно и в качестве множителя к одному из инвариантов. Такая форма записи не умаляет сферу применения уравнения состояния, так как энтропийная переменная характеризует влияние от теплового состояния и связана, прежде всего, с изменением плотности упругопластической среды, которая описывается отдельным инвариантом. 3. Будем рассматривать изотропную среду, а именно такие среды и представляют интерес. В этом случае энергетические затраты на деформацию можно выразить через инварианты симметричной матрицы, которой присваивается название тензор деформации. В наших расчетах мы будем использовать следующие виды уравнения состояния для каждой фазы. Уравнение состояния упругой среды 2 . 1 3 Уравнение состояния жидкой среды . 1 Уравнение состояния газовой фазы . 1 Решаемые уравнения имеют следующий вид 0, 0, . Домножив уравнения на, соответственно, получим закон сохранения полной энергии, который записывается в следующей форме 0. 2 Метод решения уравнений теории упругости и его анализ подробно описан в книге 14. Для разрешения модели упругопластической среды помимо решения уравнений теории упругости необходимо использовать процедуру перемещения расчетной сетки. Таким образом, вычислительный алгоритм можно представить в виде следующих шагов, которые выполняются для каждой ячейки расчетной области 1 сингулярное разложение матрицы дисторсии 2 при достижении необходимых условий учет фазового перехода и формулировка уравнения состояния 3 контроль корректности уравнения состояния 4 решение задачи Римана для сформулированного уравнения состояния 5 расчет законов сохранения 6 пересчет функции энтропии 7 движение расчетной сетки. Будем считать, что на начало временного шага нам известны следующие величины скорость, элементы тензора дисторсии и напряжения, энтропия, полная энергия 1 2, скорость звука и плотность в каждой ячейке. Кроме этого, нам известны геометрические характеристики ячейки . Схему Годунова для такой системы уравнений законов сохранения момента импульса и полной энергии можно записать в виде 0, 2 2 0. Величины потоков скорости и напряжения будут находиться из решения задачи Римана. Затем происходит пересчет энтропии и движение расчетной сетки. После чего на основании нового положения ячейки пересчитывается матрица дисторсии подробности метода см. в работе 14. Будем моделировать пластину размером 40 20 см с плотностью 3,0 гсм, продольной и поперечной скоростями звука 5,2 кмс и 3,4 кмс соответственно. Критическое давление 60 ГПа. По верхней границе пластины идет постоянный профиль давления, движущийся с постоянной скоростью 1 кмс. Результаты моделирования показаны на рис. 3, из которого видно, что в области фронта давления образуется довольно сложная геометрия сетки. В работе представлена математическая модель упругопластических сред с учетом фазовых переходов между твердым телом, жидкостью и газом. Также учтен процесс откола вещества от газовой фазы. Сформулирован один из подходов к записи уравнения состояния упруа б в г гопластических сред, выписаны основные инварианты, используемые для построения уравнения состояния. Представлены результаты математического моделирования геологических деформаций, приводящих к образованию трещин. Настоящая модель упругопластической среды была построена под руководством академика РАН Сергея Константиновича Годунова 16, которому благодарны все авторы данной статьи. В настоящем изложении исправлены неточности записи полной системы уравнений, которые имели место в книге 14. В дальнейшем построенную упругопластическую модель планируется активно использовать для решения задач образования и эволюции трещин в геологической среде. "}
{"title": "ПРИМЕНЕНИЕ МЕТОДОВ НЕЛИНЕЙНОЙ ДИНАМИКИ   ДЛЯ ИССЛЕДОВАНИЯ ХАОТИЧНОСТИ СИГНАЛОВ-ПЕРЕНОСЧИКОВ   ЗАЩИЩЕННЫХ СИСТЕМ СВЯЗИ НА ОСНОВЕ ДИНАМИЧЕСКОГО ХАОСА ", "absract": "Исследуется хаотичность передаваемых сигналов защищенных систем связи на основе динамического хаоса  с помощью распространенных методов нелинейной динамики (максимальный показатель Ляпунова, показатель Хёрста и рекуррентные графики). В качестве защищенной системы связи на основе динамического хаоса рассмотрено устройство имитозащиты контролируемых объектов с повышенной структурной скрытностью сигналов-переносчиков. С помощью методов нелинейной динамики, проведено исследование временных реализаций передаваемых в канале связи сигналов, полученных в среде ScicosLab с помощью рассматриваемого устройства. Анализ полученных данных показывает, что исследуемые сигналы в целом обладают свойствами хаотичности  и потенциально могут обеспечить защищенность передаваемой в беспроводных каналах связи информации  от несанкционированного доступа. Описанный в данной работе подход к исследованию хаотичности передаваемых сигналов, основанный на комплексном применении известного математического аппарата методов нелинейной динамики, потенциально можно применять для исследования хаотичности передаваемых сигналов широкого класса систем защищенной связи на основе динамического хаоса. : нелинейная динамика, хаотические сигналы, устройство имитозащиты контролируемых объектов, радиоканал. ", "text": "В настоящее время идет активное развитие защищенных систем связи в гражданских и военных сферах применения. Одним из самых перспективных направлений в области защищенных систем связи является использование хаотических сигналов. Хаотические сигналы по сравнению с классическими шумоподобными сигналами обладают следующими преимуществами большое потенциальное число кодовых конструкций, сплошной спектр мощности, непредсказуемость на больших интервалах времени, повышенная защищенность от несанкционированного доступа 1. В настоящее время интерес представляет исследование защищенных систем связи на основе хаотических сигналов. При этом одним из самых существенных вопросов использования хаотических сигналов в области защищенных систем связи является обеспечение хаотичности передаваемых сигналов как возможного показателя защищенности от несанкционированного доступа 2. Целью данной статьи является исследование хаотичности передаваемых сигналов защищенных систем связи на основе динамического хаоса с помощью распространенных методов нелинейной динамики. Рассмотрим некоторые распространенные методы нелинейной динамики, которые можно применить в исследовании хаотичности передаваемых сигналов в защищенных системах связи на основе динамического хаоса. Одной из самых известных количественных мер хаоса является максимальный показатель Ляпунова . Эта величина представляет собой меру расхождения изначально близких друг другу траекторий в фазовом пространстве 3. Если мера начального расстояния между двумя исходными точками, то спустя малое время расстояние между траекториями, выходящими из этих точек, становится равным 4 2. Если динамическая система описывается разностными уравнениями или отображением, то 4 2. Если показатель Ляпунова положителен, это означает, что близкие фазовые траектории потенциально расходятся и движение в динамической системе хаотическое. При этом чем он больше, тем быстрее расходятся траектории и тем хаос больше согласно этой мере оценивания. Если показатель Ляпунова отрицателен, то траектории сближаются и движутся регулярно. Если 0, то расстояние между фазовыми траекториями либо не меняется, либо увеличивается в соответствии с более медленно растущей функцией, чем экспонента 3. Далее рассмотрим показатель Хрста . Он позволяет разделить между собой стационарные, стохастические случайные и хаотические процессы. Показатель Хрста определяется следующим образом 5 2, где нормированный размах вариации разность максимального и минимального значений измеряемого параметра, стандартное отклонение корень квадратный из дисперсии, период длина ряда наблюдений. В соответствии с 6 значение показателя Хрста 0 0.5 определяет хаотический процесс, значение 0.5 1 определяет стохастический случайный процесс, а значение 1 определяет стационарный процесс. При этом значение 0.5 соответствует понятию белый шум. Далее рассмотрим понятие рекуррентного графика РГ, позволяющего исследовать размерную траекторию лагового пространства посредством двухмерного представления ее рекуррентности повторяемости траекторий по прошествии некоторого времени в пространстве реконструкции аттрактора 7. РГ представляется в виде двухмерной матрицы размером . Матрица заполняется черными и белыми точками, где черные точки обозначают рекуррентность, а белые отсутствие 7 8, где, 1,..., число рассматриваемых состояний радиус выбранной окрестности расстояние от центра окрестности до ее границы норма функция Хевисайда. Значительный интерес представляет внешний вид РГ, с помощью которого на основе их топологий можно классифицировать наблюдаемые процессы 8 однородные РГ типичны для процессов с независимыми, идентично распределенными случайными значениями например, белый шум РГ с характерным дрейфом соответствуют процессам с медленно меняющими параметрами например, обобщенное броуновское движение периодически повторяющиеся структуры соответствуют осциллирующим нелинейным системам например, хаотический процесс. Расчеты проведем с помощью следующего программного обеспечения максимальный показатель Ляпунова рассчитаем с помощью программы Lyapmax.exe 9 показатель Хрста рассчитаем с помощью программы Fractan 10 РГ построим с помощью программы Visual recurrence analysis 11. В качестве защищенной системы связи на основе динамического хаоса рассмотрим устройство имитозащиты контролируемых объектов с повышенной структурной скрытностью сигналов-переносчиков 12, основанное на перезаписываемых накопителях хаотических последовательностей и предназначенное для защиты передаваемых служебных и тревожных сообщений в беспроводных системах безопасности охранно-пожарные системы, специальная робототехника и т. д.. Рассмотрим более подробно приемо-передающую часть устройства имитозащиты контролируемых объектов с повышенной структурной скрытностью сигналов-переносчиков 12 рис. 1. Опишем математически, как функционирует схема, изображенная на рис. 1. Исходными данными будут следующие понятия 13 1 произвольный хаотический сигнал 2 исходный информационный сигнал 3 передаваемый в канале связи сигнал 4 восстановленный информационный сигнал. Информационный сигнал может принимать два значения 1 и 1. При этом выходной сигнал модулятора-передатчика представляет собой сигнал, созданный с помощью перемножения в модуляторе-передатчике исходного информационного сигнала с хаотическим сигналом . В канале связи на передаваемый сигнал действует аддитивная гауссовская помеха, поэтому на вход приемного устройства поступает смесь передаваемого сигнала и помехи 1. После вхождения в режим синхронизации в приемном устройстве из полосового фильтра выходит сигнал, который затем усиливается. После этого усиленный сигнал одновременно умножается на копию хаотического сигнала, аналогичную хаотическому сигналу в передатчике, а также умножается на ее инвертированное значение . В итоге получаются сигналы и, которые затем проходят через интеграторы и принимают следующие значения и . Причем в соответствии с 1 после выхода сигнала из интегратора возможны следующие случаи max при max при min max min при min . Здесь min и max постоянные, характеризующие порог ограничения выходного сигнала интегратора. Далее сигналы и поступают в вычитающее устройство, где вычисляется их разность. С выхода вычитающего устройства разностный сигнал поступает в решающее устройство, где происходит сравнение принятых уровней с пороговым значением 1 1 при 0, 1 при 0 . После этого восстановленный информационный сигнал поступает к получателю, при этом в идеальном случае . Воспользуемся приведенным выше математическим аппаратом нелинейной динамики для анализа передаваемых в канале связи сигналов, вырабатываемых устройством имитозащиты контролируемых объектов с повышенной структурной скрытностью сигналов-пере носчиков см. рис. 1. Сначала рассмотрим в качестве генератора хаотических сигналов аттрактор Рсслера, который задается следующей системой нелинейных уравнений 14, . 1 В работе 15 на основе аттрактора Рсслера и схемы, изображенной на рис. 1, в среде ScicosLab авторами при изменении в 1 переменной были получены различные временные реализации передаваемых в канале связи сигналов . На рис. 2 в качестве примера изображен фрагмент передаваемого сигнала при значении 4 . При этом для упрощения процесса моделирования в качестве информационного сигнала использовалась равномерная последовательность прямоугольных импульсов в диапазоне 1 1. Проведем анализ временных реализаций передаваемых в канале связи сигналов с целью определить, обладают ли они свойствами хаотичности. Рассчитаем сначала максимальный показатель Ляпунова и показатель Хрста Как видно из табл. 1, при различных значениях постоянной временные реализации передаваемых в канале связи сигналов обладают положительным максимальным показателем Ляпунова, а значения показателя Хрста попадают в интервал 0 0.5 . Оба факта указывают на то, что исследуемые сигналы обладают свойствами хаотического процесса. Расчеты показателей Ляпунова и Хрста Значение постоянной Максимальный показатель Ляпунова Показатель Хрста 1 4 2.319573 0.289822 2 6 2.112951 0.210014 3 8.5 1.649407 0.171915 4 8.7 2.001937 0.123097 Далее, рассмотрим РГ для различных значений постоянной Как видно из рис. 3, на них присутствуют разнообразные периодически повторяющиеся структуры в виде горизонтальных и вертикальных линий. Это соответствует осциллирующим нелинейным системам и указывает также на хаотичность процесса. а б в г Далее рассмотрим в качестве генератора хаотических сигналов возмущенный осциллятор Ван дер Поля, который задается следующей системой нелинейных уравнений 14, 1 cos, 2 . 2 В работе 16 на основе возмущенного осциллятора Ван дер Поля и схемы, изображенной на рис. 1, в среде ScicosLab авторами при изменении в 2 переменной были получены различные временные реализации передаваемых в канале связи сигналов . На рис. 4 в качестве примера изображен фрагмент передаваемого сигнала при 1.966 . При этом для упрощения процесса моделирования в качестве информационного сигнала использовалась равномерная последовательность прямоугольных импульсов в диапазоне 1 1. Проведем анализ временных реализаций передаваемых в канале связи сигналов с целью определить, обладают они свойствами хаотичности или нет. Рассчитаем сначала максимальный показатель Ляпунова и показатель Хрста табл. 2 Как видно из табл. 2, при различных значениях постоянной временные реализации передаваемых в канале связи сигналов обладают положительным максимальным показателем Ляпунова, а значения показателя Хрста попадают в интервалы 0 0.5 и 0.5 1 . Положительный максимальный показатель Ляпунова указывает на то, что исследуемые сигналы обладают свойствами хаотического процесса. Полученные же значения показателя Хрста указывают на то, что исследуемые сигналы обладают как свойствами хаотического процесса, так и свойствами стохастического случайного процесса. При этом следует отметить, что некоторые из значений показателя Хрста находятся рядом со значением 0.5, которое описывает понятие белого шума. Расчеты показателей Ляпунова и Хрста Значение постоянной Максимальный показатель Ляпунова Показатель Хрста 1 1.966 2.177418 0.587875 2 1.97 1.516883 0.597453 3 1.976 2.020661 0.375757 4 1.984 2.241799 0.481174 Далее, рассмотрим РГ для различных значений постоянной Как видно из рис. 5, на них присутствуют разнообразные периодически повторяющиеся структуры в виде горизонтальных и вертикальных линий. Это соответствует осциллирующим нелинейным системам и указывает также на хаотичность процесса. а б в г В данной статье проведено исследование хаотичности передаваемых сигналов защищенных систем связи на основе динамического хаоса с помощью распространенных методов нелинейной динамики. В качестве распространенных методов нелинейной динамики использованы максимальный показатель Ляпунова, показатель Хрста и рекуррентные графики. В качестве защищенной системы связи на основе динамического хаоса рассмотрено устройство имитозащиты контролируемых объектов с повышенной структурной скрытностью сигналов-переносчиков. Описано, как функционирует приемо-передающая часть устройства имитозащиты контролируемых объектов с повышенной структурной скрытностью сигналов-переносчиков. С помощью методов нелинейной динамики проведено исследование временных реализаций передаваемых в канале связи сигналов, полученных в среде ScicosLab с помощью приемо-передающей части устройства имитозащиты контролируемых объектов с повышенной структурной скрытностью сигналов-переносчиков 15 16. Анализ полученных данных показывает, что исследуемые сигналы в целом обладают свойствами хаотичности и потенциально могут обеспечить защищенность передаваемой в беспроводных каналах связи информации от несанкционированного доступа. Описанный в данной работе подход к исследованию хаотичности передаваемых сигналов, основанный на комплексном применении известного математического аппарата методов нелинейной динамики, потенциально можно применять для исследования хаотичности передаваемых сигналов широкого класса систем защищенной связи на основе динамического хаоса. "}
{"title": "АТРИБУТНАЯ КОНВЕЙЕРНАЯ МОДЕЛЬ  ДЛЯ ИНТЕРАКТИВНОЙ ВИЗУАЛИЗАЦИИ ОБЪЕКТНЫХ СВЯЗЕЙ ", "absract": "Определена модель для визуализации связей между объектами и их атрибутами в различных процессах.  На основании модели разработан универсальный абстрактный компонент графического пользовательского интерфейса и приведены примеры его программной реализации. Также проведена апробация компонента для решения прикладной задачи по извлечению информации из документов. : графическая нотация, графическая модель, диаграмма, визуализация процесса, объектная модель, объектные связи, схема фактов. ", "text": " Одной из важнейших частей моделирования различных систем является формализация протекающих в них процессах. Процесс может быть смоделирован с помощью математических формул и словесных описаний, представляющих собой условные инструкции и последовательности действий. Для сложных систем представляется трудоемким не только составление формализованной модели, но и ее восприятие человеком, поэтому часто прибегают к помощи графических средств, чтобы упростить понимание материала. В их число входят диаграммы и графические нотации стандартизируемые графические способы формализации, отображающие связи между компонентами системы или их взаимодействие в процессах. Например, технология структурного проектирования IDEF0 ICAM Definition for Function Modeling, определение функционального моделирования ICAM, ICAM это сокращение от названия набора стандартов Integrated Computer Aided Manufacturing, Интегрированное компьютеризированное производство представляет анализируемый процесс в виде совокупности множества работ, взаимодействующих на основе определенных правил, с учетом потребляемых материальных или информационных ресурсов, имеющих вход и выход 1. IDEF0 следует идее разбиения процесса на функциональные блоки с помощью графических объектов, где каждый блок преобразует ресурсы на входе в ресурсы на выходе, передавая их следующим блокам рис. 1. Еще одним популярным способом визуализации процессов является Process Flow Diagram PFD, принципиальные схемы технологического процесса. PFD предназначена для описания химических и инженерных процессов 2 3 и фокусируется на демонстрации оборудования и веществ, которые оно преобразует рис. 2. Важной составляющей PFD является перечень типичного оборудования, такого как емкости, нагреватели, клапаны и т. д. Это стандартный список, т. е. у всех инструментов и материалов имеется соответствующее стандартное графическое изображение. В этой статье мы обращаем внимание на еще одну интересную графическую нотацию. Она довольно широко используется в визуализации процессов, в которых важно взаимодействие не столько между самими объектами, сколько между их свойствами, в отличие от IDEF0 и PFD. Далее мы дадим ее формальное определение и приведем примеры использования в практическом приложении, для визуализации и моделирования процессов извлечения информации из документов. Атрибутная конвейерная модель визуализации АКМ это логическая модель данных, предназначенная для отображения связей между свойствами или атрибутами объектов, участвующих в одном процессе. АКМ составляют следующие графические элементы. Узел сущность, предназначенная для визуализации объекта. Узел представляет собой прямоугольную панель с заголовком вверху. Под заголовком, сверху вниз, располагаются составляющие, соответствующие свойствам объекта. Панели свойств это текстовые панели, соответствующие некоторым свойствам объекта, определяемым пользователем. Они располагаются внутри узла под заголовком в виде списка. Каждая панель свойства имеет один из двух типов входной или выходной. Типизация устанавливает направленные отношения между свойствами свойства выходного типа в процессе передают свои значения связанным с ними свойствам входного типа. В АКМ с одним объектным свойством сопоставляется лишь одна панель, однако разные свойства могут обозначаться одинаковым текстом. Например, при моделировании процесса Сложение мы можем создать узел для объекта Сумматор с двумя и более свойствами с именами Слагаемое. Коннекторы соединители это элементы, отображаемые в виде кружков слева или справа от панели свойства. Расположение коннектора задает тип свойства свойство имеет входящий тип, если коннектор находится слева, и выходящий тип, если коннектор справа. Соединения это линии между коннекторами, показывающие направленные связи между свойствами. Для обеспечения целостности модели на соединения накладываются следующие ограничения у коннектора свойства входного типа может быть только одно соединение у коннектора свойства выходного типа может быть сколько угодно соединений нельзя установить соединение между свойствами одного и того же объекта соединение можно установить только между свойствами разных типов. Указанные ограничения, а также способ расположения коннекторов подталкивают пользователя к созданию диаграмм, где панели с определяемыми свойствами находятся правее панелей с определяющими свойствами рис. 3. Такое расположение делает интуитивно более понятным то, в какой стадии процесса участвует тот или иной объект и его свойство. Правильные диаграммы АКМ должны обладать свойством конвейерности описывать процессы, внутри которых не возникают циклы. Иначе говоря, в этих диаграммах нельзя составить такой путь по связям, который бы начинался и заканчивался в одном и том же объекте. Определенная нами модель частично заимствует идею конвейерного процесса из диаграмм модели SCA Assembly модель сборки сервис-компонентной архитектуры 4. SCA была создана для того, чтобы описывать процессы взаимодействия служб с компонентами приложения рис. 4 компоненты передают службам ссылки на себя, когда обращаются к службам относительно компонентов эти связи представлены фиолетовыми указателями, и также выступают в роли обработчиков сигналов от служб, принимая от них сигналы эти связи представлены зелеными указателями. Диаграммы и модель SCA включают в себя также и другие элементы параметры, производитель и т. д., но в АКМ они не участвуют. Задача визуализации сформировалась во время работы над графическим редактором схем фактов, используемых для фактографического анализа текста. Схема фактов это модель, которая проецирует определенный класс выражений на естественном языке на предметную область рассматриваемой системы 5. Схема включает набор правил вывода и ограничений, по которым элементы текста порождают множество информационных объектов или экземпляров предметной области. Для описания предметной области используется онтология. Онтология это модель, позволяющая представить понятия предметной области в виде иерархии, где каждое понятие описывается классом и набором атрибутов и связей, которые наследуются вниз по иерархии. Таким образом, схемы фактов опираются на онтологию и при моделировании включают следующие основные компоненты. это набор объектов, отражающий структуру языкового высказывания, описывающего факт из выбранной предметной области. С каждым объектом сопоставляется фрагмент текста. Аргумент описывается с помощью семантических характеристик принадлежности объекта к определенному лексическому или онтологическому классу. это множество ограничений, накладываемых на взаимоотношения нескольких аргументов, такие как морфологическая согласованность, близость или порядок следования. обозначает объект, изменяемый или порождаемый при обработке схемы фактов анализатором. В соответствии со схемой атрибутам результирующего объекта присваиваются либо значения атрибутов, либо значения по умолчанию, которые можно задать отдельно для каждого . При порождении нового объекта для него указывается онтологический класс. Так как схемы фактов отображают последовательные процессы создания информации объектов онтологии, интенсивно используя при этом связи между свойствами объектов, мы решили воспользоваться подходом к визуализации на основе атрибутной конвейерной модели. Рассмотрим некоторые проблемы, возникающие при графическом моделировании схем фактов с помощью АКМ. Во-первых, для описания взаимодействия необходимо иметь возможность выбирать вид условия морфологическая согласованность, условие на сегмент, взаиморасположение и т. д. и указывать значение каких-либо параметров согласования например, для морфологической согласованности род, число, падеж и пр.. Другие элементы схемы фактов не влияют на эти параметры, поэтому при моделировании пользователь должен выбирать их сам из списков возможных значений. Во-вторых, специфика онтологического описания и схем фактов предполагает, что некоторые объекты могут сами выступать в качестве определяющих свойств. Рассмотрим эту проблему на примере схемы фактов рис. 5, которая включает два аргумента arg1 и arg2 и одно условие на их взаиморасположение. Список свойств панели состоит из двух аргументов, на которые накладывается ограничение определенного вида. Чтобы в АКМ можно было задать соединение между аргументом и его ограничением, нужно вынести этот аргумент в список его собственных свойств. Это кажется нелогичным и громоздким, тогда как наша задача упростить создание схем фактов и представить их в компактном, удобном, читаемом виде. Более правильным представляется создание обособленного свойства, отвечающего объекту. На основании изложенных проблем мы сформировали следующие требования к графической библиотеке для визуализации схем фактов 1 возможность изменять свойства объектов без обязательного использования связей 2 возможность для объекта становиться свойством. Выполнение этих требований предполагает не только необходимость расширения функционала отдельной графической библиотеки, но и необходимость расширения АКМ, поэтому далее мы расскажем, как изменения в библиотеке отразились на АКМ в целом. Так как наша модель должна предоставлять пользователю более гибкий контроль над свойствами, менять их без участия связей, мы предлагаем абстрагироваться от понятия свойство как от текстовой панели. Чтобы свойства наиболее точно соответствовали нашему представлению об интерактивной визуализации объектной модели, мы разрешили пользователю передавать в качестве свойств любой компонент Windows Presentation Foundation. Это означает, что теперь интерактивность не ограничивается прикреплением и отделением соединений, но также появилась возможность изменять объект и изнутри его визуализирующей панели. В этом подходе мы ориентировались на систему трехмерного моделирования Blender, где с помощью аналогичной библиотеки программируется процесс создания изображения, его преди постобработки. На рис. 6 слева изображена панель настройки сдвига изображения по пространственной координате . Пользователь может изменить эту координату двумя способами либо присоединив свойство к коннектору, которое передаст свое значение -координате, либо определив это значение вручную, без использования соединений. В Blender это реализовано через поля пользовательского ввода. Свойства, которые позволяют напрямую изменять объект, не используя соединения, мы будем называть независимыми. Возвращаясь к проблеме из примера со свойствами схемы, мы можем заметить, что благодаря большему абстрагированию свойств модели проблема решается добавлением в панель свойств выпадающих меню с вариантами выбора вида и значения . Ограничения свойств конвейерной модели предполагают, что каждое свойство либо принимает значение другого свойства, либо задает его, т. е. у каждого свойства есть либо входной коннектор, либо выходной. Так как некоторые независимые свойства, такие как переключатели см. рис. 6 слева на вершине списка свойств или панель выбора вида ограничения в панели схемы фактов, не предполагают изменения других свойств, мы решили изменить подход к типизации свойств. Теперь каждое свойство имеет один из трех типов 1 входной используется, если свойство принимает значения от другого свойства 2 выходной используется, если свойство передает свое значение другим свойствам 3 без соединений используется, если свойство независимое и не влияет на другие свойства. Чтобы иметь возможность использовать объект в качестве свойства, мы ввели в графическую модель дополнительный коннектор и расположили справа от заголовка узла. Коннектор обладает теми же возможностями и ограничениями, что и коннектор свойства выходного типа. Таким образом, мы определили расширенную атрибутную конвейерную модель РАКМ, которая представляет собой АКМ со следующими отличиями заголовок узла это свойство выходного типа, которое представляется только текстовой панелью свойства имеют один из вышеперечисленных типов свойства представляются текстовыми панелями или определенными пользователем интерактивными панелями. Отметим, что РАКМ предназначена в первую очередь для визуализации в графическом интерфейсе, а не для создания формализованных диаграмм, так как формальное описание каждого элемента, который пользователь желает внедрить в диаграмму, является достаточно трудоемкой задачей, тогда как программное описание пользовательских элементов формализма не требует. Для визуализации схем фактов мы разработали компонент, который основывается на библиотеке NetworkView . Несмотря на неоднозначное название, которое отсылает к сетевым моделям визуализации СУБД, она демонстрирует процесс реализации простой атрибутной конвейерной модели рис. 7. Как мы видим, библиотека NetworkView позволяет визуализировать графы, сети и модели протекания различных процессов. Она нетребовательна к ресурсам и с успехом может применяться в проектах на C, построенных с использованием Windows Presentation Foundation или Windows Forms, если пользователю доступен компонент ElementHost, обеспечивающий поддержку элементов WPF в WinForms. Несмотря на то что эта библиотека показалась нам в целом пригодной для наших целей, в дальнейшем выяснилось, что, для того чтобы обеспечить полную поддержку РАКМ, все же частично необходимо расширить ее функционал. Поэтому для разработки графического редактора схем фактов мы создали собственную версию NetworkView, изменив некоторые ее составляющие. Библиотека NetworkViev предлагает клиентским приложениям обрабатывать события, посылаемые всеми графическими элементами, такими как добавление узла, выбор узла, перетаскивание курсора из коннектора, перемещение курсора, щелчки по элементам и т. д. Альтернативным решением является построение объектной модели для узла сети, инкапсулирующей события, с учетом того, что в нашем подходе используется более абстрактная конвейерная модель. Также передача в контейнер, содержащий узлы, объекта вместо разрозненного набора обработчиков событий интерфейса делает отладку приложения значительно удобнее, а структуру программы понятнее и логичнее. Далее мы представим объектную модель узла. NodeInfo класс, определяющий узлы. В него входят следующие поля. Tag это объект, который мы визуализируем. Он же является свойством, выходной коннектор которого располагается в верхнем углу узла. Name заголовок узла. Изменение поля Name вызывает событие, для которого пользователь может задать обработчик, так клиентское приложение сможет откликаться на изменения заголовка. NameChangeable флаг, который определяет, можно ли изменять заголовок узла. Sections список свойств, отображаемых в узле. FillColor цвет панели узла, для отличительной способности. Свойства из списка Sections принадлежат к классу SectionInfo, объекты которого содержат следующую информацию Input, Output ссылки на входной и выходной коннектор соответственно IsInput, IsOutput комбинации этих полей определяют тип свойства вход, выход, без соединений InputValidation ссылка на пользовательский валидатор. Эта функция вызывается всплывающим событием перед установкой соединения между двумя коннекторами. Если она опускает флаг валидности события, то событие перестает обрабатываться, а соединение отменяется InputAdded, OutputAdded ссылка на пользовательский обработчик события, которое возникает при добавлении к коннектору входящего или исходящего соединения соответственно UIPanel визуальный элемент, отображающий свойство. Может быть и простым текстом, и сложным компонентом, делающим свойство независимым Data пользовательские данные, привязанные к свойству. Когда это поле изменяется, вызывается пользовательский обработчик события. Обычно изменения производятся внутри UIPanel. Экземпляры класса NodeInfo описывают содержимое узла и собираются в клиентском приложении. В нашей библиотеке все узлы содержатся в контейнере, в котором происходит отрисовка соединительных линий и который занимается обработкой и переадресацией событий, срабатывающих на узлах и коннекторах. Внутри контейнера пользователь может перемещать узлы, также контейнер предусматривает смещение вида сдвиг камеры и масштабирование элементов для упрощения навигации. Графический редактор схем фактов предназначен для моделирования процессов извлечения информации из текстов на естественном языке. На рис. 8 приведен пример визуализации схемы фактов, предназначенной для извлечения информации из технической документации. Предполагается, что построение структурированной модели содержания технического описания позволит ускорить и упростить процесс анализа и верификации официальных документов для экспертов и разработчиков программного обеспечения 6. Для апробации предложенного подхода были разработаны онтология предметной области Автоматизированные системы управления техническими процессами АСУ ТП и семантический словарь предметной лексики, которые загружаются в редактор схем фактов и задают множество начальных значений имена понятий, списки атрибутов и т. п., которыми может оперировать пользователь при моделирования процессов извлечения информации. Выделяются два основных типа схем фактов схемы, служащие для начальной инициализации объектов, и схемы для выявления связей. Схемы фактов первой группы необходимы для начального формирования онтологических сущностей на основании словарных признаков. Схемы фактов второй группы моделируют процессы обнаружения фрагментов онтологии. В нашем примере к таким фрагментам относятся описания различных ситуаций, связанных с устройством АСУ ТП, наличие у объектов определенных состояний, управление одних объектов другими, контроль и измерение одних объектов другими и т. п. Так, с помощью схемы, приведенной на рис. 8, моделируется процесс извлечения информации о параметрических состояниях объектов. Для создания онтологического объекта класса используется соответствующий признак словаря, а также признаки для заполнения атрибута и для атрибута . Данная схема включает два условия на синтаксическую сочетаемость аргументов и их взаиморасположение. Отвечая на вопрос, справляется ли разработанный на основе РАКМ инструмент со своей задачей упростить написание схем фактов, сравним представление описанной выше схемы фактов в графическом виде с соответствующим ей XML-кодом Если за показатель эффективности брать отношение числа графических элементов узлов, соединений, свойств к величине кода на XML, то мы видим, что для, который обозначается как Result в исходном коде, эффективность сильно растет с числом определяемых атрибутов, так как на каждый связанный атрибут приходится по одной строчке Rule с набором параметров. Эффективность, однако, будет снижаться в случае увеличения числа, так как в XML они сгруппированы по входящим в них аргументам. Эта проблема снимается, если разрешить добавление новых ограничений в существующие узлы с, чтобы не создавать новые. Таким образом, мы можем сделать вывод, что мы получили эффективную и гибкую реализацию атрибутной конвейерной модели, которую можно использовать для решения задач моделирования различных процессов. Созданный на основе расширенной АКМ редактор схем фактов может активно использоваться для решения задач в области анализа текстов на естественном языке, так как за счет визуализации позволяет сделать процесс создания схем фактов более наглядным и удобным для лингвиста, а также помогает обеспечить целостность всего процесса извлечения информации наличие входных данных для любой схемы, отсутствие циклов, корректность параметров и т. п.. В работе было дано формальное определение графической нотации модели конвейерного типа и предложено ее расширение, которое имеет большой потенциал для реализации в виде компонентов графического пользовательского интерфейса. Разработана программная библиотека, реализующая расширенную атрибутную конвейерную модель, которую можно легко встраивать в программные системы. В дальнейшем планируется решить проблему полной формализации РАКМ несмотря на то что эта модель позволяет создавать эффективные решения за счет расширения пользовательскими элементами управления, на текущий момент нет удобного способа создания, иллюстрирующих формальных диаграмм, включающих неуправляемые панели свойств, так как пользователь должен строго определить все входящие в диаграмму новые элементы. Также есть потенциал для дальнейшего развития нашей графической библиотеки и объектной модели РАКМ. Например, с текущим видом объектной модели трудно работать со свойствами и видеть результат обработки диаграмм в реальном времени, так как обратная связь от изменения свойств ограничивается только событиями подключения и удаления соединения. Планируется добавить новые сигналы, которые будут распространяться по соединениям до концов конвейера, когда создается новое соединение или изменяется независимое свойство. "}
{"title": "ОТКРЫТЫЕ РЕШЕНИЯ ВЕБ/ ВИДЕОКОНФЕРЕНЦСВЯЗИ   И ПРОЕКТ OPENMEETINGS   ", "absract": "Открытые программные решения веб/ видеоконференцсвязи анализируются как с технологической, так и с функциональной сторон в масштабе хорошо развитого ИТ-сегмента ВКС. На примере международного проекта Apache OpenMeetings новосибирская команда разработчиков детально рассматривает программные, пользовательские, сервисные и коммерческие аспекты таких проектов в динамике их развития. Показаны возможности и достоинства, обозначены дальнейшие перспективы роста. : веб-конференцсвязь, видеоконференцсвязь, ВКС, открытый код, Flash, WebRTC, фонд Apache, мобильный клиент, разработка ПО, поддержка ПО.", "text": "В современном обществе практически любой человек, регулярно пользующийся компьютером, хотя бы изредка прибегает к помощи компьютерной конференцсвязи, не употребляя, однако, этот термин. Например, известный мессенджер Skype или сервис Google Hangouts предоставляют такую возможность. Конференцсвязь это одновременное общение нескольких человек по аудиои или видеоканалам. Современные системы, обеспечивающие конференцсвязь, на макроуровне делятся на аппаратные и программные. Аппаратные требуют наличия специального оборудования управляемые видеокамеры, кодеки, серверы и др. Часто это оборудование устанавливают в специальный кабинет для проведения совещаний. Наиболее известные производители в этом сегменте Polycom и Cisco Tandberg. Программные решения более доступны по цене, так как из оборудования они требуют только компьютер, веб-камеру и головную гарнитуру или спикерфон для громкой связи. Пользователи подключаются к конференции либо через специальное ПО, которое дополнительно устанавливается на компьютер, либо через обычный веб-браузер. Программные решения, использующие веб-браузер, технически наиболее просты с точки зрения обычного пользователя. В этой статье мы сосредоточимся на них. В информационно-коммуникационной отрасли используются два похожих термина видеоконференция и веб-конференция. Хотя четкого разделения между ними нет, по интернет-источникам различие все же прослеживается . Видеоконференции обеспечиваются высококачественным оборудованием и сетью, создающими эффект присутствия, которое используется в дорогих аппаратных решениях для делового общения. Вебконференции не требуют спецоборудования, недороги или бесплатны, технические требования к сети и их установке ПО невысоки. Таким образом, веб-конференции соотносятся скорее с программными решениями. Тем не менее, термин видеоконференцсвязь широко применяется и к ним тоже. В англоязычном интернет-пространстве термин web conferencing используется в 2 раза чаще, чем videoconferencing. В русскоязычном сегменте Интернета соотношение обратное. Кроме того, активно используется аббревиатура ВКС для видеоконференцсвязи. Для удобства мы ниже также будем использовать термин ВКС, относя его сразу и к видеоконференциям, и к веб-конференциям, имея в виду программные решения. Различные программные решения ВКС отличаются несколькими параметрами. Основные из них это максимально возможное количество одновременно общающихся людей, качество передачи видео и звука, поддерживаемые операционные системы, наличие мобильного клиента. Дополнительный функционал это календарь, чат, средства для совместной работы над документами, для рисования, общий экран, средство для рассылки приглашений на электронную почту, запись конференций, возможности интеграции с другими системами. Многое из перечисленного воспринимается пользователями в настоящее время как должное. В этой статье мы рассмотрим открытые программные решения ВКС, существующие на глобальном рынке, и более подробно одно из них, которое в 2017 г. отметило свое десятилетие. Это OpenMeetings, проект с интересной историей, на примере которого можно проследить, как возникают, за счет чего живут и развиваются подобные проекты. Всего в мире известно порядка пяти открытых программных решений ВКС. Они выполняют не только утилитарную пользовательскую, но и образовательную функцию, позволяя интересующимся инженерам разобраться, как устроены и работают такие программные решения, и создать свои решения на их базе. Программный код доступен в открытых репозиториях, таких как Github и Sourceforge. В таблице см. далее представлены сравнительные технические характеристики четырех известных свободных открытых программных систем ВКС, которые работают через веб-браузер, без необходимости установки дополнительного ПО. и реализованы архитектурно как классические системы клиент сервер и близки по используемым программным технологиям и требованиям к серверному и клиентскому программному обеспечению. Так, передачу аудиои видеосигналов в обоих проектах обеспечивает открытый медиа-сервер Red5. Оба проекта пока еще используют Flash для клиентской части. Система ВКС, Программные технологии Требования к серверу Требования к клиенту ОС, поддерживаемые сервером OpenMeetings OM, Red5, Java, Adobe Flash, HTML5 Java, 1 Database MySQL..., OpenOffice, SWFTools Flash plugin, JRE 8 Linux, Unix, Windows, macOS BigBlueButton BBB, Red5, Java, Adobe Flash, HTML5, WebRTC, Redis Java, 2 Databases MySQL... Redis OpenOffice, MongoDB, SWFTools, FreeSWITCH Flash plugin Linux MConf BBB own development, Red5, Java, Ruby, Adobe Flash, HTML5, WebRTC, Redis Java, Ruby on Rails, Chef, 3 Databases MySQL... Redis MongoDB MySQL, Redis, OpenOffice, SWFTools Flash plugin Linux WebHuddle, Java, JBoss Java, JBoss, OpenOffice, Xvfb Java plugin Windows, Linux, UNIX, macOS Различия есть, например, в технологической реализации функции общего экрана и видеозаписи, в количестве баз данных для серверной части для OM требуется всего одна, а для BBB как минимум две различных по назначению. Разнится и список поддерживаемых серверами OM и BBB операционных систем у OM он расширен на Win, MacOS и Unix. Проект развился в бразильском университете UFGRGS на базе проекта BBB. Его ядром является подпроект MConf-Live, который обеспечивает серверную и клиентскую части системы. Для него разрабатываются новые функциональные модули, улучшающие интерфейс, и большая часть новых модулей поставляется также в BBB. Разработан дополнительный большой компонент в виде веб-портала, ставший основой веб-сервиса Mconf-Web, где можно завести свою виртуальную комнату для проведения видеоконференций. Существует также проект MConf Academic Network, который связывает в единое облако ВКС-серверы различных научно-исследовательских организаций, помогая балансировать и оптимизировать нагрузку, повышая надежность общего ВКСсервиса. проект технологически и функционально менее развит, чем предыдущие. Так, например, не поддерживается передача видео. Работает он как java applet в браузере, однако апплеты в современных версиях браузеров по умолчанию не поддерживаются. Плюсом можно назвать поддержку всех популярных ОС. В дальнейшее сравнение этот проект включать нецелесообразно. Есть еще две системы программной ВКС, которые стоит вкратце описать. Это и . Проект Jitsi изначально развивался как SIP коммуникатор по сути веб-телефон для звонков на VoIP-серверы, позже в нем появилась поддержка других популярных протоколов, функционал для чата, видеоконференций и видеотрансляций. Весной 2015 г. команду проекта купила известная компания Atlassian, после чего два года длилась неопределенность с развитием проекта в рамках концепции open source, а в начале 2017 г. проект продолжил развиваться как open source уже при поддержке Atlassian. Хотя у проекта много достоинств, подробно его не рассматриваем, поскольку ВКС функционал работает не через веб-браузер. Проект VMukti в первые годы 20072009 развивался как open source, а позже встал на коммерческие рельсы, существенно усилив аппаратное направление. Сейчас он предлагает широкую линейку коммуникационных решений, включая видеотрансляции, вебинары, мониторинг объектов, рассчитанных на взаимодействие с облачной инфраструктурой. В этом разделе анализируются принципиальные характеристики, присущие всем трем проектам BBB, Mconf и OM, и важные с точки зрения выбора между закрытыми коммерческими и открытыми свободными ВКС системами. Эти проекты более всего востребованы сейчас в обучении, что обусловлено как интенсивным развитием области e-learning, так и историей развития самих проектов. выполняют демо-функцию, позволяя протестировать их возможности. Здесь можно заводить постоянные виртуальные комнаты в привязке к конкретному пользователю. Но для проведения регулярных ВКС-совещаний и вебинаров с большим количеством участников эти сервисы вряд ли подходят, поскольку не могут гарантировать хорошее качество сети одновременно для множества виртуальных комнат. позволяет пользователю обеспечить необходимые ему технические характеристики объем оперативной памяти и баз данных, пропускную способность сети, подключение необходимых портов и протоколов, а также контроль всех информационных потоков. Это может быть как локальный, так и облачный сервер. При повышенных требованиях есть возможность сделать кластерную конфигурацию из нескольких серверов. Эти проекты имеют как API, так и готовые плагины интеграции для разнообразных систем управления сайтами и обучением CMS, LMS Moodle, Drupal, WordPress, Bitrix и др. У OM есть также интеграция с популярной системой управления ИТ-проектами JIRA. C помощью плагинов пользователь получает возможность переходить с сайта портала в виртуальную комнату по прямой ссылке без пароля., разработанные для каждой из систем, обеспечивают конкурентный уровень на рынке ВКС. этих проектов дает дополнительные возможности полная проверка на безопасность, интеграция и кастомизация. это частичное изменение пользовательского интерфейса. Благодаря открытому коду пользователи с хорошим программистским опытом могут сделать это самостоятельно. Брендирование наиболее популярный вид кастомизации, который подразумевает внесение элементов фирменного стиля компании в клиентскую ч асть системы. Если интеграцию и кастомизацию через различные API предлагают уже и некоторые проприетарные проекты, то безопасность кода это сильное преимущество открытых проектов, в которых весь код на 100 можно проверить. В сочетании с возможностью установки на собственный сервер заказчика под управлением нужной операционной системы и с использованием безопасных протоколов, это дает полную проверку и контроль над каналом ВКС. Для определенных категорий заказчиков именно безопасность является определяющим фактором выбора. достоверно можно сравнить, только последовательно запуская в одних и тех же условиях OM, BBB и MCоnf. Заявленные же параметры не сильно отличаются друг от друга. примерно одинаково около 100. Доступно в формате вебинара лекции, когда выступает один или несколько ведущих, а остальные слушают и могут задавать вопросы в чате либо в коротких видео аудиовключениях. Однако в общем случае максимальное количество участников зависит от размеров используемых видеоокон и пропускной способности сети между сервером и клиентами. OM, BBB и MConf имеют свободные лицензии, разрешающие коммерческое использование. Команда OpenMeetings более чем за 6 лет реализовала десятки таких проектов для клиентов со всего мира Автором проекта стал немецкий разработчик Cебастьян Вагнер, выпустивший в 2007 г. первую версию OpenMeetings. Проект успешно развивался благодаря внедрению в ряд университетов Германии для поддержки процесса обучения. С 2009 г. проект стал открытым, что помогло привлечь других разработчиков из разных стран. С мая 2009 г. проект стал развиваться и внедряться также силами российских разработчиков. Первой была компания Телеком-Экспресс, локализовавшая проект для российских заказчиков. Затем та же команда разработчиков продолжила развитие проекта в компании Датавед. Постепенно основная программная разработка и техническая поддержка проекта переместилась на российскую территорию. Несколько лет назад корпоративным евангелистом проекта стал Новосибирский центр информационных технологий Унипро, взявший на себя основную роль в развитии проекта. OpenMeetings регулярно попадает в поле зрения различных интернет-обзоров 1 . При этом услуги веб-конференцсвязи на базе OpenMeetings формально предлагают около десятка компаний в мире. С 2012 г. проект развивается под эгидой фонда открытого ПО Apache ASF и имеет одноименную лицензию, позволяющую использовать его в коммерческих проектах. Лидером проекта Apache OpenMeetings в ASF является Максим Солодовник, ведущий инженер Унипро, он регулярно представляет проект на международной конференции ApacheCon. Несколько лет проект участвовал в программе Google Summer of Code, привлекая талантливых студентов к развитию проекта под руководством главного архитектора, имеющего статус Apache Chair. Помимо своей популярной свободной лицензии, фонд Apache предоставляет свободным проектам множество удобных сервисов, избавляя разработчиков от необходимости устанавливать на собственных серверах немалый набор программных средств и поддерживать соответствующие техпроцессы. OpenMeetings использует практически все сервисы Apache, а именно автоматические ночные сборки релизов OM Continious Integration c использованием Jenkins баг трекер OM Issue Tracking, построенный на известном удобном продукте Jira списки рассылки OM Mailing lists, которые помогают поддерживать живую связь с сообществами пользователей и разработчиков в настоящий момент их шесть веб-площадка хостинг для сайта OM сертификаты для java апплета, обеспечивающего совместное использование экрана географически распределенная сетевая инфраструктура для доставки дистрибутивов CDN Wiki сервис для ведения документации. В Apache это привычный многим разработчикам Confluence. В публичной части содержится 43 раздела, их составляли разработчики разных команд с 2011 г. Использование готовых сервисов на веб-порталах Apache существенно облегчает жизнь разработчиков, поскольку нет нужды поддерживать их самим, что позволяет эффективно сфокусироваться на развитии собственно программных продуктов. OpenMeetings удовлетворяет джентельменскому набору требований для систем этого класса. При входе на демо-сайт а именно с него практически у всех начинается знакомство с функционалом OM пользователь видит дашборд рис. 1. Он выглядит одинаково независимо от того, где установлена серверная часть OM на демо-сайте разработчиков или на сервере клиента. В дашборде через кнопки двух меню и окон-виджетов пользователь может делать следующие действия 1 стартовать новое 2 пользоваться совещаний 3 создавать виртуальные комнаты через экран календаря в неограниченном количестве 4 использовать 5 делать рассылку с возможностью автоматической привязки виртуальной комнаты совещания и общаться с другими пользователями через внутренний 6 вести для планирования совещаний с автоматической рассылкой приглашений всем участникам 7 управлять каталогом совещаний 8 тестировать технические возможности своей 9 редактировать свой пользовательский 10 производить в базе зарегистрированных пользователей OM 11 читать новостную ленту 12 управлять через виджеты 13 пользователь с правами администратора может заводить неограниченное количество системы, создавать для них публичные и приватные виртуальные комнаты. Комнаты могут быть 3 разных типов а Конференция с равными правами всех участников до 25 чел. б Вебинар с ограниченными правами на видео и модерацию до 100 чел в Интервью с 2 видеоокнами для 2 чел. При планировании совещания через календарь комната выбранного типа создается на сервере автоматически. На демосервере доступны все три типа публичных комнат. Когда пользователь заходит в комнату, сервер запрашивает разрешение использовать его микрофон и веб-камеру, а также предлагает провести проверку качества изображения и звука. После входа в комнату пользователь видит следующие рис. 2, на которой можно рисовать, писать, выкладывать картинки, видео и документы во всех популярных форматах совместимых с OpenOffice таких досок может быть несколько, так что пространство комнаты можно назвать для создания разных досок для разных целей на одном экране и связанное с ней для управления параметрами доски для всех участников совещания поверх содержимого доски, которые легко передвигаются в любое место экрана для управления действиями и правами пользователей для списка участников списков документов и видеозаписей для чата и отслеживания статуса и действий пользователей. Функционал комнаты обеспечивает 1 передачу данных звука и видео 2 для коллективной работы с документами, презентациям, изображениями, видео 3, когда один из участников показывает остальным экран своего компьютера в виртуальной комнате 4 приватный c одним из участников и общий со всеми участниками 5 проведение для голосований участников, публикация их результатов, 6 пользователей внутри комнат. Зайти в дашборд или непосредственно в комнату можно также по ссылке с любого сайта или портала, интегрированного с OM подробнее об этом см. далее На данный момент код мобильного клиента OpenMeetings не является открытым, существует только платная версия под Android, которую можно купить стандартным способом через GooglePlay. Версия адаптирована для использования с мобильных устройств и имеет упрощенный функционал по сравнению с десктоп-версией. Пользователь мобильного клиента может зайти с телефона в виртуальную конференцию, слышать, что происходит в комнате и видеть окно выступающего участника. Также доступен приватный и публичный чаты. Пока мобильный пользователь не имеет доступа к доске и общему экрану, не может модерировать совещание, следить за списком участников, загружать файлы и т. д. В скором времени планируется выход аналогичной версии для мобильных устройств фирмы Apple операционной системы iOS. Полный функционал OpenMeetings будет доступен мобильным пользователям после перехода пользовательского интерфейса OpenMeetings на технологии html5webRTC. Заметим, что для мобильных устройств небольшого размера телефонов упрощенная мобильная версия в любом случае останется наиболее удобным вариантом. Система представляет собой классическое клиент-серверное приложение рис. 3. Центральным компонентом серверной части является открытый медиасервер Red5 со встроенным веб-сервером Apache Tomcat. Red5 занимается пересылкой медиа потоков и обеспечивает обмен сообщениями по технологии Flash между клиентами и сервером по протоколу AMF0AMF3, а также принимает и пересылает медиапотоки от cервера IP-телефонии Asterisk если настроено и Screen-sharing если активно. Компоненты системы реализованы как Java Spring Beans и могут быть настроены редактированием соответствующего XML-файла. Данные по объектам системы пользователи, группы, комнаты, организации, сообщения, логи и пр. хранятся в базе данных. Из коробки поддерживаются все популярные базы данных DB2, Derby, MS SQL, MySQL, Oracle, PostgreSQL. CRUD операции управления данными осуществляются по стандарту JPA используется Apache OpenJPA. Основные операции с объектами системы пользователь, группа, событие, файл, запись и т. д. могут быть совершены с использованием SOAPREST веб-сервисов, реализованных с помощью Apache CXF. Интеграция с различными сторонними системами производится через веб-сервисы. в настоящее время активно переписывается, завершается переход на технологии html5Apache Wicket web application. Технология FlashFlex используется остаточно только в отдельных элементах комнаты и в скором будущем ее в системе совсем не останется. Таким образом, стек технологий упрощается. возможна как с использованием внутренней базы пользователей, так и с использованием внешних систем 1 LDAPADS через Apache Directory LDAP API 2 GoogleFacebookVK и другие через OAUTH. распространяются через Red5 по протоколам RTMP, RTMPT для обхода брандмауэров, RTMPS для безопасного соединения., используется для просмотра записей совещаний и медиафайлов и выполнено средствами HTML5Wicket. Разработчиками OM сделано более 10 модулей интеграции плагинов. В основном это популярные CMS-системы. Большинство плагинов можно бесплатно скачать с сайта OM, но не все они являются актуальными и совместимыми с последними версиями. Большинство плагинов для последних версий ОМ являются платными, они не поддерживаются свободным сообществом. Благодаря интеграции с системой управления пользователями сайта портала система веб-конференцсвязи разрешает пользователю входить в комнату с тем же именем и реквизитами, с которыми он зарегистрирован на сайте портале. При внедрении в корпоративном секторе необходима интеграция с централизованной системой управления пользователями, такой, как, например, Active Directory или FreeIPA. Грамотные инженеры могут самостоятельно интегрировать систему, подобную OM, со множеством других систем, используя в качестве инструмента открытые веб-сервисы SOAPREST API. Команда Унипро, помимо CMS, имеет опыт интеграции с системами интернет-телефонии и видеконференцсвязи, CRM, Wiki, управления проектами и платежной системой. OpenMeetings работает на всех широко используемых операционных системах, это Linux, Unix, Windows, macOS., к ее пропускной способности, сильно варьируются в зависимости от вида проводимой встречи вебинар с одним-двумя выступающими и слушателями, либо рабочее совещание на 20 человек. Для оценки требований к пропускной способности сети сервера и клиентов был создан соответствующий калькулятор . В калькуляторе можно выбрать используемое участниками разрешение видео, количество участников с видео и количество участников без видео слушателей. На основе этих параметров выдается рекомендация о ширине канала для сервера и для участников. должна быть установлена любая база данных из списка выше кроме Derby, которая входит в состав дистрибутива. Операционные системы перечислены выше. Сервер Red5-Tomcat включен в дистрибутив OpenMeetings. В качестве аппаратного обеспечения для сервера желательно использовать сервер с многоядерным процессором хотя бы двухъядерным и оперативной памятью не менее 4 Гб. Дискового пространства без хранения видеозаписей потребуется около 2 Гб, однако если предполагается делать видеозаписи, то требуется предусмотреть достаточно дискового пространства для их хранения и обработки. Для примера часовое видео c разрешением 640 480 px требует примерно 500 Мб. для работы с OpenMeetings нужен любой браузер, поддерживающий Flash-расширение, а для использования функций Запись или Общий экран дополнительно потребуется установить Java версии 8 или выше. У существующего технологического решения есть как плюсы, так и минусы. Плюсы в том, что Flash-player доступен и уже установлен во всех популярных браузерах, и пользователю, чтобы запустить видеоконференцию в OpenMeetings, достаточно перейти на сайт по нужной ссылке. Еще одним плюсом является то, что приложение работает в браузере и соответственно на большинстве современных операционных систем. Теперь об ограничениях. Текущая реализация ограничена видеокодеками, которые поддерживаются Adobe Flash, а их немного, и большая часть этих кодеков являются закрытыми. В 2011 г. прекращена поддержка Flash под мобильные платформы, а значит, разработчикам мобильных клиентов стоит больших трудов реализация адекватного функционала без использования Flash на мобильных устройствах. Поскольку за десятилетний срок жизни проекта появились новые технологии, реализующие взаимодействие в реальном времени, сейчас рассматриваются варианты, способные адекватно заменить Flash-элементы интерфейсы на другой механизм передачи видео аудиопотоков. Одной из альтернатив является использование, позволяющих работать с видеои аудиопотоками прямо в браузере. На данный момент их поддерживает большинство современных десктопных и мобильных браузеров. WebRTC включает три различных API для обработки потоков данных 1 getUserMedia, который позволяет получать данные пользователя в браузере, например видеопоток с веб-камеры 2 RTCPeerConnection, позволяющий передавать потоки по сети 3 RTCDataChannel набор API, призванный помочь открывать UDP-соединения между двумя браузерами. Главное преимущество WebRTC перед Flash состоит в том, что эта технология обладает большей устойчивостью к падениям и использует напрямую html5 в отличие от технологии Flash. Кроме того, не нужно будет больше устанавливать какие-то плагины или расширения в браузер, поскольку все будет поддерживаться из коробки. Однако WebRTC достаточно молодая технология и пока еще плохо оптимизирована по сравнению с Flash, но так как она уже стала де-факто стандартом обработки потоковых данных, то не за горами появление высокопроизводительных реализации этой технологии. Мы ориентируемся на технологию WebRTC, поскольку она разрабатывается под патронажем веб-консорциума W3C, а значит, неизбежно станет официальным стандартом веб-передачи медиаконтента. В OpenMeetings мы начали переход на технологию WebRTC в июне 2015 г. как проект для студентов в рамках программы летней стажировки Google Summer of Code. Мы стремимся перейти к прототипу WebRTC с клиент-серверной архитектурой. Это приведет к повышению производительности и улучшит проведение веб-семинаров и веб-лекций, поскольку, имея один мощный сервер или кластер с высокой пропускной способностью сети, можно поддерживать большое количество слушателей, имеющих более скромное соединение и вычислительные ресурсы. Как только из проекта OpenMeetings уйдет Flash-технология, будет сделан качественный рывок, а именно разработка мобильных клиентов упростится на порядок, поскольку это позволит использовать только браузер без всяких дополнительных технологических требований Java, Flash, повысится стабильность, поскольку WebRTC падает гораздо реже, чем Flash, новые протоколы, используемые в технологии WebRTC, позволят ускорить пересылку видео аудио. К настоящему времени количество скачиваний с сайта OpenMeetings Apache превысило 125 тысяч. Какой процент скачавших серверную часть технических специалистов оставляет OpenMeetings в качестве долговременного решения веб-конференцсвязи для своего круга пользователей, оценить трудно. Но даже если 1 из 10, это тысячи инсталляций по миру, каждая с сообществом пользователей от 5 до сотен человек. В мейл-листах проекта состоит более 500 подписчиков, которые присылают сотни писем каждый месяц. Мейл-лист разработчиков включает 150 человек с вдвое большей активностью общения, чем пользователи. За время развития проекта в НЦИТ Унипро, с лета 2011 г., служба коммерческой поддержки OpenMeetings накопила определенную статистику, позволяющую сделать выводы о том, кто и зачем использует ОМ. Однако эта статистика достаточно приблизительная, что объясняется двумя существенными факторами. Первое самостоятельные инсталляции. В последние годы процесс инсталляции сервера ОМ существенно упростился, и его может выполнить любой продвинутый пользователь, зайдя на Apache сайт проекта. Подавляющее большинство инсталляций ОМ пользователи со всего мира делают сами, не прибегая к помощи официальной поддержки. Второе закрытость бизнеса клиентов. Около 40 тех, кто обращается к коммерческой поддержке, не раскрывают свои карты, не разглашая информацию о характере своего бизнеса. В порядке количественного убывания типы запросов описаны ниже. 1. свой или арендуемый до 2015 г. была самой распространенной услугой и составляла 60 от общего количества заказов. Обычно процесс установки сопровождался простым ребрендингом, который включал в себя замену лого и заголовка OM на логотип и название компании клиента. Сейчас процесс инсталляции уже настолько упрощен, что помощь коммерческой поддержки многим не требуется. 2. второй по распространенности вид услуг. Мы поддерживаем плагины к большинству широко используемых систем Joomla, Moodle, WordPress, Bitrix и др.. В открытый доступ для последних версий OpenMeetings выложен только плагин для Moodle, все остальные актуальные плагины коммерческие. Было несколько заказов на интеграцию с сайтами, написанными на php без CMS, также есть успешный опыт интеграции ОМ с PayPal. Это составило 20 . 3. это внесение любых изменений пользовательского интерфейса под требования заказчика. Как минимум клиенты просят поместить свой бренд. Кроме того, меняются элементы, стили, цветовая гамма. Бывают клиенты, которым нужно полностью изменить вид виртуальной комнаты, так что потом их пользователи и не догадываются, что в основе очередного брендированного сервиса ВКС лежит OM. 4. включает обновления системного ПО и OpenMeetings, мониторинг активности OM и поддержку всей работоспособности сервера OM. В последнее время он становится все более популярным. 5. это интеграция с серверами IP-телефонии обычно с Asterisk. 6. Модерирование было востребовано в нескольких проектах. Самый показательный российский ОНФ, перед выборами президента РФ в 2012 г. Для вебсовещаний, в которых участвуют с полными правами более 20 человек, имеет смыл привлекать опытного модератора 7. делалась под конкретного заказчика, которому требовалось проводить большее количество совещаний, чем позволяет один сервер одномоментно. В итоге было реализовано масштабирование на несколько серверов, которое в разы увеличило суммарную емкость системы. Этот компонент стал частью открытого кода системы с согласия заказчика. 8. для клиента заводится комната на сервере нашей компании, обычно эта комната интегрируется с сайтом клиента. Если говорить о том, кто наши клиенты, то их можно распределить на четыре категории. Здесь OM наиболее востребован 2. Как уже говорилось, основатель проекта Себастьян Вагнер начинал с того, что распространял ОМ в университетах Германии, интегрируя его с системой Moodle, традиционно используемой учебными заведениями. И если в начале развития проекта это были государственные университеты, то сейчас это в большинстве своем частные организации, зарабатывающие на различном онлайнобучении. Например, мы интегрировали ОМ с несколькими сайтами для онлайн-кон сультантов школьных репетиторов США. Есть и интересные нестандартные примеры, например, сайт музыкальной школы для взрослых в Германии. Согласно публичной статистике сайта, количество Moodle-сайтов, использующих OM, уже превысил тысячу . смежные с обучающими организациями потребители ВКС. В нашей практике это клиенты, занимающиеся медицинским онлайн-консультированием, а также несколько юридических компаний, проводящих консультации по Интернету. третий по распространенности вид клиентов, имеющих отделения в разных городах и даже странах 3. Сюда входят как госструктуры и некоммерческие организации, так и коммерческие компании, например банк. Здесь нельзя не сказать о нашем долговременном сотрудничестве с двумя крупными отечественными клиентами Объединенным народным фронтом и Агентством по инновациям и развитию Воронежской области. Наше сотрудничество с ними длилось несколько лет. Несомненно, ОМ получил сильнейший толчок в развитии благодаря такому сотрудничеству, так как за время совместной работы был существенно переделан пользовательский интерфейс и улучшен функционал. Мы получили бесценный опыт практического использования системы и модерировали несколько сотен совещаний. В течение 3 лет мы поддерживали три сервера заказчиков, на которых проводились регулярные видеоконференции с участниками из разных городов. Максимальное количество участников конференции достигало 100 человек. те, кто выпускает свои программные продукты и интегрирует в них функционал ВКС. В нашей практике это системы дистанционного обучения, платформы совместной работы. OpenMeetings как продукт для массового использования хорош уже и в текущей реализации плюс настолько прост в установке, что любой продвинутый пользователь может поставить его на сервер без посторонней помощи. Тем не менее, проект постоянно развивается. Намеченные к реализации в ближайшем будущем улучшения включают в себя следующее. Зачастую именно интерфейс отличает разные системы веб-конференцсвязи друг от друга, а технологическая начинка может быть одинаковой. И часто именно удобство интерфейса определяет выбор клиента. Поэтому совершенствование интерфейса постоянная задача в развитии продукта. Завершается переход к версии ОМ реализованной на html5Wicket. Осталась только небольшая часть элементов виртуальной комнаты с флеш-элементами. Благодаря этому комната и другие используемые экраны выглядят современно. Но главное то, что с появлением html5 любые изменения стилей и элементов могут делаться в разы быстрее, чем ранее. Еще одно преимущество этих изменений новый интерфейс поддерживается любыми браузерами, т. е. в ближайшее время функционал комнаты ОМ будет доступен в полном объеме из любого браузера, в том числе на мобильных устройствах с операционными системами iOS и Android. Об этом подробно написано выше. Кратко суммируем 1 использование устоявшихся кодеков для видео и аудио без перекодирования позволит сохранить совместимость со старыми клиентами и поддержать новых без заметных накладных расходов 2 существенно упростится разработка мобильных клиентов 3 повысится стабильность системы и скорость передачи медиасигналов. На данный момент доступен только мобильный клиент под ОС Android с достаточно ограниченным функционалом. Пользователь может подключиться к видеоконференции, однако не может видеть доску, принимать участие в голосовании, выполнять администраторские функции. В наших планах создание улучшенной версии с более широким функционалом, доступной также и с мобильных устройств Apple под iOS. Большое количество пользователей по всему миру является весомым стимулом для того, чтобы открытые системы ВКС жили и развивались. Несмотря на то что в концепции open source нет мощной коммерческой составляющей, технологические изменения популярных открытых программных систем продолжаются. Во многом это опирается на энтузиазм разработчиков, поскольку рядовые коммерческие клиенты расположены тратить средства на свои утилитарные нужды, а не на капитальный реинжиниринг систем. Стимулировать процесс может финансовая поддержка со стороны крупных институтов, как это делает бразильская научно-образовательная сеть RNP для проекта MConf или международная программа Google Summer of Code для проекта OpenMeetings, либо крупный заказчик или инвестор, заинтересованный в скорейшем улучшении открытого проекта с целью его интеграции в свои бизнес-процессы или в определенную технологическую платформу. "}
{"title": "АНАЛИЗ УПРАВЛЕНИЯ РЕГИОНАЛЬНОЙ ЗАЩИТОЙ   В ЧРЕЗВЫЧАЙНЫХ СИТУАЦИЯХ   ", "absract": "Исследуются процессы развития чрезвычайных ситуаций (ЧС) и формулируются задачи управления защитными мероприятиями. Уточняются исходные понятия, и разрабатывается общая классификация ЧС. Выделяются существенные, определяющие процессы проявления поражающих воздействий и выполнения  защитных мероприятий. Для структуризации этих факторов и формулировки задач управления предлагается система показателей защиты, которые допускают оперативное измерение в реальных условиях. : математические модели, чрезвычайная ситуация, принятие решений, региональная защита, управление.", "text": "В современных экономических условиях наблюдается рост конкуренции среди отраслей. Стремясь увеличить производство, многие предприятие пренебрегают соблюдением элементарной техники безопасности, что приводит к возникновению чрезвычайных ситуаций ЧС, которые сопряжены и с большими материальными потерями, и, к сожалению, с человеческими жертвами. Используя постоянный контроль за всеми источниками повышенного риска, можно многократно уменьшить последствия ЧС. Для упреждения аварийных ситуаций многие предприятия используют новейшие методы борьбы с ЧС. Самым эффективным в мировой практике является управление региональной защитой РЗ. Эта программа соединяет в себе комплексное использование вычислительной техники, факторы автоматики и связи, а также методы математического моделирования 18. Чтко действуя по этой программе, можно свести потери во время ЧС к минимуму. Поскольку разнообразие чрезвычайных ситуаций, которые уже проявились или могут проявиться, весьма велико, используем для их классификации общие причинно-след ственные и пространственно-временные признаки. По причине возникновения различаются ЧС техногенного, природного, экологического, социального и военного происхождения. Техногенные источники проявляются в виде аварий на производственных объектах, продукция или технологические процессы которых связаны с использованием высокого давленя, легковоспламеняющихся или агрессивных веществ. Выделяются следующие виды аварий на химически, радиационно и биологически опасных производствах при повреждении технологического оборудования, неисправностях в системе запуска и отключения, ошибках обслуживающего персонала на железнодорожном, автомобильном, воздушном, водном и трубопроводном транспорте при повреждении емкостей для перевозки опасных веществ или нарушении правил транспортировки на газо-, электро-, тепло-, водои канализационных сетях при их повреждении или разрушении на гидродинамических сооружениях при прорыве напорных плотин, защитных дамб или отстойников на строительных объектах при обрушении производственных или жилых зданий, железнои автодорожных мостов. Природные источники обусловлены разрушительными стихийными явлениями, среди которых выделяются геологические в виде землетрясений, оползней, селей, обвалов, лавин и камнепадов гидрометеорологические в виде снегопадов, ливней, паводков и наводнений агрометеорологические в виде циклонов, ураганов, смерчей, заморозков, засухи гелиофизические в виде природных пожаров, включая лесные, степные, торфяные и подземные астрофизические в виде опасных космических излучений, а также гравитационных, магнитных и электромагнитных возмущений, вызываемых различными космическими объектами. Экологические источники возникают в результате чрезмерной антропогенной нагрузки на окружающую среду. Среди них выделяются в литосфере при аномальном изменении и деградации почв, недр и лесов в гидросфере при загрязнении, заболачивании обмелении и пересыхании водоемов, рек и озер в атмосфере при уменьшении содержания озона, превышении допустимой концентрации опасных веществ, глобальных климатических изменениях в биосфере при уменьшении биопродуктивности, генетических мутациях, эпидемиях, эпизоотиях и эпифоотиях в экосфере в целом. Социальные источники являются результатом взаимовлияния экономических, политических, психологических и других факторов и предпосылок. Среди крайних проявлений социальных конфликтов выделяются забастовки саботаж террористические акты диверсионные акты массовые психические заболевания. Военные источники связаны с использованием средств вооруженного противоборства при пограничных конфликтах и в локальных войнах, а также в стратегических планах глобальной конфронтации. Среди этих средств выделяются обычное высокоточное оружие боеприпасы объемного взрыва, зажигательные, фугасные, осколочные, шариковые, кумулятивные и бетонобойные ядерное оружие химическое оружие бактериологическое оружие. В общем случае возможно взаимно обусловленное комбинированное проявление различных источников поражающих воздействий. По неблагоприятным последствиям различаются ЧС, приводящие к потерям среди населения, к ущербу народнохозяйственным объектам и к поражению окружающей природной среды. Выделение среди них тех или иных видов зависит от характера поведения указанных объектов в условиях возможных или реальных поражающих воздействий. По рассматриваемому признаку среди населения выделяются нетрудоспособное население, включая детей, стариков и стационарных больных трудоспособное население, включая работников производственной сферы и сферы обслуживания подготовленное население, включая подразделение гражданской обороны. Среди объектов народного хозяйства можно выделить следующие объекты производственной сферы, ресурсы которых могут быть использованы для выполнения защитных мероприятий объекты сферы обслуживания, ресурсы которых могут быть использованы для жизнеобеспечения населения исторические памятники и произведения искусства, ценную научно-техниче скую документацию и оборудование. В окружающей природной среде выделяются представители животного мира фауна представители растительного мира флора водоисточники, полезные ископаемые. По обеспечению защиты от неблагоприятных последствий различаются ЧС, характеризуемые использованием разведывательно-контролирующих, инженерно-техниче ских, медико-биологических, эвакотранспортных и материально-продовольственных ресурсов. Среди этих ресурсов выделяются в зависимости от их целевого назначения различные виды подразделений, которые реализуют необходимые защитные мероприятия. Разведывательно-контролирующие ресурсы предназначены для ведения разведки и контроля за изменением обстановки в зонах возможного или реального проявления поражающих воздействий. Эти цели достигаются с помощью подразделений инженерной разведки для выявления границ и степени разрушения жилых зданий и производственных сооружений, обнаружения вторичных источников поражающих воздействий, определения мест нахождения пострадавших и подходов к ним химической разведки для выявления границ химического заражения, определения концентрации ядовитых веществ и направления распространения зараженного воздуха, наблюдения и лабораторного контроля за изменением химической обстановки радиационной разведки для выявления границ и уровней радиоактивного загрязнения, установления режимов радиационной защиты, наблюдения и дозиметрического контроля за изменением радиационной обстановки медицинской разведки для выявления пострадавших людей, определения их состояния и условий оказания первой медицинской и врачебной помощи ветеринарной и агротехнической разведки для выявления пострадавших животных и растений, определения их состояния и условий оказания ветеринарной и агротехнической помощи. Инженерно-технические ресурсы необходимы для уменьшения ущерба народнохозяйственным объектам. Указанные цели реализуют подразделения инженерной защиты для повышения физической устойчивости жилых зданий и производственных сооружений, строительства и обслуживания защитных сооружений, расчистки проходов и разработки завалов в зонах разрушений, извлечения пострадавших из-под завалов, обустройства подъездных путей и маршрутов эвакуации химической защиты для обеспечения населения индивидуальными средствами защиты, локализации очагов выброса и обваловки мест разлива ядовитых веществ, дегазации прилегающей местности, помещений, оборудования, одежды и продуктов питания радиационной защиты для обеспечения населения противорадиационными укрытиями и организации йодной профилактики, сбора и захоронения опасных радиоактивных осколков, дезактивации прилегающей местности пожарной защиты для обеспечения объектов народного хозяйства средствами автоматической сигнализации и пожаротушения, локализации и ликвидации пожаров в жилых зданиях и в производственных сооружениях, извлечения людей из горящих помещений, борьбы с лесными, степными, торфяными и подземными пожарами технической защиты для повышения безопасности технологического оборудования с помощью средств автоматического контроля и отключения, выполнения профилактических и ремонтно-восстановительных работ на коммунально-энергетических сетях, а также для ремонта транспортной, инженерной, противопожарной и другой техники. Медико-биологические ресурсы требуются для уменьшения потерь населения, животных и растений защита биосферы. Эти цели обеспечивают подразделения медицинской защиты для оказания первой медицинской и врачебной помощи пострадавшим непосредственно в зонах поражения, погрузки их на транспорт и сопровождения при эвакуации врачебной защиты для оказания специализированной медицинской помощи и стационарного лечения пострадавших за пределами зон поражения в клиниках, больницах и госпиталях эпидемиологической защиты для санитарной очистки зон поражения, контроля за санитарно-гигиеническим состоянием прилегающей местности, профилактики и лечения инфекционных заболеваний среди населения ветеринарной защиты для санитарной обработки и лечения животных, локализации и ликвидации эпизоотий агротехнической защиты для обеззараживания растений и фуража, локализации и ликвидации эпифоотий. Эвакотранспортные ресурсы обеспечивают перемещение объектов биои техносферы внутри и вне зон поражения с помощью железнодорожного, автомобильного, воздушного, речного и морского транспорта. Указанные цели осуществляют подразделения обеспечения эвакуации пострадавших обеспечения транспортировки подразделений обеспечения подвоза материально-технических средств обеспечения подвоза воды, продуктов питания и предметов первой необходимости обеспечения эвакуации уникального оборудования и культурных ценностей. Материально-продовольственные ресурсы обеспечивают процессы выполнения защиты мероприятий необходимыми материалами и средствами. Эти цели реализуют подразделения материального обеспечения для хранения и распределения строительных, дегазационных, медицинских и других материалов и средств энергообеспечения для заправки транспорта горюче-смазочными материалами, подзарядки и замены аккумуляторных батарей, организации автономного электроснабжения коммунального обеспечения для расселения и коммунально-бытового обслуживания эвакуированного населения вещевого обеспечения для хранения и распределения спецодежды среди личного состава подразделений и предметов первой необходимости среди эвакуированного населения продовольственного обеспечения для хранения и распределения продуктов питания среди подразделений и населения. По пространственному признаку различаются ЧС в зависимости от масштабов неблагоприятных последствий локальные в пределах производственного участка, предприятия или микрорайона в городе местные в пределах городского района или города региональные в пределах района в области, нескольких сопредельных районов или всей области национальные в пределах нескольких сопредельных областей или всего государства глобальные в пределах нескольких сопредельных государств или континентов. По временному признаку различаются ЧС в зависимости от периода и динамики проявления поражающих воздействий и выполнения защитных мероприятий угрожаемые в период возможного проявления поражающих воздействий и выполнения предупредительных мероприятий кризисные в период первичного проявления поражающих воздействий и выполнения спасательных мероприятий после кризисные в период вторичного проявления поражающих воздействий и выполнения восстановительных мероприятий. Таким образом, рассматриваемые ЧС характеризуются следующей совокупностью открытых классификационных группировок, где, . Далее, не ограничивая общности рассмотрения, исследуем причинно-следственные связи между источниками поражающих воздействий, объектами поражения и защиты и ресурсами защитных мероприятий в ЧС регионального уровня. Функционирование региона в чрезвычайных ситуациях рассматривается как процесс последовательно-параллельного изменения состояний региональных компонентов. Поэтому его можно представить в виде формальной системы, 1 где множество компонентов времени множество состояний системы множество допустимых входных воздействий множество выходных величин оператор переходов системы, оператор выходов системы. Множество моментов времени, на котором рассматривается функционирование региональной системы, задается упорядоченным подмножеством множества вещественных чисел. В любой момент времени состояние системы представляется вектором состояний объектов поражения и защиты,...,..., . Множество альтернативных состояний каждого объекта на интервале времени обозначим . Пространством состояний или фазовым пространством системы является прямое произведение ... ... . Множество допустимых входных воздействий естественно разбивается на два непересекающихся подмножества защитных мероприятий и поражающих воздействий . При этом допустимые защитные мероприятия характеризуются возможными состояниями привлекаемых ресурсов, а допустимые поражающие воздействия возможными состояниями выявленных источников . Защитные мероприятия могут выполняться в любой момент времени ресурсами, которые образуют вектор,...,..., . Обозначим множество альтернативных состояний каждого ресурса на интервале . Тогда прямое произведение ... ... представляет пространство защитных мероприятий. Поражающие воздействия также могут проявляться в любой момент времени от источников, образующих вектор ...,..., . Пространство поражающих воздействий представляется прямым произведением ... ..., где множество альтернативных состояний каждого источника на интервале . Выходные величины, характеризующие функционирование системы в любой момент времени, образуют вектор характеристик,...,..., . Если множество различных значений каждой характеристики на интервале, то прямое произведение называется пространством выходных величин ... ... . Оператор переходов определяет траекторию движения систем в фазовом пространстве в зависимости от входных воздействий и, т. е. . Указанные воздействия разнонаправлены. Поэтому в пространстве различаются две области желательных и нежелательных состояний. Область образуется при движении системы в пространстве защитных мероприятий, а область при движении системы в пространстве поражающих воздействий . Целенаправленное функционирование системы происходит при выполнении защитных мероприятий, которые удерживают или переводят систему в область желательных состояний, противодействуя тем самым ее нахождению или переходу в область нежелательных состояний. Для эффективного управления указанными процессами необходимо предвидеть нежелательные переходы и с упреждением выполнять адекватные защитные мероприятия. Отсюда следует, что оператор, управляющий на интервале переходами системы в желательные состояния, должен строиться на основе предвидения возможных ее переходов в этом же интервале времени в нежелательные состояния от ожидаемых источников . Оператор в представлении реализуется как логически взаимоувязанная система защитных мероприятий, выполняемых ресурсами . Управление этими мероприятиями ресурсами должно формировать такую траекторию движения системы, которая обеспечивает достижение ее целевого состояния на ограниченном интервале . Эффективность управления региональной защитой Р3, характеризуемая оператором, зависит от умения упреждающе противодействовать или компенсировать ожидаемые поражающие воздействия от источников рациональным выбором или распределением ресурсов защитных мероприятий по объектам возможного поражения на интервале предвидения . Общим критерием эффективности управления Р3 является оценка степени достижения системой целевого состояния в пределах ограниченного интервала . Эта оценка производится на основе выходных величин, характеризующих функционирование системы на рассматриваемом интервале времени. Учитывая, что в представлении 1 оператор выходов и оператор переходов имеют одну и ту же область определения, выходные величины могут выражаться в терминах состояний объектов, ресурсов и источников . Соответственно в пространстве выходных величин можно различить область характеристик желательного функционирования системы, и область характеристик нежелательного ее функционирования, . Указанные выходные величины характеристики рассматриваются в каждый момент времени как координаты соответствующих векторов, и . Практическое измерение этих характеристик для оценки эффективности управления Р3 возможно с помощью показателей, рассмотренных выше при построении событийной модели развития ЧС. Различные значения этих показателей характеризуют те или иные состояния региональных компонентов, а общим критерием эффективности управления Р3 выступает обеспеченность объектов поражения и защиты ресурсами защитных мероприятий, которые необходимы для противодействия неблагоприятной среде. Поскольку указанные показатели и их значения существенно зависят от периода развития ЧС, разобьем множество моментов времени, на следующие подмножества, угрожаемый период, кризисный период, после кризисный период, где . Используя введенные понятия и обозначения, можно представить показатели состояний региональных компонентов следующими векторами а показатели желательных состояний ресурсов, где объектов, где б показатели нежелательных состояний источников, где объектов, где . Повышение эффективности управления Р3 проявляется в уменьшении значений показателей нежелательных состояний за счет увеличения значений показателей желательных состояний. В соответствии с событийной моделью развития ЧС общий целевой показатель max достигается последовательно путем реализации промежуточных целевых показателей состояний региональных компонентов в угрожаемый, кризисный и после кризисный периоды. Вышеизложенное позволяет расчленить общую задачу управления Р3 по выделенным периодам развития ЧС на три основные задачи 1 в угрожаемый период при заданном начальном состоянии объектов, предупредительности ресурсов и угрожаемости источников определить на ограниченном интервале времени, такой вектор ресурсов, который обеспечивает объектам, находящимся в зонах риска, максимальную сопротивляемость max, 2 в кризисный период при заданной начальной сопротивляемости объектов, спасательности ресурсов и критичности источников определить на ограниченном интервале времени, такой вектор ресурсов, который обеспечивает объектам, попадающим в зоны поражения, максимальную выживаемость max, 3 в послекризисный период при заданной начальной выживаемости объектов, восстановительности ресурсов и послекритичности источников определить на ограниченном интервале времени, такой вектор ресурсов, который обеспечивает объектам, находящимся в зонах последствия, максимальную реабилитируемость max, . В реальных условиях непосредственное и точное решение сформулированных задач существенно затрудняется следующими обстоятельствами быстро изменяющаяся обстановка требует оперативного перераспределения маневра ограниченных сил и средств в каждом периоде развития ЧС различная ведомственная соподчиненность специализированных подразделений приводит к необходимости непрерывного вертикального и горизонтального согласования многочисленных служб и органов, осуществляющих управление региональной защитой по ходу изменения обстановки отсутствие современной, достоверной и полной информации о складывающейся обстановке осложняет подготовку оперативных и обоснованных решений по адекватному противодействию неблагоприятной среде. Информационные процессы в указанных выше контурах периодически инициируются сообщениями из точек контроля текущего состояния региональных компонентов. Каждый информационный цикл в любом контуре включает последовательные этапы сбора, обработки и выдачи управленческих данных. На самом нижнем уровне этап сбора связан с измерением текущего состояния исполнительных элементов, передачей и приемом этих данных вышестоящим органом управления. На этапе обработки принятых данных вначале решаются задачи самоуправления, результаты решений передаются наверх, а также используются тем же органом для решения внутренних задач координации. Результаты последних выдаются на исполнительные элементы для непосредственной реализации. В вышестоящих подсистемах этап сбора связан лишь с приемом сообщений о состоянии подведомственных подсистем, в котором они находились в момент контроля. Принятые сообщения используются в управляющих подсистемах для решения своих задач самоуправления и координации. При этом результаты задач самоуправления выдаются на подсистемы более высокого уровня, а результаты задач координации на подведомственные подсистемы. Для выработки согласованных упреждающих решений в рассматриваемой иерархии подсистем необходимо выполнять следующие условия каждый цикл расчетов по корректировке траектории движения подсистемы на оставшемся интервале времени осуществляется в предыдущем интервале и по продолжительности не превышает этот интервал каждый этап выдачи подсистемой результатов задач самоуправления происходит одновременно с этапом сбора этих данных в вышестоящей подсистеме каждый этап выдачи подсистемой результатов задач координации и происходит одновременно с этапом сбора этих данных в подведомственных подсистемах. Цикличность рассматриваемых процессов обусловливает разбиение непрерывной оси времени на конечные интервалы, соответствующие периодам выработки реализации управленческих решений, не обязательно равные между собой. Изменение состояний региональных компонентов рассматривается в дискретные моменты времени, являющиеся точками на числовой прямой . Пусть момент окончания выполнения защитных мероприятий в 1 -ю смену, совпадающий с началом выполнения мероприятий в следующую -ю смену. Обозначим продолжительность -й смены. Допустим также, что в мини-регионе на выполнение мероприятий -й смены привлекаются его внутренние ресурсы, 1 -й смены свободные ресурсы региона и 2 -й смены свободные ресурсы макрорегиона. Если момент контроля предшествующего состояния региональных компонентов и, продолжительность одного информационного цикла выработки управляющих воздействий соответственно на, уровнях управления, то для синхронной подготовки и реализации указанных воздействий должны выполняться следующие ограничения . Эти ограничения определяют выбор точек контроля текущего состояния региональных компонентов, а также интервалы времени для межуровневого взаимодействия подсистем на этапах сбора донесений и выдачи распоряжений. Заложенный в систему принцип прогнозного управления по промежуточным целям реализуется путем периодической корректировки защитных мероприятий в зависимости от текущего, возможного и требуемого состояний региональных компонентов. С этой целью в каждом управленческом цикле выполняется определенная последовательность функций управления учет текущего состояния объектов, ресурсов и источников прогнозирование возможного состояния объектов ресурсов и источников, включая внешние планирование требуемого состояния ресурсов анализ рассогласования требуемого состояния ресурсов регулирование критических ресурсов, включая свободные внешние . Применительно к ситуациям кризисного периода задача оперативного управления РЗ подразделяется так для каждого мини-региона, принадлежащего региону в макрорегионе, при заданной начальной сопротивляемости объектов, самовыручка внутренних ресурсов и свободных внешних, критичности внутренних источников и возможных внешних на ограниченном интервале времени, где, такой вектор ресурсов, который обеспечивает минимальное отклонение требуемого объема спасательных мероприятий от возможного для объектов, попадающих в зоны поражения min, . Формулировка задач оперативного управления РЗ для других периодов осуществляется в терминах их показателей аналогично, и особых затруднений не вызывает. Для сформулированной выше задачи контур оперативного управления включает следующие функциональные задачи 1 учет текущего состояния региональных компонентов,...,...,..., 2 прогнозирование возможного состояния региональных компонентов, 3 планирование требуемого состояния ресурсов спасательных мероприятий, 4 анализ рассогласования требуемого и возможного состояния ресурсов спасательных мероприятий, 5 регулирование критических ресурсов спасательных мероприятий, Иерархическая структура СУРЗ взаимообусловлена пространственно-временными связями между функциональными задачами в контурах различных уровней и звеньев. Решение функциональных задач должно быть направлено на выработку таких управляющих воздействий, которые обеспечивают оперативное и согласованное движение подсистем различных уровней и звеньев к общей цели. Это достигается с помощью внутри и межуровневых взаимосвязей и взаимодействия указанных подсистем при решении функциональных задач. В иерархической системе контуров оперативного управления РЗ по каналам прямой связи поступают распоряжения на выполнение необходимых мероприятий, а по каналам обратной связи донесение о результатах выполнения этих мероприятий. Таким образом, каждая подсистема оперирует лишь с информационным отображением своего объекта. Текущее и возможное состояние объекта определяется в результате решения задач учета и прогнозирования. Выработка управляющих воздействий на объект сводится к определению требуемого состояния ресурсов защитных мероприятий и его согласованию с возможным состоянием, т. е. к решению задач планирования, анализа и регулирования. Поэтому далее будем различать в каждом контуре два взаимосвязанных комплекса функциональных задач моделирующий и управляющий. Моделирующий комплекс обеспечивает информационное отображение текущего и возможного состояния объекта путем решения задач учета и прогнозирования. Управляющий комплекс на основе этой информации обеспечивает выработку управляющих воздействий по корректировке хода выполнения защитных мероприятий путем решения задач планирования, анализа и регулирования. В каждую подсистему информация может поступать как с ее объекта, так и с вы шестоящей подсистемы. Свои действия каждая подсистема может согласовывать с подведомственными подсистемами, также с подсистемами одного с ней уровня непосредственно или вышестоящую подсистему. Эти согласования реализуются с помощью интернациональной процедуры, включающей взаимосвязанные информационные циклы двух видов внутрии межуровневые. Первые выполняются в контуре какого-либо уровня при децентрализованном управлении. Вторые возникают в процессе взаимодействия контуров различных уровней при централизованном управлении. Последовательное включение и выключение тех и иных контуров осуществляется результатом периодического контроля состояния региональных компонентов и определение рассогласования между возможным требуемым состоянием ресурсов защиты. В случае обнаружения отклонения подключаются контуры соответствующих уровней и звеньев для согласованного решения задач по перераспределению и свободных внешних ресурсов с целью удержания или возвращения этой подсистемы на заданную траекторию. Проблема оперативного и согласованного решения рассматриваемых задач в условиях ЧС связана с весьма жесткими временны ми ограничениями на выполнение внутренних и межуровневых информационных циклов, а также с необходимостью строгой синхронизации процессов выработки управляющих воздействий с процессами приема-передачи данных по каналам прямой и обратной связи. Указанные обстоятельства обусловливают комплексную автоматизацию процессов сбора, обработки и выдачи данных в иерархической системе органов управления РЗ. Процессы развития ЧС практически не поддаются достаточно точному формальному описанию. Вместе с тем они допускают классификацию и структуризацию составляющих компонентов источников поражающих воздействий, объектов поражения и защиты и ресурсов защитных мероприятий по общим причинно-следственным и пространственно-временным признакам. Осуществлена качественная детализация описания контуров оперативного управления в ЧС. В результате подразделены математические модели, описывающие переходы объектов поражения и защиты в те или иные состояния, в зависимости от состояний ресурсов защитных мероприятий и источников поражающих воздействий. Общая задача управления защитой регионов разделена на три основные задачи, которые подразделены для угрожающего, кризисного и послекризисного периодов развития чрезвычайной ситуации. "}
{"title": "ОПТИМИЗАЦИЯ ПЕРЕУПОРЯДОЧИВАНИЯ МОДЕЛЬНЫХ ЧАСТИЦ   ПРИ РЕАЛИЗАЦИИ МЕТОДА ЧАСТИЦ В ЯЧЕЙКАХ НА GPU  ", "absract": "Представлено описание реализации метода частиц в ячейках на GPU. Основным недостатком метода, с точки зрения затрат по времени, является функция переупорядочивания частиц между ячейками. Изложена оригинальная методика оптимизации данного этапа расчета, позволяющая избавиться от атомарных операций. Приведены результаты тестирования производительности на ряде современных графических процессоров. ", "text": " Для численного моделирования плазмы часто используется метод частиц в ячейках англ. Particle-in-Cell method, PIC 1 2. Моделирование плазменной турбулентности может проводится либо в гидродинамическом приближении путем добавки в уравнения магнитной гидродинамики МГД дополнительных слагаемых, обеспечивающих аппроксимацию турбулентности, либо в кинетическом приближении путем решения непосредственно кинетического уравнения Власова или Больцмана. Первый вариант является в данном случае неприемлемым в силу того, что характер возникающей турбулентности экспериментально и теоретически слабо изучен, а также в силу того, что плазма в данном случае субтермо ядерная плазма установки ГОЛ-3, ИЯФ СО РАН 3 и плазма перспективных установок управляемого термоядерного синтеза не является даже приближенно равновесной, так что уравнения МГД не могут быть использованы. Кинетическое уравнение может быть решено либо методом частиц в ячейках, либо прямым конечно-разностным методом. В обоих случаях существует пространственная сетка для решения уравнений Максвелла. При использовании метода частиц в каждую ячейку сетки добавляются модельные частицы, уравнения движения которых представляют собой уравнения характеристик для кинетического уравнения Власова, при использовании прямого конечно-разностного метода вводится дополнительная сетка в пространстве скоростей, так что возникает сетка в 6-мерном пространстве. Таким образом, вариант с использованием метода частиц является более затратным по количеству операций, но значительно более экономичным по памяти по сравнению с прямым конечно-разностным методом. Итак, только метод частиц в ячейках обеспечивает возможность решения задачи. Все варианты построения более хорошего быстрого метода на данный момент связаны с внесением тех или иных некорректных упрощений в физическую постановку задачи. По сути дела, расчеты с использованием метода частиц в ячейках проводятся именно с целью проверки того, какая из упрощенных физических моделей МГД, модель на основе первых моментов уравнения Больцмана... будет в данном случае корректной. Вычислительные эксперименты показывают, что при реализации метода частиц в ячейках наиболее важной характеристикой оборудования является доступ к оперативной памяти. С этой точки зрения целесообразно использовать для реализации метода частиц в ячейках гибридные вычислительные системы на базе графических процессоров GPU 4, которые обладают высокой пропускной способностью по доступу к памяти за счет своей архитектуры и таких аппаратных средств, как текстурный кэш и разделяемая память. Кроме того, большое количество ядер на GPU, так же как и на ускорителях Intel Xeon Phi, может быть использовано для создания более быстрой реализации метода частиц, чем на обычных многоядерных процессорах, таких как Intel Xeon, Intel Nehalem, IBM Power и др. Кроме того, необходимость перехода на GPU диктуется тем, что среди наиболее мощных компьютеров мира имеется тенденция к увеличению доли гибридных суперЭВМ. В 2018 г. это выглядит следующим образом суперЭВМ на основе Intel Xeon Phi и Nvidia Volta или Nvidia Pascal в Top500 и Top10 1, 2, 5, 6, 7, 9 . Такая тенденция поддерживается тем, что энергоэффективность гибридных систем выше, чем систем, имеющих традиционную архитектуру. В последнее время появилось много программных пакетов для моделирования динамики плазмы на основе метода частиц в ячейках, использующих графические ускорители GPU, например, PIConGPU 5 и ALaDyn 6 и др. 7 8. Вместе с тем многие имеющиеся коды для расчета динамики плазмы на GPU ориентированы на конкретный вычислительный либо алгоритмический вопрос и с точки зрения физических расчетов носят предварительный характер. В итоге имеется или корректно работающий численный код, которому не хватает вычислительной мощности, или очень быстро работающий код для гибридной суперЭВМ, физическая корректность результатов которого вызывает сомнения, потому что в его разработке участвовали только специалисты по суперЭВМ. Описываемый в данной работе код разрабатывался при участии физиков 9 10, что освобождает его от упомянутых выше недостатков. Математическая модель высокотемпературной бесстолкновительной плазмы представляется кинетическим уравнением Власова и системой уравнений Максвелла 1, которые в безразмерной форме имеют следующий вид 1 0, 4 1, 1, 4, 0. Здесь индексами и помечены величины, относящиеся к ионам и электронам соответственно 1, функция распределения частиц, масса, импульс, положение иона или электрона, напряженности электрического и магнитного полей. Для перехода к безразмерному виду в качестве единиц используются следующие базовые величины скорость света 310 смс плотность плазмы 10 см плазменная электронная частота 5,610 c . В начальный момент времени в трехмерной области решения, имеющей форму прямоугольного параллелепипеда 0, 0, 0, находятся плазма, состоящая из электронов и ионов водорода, и пучок электронов. Заданы плотности электронов пучка и электронов плазмы 1 . Плотность ионов плазмы равна сумме плотностей электронов пучка и электронов плазмы. Температура электронов плазмы и пучка температура ионов считается нулевой 0. Начальное распределение частиц по скоростям максвелловское с плотностью распределения 1 exp, 2 где разброс частиц по скоростям, средняя скорость пучка. Средняя скорость ионов и электронов фона нулевая. Все частицы распределены по области равномерно, начальная средняя скорость пучка направлена по и равна 0,2. Граничные условия периодические. В расчетах представляет интерес развитие отдельно взятой неустойчивой моды, поэтому длина области в направлении выбрана равной одной длине исследуемой плазменной волны, 4 шаг сетки. Эти эксперименты описаны в статьях 9 10. Основываясь на книге 2, приведем описание идеи метода. Пусть задача записана в абстрактной операторной форме 0. 1 Здесь, вектор-функция со значениями в, вектор независимых переменных с областью изменения в, 0 . В реальных задачах роль уравнения 1 выполняет кинетическое уравнение уравнение Власова или Больцмана или уравнения гидродинамики. Решение задачи 1 представляется в виде следующей интерполяционной формулы, . Этот переход называют разбиением среды на модельные частицы. Функция, называется ядром или форм-фактором модельной частицы. Эта функция описывает распределение некоторого признака массы, заряда, скорости в рамках одной частицы. Далее, если представить функцию в виде, где радиус-вектор частицы, импульс частицы, то можно показать, что решение уравнения 1 тождественно решению следующей динамической системы,..., 1... 2 Здесь вектор обобщенного поля. Исключительно важно, что переход к модельным частицам не означает замены реальной физической системы, где число частиц молекул, атомов, ионов и пр. порядка числа Авогадро 6,0210 на некую упрощенную систему из значительно меньшего количества таких же частиц, но более крупного размера даже для самых больших расчетов на суперЭВМ на данный момент не превышает 10 . Система уравнений 2 является не более чем математическим формализмом для решения уравнения 1, т. е. на данном этапе никакого нарушения математической строгости не происходит, система уравнений 2 точно так же описывает физический процесс, как и исходное уравнение 1. Вначале выполняется задание начальной конфигурации распределения вещества в расчетной области и полей. Производится распределение частиц по ячейкам так, чтобы плотности или токи, вычисленные по частицам, соответствовали заданной конфигурации. Далее на каждом временном шаге процесса моделирования выполняется 1 вычисление токов по значениям координат и скоростей модельных частиц 2 расчет электрического и магнитного полей по токам 3 сдвиг частиц вычисление новых значений координат и скоростей модельных частиц с учетом новых значений поля. При разбиении пространства на ячейки на 3-м шаге возникает необходимость перераспределения частиц между ячейками. Для того чтобы подчеркнуть значение полученной на GPU производительности, вначале приведем данные о производительности на CPU для процессора Intel Xeon Е5540 на 4 его ядрах время вычисления сдвига частиц было в 41,6 раза больше, чем для GPU Nvidia Tesla K40, т. е. 11,7 с кинетический вариант развития неустойчивости, 1 000 модельных частиц в ячейке. Причина этого заключается в том, что частицы обычно, в большинстве программ на основе метода частиц, хранятся в памяти без учета их расположения в пространстве моделирования, т. е. следующая по номеру в массиве координат частица может быть расположена в пространстве моделирования очень далеко от предыдущей. Это значит, что значения полей при расчете сдвига частиц будут взяты из совершенно другой части трехмерного массива, в виде которого хранятся поля. Это, в свою очередь, означает, что использование кэш-памяти будет очень неэффективным. Поскольку еще в работе 11 было показано, что переход от хранения координат и скоростей частиц в одном массиве без учета расположения в пространстве 1 вариант к отдельным массивам по каждой ячейке 2 вариант приводит к ускорению движения частиц в 1,52 раза, что подтверждено и в данной работе см. таблицу, то частицы хранятся распределенными по ячейкам напомним, что количество частиц в ячейке около 1 000. Но при этом возникает проблема переупорядочивания модельных частиц, т. е. передачи частиц, перелетающих в другие ячейки, на хранение в массивы, связанные с этими другими ячейками см. рисунок, . Напомним, что по соображениям устойчивости метода частиц модельные частицы могут перелетать только в соседнюю ячейку. Конфликт чтения-записи см. рисунок, возникает в силу того, что каждое перемещение частицы выполняется отдельным потоком CUDA, при этом необходимо считать частицу из массива частиц соседней ячейки и удалить ее оттуда, т. е. выполняется и чтение, и запись одновременно несколькими потоками, а для мощных GPU Volta, Pascal и др. несколькими тысячами потоков. Для разрешения конфликта в данном случае используются атомарные операции CUDA, что существенно замедляет выполнение алгоритма в целом. Поэтому есть необходимость выполнять операцию переупорядочивания по-другому. В данной статье предложен альтернативный более быстрый вариант. Время выполнения различных этапов вычислительного алгоритма на нескольких GPU оптимизированный вариант без атомарных операций по сравнению с неоптимизированным полужирный шрифт вариантом на Kepler K40. Время указано в микросекундах Execution time for different stages of the computational algorithm for various GPUs optimized version without atomic operations compared to non-optimized algorithm on Kepler K40 bold font. Time is given in microseconds Этап алгоритма GPU Kepler K40 Kepler K80 Pascal P100 Сдвиг частиц 433.8 348.06 338.1 Расчет поля 31.7 25.4 19.3 Переупорядочивание 1131 446.43 98.9 1 2 3 Следующая схема предложена для сокращения времени переупорядочивания модельных частиц 1 функция, исполняемая на GPU и производящая переупорядочивание, разделяется на две части 2 в каждой ячейке формируется список модельных частиц, которые должны быть перемещены в каждую из соседних ячеек 3 заполняется матрица размером 3, в которой записано, сколько модельных частиц должно быть перемещено в каждую из соседних ячеек всего таких ячеек 26 4 перемещаемые частицы копируются в буфера, соответствующие соседним ячейкам см. рисунок, . При этом ни разу не возникает конкуренция за доступ к памяти, именно поэтому удается избавиться от использования атомарных операций. "}
{"title": "ИНФОРМАЦИОННО-АНАЛИТИЧЕСКАЯ СИСТЕМА   С АЛГОРИТМАМИ ГЕНОМНОГО АНАЛИЗА ПАТОГЕНОВ ВИРУСНЫХ ИНФЕКЦИЙ  ", "absract": "Работа посвящена описанию структуры информационно-аналитической системы «Ixodes», ориентированной на работу c представительной коллекцией иксодовых клещей из разных биотопов, а именно для территорий Алтая, Сибири и Дальнего востока. Показаны варианты применения системы для анализа генетического разнообразия клещей и переносимых ими патогенов при помощи методов статистической обработки в виде круговых и столбчатых диаграмм (гистограмм). Описаны реализованные алгоритмы, позволяющие проводить анализ генетической последовательности исследуемого патогена на основе L-граммного подхода и методами разбиения филогенетического дерева на группы близких последовательностей. При этом для первичной обработки набора геномов используются методы множественного выравнивания последовательностей и метод присоединения соседей, позволяющий выполнить построение филогенетического дерева. Представленные алгоритмы и методы использовались для решения задачи генотипирования вируса клещевого энцефалита (ВКЭ). Представлены результаты апробации для методов разбиения филогенетического дерева и их сравнительный анализ. Описана архитектура информационно-аналитической системы для анализа набора геномов. Система предназначена для анализа множества геномов и их классификации, а именно для анализа генотипов внутри одного вида живых организмов, поскольку методы направлены для выделения различий геномов, имеющих схожую структуру. ", "text": " Территория России один из самых больших в мире ареалов, где распространены около 60 видов иксодовых клещей, для которых мелкие млекопитающие и животные, а также человек являются кормовой базой. При этом опасны не сами клещи, а передаваемые ими при укусах бактериальные инфекции боррелиоз, анаплазмоз, эрлихиоз, клещевой риккетсиоз. Заболевания вызываются бактериями и, вирусом Кемерово и вирусом клещевого энцефалита ВКЭ. ВКЭ самый распространенный и тяжелый эпидемический энцефалит на территории России и других стран. Осложнения этой острой инфекции могут завершиться параличом и летальным исходом 15. Ранее была разработана информационно-аналитическая система, позволяющая хранить данные полевых экспедиций, включая информацию по ареалам расселения, видовому составу насекомых и переносимых ими патогенов инфекционных заболеваний, определяемых путем проведения процедуры секвенирования. Основой информационной системы ИС является интерактивная карта рис. 1 с отображением мест полевых сборов и информации о них административное название, биотоп, климат, координаты мест сбора информации. Была реализована возможность просмотра численности клещей по виду, полу, биотопу, генам и инфекциям, связанным с конкретным насекомым рис. 2. Встроенные алгоритмы статистики позволяли провести сравнительный анализ встречаемости инфекций и генов и построить столбчатые и круговые диаграммы. Разработанные методы позволяют производить простой анализ, который можно расширить. Для расширения системы были реализованы методы кластеризации и классификации для обработки и проведения анализа набора геномов на основе их последовательностей. Можно определять родственные отношения между организмами по их геномам при помощи методов филогенетического анализа. Привлечение иерархических методов кластеризации позволяет получить визуальное представление исходных геномов, но при больших исходных данных возникает проблема поиска и анализа визуализированных объектов. Для этого необходимо применить алгоритмы кластеризации. Кластеризация позволяет разбить объекты геномы на классы со специфическими характерными признаками. Полученное разбиение на гены решает задачу генотипирования. Под генотипированием мы понимаем задачу отнесения произвольного штамма, представленного полной кодирующей последовательностью, к одному из известных генотипов. Использование технологии секвенирования 6 определения последовательности нуклеотидов ДНК всего генома обеспечивает возможность анализа связи полиморфизма сотен тысяч маркеров однонуклеотидных полиморфизмов Single Nucleotide Polymorphism, SNP, рассеянных по всему геному, с набором патогенов, переносимых клещами. Спектр задач, решаемых с помощью молекулярно-генетических маркеров в биологии, является весьма существенным. Это типирование и паспортизация хозяйственно ценных генов, генотипов, индивидов, включая трансгенные растения коммерческая сертификация анализ генетического родства и происхождения особей, сортов, форм, насаждений исследование генетической структуры популяций и ее динамики изучение уровня генетического разнообразия видов. Благодаря таким маркерам можно установить филогенетические взаимоотношения видов, решать спорные вопросы таксономии, осуществлять диагностику вирусных, бактериальных и грибных инфекций, построить генетические карты и др. 1. Чрезвычайно высокая опасность для человека вируса клещевого энцефалита объясняет пристальный интерес биологов к этому феномену и появление большого количества информации по ВКЭ, получаемое методами секвенирования генетического материала насекомых. Стала актуальна задача генотипирования, с помощью которой появилась возможность выделения разнообразных типов ВКЭ, с разной вирулентностью способностью инфекционного агента заражать живой организм. Исчерпывающая информация о генотипе содержится в полной кодирующей последовательности генома ВКЭ. Из нее можно извлечь ограниченное количество маркеров генотипирования в виде относительно коротких структурированных фрагментов РНК. В данной работе для апробации разработанных методов в задаче генотипирования ВКЭ мы выделяем структурированные РНК-маркеры 4. Для формального описания определим конечное множество символов алфавит, описывающих РНК-маркеры, обозначим . При кодировании генома для РНК это 4 символа соответствующие азотистым основаниям без, что соответствует используемым геномным данным 7. В системе разработан функционал, позволяющий решать задачу генотипирования на основе двух подходов кластеризации и классификации. Каждый из двух подходов базируется на уже известных теоретических основах кластеризации и классификации соответственно и включают новые методики решения этих задач для генотипирования. Для апробации методов используется уже известное разбиение штаммов на типы ВКЭ 8. Прилож. 1. Геномы для отдельных типов ВКЭ были предоставлены НИИ Биомедицинских технологий Иркутского государственного медицинского университета. Первый подход направлен на решение задачи генотипирования через кластеризацию на основе филогенетического дерева штаммов. Построение филогенетического дерева относится к задачам иерархической кластеризации 9. Филогенетическое дерево может строиться на основе различных алгоритмов, таких как UPGMA 10, WPGMA 10, Molecular clock 11 и др. Neighbor Joining 12 алгоритм использовался в работе для построения филогенетического дерева. Алгоритм позволяет итеративно построить филогенетическое дерево, присоединяя на каждом шаге итерации наиболее близкие геномы, используя расстояние Хэмминга. Филогенетическое дерево дает представление отношений между штаммами, но не решает задачу генотипирования. Для этого в работе разработаны алгоритмы кластеризации на основе филогенетического дерева, которые позволяют произвести генотипирование набора штаммов. Некоторые алгоритмы по методике выполнения напоминают уже существующие алгоритмы разбиения графов 13, но направлены на работу с филогенетическими деревьями, решая задачу генотипирования. Второй подход направлен на решение задачи генотипирования через классификацию. Классификация подразумевает наличие обучающей выборки, которая задает классификатор для каждого генотипа 14. Возможный подход к выделению РНК-маркеров на основе Lграмм был представлен ранее 15. В качестве L-грамм рассматриваются последовательности символов, длина последовательности соответствует фиксированному значению L. В системе представлен метод, при котором в качестве классификатора выступает линейный оператор на основе L-граммной характеристики генотипа, позволяющий при помощи L-граммной характеристики нового штамма отнести его к тому или иному типу 8. Ранее была разработана информационно-аналитическая система Ixodes, которая представляет собой трехуровневую систему. Трехуровневая архитектура базируется на системе клиент-сервер 16, которая содержит три основных компонента клиент, сервер и база данных. Клиентом в нашем случае выступает браузер пользователя. Клиент отправляет запрос на сервер, где хранится логика приложения, которая обрабатывает запрос и манипулирует с базой данных. Из базы извлекается нужная информация, снова обрабатывается, и ответ отправляется обратно пользователю. В системе предусмотрена аутентификация и авторизация. Аутентификация позволяет подтвердить, что клиент является зарегистрированным пользователем сайта. Авторизация позволяет проверять имеет ли пользователь доступ на выполнение определенных действий. Для авторизации в базе данных хранится таблица прав доступа. На текущий момент уже существующую систему дополнили новыми функциями, которые позволяют производить вычисления для ранее описанных алгоритмов и методов. На сервере выделен отдельный блок, который занимается только сложными вычислениями. Серверная часть разделена на две части. Первая занимается обработкой фактологической информации о патогенах, которая хранится в базе данных. Вторая направлена на вычисление результатов геномного анализа. Усовершенствованная система представима в виде схемы рис. 3. Такое разграничение позволило выбрать подходящие инструменты разработки для каждой части. Соответственно для обработки фактологической информации подходит программное обеспечение ПО, которое работает непосредственно с сервером и быстро обрабатывает простые запросы, например PHP скриптовый язык общего назначения, интенсивно применяемый для разработки веб-приложений. Для геномного анализа кроме ПО для работы с сервером необходимо использовать средства для вычислительных задач. На первом этапе геномного анализа рис. 4 выполняется запрос на вычисление филогенетического дерева. Сначала геномы, представленные в формате, подвергаются выравниванию с помощь программного обеспечения MAFFT, написанного на языке компилируемый, статически типизированный язык программирования общего назначения. Затем по выровненным последовательностям в формате строится филогенетическое дерево методом NeighborJoining через программу, написанную нами на . Полученное дерево записывается в формате . Затем рассчитываются гистограммы плотности параметра разбиения. Результат отправляется клиенту для получения следующего запроса. На втором этапе клиент подает на вход филогенетическое дерево в формате и параметр разбиения. На сервере в написанной нами программе дерево из формата преобразуется в объект, затем по параметру строится разбиение дерева на классы. Для каждого класса рассчитывается L-граммная характеристика, которая вместе с классами отправляется обратно клиенту. На третьем этапе пользователь может определить новый геном и отправить его на сервер вместе с L-граммными характеристиками других классов и порогом принятия решения. На сервере написанная нами программа вычисляет L-граммную характеристику нового генома, решает задачу классификации и возвращает клиенту ответ в виде числа совпавших L-грамм для каждой из характеристик и класса, к которому отнесен новый геном. Геномы для групп ВКЭ были предоставлены НИИ Биомедицинских технологий Иркутского государственного медицинского университета. Кодирующая последовательность символов CDS для каждого генома была взята из открытой базы данных генетических последовательностей GenBank . В соответствии с официально принятой классификацией различают три основных типа ВКЭ 5 1 дальневосточный 2 европейский 3 сибирский. Каждый геном из общего набора нумеруется цифрой от 1 до 3 в зависимости от его типа, которая для входных данных алгоритма эквивалентна группе. Для удобства все геномы нумеруются по порядку внутри группы. Нумерация геномов представлена в приложении 1 8. Построенное дерево отображается при помощи библиотеки phylotree.js . Дерево представлено в радиальной форме, иначе его было бы сложно разметить компактно на одном рисунке. Для лучшего понимания представлен путь от листа до корня дерева рис. 5. Для извлечения классов геномов разработаны следующие алгоритмы кластеризации на филогенетическом дереве 8 1 простой алгоритм разбиения 2 алгоритм последовательного сравнения листьев 3 поуровневый алгоритм. Для набора групп ВКЭ проведено выделение классов по каждому алгоритму для трех типов 1 разбиение на классы, которые соответствуют группам. 2 разбиение на классы меньшие, чем группы. 3 разбиение на классы большие, чем группы. Изначально подобран параметр, чтобы получить разбиение на классы, которые будут соответствовать исходным группам. Затем параметр изменен так, чтобы получить классы большие или меньшие исходных групп, при этом проверяется соответствие классов визуально на филогенетическом дереве для оценки качества работы алгоритма. Результаты представлены в таблице . После проведенных вычислений на основе данных ВКЭ можно сделать следующие заключения. Алгоритм последовательного сравнения листьев строит разбиение на классы, которые больше соответствуют визуальному представлению, чем классы, полученные другими алгоритмами. Поэтому для анализа групп и соответствующих им классов лучше использовать его. Алгоритм простого разбиения может помочь при анализе дерева на выделенные визуально узлы, состоящие из одного листа, но он хуже подходит для построения разбиения, которое соответствует крупным визуальным представлениям, чем предыдущий алгоритм. Предполагалось, что поуровневый алгоритм покажет лучший результат, но из-за того что у корня дерева расположены геномы первой группы, а уже потом из них выходит 2 и 3 группы, алгоритм строит разбиение, которое может не соответствовать визуальному представлению на дереве. Эту проблему можно решить, если начинать проход дерева с узла, где соединяются все три группы, но это можно выполнить только в том случае, если считать филогенетическое дерево неукорененным. В нашем случае рассматривалось укорененное дерево. Алгоритмы находят непересекающиеся классы, поскольку изначально можно положить, что каждый геном лежит в своем классе. Эти классы попарно не пересекаются. Во время работы алгоритма производится объединение непересекающихся классов, в конце которого получается разбиение. Помимо этого, объединяются всегда класс, состоящий из ранее объединенных геномов, и один новый геном, для которого вершина становится открытой, что исключает возможность повторного добавления генома в класс. При соотнесении групп и полученных классов геномы из одного класса могут не находиться в одной и той же группе. Во-первых, если мы получим разбиение на классы, один из которых содержит большее количество геномов, чем соответствующая ему группа, то очевидно, что часть геномов класса будет получена из других групп. Во-вторых, группы геномов устанавливает эксперт, что не гарантирует соответствие результату кластеризации. Для филогенетического дерева ВКЭ в силу соответствия групп и визуального представления мы не получили случая, когда геномы разных групп находятся в одном классе. Результаты работы алгоритмов The results of the algorithms Название Группы Классы меньшие групп Классы большие групп Простой алгоритм разбиения Дерево содержит выделенный узел, который разбивает дерево на группы в соответствии с визуальным представлением. При неправильном выборе параметра наблюдается выделение отдельных листьев дерева. Такой лист визуально выделен на дереве. Много классов из одного листа, которые соответствуют визуальному представлению на дереве для отдельного генома. При подборе правильных параметров, можно получить, помимо листьев, выделение классов 7 из геномов 9, 10 из геномов 3, 13 из геномов 4 8. Прилож. 2. Классы соответствуют визуальному представлению на дереве. Получили класс, в котором полное присоединение группы 3 к 1. Группа 2 осталась отдельным классом. Объединение групп соответствует визуальному разбиению, поскольку расстояние между визуальным представлением групп 1 и 3 меньше, чем для 1 и 2 8. Прилож. 2. Алгоритм последовательного сравнения листьев 3 группы представлены в виде 4 классов, которые совпадают с визуальным представлением. Группа 1 разбита на 2 класса, это связано с тем, что группы 2 и 3 расположены внутри группы 1 8. Прилож. 3. Алгоритм выделяет крупные классы и классы, состоящие из одного листа, соответствующие визуальному представлению на дереве. При получении более мелких классов, противоречий с визуальным представлением не возникает. Такая точность, возможно, обусловлена тем, что дерево изначально строится, опираясь на расстояние Хэмминга. Сначала присоединятся 3 группа к классу для части 1 группы, а потом и 2 группа к этому же классу. Объединение групп соответствует визуальному представлению, поскольку расстояние между визуальным представлением групп 1 и 3 меньше, чем для 1 и 2 8. Прилож. 3. Поуровневый алгоритм Дерево обладает выделенным узлом. На уровне этого узла, удалось построить разбиение для 2 и 3 групп в соответствии с визуальным представлением, но отдельно выделились классы для группы 1, которые могут не соответствовать визуальному представлению 8. Прилож. 4. При правильно выбранном параметре получаем разбиение на классы, среди которых есть как крупные, так и мелкие. Имеются классы, состоящие из листьев, не соответствующие визуальному представлению, их небольшое количество, что может говорить о том, что параметр разбиения подобран правильно. Есть уровни, на которых число листьев равно 0. Для этих уровней строились классы. Получаем, что группы 2 и 3 объединяются в класс, захватывая классы группы 1, а группа 1 распадается на классы. Классы группы 1 не соответствуют визуальному представлению 8. Прилож. 4. Описаны разработанные и реализованные алгоритмы кластеризации. Проведены апробация и сравнительный анализ алгоритмов кластеризации, при помощи апробации алгоритмов на геномах вируса клещевого энцефалита. Описана архитектура информационно-аналитической системы для анализа набора геномов. Система содержит реализацию разработанных методов и может работать на наборах из любых символьных последовательностей, а не только на наборах геномов. Система помогает в анализе множества геномов и их классификации, а именно для анализа генотипов внутри одного вида живых организмов, поскольку методы направлены на выделение тонких различий геномов, имеющих схожую структуру. Дополненный новыми функциями электронный ресурс позволит специалистам в области молекулярной биологии проводить анализ геномов, используя новые методы. На данный момент система включает новые функции, которые не использовались раньше в задачах генотипирования для вируса клещевого энцефалита. "}