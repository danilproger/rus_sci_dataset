РАСПРЕДЕЛЕННАЯ ПЛАТФОРМА ДЛЯ ПАРАЛЛЕЛЬНОГО ОБУЧЕНИЯ ИСКУССТВЕННЫХ НЕЙРОННЫХ СЕТЕЙ DISANN 

В данной работе описан процесс проектирования, реализации и внедрения системы распределенного обучения нейронных сетей на основе алгоритма learning-by-blockдля нейронных сетей прямого распространения. Распределение происходит в рамках массива обучающих векторов, который разделяется на несколько блоков, а блоки в свою очередь передаются вычислительными узлами. Таким образом, обучение нейронной сети распараллеливается в рамках одной эпохи. Так как нейронные сети по принципу  своей работы устойчивы к ошибкам, то потери блоков не критичны. Для избежания узких мест в момент синхронизации в конце каждой эпохи обучение может проводиться с потерями. При синхронизации и переходе к следующей эпохе необходимо и достаточно определенного процента использованных для обучения блоков или заданного объема процессорного времени. В рамках каждой эпохи потери в обучении компенсируются взвешенным значением последнегоуспешного результата. Система базируется на созданной ранее open-source платформе для проведения grid-вычислений Anthill. Применение концепции grid-вычислений, возможность управления через web-интерфейс  и свободного выбора библиотек для моделирования нейронных сетей позволили создать систему, обладающую высокой степенью гибкости и простоты использования.

 Распределенные вычисления открыли новые пути приложениям, требующим больших вычислительных мощностей. Рост объемов данных обусловил практически повсеместное использование распределенных вычислений 1. Вместе с тем применение распределенных вычислений для обучения искусственных нейронных сетей ИНС является относительно новой и мало исследованной задачей 2, 3. Еще в 40-х годах прошлого века достижения нейробиологии позволили создать первую искусственную нейронную сеть, которая имитировала работу человеческого мозга. Но только через несколько десятилетий, с появлением современных компьютеров и адекватного ПО стала возможной разработка сложных приложений в области ИНС. Сегодня теория нейронных сетей одно из наиболее перспективных направлений научных исследований. Этому способствовали сама природа параллельных вычислений и практически доказанная возможность адаптивного обучения нейронных сетей. C увеличением сложности задач, решаемых современной наукой, появляется необходимость во все больших вычислительных мощностях. Это требует серьезных инвестиций в модернизацию вычислительных систем. Однако в действительности уже имеющиеся ресурсы расходуются непродуктивно так, компьютеры в научных организациях работают максимум на 10 своей мощности, а серверы на 30 3. При рациональном использовании этих ресурсов можно выполнять существенные объемы вычислений. Решить задачу эффективного использования в глобальном масштабе ресурсов, принадлежащих одной или нескольким организациям, призвана технология grid-вычислений. Данные вычисления подтвердили свою значимость в науке такими проектами, как Boinc, EGEE, AntHill. Таким образом, растущая потребность в вычислительных мощностях и высокая степень интеграции распределенных вычислительных ресурсов делают создание платформы для обучения нейронных сетей приоритетной задачей. В данной работе изучены подходы к построению и параллельному обучению ИНС, раскрыты преимущества и недостатки каждой отдельной архитектуры, описана созданная распределенная вычислительная платформа для ресурсоемкого обучения нейронных сетей DisANN . Основные концепции DisANN В настоящее время распределенные вычислительные системы мало задействованы для решения задач с применением нейронных сетей. Исследование существующих технологий распределенного обучения нейронных сетей 46 позволило сформулировать основные концепции для построения и функционирования программной платформы, удовлетворяющей актуальным потребностям в моделировании нейронных сетей. Использование свободных мощностей. Зачастую крупные организации имеют большое количество свободных гетерогенных вычислительных ресурсов. Применение распределенных вычислений обеспечит оптимальное использование ресурсов, делегируя обработку заданий свободным узлам. Волонтерские вычисления. Принадлежность всех вычислительных ресурсов к одной организации не является обязательным условием. Организации должны придерживаться некоторых общих правил при участии в системе, но в целом могут работать независимо. Таким образом, для решения одной общей задачи могут быть задействованы ресурсы нескольких организаций, а также любых заинтересованных лиц. Использование стандартных интерфейсов и протоколов. Кроссплатформенные приложения и протоколы позволяют легко расширять вычислительную сеть на все возможные типы вычислительных ресурсов, включая персональные компьютеры, а также некоторые мобильные устройства и высокопроизводительные системы. Масштабируемость. Вычислительные ресурсы не управляются централизованно. Следуя концепции REST, информация о текущем состоянии задачи не хранится на клиенте, поэтому в любой момент можно добавить и удалить ресурс из системы. Обмен по протоколу HTTPHTTPS. Существует множество протоколов для передачи и приема данных, однако HTTPHTTPS используется практически повсеместно. Обеспечить безопасность информации в сложных средах распределенных вычислений чрезвычайно трудно, но простой перевод сервера системы в режим HTTPS сразу снимает эту проблему. Высокие требования к качеству услуг.Упрощение заданий и некоторая степень избыточности позволяют эффективно распределить нагрузку и обеспечить вычисления с максимальной надежностью. Минималистичный подход к распределению нейронных сетей. Для решения широкого круга задач необходимо распределение не самой нейронной сети, а только обучающей выборки. Массив обучающих векторов разделяется на несколько блоков, а блоки, в свою очередь, распределяются между вычислительными узлами. Таким образом, обучение ИНС распараллеливается в рамках одной эпохи. Такой процесс обучения относится к классу слабосвязанных задач. Свободный выбор архитектуры ИНС. Архитектуры ИНС крайне разнообразны, и для их применения к конкретной задаче зачастую требуется изменение не только параметров, но и самой модели. Поэтому система должна поддерживать модульную интеграцию программных библиотек, реализующих различные типы нейронных сетей. Потери данных. Так как ИНС по принципу своей работы являются устойчивыми к ошибкам, потери блоков не критичны. Более того, во избежание узких мест в момент синхронизации в конце каждой эпохи обучение может проводиться с потерями. Для синхронизации и перехода к следующей эпохе необходим и достаточен определенный процент использованных для обучения блоков или заданный объем времени процессора. Высокая скорость вычислений. Для разработки системы требуется простой и популярный в научной среде кроссплатформенный язык программирования. Исходный код программы должен быть минималистичным и легким в управлении и развитии. Поэтому основным языком разработки выбран Python. Код на Python несет обобщающую функцию, все критические задачи оптимизированы. Реализованы механизмы кэширования, оптимизированы запросы к БД, обмен изменениями весов ИНС происходит в бинарном формате, поддерживаются многопроцессорные системы. Разработка DisANN Руководствуясь описанными концепциями, авторы создали программную платформу DisANN с открытым исходным кодом 4. Система реализована в виде клиент-серверной модели, управляемой посредством web-интерфейса, созданного на основе Django. Для иллюстрации работы системы рассмотрим пример решения задачи. Пользователь должен войти в web-интерфейс и загрузить файл с описанием структуры ИНС, а также файл с обучающей выборкой. Далее обучающая выборка разбивается на заданное количество блоков, которые вместе со структурой нейронной сети распределяются по вычислительным узлам. На каждом узле проходит обучение сети на основе полученного блока, и на сервер возвращаются бинарные изменения весов. В конце каждой эпохи сервер обновляет модель ИНС и снова рассылает ее клиентам. Обратное распространение ошибки. 1. 2. 3. Обновляем выходные веса где wo вес, соединяющий скрытый нейрон j с k в выходном слое сети. 4. Обновляем скрытые веса где wh вес, соединяющий входной нейрон j с k в скрытом слое сети. 5. Результаты испытаний Было протестировано несколько обучающих выборок. Эффективность распределения обучения показана на рисунке 2. Обучающая выборка составила 10 000 векторов, вычисления производились на одной машине и 10 компьютерах. Следует отметить, что в среде с потерями данных функция ошибки заведомо не будет гладкой. Epochs Er ro r Er ro При распределении заданий между вычислительными узлами небольшой процент мощности тратится на обеспечение функционирования системы. Время отправкиполучения данных будет больше, но итоговое время обучения сети во много раз меньше, чем в случае обучения на одной машине. Практическое применение Система DisANN используется для решения обратных задач механики твердого тела на кафедре Информационные технологии Донского государственного технического университета. Система показала высокую эффективность при обучении сетей размером до 10 000 нейронов. Таким образом, в результате проведенного исследования была успешно разработана программная платформа, которая позволяет реализовать рапределенное обучение нейронных сетей. Пользователи могут подключать собственные модели нейронных сетей. Программа оптимизирована с точки зрения производительности, функциональности и надежности. Система может быть применена для создания импровизированного дата-центра и для обеспечения исследователей расчетами при минимальных временных затратах на развертывание и функционирование. 