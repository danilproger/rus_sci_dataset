ЭВРИСТИЧЕСКИЙ АЛГОРИТМ РАСЧЕТА РАЗМЕРОВ ПАМЯТИ  В МНОГОУРОВНЕВОЙ СИСТЕМЕ ХРАНЕНИЯ 

Введение:  рассматривается многоуровневая блочная система хранения данных. Уровни отличаются типом памяти  и скоростью работы с данными. Для каждого приложения, работающего с системой, задано требуемое качество обслуживания, выражаемое в виде времени отклика системы на запрос. Распределение адресного пространства приложений между уровнями памяти влияет на время отклика системы. Целью работы является автоматическое распределение  областей памяти приложений в зависимости от входного потока заявок таким образом, чтобы требования на качество  обслуживания были выполнены.  Результаты:  сформулирована оптимизационная задача расчета размеров памяти приложений на всех уровнях системы и предложен эвристический алгоритм ее решения. Используются такие характеристики потока запросов, как среднее значение доли запросов, попадающих в кэш, и распределение частот запросов  к блокам данных на дисках. Оценка работы алгоритма вычислена с помощью имитационного моделирования системы  хранения, на которую подавался поток заявок, снятый ранее с реальных систем хранения. Результаты моделирования  демонстрируют, что предложенный алгоритм в некоторых случаях позволяет повысить эффективность работы системы  хранения до 10 %.  Практическая значимость:  предложенный алгоритм может улучшить качество обслуживания в многоуровневой системе хранения данных. Ключевые слова  — многоуровневая система хранения, управление многоуровневой системой хранения, Storage  Area Network, качество обслуживания, моделирование. 

Системы хранения данных очень разнообразны по уровню сложности. Для некоторых задач обычные жесткие диски, которые используются в персональных компьютерах, не подходят. Например, у сервисов по бронированию и покупке билетов или у социальных сетей возникают дополнительные требования к системам хранения данных. Требуется хранить больше данных, одновременно обрабатывать заявки от большого числа клиентов, а также быстро работать с данными. Для таких целей используются специализированные сложные системы хранения, которые могут представлять собой целую сеть. В работе рассматривается пример такой системы хранения данных. Для увеличения скорости работы системы используются диски разного типа. Применение только очень быстрых дисков значительно увеличивает стоимость всей системы. Обычно комбинируют диски с разной скоростью работы. В этом случае более востребованные данные хранятся на более быстрых дисках, менее востребованные данные хранятся на медленных дисках. Со временем востребованность данных меняется, и управляющая система должна перекладывать данные между дисками разного типа. С системой хранения работает множество клиентов приложений. У каждого приложения свой объем востребованных данных, следовательно, пропорции, в которых данные распределены между дисками разного типа, у каждого приложения свои. Одному приложению может требоваться больше быстрой памяти для обеспечения заданной скорости работы, другому меньше, а со временем эта ситуация может поменяться в обратную сторону. Если объем быстрой памяти, выделенный приложению, слишком мал, то все наиболее востребованные данные приложения не поместятся в быструю память, и часть данных будет считываться с медленных дисков, что приведет к уменьшению средней скорости работы с данными для приложения. Кроме дискового пространства у каждого приложения есть своя область в кэш-памяти. Требуемые размеры этих областей также разные для разных приложений и зависят от характеристик потока запрашиваемых данных. В данной работе рассматривается задача выбора для каждого приложения размера выделяемой памяти в кэше и на дисках всех типов. Многоуровневые системы хранения известны давно. В работе 1 дано функциональное описание такой системы, а в работе 2 предложен алгоритм перемещения блоков данных между дисками разных типов. В работе 3 для идеализированной модели системы хранения представлены аналитические выражения для расчета требуемого размера кэша, а также для размеров дисков и оптимального количества уровней системы хранения. Оптимизация размеров кэш-памяти рассмотрена в работах 46, а распределение места на дисках в работах 7, 8. В работе 7 система состоит из двух уровней памяти SSD-дисков и обычных дисков, причем SSD-память работает в режиме кэша. В настоящей работе, в отличие от многих других, рассматривается изоляция приложений друг от друга в кэше и на дисках. Решения алгоритма распространяются не только на диски, но и на кэш, для которого вычисляются требуемые хит-рейты. Опишем систему хранения с четырьмя типами памяти. Имеется кэш-память и три типа дисков рис. 1, которые отличаются объемом и скоростью работы. Запрашиваемый блок данных сначала проверяется на наличие в кэше. Если блок в кэше отсутствует, то он считывается с того диска, на котором записан. Рассмотрим сценарий, в котором у каждого приложения, работающего с системой, есть своя независимая область в кэше и свой логический диск, при этом физически пространство логического диска распределено между дисками всех типов. Более подробно работа системы проиллюстрирована на рис. 2. Когда приложение 1 запрашивает блок данных, то система хранения сначала ищет его в выделенной для приложения 1 области кэша. Если блок найден, то время чтения блока равно времени чтения из кэша. Если блок отсутствует в кэше, то он считывается с диска. Приложение работает с логическим диском. На более низком уровне системы хранения лежат физические диски разного типа. Блок данных может лежать либо на быстрых дисках, либо на медленных. Примером быстрых дисков могут служить диски на flashпамяти SSD-диски, примером медленных дисков могут служить SATA-диски. Расположение блоков данных постоянно меняется системой. Будем считать, что раз в час система перемещает блоки данных в соответствии с вероятностями их запросов. Все блоки сортируются по популярности, и самые популярные записываются на самые быстрые диски, пока место, выделенное для данного приложения, не закончится далее блоки записываются на более медленные диски. Статистика по вероятностям запросов собирается в течение часа до следующего перемещения блоков. Пусть время доступа к блоку данных в кэше равно, а времена доступа к дискам, и . Пусть объемы памяти в кэше и на дисках соответственно равны, . C системой работает приложений, . Пусть объем памяти, выделенный для -го приложения на -м уровне памяти, равен Под уровнем понимается тип памяти. Тогда 1 Пусть вероятность того, что блок данных, запрошенный -м приложением, окажется на -м уровне памяти. Тогда среднее время доступа к блоку данных для -го приложения 2 где 1. Пусть заданы ограничения на средние времена доступа к блоку данных для каждого приложения 3 Следовательно, присутствует ограничение на вероятности 4 Вероятности связаны с объемами памяти . Чем больше памяти приложение использует на -м уровне относительно других уровней памяти, тем выше вероятность . Обозначим эту зависимость так где и функции зависимости между размером занимаемой памяти и вероятностью попадания на нее для кэш-памяти и дисков соответственно. Вероятность называют хит-рейтом. Важной характеристикой кэш-памяти является стековое расстояние 9 это количество уникальных блоков данных, запрошенных между запросом одного и того же блока, плюс один. Например, если блоки запрашивались в последовательности A, B, C, D, E, D, C, B, D, A, то стековое расстояние для второго появления блока A равно пяти. Функция распределения стековых расстояний дает вероятность того, что стековое расстояние для следующего запрошенного блока будет меньше либо равно . Это означает, что если иметь в распоряжении кэш размером блоков, то хит-рейт кэша будет равен . Для -го приложения этот факт можно записать таким образом Заметим, что . Рассмотрим теперь функцию распределения вероятностей того, что следующий запрошенный -м приложением блок данных будет находиться среди первых блоков с наивысшей вероятностью появления. Иногда называют популярностью адресов 9. Чтобы получить эту функцию для потока запрашиваемых блоков данных, необходимо посчитать частотные вероятности каждого блока. После этого отсортировать пары значений номер блока, вероятность по убыванию вероятности. Перенумеруем блоки по порядку после сортировки, начиная от самого вероятного. Функция, задаваемая этими парами, где аргумент номер блока по порядку, а значением является вероятность, будет функцией плотности вероятности блока, а построенная по ней функция распределения будет искомой . Если имеется три диска разных типов с размерами, и данные упорядочены по степени востребованности так, что самые востребованные хранятся на диске 1, а самые невостребованные на диске 3, то вероятность того, что данные будут запрошены с диска 1, равна 5 вероятность запроса данных с диска 2 6 а вероятность запроса данных с диска 3 7 Таким образом, функция для дисков разных уровней будет отличаться. В рассматриваемой системе хранения приложению выделена только часть каждого диска, т. е. . Перепишем уравнения 57 другим образом 8 9 10 При этом на вероятности имеется ограничение 4, а на ограничение 1. Все необходимые зависимости определены, перейдем к постановке задачи. Пусть известны параметры, требуется найти такие, чтобы выполнялись заданные ограничения . Кроме заданных параметров, в выражениях 810 присутствуют функции и, которые меняются в зависимости от потока запросов, и для реальной системы их можно получить только численно, они задаются таблицей. Это приводит к тому, что известные методы решения задач оптимизации в данном случае не применимы. По этой причине нами предлагается эвристический алгоритм решения задачи. Функционально предлагается заменить исходный кэш со статичным разделением областей между приложениями на описанный в работе 6 динамический кэш, который меняет границы областей приложений в зависимости от заданного для каждого приложения хит-рейта. В настоящей работе вводится дополнительный блок рис. 3, который раз в час будет пересчитывать для каждого приложения размеры областей, выделяемых системой на дисках разного типа. Значения вычисляются динамическим кэшем 6, чтобы достичь хит-рейтов, заданных для приложений. В предлагаемой схеме хит-рейты задает блок расчета . В начале работы системы размеры задаются некоторым типовым образом, например, одинаковыми или пропорционально требованиям на отклик системы. Рассмотрим алгоритм расчета . Как упомянуто выше, алгоритм вычисляет границы областей один раз в час. За час собирается статистика, вычисляется, и вместе с текущими значениями границ по выражениям 57 могут быть рассчитаны вероятности, . Используя эти вероятности и, которую можно посчитать в кэше, с помощью выражения 2 вычисляем . Далее все разделим на два списка. В первый список попадут, а во второй список где характеризует необходимый запас по требуемой задержке и представляет собой долю от . В первый список 1 попадут задержки тех приложений, для которых требование не выполнилось, а во второй список 2 задержки тех, для которых они выполнились с избытком. Если эти списки не пустые, то далее задача алгоритма состоит в таком изменении, при котором для всех приложений требования станут удовлетворяться. Для этого сначала списки 1 и 2 сортируются по возрастанию. Далее для приложений, чьи оказались в начале списков, происходит изменение размеров областей на дисках. Изменения производятся пошагово, по одному слоту, начиная с самой быстрой памяти. Сначала приложения с избытком уменьшается на один слот, а приложения с недостатком увеличивается на один слот. После этого по формуле 2 снова пересчитываются для двух приложений. В таблице представлены различные варианты значений и дальнейшие шаги. Параметр необходим для того, чтобы приложение с запасом по не стало приложением, не удовлетворяющим требованию. Если выполнилось условие 2, то дальше выбирается следующая пара приложений с недостатком и избытком причем приложение с избытком может остаться тем же, что было на предыдущем шаге. Если выполнилось условие 3, то резерв быстрой памяти у приложения с избытком закончился. В этом случае после шага назад приложение с недостатком все еще не удовлетворяет требованию. Далее необходимо повторить процедуру перераспределения для следующего уровня памяти . Если и в нем будет такой же результат, то выбирается следующее приложение с избытком, и процедура перераспределения памяти повторяется с уровня . Далее либо закончатся все приложения с недостатком быстрой памяти, что означает успешное завершение алгоритма, либо закончатся приложения с избытком, а с недостатком останутся. В последнем случае система не сможет удовлетворить текущим требованиям на задержку. Работа алгоритма основана на предположении, что во время функционирования системы присутствуют достаточно длинные периоды стабильности, тогда, собрав за определенное время статистику, можно рассчитывать на то, что новые значения будут актуальны. Для того чтобы быстрее реагировать на изменения потока запросов, в алгоритме предусмотрена процедура пересчета требуемого хит-рейта. Она работает каждые 10 мин, в то время, когда пересчет, не производится. По текущим значениям, с помощью формул 57 вычисляются, . Далее из этих формул можно выразить вероятность, которая и является требуемым хит-рейтом. Найденное значение передается в блок управления кэшем, который должен в результате работы выдерживать заданные . Определим коэффициент, по которому предложенный алгоритм будет оцениваться и сравниваться с системой без пересчета размеров областей на дисках. Для этого введем вспомогательный коэффициент 11 где количество десятиминутных интервалов, в течение которых среднее время считывания блока данных не превышало заданное для приложения, а общее количество десятиминутных интервалов работы системы. Тогда 12 откуда видно, что характеризует работу системы в целом по всем приложениям. Для вычисления коэффициента воспользуемся имитационным моделированием. В качестве модели кэша будем использовать LRU стек 9. В случае с постоянными размерами областей памяти в кэше будем использовать несколько LRU-стеков фиксированного размера. В случае с изменяемыми размерами областей размеры будут пересчитываться 6. В качестве модели дисков будем использовать таблицу, в которой записано, к диску какого типа относится каждый блок данных. Каждый час блоки будут перемещаться между дисками разного типа согласно, как описано выше. В качестве потока заявок использовались логи реальных систем хранения 10. На рис. 4 представлены пары коэффициентов для одного синтезированного лога и для нескольких общедоступных логов реальных систем хранения. Первый коэффициент получен для системы с размерами, выставленными пропорционально требованиям на задержку статические границы. Второй коэффициент получен при работе системы с предложенным алгоритмом пересчета динамические границы. Логи Financial1, Financial2 сняты с систем обработки транзакций в реальном времени в финансовых организациях. Логи WebSearch2, WebSearch3 собраны с известных поисковых систем 10. Из рисунка видно, что наибольший выигрыш получается на синтезированном логе. Как было отмечено, предлагаемый алгоритм опирается на предположение о наличии достаточно длинных периодов времени, на которых функция постоянна. В синтезированном логе это условие строго выполняется, поэтому выигрыш наибольший. В реальности поведение непредсказуемо. Кроме предсказуемости функции популярности для успеха алгоритма необходимо, чтобы приложениям требовались разные объемы памяти для выполнения заданных ограничений и чтобы эти объемы достаточно отличались от выделенного изначально объема. На логах Financial1 и WebSearch3 наблюдается незначительный выигрыш предложенного алгоритма. На логе Financial2 разницы нет. Это связано с тем, что свободных для перераспределения ресурсов не было и выдерживались изначально выставленные границы. На логе WebSearch2 выигрыш предложенного алгоритма составляет 12 . Можно также отметить, что благодаря введенным защитным параметрам и, на всех рассмотренных логах критерий не стал хуже по сравнению с исходной системой со статическими границами. Также были исследованы логи и других систем. На них выигрыш составил 110 . Работа предложенного в статье алгоритма перераспределения места на дисках основана на предположении о стабильности распределения популярностей адресов. Если это выполняется, то алгоритм дает ощутимое преимущество, что показано с помощью моделирования на искусственном потоке запросов адресов. При использовании потока с реальных систем данное предположение может не выполняться, однако моделирование показало, что довольно часто и на реальных потоках запросов алгоритм дает выигрыш до 10 . Это позволяет сделать вывод, что алгоритм можно использовать как помощника при конфигурировании системы хранения. 