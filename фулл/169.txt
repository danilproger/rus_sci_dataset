ИССЛЕДОВАНИЕ ПЕРЕОБУЧЕННОСТИ РАСПОЗНАЮЩИХ ПРОЦЕДУР НА ОСНОВЕ ПОЛНЫХ РЕШАЮЩИХ ДЕРЕВЬЕВ 

Статья посвящена разработке алгоритмов классификации на основе полных решающих деревьев. Данная конструкция решающего дерева позволяет учитывать все признаки, удовлетворяющие критерию ветвления. Исследуются вопросы снижения переобучения полных решающих деревьев с энтропийным критерием ветвления. Приведены результаты тестирования на реальных задачах.

 При решении задачи распознавания по прецедентам многие методы подвержены переобучению ситуация, когда качество работы алгоритма на новых объектах, не вошедших в состав обучения, оказывается существенно хуже, чем на обучающей выборке. Данная проблема может быть связана с такими явлениями, как минимизация эмпирического риска не гарантирует, что вероятность ошибки на тестовых данных будет мала переобучение появляется именно вследствие минимизации эмпирического риска переобучение связано с избыточной сложностью используемой модели всегда существует оптимальное значение сложности модели, при котором переобучение минимально 1. Деревья решений являются одним из известных инструментов, используемых в задаче распознавания, которые также подвержены переобучению. Процедура построения классического дерева решений представляет собой итерационный процесс. На каждом шаге выбирается признак, удовлетворяющий некоторому критерию ветвления, и строится вершина дерева. Однако, если при построении дерева несколько признаков удовлетворяют критерию ветвления в равной или почти в равной мере, выбор одного из них происходит случайным образом. При этом в зависимости от выбранного признака построенные деревья могут существенно отличаться как по составу используемых признаков, так и по своим распознающим качествам. В работе 2 при возникновении ситуации, когда два или более признака удовлетворяют критерию ветвления в равной или почти в равной мере, предлагается проводить ветвление по каждому из этих признаков независимо. Полученная в результате конструкция названа полным решающим деревом . Таким образом, в отличие от классического дерева решений, в ПРД на каждом шаге строится так называемая полная вершина, которой соответствует набор признаков X, и ветвление происходит по каждому из признаков. В 2 данный подход успешно продемонстрирован на примере усовершенствования алгоритма построения допустимых разбиений для случая бинарной информации без пропусков в признаковых описаниях объектов. В 3 для случаев вещественнозначной информации, наличия пропусков в признаковых описаниях объектов и неравномерного распределения объектов по классам описан алгоритм классификации, использующий при построении ПРД энтропийный критерий ветвления. В данной работе исследуется эффект переобучения ПРД на примере алгоритма AGI.Bias 3, так как ПРД является усложненной моделью классических деревьев решений. Предлагается методика снижения эффекта переобучения ПРД с использованием числовых характеристик построенного дерева для задачи, а именно, средней глубины дерева и среднего числа обучающих объектов, описание которых попадает в лист дерева. Опишем структуру ПРД. При построении ПРД могут встречаться два типа внутренних вершин полные и обычные. Определение 1. Определение 2. Определение 3. Глубиной ветви в ПРД называется число обычных вершин, содержащихся в этой ветви. Определение 4. Ребром в ПРД называется дуга, выходящая из обычной вершины и входящая в полную или висячую вершину дерева, а также дуга, выходящая из полной и входящая в обычную вершину. Определение 5. Глубиной ПРД называется максимальная глубина среди всех построенных ветвей дерева. На каждом шаге построения ПРД формируется в точности одна полная вершина. Далее из полной вершины X строится ровно q дуг.Каждая из этих дуг входит в обычную вершину, соответствующую признаку x, x X. Далее по каждой дуге, выходящей из обычной вершины дерева, соответствующей признаку x, осуществляется спуск и происходит переход к следующему шагу построения ПРД до тех пор, пока не выполнятся условия останова 4. В случае вещественнозначной информации для ветвления из обычной вершины, соответствующей признаку x, осуществляется бинарная перекодировка текущих значений признака x посредством выбора оптимального порога d 4. Обозначим через T подмножество обучающих объектов для левой ветви. Пусть v вершина, порожденная ветвью дерева с обычными вершинами x,. Если вершина v не является висячей, то ей ставится в соответствие порождающий набор N. В случае бинарной информации ветвление из обычной вершины, помеченной x, осуществляется стандартным способом. Пусть Q множество всех голосующих висячих вершин ПРД для распознаваемого объекта S. Если классов с максимальной оценкой несколько, среди них выбирается только один, а именно тот, который имеет наибольшее число объектов в обучающей выборке, иначе происходит отказ алгоритма от классификации объекта S. В алгоритме AGI.Bias вектор оценок,. Пусть m число обучающих объектов класса K, описания которых равны N, m число обучающих объектов класса K, и пусть m m. Таким образом, в алгоритме AGI.Bias оценка за класс K для висячей вершины v нормируется с учетом числа всех объектов класса K в обучающей выборке. Переобученность алгоритма AGI.Bias Исследование проблемы переобученности ПРД осуществлялось на задачах распознавания по прецедентам в случае вещественнозначной информации с пропусками в признаковых описаниях объектов и неравномерным распределением объектов по классам. Численный эксперимент осуществлялся на десяти реальных задачах из коллекции, собранной в отделе математических проблем распознавания и методов комбинаторного анализа ВЦ им. А.А. Дородницына РАН . Следует отметить, что для снижения эффекта переобучения в классических деревьях применяются методы, которые условно можно разделить на две группы. Первая группа методов используется в процессе синтеза дерева и заключается в раннем прерывании синтеза создание висячей вершины при выполнении определенных условий. Вторая группа методов используется после синтеза дерева. К таким методам относятся отсечение, слияние ветвей или замена листа поддеревом при выполнении определенных условий. При использовании ПРД для решения задачи распознавания, особенно для задачи с большим числом обучающих объектов или признаков, дерево получается ветвистым, с большим числом висячих вершин. Поэтому для снижения эффекта переобучения применяются методы из первой группы, а именно, ограничение на глубину ветви и на минимальное число объектов в висячей вершине. Так как значения этих величин для каждой задачи неизвестны и эмпирическое вычисление оптимальных значений требует немало времени, хотелось бы иметь механизм для их определения. Поэтому предлагается использовать свойства синтезированного дерева для конкретной задачи. К таким свойствам относятся средняя глубина дерева D и среднее число обучающих объектов O, описание которых попадает в висячую вершину. Данные свойства являются важными характеристиками и могут существенно повлиять на снижение эффекта переобучения. Таким образом, предлагаемый метод снижения эффекта переобучения состоит из двух процедур. Первая заключается в синтезе дерева с вычислением D и O, вторая в использовании характеристик D и O при построении дерева для классификации объекта. Исследуем переобученность на примере алгоритма AGI.Bias. Процедура заключается в случайном разбиении исходной выборки на обучение и контроль в процентном соотношении. Последний шаг на обучение попадает 90 всех объектов исходной выборки, на контроль 10 . Процедура разбиения исходной выборки на две части повторяется по 10 раз для каждого шага. При этом необходимо сохранять одинаковое соотношение числа объектов из разных классов в обучаемой и контрольной частях, равное соотношению числа объектов из разных классов в исходной выборке, то есть использовать стратификацию классов. Отличие изложенной процедуры от процедуры в системе Полигон в том, что в системе при переходе к следующему шагу приращение составляет 10 . В данной работе в том же сравнении используется другой функционал качества, q l где q процент правильно классифицируемых объектов класса K. На каждом шаге разбиения вычислялась величина 1 10, где значение функционала на объектах из обучения для i повтора на текущем шаге разбиения значение функционала на объектах из контроля для i повтора на текущем шаге разбиения. Исследование состоит из нескольких этапов. Этап I. Исследование влияния значения характеристики D на переобученность. Для этого использовались следующие комбинации алгоритма AGI.Bias с характеристикой D без использования характеристики D c использованием только характеристики D c использованием характеристики D1 c использованием характеристики D2. Модификация алгоритма AGI.Bias c использованием характеристики D2 означает, что при классификации объекта одним из условий, когда будет построен лист дерева, является превышение глубины текущей ветви дерева значения средняя глубина2. Этап II. Исследование влияния значения характеристики O на переобученность. Для этого использовались следующие комбинации алгоритма AGI.Bias с характеристикой O без использования характеристики O c использованием характеристики O c использованием характеристики O1 c использованием характеристики O2. Модификация алгоритма AGI.Bias c использованием характеристики O2 означает, что при классификации объекта одно из условий, когда будет построен лист дерева, число обучающих объектов в текущем множестве станет меньше величины среднее число обучающих объектов в листе2. Этап III. Исследование комбинации значений характеристик O и D. Для этого использовались следующие комбинации характеристик O и D без использования характеристик O и D c использованием характеристик D и O c использованием характеристик D1 и O1 c использованием характеристик D2 и O2. Для каждой задачи и каждой модификации алгоритма AGI.Bias вычислялась величина 1 17, где значение величины на i-м шаге разбиения. Результаты представлены в таблице 1. AGI.Bias D O означает, что использовалась модификация алгоритма AGI.Bias с использованием характеристик D и O. На каждом этапе также строилась кривая обучения зависимость средней частоты величины 1 частота ошибок на контроле от длины обучающей выборки. Для этого на каждом шаге вычислялась величина 1 10. При использовании методов для снижения переобученности появляется вероятность того, что модифицированный алгоритм будет совершать больше ошибок, чем стандартный. Поэтому важно выбрать такую комбинацию используемых характеристик O и D, которая даст хорошее снижение переобученности, и при этом качество классификации не будет сильно снижено. На рисунках 1 и 2 приведены кривые переобученности на этапах I и III для двух задач, ось ординат значение величины, ось абсцисс текущий шаг в . На рисунках 3 и 4 приведены кривые обучения на этапах I и III для двух задач, ось ординат значение величины, ось абсцисс текущий шаг в . Для этапа II графики не строились, так как значение характеристики O несущественно влияет на снижение переобученности и на показатели качества классификации. Кроме того, был проведен анализ качества модификаций алгоритма AGI.Bias с помощью метода скользящего контроля . Результаты приведены в таблице 2. Для каждой задачи и каждой модификации алгоритма в соответствующей ячейке приведены значения величины. Анализ результатов показал, что наибольшее влияние на снижение переобученности алгоритма AGI.Bias оказывает характеристика D. При этом в случае модификации алгоритма AGI.Bias с величиной D, начиная с момента, когда на обучение попадало более 70 объектов из исходной выборки, возникали случаи недообученности. При использовании характеристики D2 они происходили в среднем в 2-3 повторах на каждом из последующих шагов. Характеристика O незначительно влияет на переобученность в рассмотренных модификациях, в среднем снижение в случае O2 составляло 22,5 от исходного алгоритма. При использовании комбинаций характеристик D и O наблюдалось, что влияние характеристики O на показатели переобученности тоже незначительно. Анализируя таблицу 2, можно сделать вывод, что хорошие результаты показали комбинации AGI.Bias D O, AGI.Bias O1, AGI.Bias O2, AGI.Bias D2 O2. Характеристика O не так сильно влияет на обучение, и всплески, характерные при использовании величины D, появляются намного реже. При использовании характеристики O качество классификации во многих случаях немного улучшалось. Результаты представлены также для алгоритма С5.0 с применением встроенной процедуры отсечения в программу . Результаты тестирования представлены в таблице 3. Для каждой задачи и каждой модификации алгоритма в соответствующей ячейке приведены значения величины. Следует отметить, что в таблице 3 представлены наилучшие результаты алгоритма RandomForest на этих задачах. Это было достигнуто, когда число строящихся решающих деревьев было равно 30, при этом данный алгоритм анализировался с 10, 20 и 40 решающими деревьями. В таблице 3 представлены результаты алгоритма LADTree с 10 шагами бустинга, так как при этом значении алгоритм показал наилучшее качество. Кроме того, рассматривались случаи с 20, 30 и 40 шагами бустинга. Сравнение алгоритмов показало, что применение разработанной методики позволило понизить переобученность и в большинстве случаев повысить качество распознавания объектов для алгоритма AGI.Bias. Обобщая, отметим, что в работе проведено исследование переобученности ПРД на примере алгоритма AGI.Bias. Предложена процедура снижения переобученности с использованием свойств построенного ПРД. Первая часть процедуры заключается в синтезе дерева для конкретной задачи с вычислением D средней глубины дерева и O среднего числа обучающих объектов, описания которых попадают в висячую вершину дерева. Вторая часть процедуры использование характеристик D и O в процессе построения дерева при классификации объекта. Наилучшее соотношение снижение переобученностикачество классификации показали модификации алгоритма построения ПРД с комбинациями D O и D2 O2. Модификация D2 O2 алгоритма означает, что в процессе построения дерева при классификации объекта одним из условий, когда будет построен лист дерева, является условие, при котором глубина текущей ветви дерева превышает значение средняя глубина2 или число обучающих объектов в текущем множестве станет меньше величины среднее число обучающих объектов в листе2. Тестирование модифицированного алгоритма с другими известными методами построения решающего дерева показало его преимущество на большинстве реальных задач, рассмотренных в работе. 