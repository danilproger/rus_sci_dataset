АНАЛИЗ СВЯЗАННОСТИ СЛОЖНО-СТРУКТУРИРОВАННЫХ ТЕКСТОВЫХ ДАННЫХ, ХАРАКТЕРИЗУЮЩИХ ПРОЦЕССЫ ФОРМИРОВАНИЯ, РАЗМЕЩЕНИЯ И ИСПОЛНЕНИЯ ГОСУДАРСТВЕННЫХ ЗАКАЗОВ В НАУЧНО-ТЕХНИЧЕСКОЙ СФЕРЕ 

Проведен анализ существующих актуальных задач информационной поддержки административных государственных структур, отвечающих за реализацию федеральных и региональных целевых программ в научно-технической сфере. Описаны основные проблемы используемых способов накопления данных, характеризующих процессы формирования, размещения и исполнения государственных заказов (выполняемых в рамках целевых программ). Для решения данных задач предлагаются разработанные средства смыслового содержательного анализа исходного набора данных государственных контрактов с целью последующего установления связей между ними на основе методов семантического анализа. Проведен сравнительный анализ основных алгоритмов классификации и кластеризации текстовых данных, описано тестовое применение алгоритма LSA/LSI (Latent Semantic Analysis/Indexing) к имеющимся данным государственных контрактов научно-технической сферы, приведены необходимые сведения об их исходных характеристиках и о полученных результатах выявления тематически связанных групп (алгоритм реализован на базе разложения исходной диагональной матрицы употребляемости слов в документах по сингулярным значениям). Рассматриваются процедура морфологической обработки исходных текстовых описаний, проведенная с использованием библиотеки морфологического анализа Pymorphy, и процедура исключения стоп-слов, а также наиболее редко и наиболее часто встречающихся слов. Из-за отсутствия в алгоритме LSA/LSI поддержки пересекающихся кластеров обоснованно предложено и описано использование алгоритма нечеткой кластеризации FCM (Fuzzy Classifier Means). Подчеркивается научная новизна ожидаемых результатов, а также определена целевая аудитория конечных пользователей инструментальных программных средств, в которых в перспективе могут быть реализованы результаты работы

 Для административных структур государственных заказчиков-координаторов и специализированных дирекций, отвечающих за реализацию мероприятий федеральных и региональных целевых программ в научно-технической сфере, в условиях постоянно растущего объема массива сложно-структурированных данных государственных контрактов все более актуальным становится наличие средств информационной поддержки для решения следующих практических задач классификация имеющегося объемного массива данных об информационных объектах процессов размещения и реализации ГК по отраслям науки и техники, а также по прикладному назначению с последующим формированием соответствующих тематических кластеров знаний анализ ретроспективной информации массива данных об Объектах с целью принятия рациональных управленческих решений по реализации мероприятий федеральных и региональных целевых программ в научно-технической сфере анализ ретроспективной информации массива данных об Объектах с целью прогнозирования хода реализации мероприятий федеральных и региональных целевых программ в научно-технической сфере выявление схожих или идентичных по содержанию материалов различных ГК . В решении вышеуказанных практических задач следует выделить две основные проблемы. 1. Используемые принципы накопления данных ГК на сегодняшний день не позволяют при необходимости сгруппировать Объекты по их отраслевому и прикладному назначению, обобщить данные ГК по какому-либо специализированному направлению науки или техники. 2. Для решения вышеописанных научно-технических задач авторами статьи выбраны методики исследований и разработки средств смыслового содержательного анализа исходного набора Объектов на основе методов семантического анализа. Перечислим наиболее распространенные на сегодняшний день алгоритмы классификации и кластеризации текстовых данных. LSALSI Latent Semantic AnalysisIndexing. С использованием факторного анализа множества документов выявляются латентные факторы, которые в дальнейшем являются основой для образования кластеров документов. STC Suffix Tree Clustering. Кластеры образуются в узлах специального вида дерева суффиксного дерева, которое строится из слов и фраз входных документов. Single Link, Complete Link, Group Average. Данные алгоритмы разбивают множество документов на кластеры, расположенные в древовидной структуре, получаемой с помощью иерархической агломеративной кластеризации. ScatterGather. Итеративный процесс, сначала разбивающий множество документов на группы, а затем представляющий эти группы пользователю для дальнейшего анализа. Далее процесс повторяется, но уже над указанными пользователем группами. K-means. Относится к неиерархическим алгоритмам. Кластеры представлены в виде центроидов, являющихся центром массы всех документов, входящих в кластер. CI Concept Indexing. Разбивает множество документов методом рекурсивной бисекции, то есть разделяет на две части на каждом шаге рекурсии. Метод может использовать информацию, полученную на этапе обучения. Сравнительный анализ алгоритмов классификации и кластеризации текстовых данных по основным характеристикам приведен в таблице. Координаты документов в пространстве терминов записываются в матрицу TF-IDF. Числовым алгоритмам кластеризации присущи два способа выполнения кластеризации множества документов top-down и bottom-up. При top-down весь имеющийся объем документов изначально рассматривается как единый кластер, далее происходит его деление на более мелкие составляющие. При bottom-up изначально каждый документ рассматривается как отдельный кластер. В процессе работы наиболее близкие документы объединяются в кластеры, включающие все больше и больше документов. Реализация алгоритма заключается в сравнении множества всех контекстов, в которых употребляются слова или группы слов, и контекста, в которых они не употребляются, что позволяет сделать вывод о степени близости смысла этих слов или групп слов. Также данный алгоритм позволяет успешно преодолевать проблемы синонимии и омонимии, основываясь только на статистической информации о множестве документов и терминов. Технически метод заключается в разложении исходной диагональной матрицы употребляемости слов в документах по сингулярным значениям. Пусть А матрица, где элемент отображает употребление слова i в отрывке j 1. Матрица А будет иметь следующий вид. Элемент x представляет собой количество употреблений i-го слова в j-м отрывке. Каждая строка в этой матрице это вектор, соответствующий слову и отражающий его употребляемость в каждом документе. Следует заметить, что единственная часть матрицы V, которая влияет на элементы вектора t, это ее i-я строка. Аналогично на d влияет только j-й столбец, U d. Если из всех сингулярных значений отобрать k наибольших, получим аппроксимацию исходной матрицы векторами ранга k. Такое разложение обладает следующей особенностью если в матрице W оставить только k наибольших сингулярных значений, а в матрицах U и V только соответствующие этим значениям столбцы, произведение получившихся матриц W, U и V будет наилучшим приближением исходной матрицы A к матрице ранга k. В рамках НИР была проведена экспериментальная проверка использования алгоритма ЛСА для анализа имеющихся данных о заключенных контрактах научно-технической сферы. Каждый документ был представлен идентификатором и текстовым описанием, включающим следующие поля наименование контракта, общее описание выполняемой работы по контракту, описания работ на отдельных этапах выполнения контракта. В этой структуре очевидными недостатками исходных данных являются периодически встречающееся дублирование данных в описаниях, разнородность описаний контрактов по объему текста и наличие незаполненных полей. В качестве исходных данных были взяты 4 212 анализируемых контрактов, 1 561 контракт с пустыми общими описаниями работ, 1 283 контракта с пустыми описаниями работ по этапам выполнения контракта. На следующем этапе исключались наиболее редко и наиболее часто встречающиеся слова. В документах научно-технической сферы данные слова не влияют на классификацию. Слова, встречающиеся крайне редко, тоже следует исключить из исходных текстов. Подбор верхней и нижней границ частот осуществляется эмпирически экспертом и индивидуален для каждой тематики документов. Для исследуемых данных были отобраны слова, значения частот вхождения которых составили от 10 до 600. Изначально в документах содержалось 34 516 слов, исключение редко и часто встречающихся слов сократило объем слов, используемых при классификации, до 4 200. Далее была заполнена и нормализована матрица употребляемости отобранных слов в документах, проведено ее сингулярное разложение. В итоге при наиболее успешном варианте понижения ранга до 300 было выявлено 60 тематических групп слов. В каждой из групп содержалось от 4 до 15 слов. Группы, включающие менее 4 слов, не рассматривались, так как не имели смысловой практической значимости. Приведем примеры найденных тематических групп слов, подтверждающих возможность применения метода ЛСА для поставленных задач. Группа 1 преподаватель, рассмотрение, совет, ученый, школа, молодой. Группа 2 жилой, сооружение, энергопотребление, отопление, здание. Группа 3 больной, лечение, ранний, мозг, пациент, патология, аппаратно-программный. Группа 4 сервис, облако, высокоскоростной, трафик, реальный, сетевой, атака, облачный. Одним из главных недостатков метода ЛСА является отсутствие поддержки пересекающихся кластеров, то есть при кластеризации текстов отсутствует потенциальная возможность включения документа в несколько кластеров. Таким образом, в рамках исследуемой предметной области отсутствует возможность отнести контракт к нескольким тематикам одновременно . Найденные алгоритмом кластеры представляются нечеткими множествами, границы между кластерами также являются нечеткими. FCM-алгоритм кластеризации предполагает, что объекты принадлежат всем кластерам с определенной степенью принадлежности. Степень принадлежности определяется расстоянием от объекта до соответствующих кластерных центров. Данный алгоритм итерационно вычисляет центры кластеров и новые степени принадлежности объектов. Для заданного множества К входных векторов х и N выделяемых кластеров с предполагается, что любой х принадлежит любому с с принадлежностью интервалу 0, 1, где j номер кластера k номер входного вектора 2. Совместно с условиями нормирования данная система дифференциальных уравнений имеет такое решение и. На каждом итерационном шаге выполнения алгоритма осуществляются 1 регулирование позиций центров кластеров 2 корректировка значений принадлежности учитывая известные, вычисляются, если, в противном случае 3 проверка условия остановки алгоритма. На данный момент проводятся экспериментальные исследования использования алгоритма применительно к имеющимся данным ГК. Результаты работ, реализованные в виде инструментального программного средства, могут использоваться административными структурами государственных заказчиков-координаторов и специализированных дирекций, отвечающих за реализацию мероприятий федеральных и региональных целевых программ в научно-технической сфере, в качестве инструмента поддержки принятия управленческих решений и прогнозирования хода реализации мероприятий целевых программ в научно-технической сфере, а также выявления схожих или идентичных по содержанию материалов различных ГК представителями инвестиционных организаций для информационного обеспечения выбора направлений инвестиций в научно-технической сфере участниками проектов в научно-технической сфере для систематизации и классификации массива данных ГК по интересующему отраслевому и прикладному назначению. 