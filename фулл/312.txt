ФОРМЫ, ЯЗЫКИ ПРЕДСТАВЛЕНИЯ, КРИТЕРИИ И ПАРАМЕТРЫ СЛОЖНОСТИ ПАРАЛЛЕЛИЗМА 

Рассматриваются различные аспекты создания языков и сред параллельного программирования и реализации параллелизма в компьютерных системах. 

 Компьютер сегодня не только тонкий инструмент для решения сложнейших научно-технических проблем, но и, пожалуй, главенствующее звено в процессе автоматизации всех сфер человеческой деятельности. Ал-Хорезми, выдающемуся мыслителю и математику Древнего Востока, пытавшемуся найти описание нечто общего и многократно повторяющегося в рациональной деятельности людей, было бы приятно узнать, насколько плодотворной оказалась его идея. Другому математику и выдающемуся инженеру фон Нейману повезло значительно больше в воплощении алгоритмической парадигмы в реальность его решение о представлении алгоритма в виде командной программы, хранящейся вместе с данными в памяти компьютера и выполняемой в виде упорядоченной последовательности операций над адресуемыми данными, оказалось настолько простым и плодотворным, что до сих пор продолжает жить в устройстве почти всех компьютеров. Сегодня нередко можно услышать критику в адрес строго последовательной концепции программы фон Неймана 1 как весьма ограниченной на общем фоне обычно параллельных и асинхронных процессов, с которыми мы сталкиваемся при программировании реальных задач. Но при этом игнорируется тот факт, что модель последовательной программы фон Неймана существенно упрощает архитектуру компьютера, в частности процессорную часть, оставаясь в то же время универсальной в алгоритмическом смысле. Последнее означает, что любые параллельно протекающие конструктивные процессы могут быть представлены в виде последовательной программы с сохранением их функционального значения как однозначных преобразователей входных данных в результаты. Однако хорошо известно, что последовательные языки оказались совершенно неприспособленными, когда их пытались применить для описания моделирования работы сложных систем, где асинхронность и одновременность выполняемых процессов норма, а не исключение. Их последовательная операционная семантика весьма ограничительная при программировании вычислений многих семантических объектов, таких, как, например, параллельные функции 2, или при вычислениях, в которых параллелизм является необходимым условием достижения требуемого качества алгоритма. Так, если ставить задачу минимизации времени вычисления значений функции на заданном множестве входных данных, используя при этом множество различных алгоритмов, естественным решением является их одновременное применение к каждому из данных и рассмотрение в качестве результата того из них, которое получено за наименьшее время. Сегодня компьютерная индустрия может производить компьютерные, или вычислительные, системы с сотнями тысяч самостоятельных компонентов, способных коллективно выполнять сложную работу, будь то вычислительные или управляющие процессы. Поэтому требуются совсем иные модельные, языковые и управляющие средства для их эффективного программирования и последующего параллельного выполнения. Традиционный подход к решению этой непростой проблемы на основе расширения языков последовательного программирования с целью описания параллелизма и создание распараллеливающих компиляторов, как показывает практика, не дает нужных результатов. Во-первых, возникает вопрос, зачем естественный параллелизм задач сначала надо превращать в последовательные формы описания, а затем выявлять его при компиляции, что не всегда можно сделать в принципе. Во-вторых, какие должны быть языковые средства, чтобы сразу строить программу как параллельную. Конечно, предыстория развития компьютеров, огромный багаж алгоритмов и программного обеспечения, созданных с использованием языков последовательного программирования, архитектура компьютера как последовательной машины еще долгое время будут обусловливать осторожность при всякой попытке кардинального изменения парадигмы, стиля и языков программирования. Считается, что история параллелизма началась с работы 3, хотя уже фон Нейман хорошо понимал все ограничения, которые создает концепция последовательного программирования с точки зрения развития архитектуры компьютера и повышения его быстродействия. Опережающие устройства обработки команд в компьютерах 60-х годов stretch и БЭСМ-6, динамический анализ и одновременное выполнение независимых в программе команд в CDC-6600, арифметический конвейер, введение векторных команд в компьютерах Crey наиболее значимые архитектурные нововведения, существенно увеличивающие быстродействие современных компьютеров. В среднем компьютер выполняет три-четыре операции одновременно благодаря усовершенствованию его процессора при выполнении последовательных программ. Все эти решения, хотя просты и имеют ограниченные возможности с позиции представления параллелизма, интересны тем, что дают средства, адекватные для представления параллелизма на задачном уровне, по крайней мере, вычислительных задач линейной алгебры. Рекурсия как более мощное средство с точки зрения задания параллелизма, задание упреждающего параллелизма в программе и другие особенности реального параллелизма задач и процессов остались за пределами возможностей простых средств представления параллелизма. Средства PVM, MPI, Multithreading 4, 5 стали стандартными решениями, вообще говоря, достаточно низкоуровневого процессного описания параллелизма в последовательных программах. Да и OPEN MP мало что изменяет в этой концепции параллельного программирования, давая возможность программисту с помощью комментариев указывать участки последовательной программы, подлежащие параллельному выполнению. Радикальный подход к решению проблемы параллелизма в работах по созданию комплексных средств параллельного программирования и управления параллельными процессами на компьютерных системах 6, 7 состоит в комплексном решении трех взаимосвязанных задач. Первая задача создание высокоуровневых языков параллельного программирования с формальной денотационной, ориентированной на описание параллелизма на задачном уровне, и формальной операционной семантикой, строго регламентирующей процессы параллельного выполнения программы на компьютерных системах. В основу такого языка в отличие от языков последовательного программирования может быть положен принцип явного отражения только информационной зависимости по данным между компонентами ее декомпозиции. Как следствие, независимые компоненты становятся источником параллелизма, реализуемого при выполнении программы 8, 9. Другой способ явного задания состоит в использовании функциональной нотации для отражения параллелизма через характеризацию как параллельных или последовательных операций композиции функций, используемых в языке. По этому принципу построен и реализован на компьютерных системах созданный авторами язык функционального параллельного программирования FPTL 10. Вторая задача создание среды, позволяющей упростить процесс разработки, отладки, прогонок на компьютерных системах и оптимизации параллельных программ 6, 11. В отличие от сред поддержки разработки последовательных программ экспериментальное исследование на реальной компьютерной системе параллельной программы с целью ее оптимизации принципиально важно для проектирования качественных и эффективных по времени выполнения и использованию ресурсов параллельных программ. Наконец, третья задача создание эффективных средств управления параллельными процессами, индуцируемыми при выполнении параллельных программ на масштабируемых и многоплатформенных компьютерных системах. Эта задача состоит из двух подзадач оптимального планирования процессов и оптимального управления загруженностью с целью оптимизации использования ресурсов компьютерной системы 6, 7, 11. Успешно решенная задача позволит существенно упростить и сделать независимым от конфигурации компьютерных систем проектирование параллельных программ для сложных вычислительных задач, задач распределенного управления, распределенной обработки информации и др. Предмет обсуждения в данной статье существенные для создания высокоуровневых языков параллельного программирования особенности, формы представления и характеристики параллелизма, а также критерии, по которым можно судить о сложности параллельных программ. Формы и характеристики параллелизма Понятие параллелизма в вычислениях, управлении, коллективной работе и в других процессах связано с понятием процесса и одновременностью протекания актов и действий в процессах и их взаимодействием. Поскольку практический интерес представляют процессы, реализующие определенные цели, семантика параллелизма часто имеет внепроцессное обоснование причин, по которым те или иные действия в процессах или сами процессы могут выполняться одновременно. Систематизируем типы и формы параллелизма, возникающего в процессе решения задач, которые необходимо учитывать при создании методов и языков параллельного программирования и их реализации на ВС. Параллелизм на процессном уровне Работу компьютера, его операционной системы сегодня невозможно представить без понятий процесса, одновременности, синхронизации и взаимодействия процессов. Любая электронная схема компьютера построена на основе хорошо выверенных законов, как правило, параллельной работы и методов синхронизации ее взаимодействующих элементов. По сути многие базисные понятия, используемые в широко известных моделях параллельных процессов сетях Петри 11, моделях Р. Милнера 12, Ч. Хоара 13 и других, наследуются из языка описания электронных схем. Последовательная и параллельная композиции процессов, их порождение и взаимодействие, синхронность и асинхронность наиболее важные понятия, посредством которых описываются различные модели и языки описания параллельно протекающих и взаимодействующих друг с другом процессов. Именно на базе этих моделей созданы и широко применяются процессные языковые стандарты и средства, используемые для параллельного программирования . Для вычислительных задач, обработки информации, распределенного управления эти средства могут оказаться низкоуровневыми и в принципе ненужными, если есть развитые средства для управления процессами в том числе параллельными в компьютерных системах. Однако для описания работы операционной системы, процессов функционирования различных систем без этих средств не обойтись. Очевидно, не все в многообразии поведения процессов может быть непосредственно выражено средствами данных процессных моделей и языковых средств, поскольку они предполагают строго определенные операции композиции элементарных процессов объединение процессов, последовательную и параллельную композицию процессов, организацию циклов илии рекурсивные определения как механизмы порождения процессов 12, 13. Как следствие, переходы из состояния в состояние в процессной модели однозначно определяются локально, на основе непосредственно взаимодействующих процессов. Тем не менее, процессные модели и языки необходимы, если речь идет о реализации параллелизма на практике. Представление параллелизма на задачном уровне Декомпозиция и информационная независимость компонентов декомпозиции основа отражения параллелизма при разработке программ решения сложных задач. Параллелизм в программах на этом языке есть следствие информационной независимости их компонентов, он может быть эффективно реализован средствами программы в ВС 7. Уточним понятие информационной зависимости компонентов K и K, которые вводятся при декомпозиции сложной задачи и ее представлении на этом языке. Семантическое значение того, что делает K, пока не затрагиваем. Определение. Транзитивное замыкание отношения непосредственной информационной зависимости позволяет говорить об информационной зависимости K от K, если K K. Обозначим K множество всех входящих в описание задачи компонентов, которые зависят от K, и назовем K транзитивным классом K. Если K K, то K определен рекурсивно или принадлежит циклическому участку информационно зависимых от K компонентов, при этом K K. Определение. Компоненты K и K информационно независимы, если K K и K K . Языки, в программах которых явно задаются связи, отражающие непосредственную информационную зависимость между их компонентами, и только они, как это сделано в языке граф-схемного потокового параллельного программирования 8, 9, позволяют одновременно эксплицировать параллелизм в программе как следствие информационной независимости компонентов. Более того, данный принцип построения программ дает возможность просто реализовать одновременное выполнение компонентов по готовности их входных данных, что практически нельзя эффективно сделать для последовательных программ. Кроме того, легко реализовать также потоковый принцип выполнения программы, когда она применяется к потоку в общем случае поступающих в реальном времени данных на ее входе. При построении языков, в программах которых информационная зависимость между компонентами задается явно, представление условных конструкций требует особого рассмотрения. Определение. Допустим, что компонент программы K условно зависит от K, если K определяет необходимость использования выходных данных K после выполнения K. На рисунке 1 приведен фрагмент граф-схемы программы, у которой компоненты K, K, K и K зависят от условия K. Условные входы и выходы компонентов изображаются как квадраты, а другие входы и выходы в виде точек. При этом, если по левой связи передается значение истина, будут востребованы результаты выполнения компонентов K и K если значение истина передается по правой связи, будут использованы результаты выполнения компонентов K и K. В отличие от этого случая K или K будет выполняться только после завершения выполнения компонента К и компонентов K и K, от которых они непосредственно информационно зависят. Определение. Условную зависимость компонентов K и K от К, разрешающую упреждающее выполнение K и K, назовем слабой, в отличие от этого условную зависимость K и K от К, разрешающую выполнение K или K только после выполнения K, назовем сильной. Эквивалентными преобразованиями слабую зависимость можно трансформировать в сильную и наоборот, уменьшая или увеличивая параллелизм в программе. Ясно, что, увеличивая распараллеливание программы за счет увеличения упреждающих вычислений, в модели параллельного выполнения программы должны быть механизмы явного различения компонентов, отнесенных к упреждающим вычислениям, чтобы всегда отдавать приоритет в выполнении неупреждающим компонентам с целью обеспечения корректности . Кроме того, по той же причине и с целью увеличения эффективности необходим механизм прерывания выполняемых с упреждением компонентов после того, как станет известно, что их результаты не потребуются. Если параллельное выполнение программы организовано таким образом, что выполнение компонентов с упреждением подавляется, то такой параллелизм назовем строгим в противном случае упреждающим. При потоковом параллельном выполнении программы также необходимо учитывать, что временной порядок поступающих на вход графсхемы данных и вычисленных для них результатов может оказаться нарушенным. Введение в ЯГСПП 6, 9 тегирования данных, передаваемых между компонентами программы, позволяет обеспечивать взаимно однозначное соответствие между входными данными и выходными результатами выполнения программы. Информационная независимость компонентов программы может выражаться не только явным заданием информационных связей между ними, но также косвенно посредством применения операций композиции компонентов, обладающих свойством параллельности. В модели параллельного вычисления значений функций на FPTL только суперпозиция задает последовательный характер вычисления значений функций, к которым она применяется. Другие три операции композиции параллельны, более того, для операции требуется параллельное или квазипараллельное вычисление значений функций, к которым она применяется. Рассмотренные языки параллельного программирования, на которых параллелизм представляется соответствующими конструкциями языка, назовем языками с явным заданием параллелизма. В языках последовательного программирования параллелизм представлен неявно, и для его реализации нужны, с одной стороны, распараллеливающие компиляторы, выявляющие параллелизм, а с другой языки параллельного программирования, в которые транслируются последовательные программы. Коммутативный и некоммутативный параллелизм Выделение этих форм параллелизма связано с закономерным вопросом всегда ли компоненты программы, которые могут выполняться одновременно, можно выполнять последовательно в любом порядке. Ответ на этот вопрос имеет принципиальное значение, поскольку ресурсы ВС всегда ограничены и естественны ситуации, когда количество индуцируемых при выполнении программы и способных одновременно выполняться компонентов больше количества процессоров или компьютеров в ВС. В этом случае приходится упорядочивать выполнение этих компонентов, причем избранный порядок не всегда может быть произвольным. Определение. Параллелизм назовем коммутативным, если допустим произвольный порядок компонентов программы, которые могут выполняться одновременно. В противном случае параллелизм будем называть некоммутативным. Сложнее обстоит дело с так называемыми параллельными функциями, корректное вычисление значений которых не может быть просто сведено к последовательной форме. Достаточно рассмотреть случай, когда вычисление одного из этих значений не определено и длится неограниченно, а два других определены и равны. Программирование таких функций на последовательных или параллельных языках требует особого подхода. В функциональном языке FPTL представление и корректное вычисление подобного рода параллельных функций не вызывает проблем. Операционная семантика FPTL требует, чтобы при вычислении значения функции f f, полученной путемвремени. Кроме того, параллельные функции относятся к функциям с некоммутативным параллелизмом. В отличие от упреждающего параллелизма, когда значения компонентов программы, которые должны выполняться с упреждением, можно откладывать, для параллельных функций, как уже было сказано, это может приводить к тому, что вообще не будет получен результат выполнения программы. Потоковый параллелизм множества данных Природа информационной независимости компонентов программы как необходимое условие ее распараллеливания рассмотрена выше. Потоковый параллелизм имеет, скорее, организационную основу и восходит к конвейерной обработке, которая предполагает совмещение нескольких этапов последовательной обработки деталей . Конвейерный принцип выполнения команд в опережающем устройстве компьютера или операций в его арифметическом устройстве примеры реализации конвейера в компьютерах. Организуя поток данных на входе последовательной программы, получим классическую конвейерную схему, когда любой компонент программы, завершив выполнение поступивших данных, переходит к обработке следующих данных входного потока. Линейный конвейер естественным образом можно расширить, введя разветвленную схему параллельной обработки, представляемую, например, в виде граф-схемы, как это сделано в ЯГСПП. Таким образом, легко достигается объединение параллельных процессов, индуцируемых при выполнении информационно независимых компонентов программы и разветвленной конвейерной обработки. Это существенно упрощает разработку параллельных программ для задач реального времени, в частности, распределенных управляющих систем. Вместе с тем нет необходимости на каждой стадии конвейера обрабатывать только одну порцию входного потока данных. Можно использовать схему одновременного применения компонента программы к множеству всех поступивших на его вход данных, если для этого есть свободные процессоры или компьютеры в ВС. Эта форма параллелизма реализована в ЯГСПП и в классификации Флинна соответствует способу организации параллельной обработки SIMD один поток команд и множество потоков данных. SISD последовательная обработка, MISD типичная схема обслуживания запросов к БД, а MIMD это то, что присуще работе любой многомашинной и многопроцессорной ВС. Асинхронный и синхронный параллелизм Оба эти понятия отражают отсутствие или наличие временных ограничений, накладываемых на следование событий в процессах, реализующих вычисления или управление. Определение. Он также предполагает, что выполнение любого акта начинается сразу при выполнении условий, вытекающих из причинно-следственных связей его с другими актами, определяющими его готовность к выполнению. Если это условие нарушается, например, искусственно увеличивается время выполнения операторов, входящих в векторную конструкцию, то такой процесс называется синхронным. Введение синхронизации часто упрощает описание и реализацию параллельных вычислений, как это очевидно для векторных и матричных задач. Описание и реализация асинхронных процессов существенно усложняют и то, и другое. Для этого достаточно ознакомиться с методами построения асинхронных схем, базирующихся на апериодических автоматах 15, или с моделью асинхронных вычислений значений функций на языке FPTL. Заметим, что понятия асинхронности и параллельности не тождественны. Например, реализация процессов выполнения последовательной программы может быть асинхронной и в то же время не содержать параллелизма. Параллелизм и проблемная среда По-видимому, полезным может быть рассмотрение специфики задачных сред и особенностей построения в них параллельных алгоритмов и программ. Очевидно, матричные задачи, сеточные схемы решения уравнений в частных производных и другие задачи линейной алгебры просты в распараллеливании, и параллельный Фортран, языки PVM, НОРМА, mpC и другие приспосабливались к этому типу задач. Стандарт OpenMP полезен для ручного распараллеливания программ, особенно, если они написаны для этого круга задач. Совсем иные языковые средства требуются для описания сложных процессов, возникающих, например, в работе ВС, управлении, в системах массового обслуживания, для которых асинхронность и параллелизм являются неотъемлемыми свойствами. ЯГСПП создавался с ориентацией на эффективное параллельное программирование этого круга задач. Критерии и параметры оценки параллелизма Процесс программирования можно рассматривать как многоэтапный переход от задачи к представлению выбранного метода ее решения на конкретном языке программирования. Для оценки сложности и качества параллельных программ используется целый ряд критериев и параметров. Предельное ускорение при неограниченном N, очевидно, равно 1. В реальности ускорение меньше предельного из-за затрат времени на управление параллельным выполнением программы на ВС, реализацию обмена данными. На практике более важно понять, как ведет себя ускорение в зависимости от сложности задачи и количества компьютеров N в ВС. Пусть C есть функция, определяющая ускорение решения задачи в параллельной форме в зависимости от параметров x, x, x сложности задачи и количества узлов N в ВС. 7. Именно при этих предположениях обычно определяется коэффициент ускорения для многих методов и параллельных программ. В качестве параметров x, x, x, характеризующих вычислительную сложность задачи, во многих случаях используются параметры, определяющие размерность задачи, которые одновременно являются и аргументами программы, представляющей метод ее решения. Если попытаться реализовать процесс вычисления значения n по этой программе, используя все возникающие возможности распараллеливания, нетрудно показать, что этот процесс следует схеме, изображенной на рисунке 3. Таким образом, с усложнением задачи можно неограниченно сокращать время выполнения этой программы при условии неограниченных ресурсов. Параллельные программы такого типа назовем программами с неограниченным параллелизмом. Глубина и степень распараллеливания Введем еще один параметр, определяющий глубину распараллеливания метода и интуитивно характеризующий в среднем вычислительную сложность компонентов параллельной программы, которые рассматриваются как ее самостоятельные части и могут выполняться одновременно. В литературе этот параметр часто называется зернистостью параллелизма. Определение. Глубиной распараллеливания d назовем усредненную вычислительную сложность компонентов, которые рассматриваются в параллельной программе как самостоятельные процессы, идентифицируемые и планируемые при ее выполнении на ВС. Обратную к d величину определим как степень распараллеливания, характеризующую усредненное количество компонентов параллельной программы, которые могут выполняться одновременно. Нетрудно заметить, что во всех четырех случаях коэффициент ускорения неограниченно растет с увеличением n. Обратим внимание, что степень распараллеливания ведет себя как неубывающая функция в зависимости от величины 1d и всегда существует ее предельное значение, определенное предельной и всегда ограниченной глубиной распараллеливания. Варьирование степени распараллеливания задачи чрезвычайно важно при оптимизации процесса выполнения ее на ВС с позиции минимизации времени выполнения и использования ресурсов. Это может происходить как на стадии разработки параллельной программы и ее статическом планировании на ВС, так и на стадии выполнения, когда динамически варьируется степень распараллеливания с целью увеличения фронта готовых к выполнению процессов, что ведет к увеличению загруженности ВС. Интенсивность обменных взаимодействий Эффективность параллельной работы ВС также существенно зависит от пропускной способности коммуникаций и интенсивности обменных взаимодействий между ее компонентами в процессе выполнения параллельной программы. Поэтому важно понять, каким образом при изменении степени распараллеливания будет изменяться интенсивность обменных взаимодействий при выполнении программы на ВС. Определение. Определим интенсивность обменных взаимодействий для параллельной программы при глубине распараллеливания d как функцию, где n количество обменных взаимодействий при выполнении параллельной программы заданной сложности на ВС с N узлами. При увеличении степени распараллеливания до определенного предела путем изменения d время выполнения параллельной программы сначала уменьшается. Однако при этом увеличивается интенсивность обменов между узлами ВС и при dd начинается естественное замедление вычислений из-за увеличения издержек на их реализацию. Может показаться, что параллельные вычисления на ВС с общей памятью устраняют проблему снижения эффективности их работы из-за обменных взаимодействий между компьютерами. Однако достаточно рассмотреть пример вычисления значений функции n в абсолютно параллельной форме согласно рисунку 1, чтобы понять при реализации этой стратегии к общей памяти одновременно могут обращаться порядка n2 команд. С увеличением n ограниченная пропускная способность системы процессорыпамять станет узким местом, что существенно уменьшит эффект от распараллеливания. Использование ресурсов На практике при организации параллельных вычислений важно знать не только ускорение, получаемое при выполнении параллельной программы на реальной ВС, но и то, как при этом используются ее ресурсы. В действительности это не так, поскольку для сложных задач, требующих большого объема памяти, ускорение может быть больше N. Это связано с тем, что для сложных задач время выполнения программы на одном компьютере может существенно увеличиться из-за большой интенсивности обменов между оперативной памятью и дисковой. Обычно о загруженности ВС судят по загруженности только ее процессоров, что часто оправдано для вычислительных задач. Однако задача может быть такой, что в ее программе основную часть времени занимает работа с периферией или обработка сложных массивов данных. В этих случаях акцент смещается в сторону организации эффективного управления памятью, портами, периферией и др. В 7 при исследовании проблемы управления параллельной работой ВС показано, что ее эффективность существенно зависит от интенсивности индуцируемых при выполнении программ команд вводавывода, обмена с дисковой памятью, в том числе из-за возникающего обмена страницами между оперативной и дисковой памятью по причине недостатка первой, а также из-за обмена данными между узлами. Интересно проследить общий характер изменения показателя эффективности использования ресурсов ВС для задачи заданной сложности с увеличением N количества узлов ВС. Очевидно, если не изменяется глубина распараллеливания и сохраняется общая схема организации выполнения параллельной программы на ВС, этот показатель сначала должен увеличиваться с увеличением N. Однако всегда будет существовать некоторое оптимальное значение N, больше которого уже нельзя уменьшить время выполнения программы . Можно сделать вывод, что при построении эффективных параллельных программ необходимо не только уделять серьезное внимание разработке параллельных методов решения задач, но и уметь их анализировать и приспосабливать к масштабу ВС и ее техническим возможностям для достижения максимального эффекта. Подобно всяким изобретениям языки программирования, конечно, имеют прикладное значение и их создание и развитие обусловлены как реальной практикой применения, так и бурным развитием вычислительной техники. В статье авторы попытались обозначить реперные точки, вокруг которых происходит объективное столкновение различающихся и часто противоположных подходов к созданию языков и сред параллельного программирования. Очевидно, что созданное фирмами-разработчиками программное обеспечение пока далеко от того, чтобы сделать эффективными процессы разработки параллельных программ и их выполнение на различных компьютерных системах. Уже разработано огромное количество языков последовательного программирования и операционных средств, и понятно, что объектно-ориентированное программирование лишь очередной этап развития. Скорее всего, это касается создания и повышения уровня языков и сред параллельного программирования, а также создания теоретической базы и практической реализации методов и средств управления процессами в больших компьютерных системах. 