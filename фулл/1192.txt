КОНТЕКСТНО ЗАВИСИМЫЙ СПОСОБ ПОИСКА  НЕЧЕТКИХ ДУБЛИКАТОВ В РЕЛЯЦИОННЫХ БАЗАХ ДАННЫХ 

Постановка проблемы:  одной из важных проблем в области управления данными является их неполное (нечеткое)  дублирование, ведущее к снижению качества, в частности к ошибочной интерпретации информационной системой  одного и того же объекта как нескольких разных. Реляционная модель данных, а также промышленные СУБД на основе реляционной модели, позволяют исключить ситуации полного дублирования данных, но не имеют механизмов для  распознавания и предотвращения появления нечетких дубликатов. Целью работы является разработка такого способа  обнаружения нечетких дубликатов, который мог бы быть реализован в реляционной модели данных и промышленной  реляционной СУБД.  Результаты:  рассмотрена общая для информационных систем проблема нечеткого дублирования,  предложены пути внесения смысловой дублирующей информации в реляционную базу данных. Определено, что для  решения проблемы неполного дублирования следует использовать механизмы нечеткого сравнения строк с учетом их  семантики. Приведен пример практической реализации способа для СУБД PostgreSQL с использованием реляционных  механизмов обработки данных.  Практическая значимость:  разработанный способ позволяет автоматически обнаруживать дубликаты, исключив вмешательство человека-оператора, и тем самым повысить качество данных информационной системы. Пример практической реализации для промышленной СУБД позволяет непосредственно использовать  предложенный способ в инженерной практике разработки информационных систем. Данный способ также был использован авторами при разработке коммерческой автоматизированной информационной системы. Ключевые слова  —   нечеткие дубликаты, смысловые дубликаты, метод n-грамм, реляционная база данных, очистка данных, качество данных .  

Стандарт 1 определяет качество данных как уровень совокупности присущих объекту характеристик, отвечающий установленным требованиям. Присущий в противовес присвоенному означает существующий в чем-то как постоянная характеристика объекта. Термин качество может применяться с такими прилагательными, как низкий, плохой, годный, хороший и превосходный. Предлагаемые стандартом оценки уровня качества, таким образом, являются нечеткими низкий, годный и зависят от субъективной оценки данных потребителями. Возникает необходимость вводить в процесс обеспечения качества данных объективные показатели, позволяющие производить независимые оценки и сравнения. Одним из показателей низкого качества данных является их дублирование, ведущее в итоге к ошибочной интерпретации одного и того же объекта как нескольких разных. Можно выделить два основных типа дублирования атрибутов имеющих жестко заданную структуру формат содержания и не имеющих таковой, т. е. неполно структурированных. В первом случае примером могут служить различные коды классификаторов или используемые в качестве ключевых атрибутов поиска идентификаторы, такие как номера телефонов, ИНН и т. п. Проблема решается стандартным ограничением уникальности значения атрибута в соответствующей колонке таблицы поиск дубликатов производится системой управления базой данных СУБД по точному совпадению значения. Во втором случае речь идет о разнообразных именах собственных и названиях, используемых для идентификации, таких как антропонимы, топонимы, названия предприятий, медикаментов, почтовые адреса и т. д. Не представляется возможным использовать стандартные ограничения целостности, предоставляемые реляционной моделью и соответствующими СУБД. Также практически невозможно использовать словари-справочники данных по следующим причинам 2 на текущий момент существует огромное число подобных имен непрерывно порождаются новые имена . Размер географического справочника адресов для международной рассылки будет исчисляться многими миллионами записей, требующих регулярной поддержки в актуальном состоянии. Структурирование антропонима в общем случае невозможно, так как количество и порядок составляющих полного имени человека может зависеть не только от культуры страны происхождения и степени псевдонимизации, но и от общественного статуса. Для решения вышеназванных проблем был разработан подход, целями которого являлись использование особенностей реляционной модели введение в рассмотрение объективных численных характеристик качества информации по критерию ее дублирования описание ключевых этапов процесса по обеспечению качества на основе введенных характеристик. Задача поиска дубликатов может быть решена при помощи алгоритмов нечеткого сравнения строк. Известные способы вычисления дистанции, такие как EDIT или LCS, имеют существенный недостаток они нечувствительны к контексту 3, 4. Например, LCS для пар названий лекарств cardura benadrol и osmitrol benadrol дает одинаковое значение, равное 3. Применение метода n-грамм 2, 3, 5, 6 в сочетании с коэффициентом Дайса дает лучшие результаты при сравнении отдельных слов и простых словосочетаний. Коэффициент вычисляется следующим образом 3 dice, 2 n-grams n-grams n-grams n-grams . Здесь, строки n-grams множество грамм строки n-grams мощность множества. Для тех же самых пар названий лекарств из примера LCS при разбиении на триграммы коэффициент будет равен нулю в первом случае и 0,17 во втором. Но при сравнении предложений и фраз начинают проявляться смысловые ошибки. Например, если информация о контактном лице сравнивается в виде строк табл. 1, то общий коэффициент схожести может быть высоким, тогда как по некоторым смысловым единицам фразы схожесть низкая. Метод n-грамм предлагает решать эту проблему использованием вероятностей появлений грамм в соответствующих позициях фразы. Однако определение таблиц таких вероятностей не только представляет собой объемный труд, но и является зависимым от естественного языка 2, 5, 6. В рамках реляционной базы данных информация уже структурирована в соответствии не только с языковыми особенностями, но, в первую очередь, со спецификой предметной области. Каждый объект, кроме своего первичного ключа, может иметь несколько составных ключей-идентификаторов, состоящих в том числе из текстовых атрибутов. Тогда интегральная оценка схожести составных идентификаторов объектов в базе данных может проводиться с учетом смыслового веса значений входящих в них отдельных атрибутов. Пусть идентификатор состоит из атрибутов, ..., . Введем для каждого атрибута его смысловой вес, в диапазоне 0..1. Очевидно, 0, иначе атрибут исключается из рассмотрения. Тогда взвешенная схожесть sim двух идентификаторов и вычисляется по формуле Порядок необходимых действий для поиска дубликатов будет следующим. 1. Определение атрибутов, идентифицирующих объект. 2. Определение весовых коэффициентов для атрибутов в составе идентификатора. 3. Вычисление взвешенной схожести всех пар идентификаторов. Данный показатель будет лежать в интервале 0..1, где 0 полное несовпадение, 1 полное совпадение. 4. Экспериментальным путем для тестового массива данных определяется нижний порог взвешенной схожести, за которым количество ошибок распознавания дубликатов становится неприемлемым. Назовем это значение порогом автоматической обработки и обозначим как П . Основными путями внесения и изменения информации являются непосредственный ввод пользователями импорт данных из внешних источников. При пользовательском вводе требуется обеспечить минимальное время отклика системы, поэтому используемый на этом этапе алгоритм должен работать не столько точно, сколько предельно быстро. При этом параметр П для данной операции может быть изменен в соответствии с требованиями по скорости поиска. Так как система распознавания не может предоставить 100-ю точность, пользователь должен также иметь возможность игнорировать подсказку системы и ввести данные. При таких условиях в базу данных неизбежно будет попадать часть некачественной информации, которая должна быть обнаружена в дальнейшем. Задачу выявления и устранения дубликатов в информационной системе можно разбить на три этапа 1 первичное выявление дубликатов на уровне ввода информации пользователями и определение их отклонения, если sim П 2 выявление дубликатов путем сравнения и анализа уже введенных данных в соответствии с заданным П и автоматическое удаление дублирующей информации, если sim П 3 анализ и обработка человеком результатов п. 2, которые не могут быть обработаны автоматически, т. е. sim П . Следует упомянуть о недостатке метода n-грамм, который может оказаться существенным для СУБД большой размер производного множества n-грамм относительно словаря грамм. При заданном количестве символов для каждой строки будет сформировано словарных элементов 1, где длина строки, при, 0 и поиск невозможен. Максимальное количество элементов словаря грамм зависит от и мощности алфавита, если считать все комбинации из букв допустимыми, и равно соответствующему количеству размещений с повторениями Например, для русского языка при алфавите из 33 букв количество n-грамм при 3 равно 35 937. Однако, как показывает практика, в реальных текстах реализуется не более 2530 n-грамм от общего допустимого их числа 6, т. е. не более 11 000. Если имеется база данных на 50 000 абонентов, средняя длина значений атрибутов составного идентификатора равна 50 символам, то мощность множества триграмм будет составлять примерно 50 000 50 3 2 350 000 элементов. При этом количество уникальных элементов словаря грамм не будет превосходить теоретический максимум в 35 937 или практический в 11 000. Быстрый поиск по такому множеству при использовании ст андартных средств реляционной СУБД в виде индексов будет затруднен, так как избирательность этих индексов мала. Решением проблемы при большом количестве данных для словаря будет увеличение . Рассмотрим пример системы распознавания дубликатов в списке компаний для открытой и свободно распространяемой СУБД PostgreSQL 9. Пусть компания характеризуется следующим набором атрибутов табл. 2. В случае триграмм схема данных реализации нечеткого поиска компаний в рамках реляционной модели может выглядеть следующим образом рисунок. Средства СУБД PostgreSQL позволяют реализовать разбиение строки на граммы в виде пользовательской функции, возвращающей множество подстрок. Тогда для инициализации таблицы грамм компаний может быть использован следующий SQL-запрос. Для нечеткого поиска может использоваться следующий запрос, выдающий список найденных значений в порядке убывания их взвешенной схожести. В статье рассмотрены определения качества данных, проблемы снижения качества при наличии дублирующей информации, приведены существующие способы нечеткого сопоставления строк и их характеристики. Предложен способ обнаружения дублирующей информации на основе методов нечеткого сравнения текста. С использованием существующих методов нечеткого сравнения текста способ был доработан для применения в рамках реляционной модели и СУБД с учетом семантики его элементов. Приведен практический пример реализации способа на базе свободно распространяемой СУБД PostgreSQL. Предложенный способ может быть использован для реализации соответствующей встроенной функциональности в промышленных СУБД. 