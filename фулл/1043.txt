КЛАСТЕРИЗАЦИЯ АВТОРЕГРЕССИОННЫХ МОДЕЛЕЙ  РЕЧЕВЫХ СИГНАЛОВ ПО КРИТЕРИЮ МИНИМУМА  ИНФОРМАЦИОННОГО РАССОГЛАСОВАНИЯ   КУЛЬБАКА — ЛЕЙБЛЕРА 

Решается задача кластеризации множества авторегрессионных моделей речевых сигналов в рамках теоретико-информационного подхода. Для этого был разработан алгоритм нахождения оптимальных параметров авторегрессионной модели в смысле минимума информационного рассогласования Кульбака — Лейблера. На его  основе проведена модификация известного алгоритма кластеризации k-средних. Экспериментально исследована эффективность применения разработанных алгоритмов при дикторонезависимом распознавании изолированных слов с использованием аппарата скрытых марковских моделей с дискретным распределением вероятностей наблюдений. Установлено, что наилучшие результаты по точности распознавания достигаются при использовании коэффициентов линейного предсказания с неравномерным частотным разрешением в качестве  вектора признаков и размере кодовой книги векторного квантователя, равном 256. Ключевые слова  — автоматическое распознавание речи, авторегрессионная модель, информационное  рассогласование, центроид, кластер. 

В исследованиях по информационной теории восприятия речи ИТВР 15 предложены подходы к решению задач анализа, распознавания и обработки речевых сигналов в рамках теоретикоинформационного подхода. Данная тематика исследований является весьма актуальной по причине широкого распространения в последнее время теоретико-информационного подхода в теории распознавания образов. Так, в работе 6 проводится оценка и дается обоснование возможности применения указанного подхода для кластеризации данных. В работах 7, 8 рассматриваются примеры использования различных видов информационных метрик при решении задач обработки изображений. Работы 911 посвящены применению теоретико-информационного подхода и информационной геометрии в различных методах машинного обучения. В связи с этим вызывает интерес адаптация подходов, представленных в ИТВР, к использованию в уже существующих методах машинного обучения и распознавания образов применительно к задаче кластеризации и обработки речевых сигналов. Для этого рассмотрим вначале основные положения данной теории. В рамках ИТВР элементарная речевая единица ЭРЕ задается некоторым информационным центром-эталоном, в качестве которого выбирается реализация речевого сигнала представленная соответствующей авторегрессионной АР моделью и характеризующаяся минимальной суммой информационных рассогласований в метрике Кульбака Лейблера 1, 5, 12 относительно всех других реализаций данной ЭРЕ 1 где число реализаций -й ЭРЕ информационное рассогласование по Кульбаку Лейблеру между -й и -й ЭРЕ. Иллюстрирует сформулированное выше определение модели ЭРЕ 1 рис. 1. В приведенной формулировке модели ЭРЕ есть два недостатка. Первый заключается в том, что выбор информационного центра-эталона делается из дискретного множества реализаций. Это значит, что критерий 1 не является в строгом смысле оптимальным. Второй недостаток состоит в переборном характере алгоритма поиска информационного центра-эталона, сложность которого составляет т. е. количество необходимых вычислений будет быстро возрастать с увеличением множества реализаций заданной ЭРЕ. В связи с этим представляется актуальным создание алгоритмов, свободных от указанных недостатков. Согласно работе 2, информационное рассогласование по Кульбаку Лейблеру между неизвестным сигналом и эталоном, заданными их АР-моделями, определяется в спектральной области следующим образом 2 Здесь порядок АР-модели и элементы векторов авторегрессии сигналов и соответственно верхняя граница частотного диапазона. Можно показать 13, что 0 для любых АР-моделей и, если их полюсы находятся внутри единичной окружности на комплексной плоскости. Отметим также, что информационное рассогласование Кульбака Лейблера является частным случаем рассогласования Брэгмана 14, определяемого между двумя функциями плотности распределения вероятностей и как 3 где производящая функция, обладающая свойствами выпуклости и дифференцируемости. Собственно само информационное рассогласование Кульбака Лейблера легко получить из 3, выбрав в качестве производящей функции негэнтропию Шеннона log d . Отсюда следует, что информационное рассогласование 2 также относится к классу рассогласований Брэгмана. Приведенное замечание будет использовано далее при доказательстве сходимости модифицированного алгоритма кластеризации -средних. Определим теперь информационное рассогласование Кульбака Лейблера в случае сравнения эталонного сигнала, заданного его АРмоделью, сразу с множеством реализаций -й ЭРЕ как величину среднего искажения 4 где элементы вектора авторегрессии -го сигнала из множества . Вид данной формулы вытекает из определения центроида множества. Центроидом множества является такой вектор, который минимизирует среднее искажение 5 где обозначает некоторую меру расстояния между двумя векторами, называемую также мерой искажений 15. Формула 5 во многом похожа на критерий 1, за исключением того, что получаемый вектор не обязан соответствовать какому-либо конкретному элементу множества . Задача поиска оптимальной АР-модели -й ЭРЕ состоит в выборе такого вектора АР-коэффициен тов при котором величина стремится к своему глобальному минимуму 6 Из 5 нетрудно видеть, что решение поставленной задачи в формулировке 4, 6 фактически сводится к поиску АР-модели центроида множества Поскольку применяемая в данной работе мера расстояния между векторами 2 с учетом свойств рассогласования Кульбака Лейблера не является симметричной, то, согласно работе 7, формула 5 определяет правосторонний центроид. Выбор центроида данного типа обусловлен возможностью получить эффективный алгоритм его вычисления, описание которого приводится далее. Найдем решение задачи 6. Для этого нам необходимо решить относительно простую систему дифференциальных уравнений 7 Получим выражение для частной производ ной Для этого определим две функции Тогда формулу 4 можно переписать следующим образом 8 Выражение 8 легко преобразовать к матричному виду, определив такую матрицу и вектор-строку, что Отсюда получаем 9 где единичный вектор-строка размера 1 . Можно показать 16, что частная производ ная определяется как 10 Тогда выражение для с учетом 8 и 10 приобретает вид Отсюда легко видеть, что уравнение 7 после группировки множителей будет представлено следующим образом В этом случае решение уравнения 7 относительно может быть представлено как система линейных уравнений вида 11 где вектор-столбец, элементы которого определяются как 12 квадратная матрица размера, элементы которой задаются следующим выражением 13 Преобразовав выражения 12 и 13 в матричный вид, получаем 14 где матрица размера, состоящая из единичных элементов, а и векторы-строки, которые определяются как Интересной особенностью уравнения 11 является то, что оно по своей структуре сходно с известными уравнениями Юла Уолкера 17, для которых существует быстрый алгоритм решения. В матричной форме данные уравнения задаются в виде 15 где соответствующий элемент некоторого вектора размерности 1 в оригинале вектор автокорреляции, а обозначение является операцией комплексного сопряжения. Для того чтобы свести уравнение 11 к виду 15, необходимо задать вектор в виде, где первая строка матрицы . Для быстрого решения 15 обычно применяется рекуррентный алгоритм Левинсона Дарбина 18, шаги которого приведены ниже 16 Результатом его работы является вычисление вектора АР-коэффициентов без необходимости непосредственного обращения автокорреляционной матрицы. Вычисления по алгоритму 11 16 позволяют получить значения коэффициентов АРмодели ЭРЕ которые являются оптимальным решением задачи 6. Особенностью данного решения является то, что оно всегда будет оптимальным в глобальном смысле, поскольку величина среднего информационного рассогласования в виде 4 является квадратичной формой относительно . Также легко видеть, что предложенный алгоритм имеет линейную сложность, в отличие от критерия 1. Наглядным примером практического применения полученного алгоритма 11 16 решения задачи 6 может служить использование его при построении алгоритмов кластеризации без учителя. Одним из наиболее известных алгоритмов такого типа является алгоритм -средних 19, 20. В общем виде он может быть задан следующим образом 21. Пусть мы имеем некоторую случайную величину в пространстве наблюдений такую, что где -мерное евклидово пространство. Нас интересует возможность разбиения пространства на Г кластеров. Алгоритм -средних предполагает, что число кластеров Г заранее известно, и требуется найти такую матрицу параметров, которая бы минимизировала целевую функцию ошибку квантования, заданную следующим выражением 17 Здесь множество векторов наблюдений -й столбец матрицы, который представляет собой вектор параметров, связанный с кластером . При кластеризации по алгоритму -средних вектор параметров представляет собой обычное среднее значение всех векторов наблюдений, входящих в кластер . В этом случае мы можем определить матрицу средних значений, каждый -й столбец которой является вектором параметров . Отсюда можно записать, что где оценка среднего значения элементов -го кластера. Для случая, когда наблюдения представлены в виде векторов авторегрессии в метрике 2, необходимо внести в рассматриваемый алгоритм кластеризации изменения, касающиеся целевой функции 17 и меры искажений . Возможность таких изменений связана с тем, что алгоритм -средних может использоваться с широким классом мер искажений, включая меры, не являющиеся метрическими 22. Сходимость рассматриваемого алгоритма гарантируется для любых мер искажений, которые относятся к классу информационных рассогласований Брэгмана 6. Как было отмечено выше, информационное рассогласование 2 также относится к данному классу. Из сказанного следует, что алгоритм -средних сходится при использовании 2 в качестве меры искажений. Ниже представлены шаги модифицированного алгоритма. 1. Выбрать число кластеров Г, инициализировать оценки центроидов по каждому кластеру используя значения, полученные на основе априорных данных, или случайные значения. Затем на основе этих параметров, обозначенных как формируется матрица 2. С учетом текущих определений кластеров распределить по каждому из них имеющиеся АР-модели векторов наблюдений используя следующую индексную функцию принадлежности Вычисление значений информационного рассогласования в формулировке 2 можно также выполнять в матричном виде аналогично 9 и 14. 3. Вычислить целевую функцию с учетом распределения наблюдений по кластерам 18 4. Вычислить изменение целевой функции Алгоритм завершает свою работу, если выполняется условие или . 5. На основе нового распределения векторов наблюдений по кластерам вычислить значения используя алгоритм 1116. Из полученных векторов сформировать матрицу параметров . 6. Увеличить номер итерации и повторить вычисления, начиная с шага 2. Алгоритм -средних реализует в себе метод наискорейшего спуска вдоль вектора градиента ошибки квантования 18 23. Из этого следует, что на каждой последующей итерации алгоритма значение целевой функции должно уменьшаться. Еще одним свойством данного алгоритма является уменьшение величины ошибки квантования при увеличении числа кластеров. Разработанные выше алгоритмы могут использоваться в различных областях, в частности, в распознавании речевых сигналов. Результаты такого применения приводятся в следующем разделе. Для проверки эффективности разработанной модификации алгоритма -средних были проведены его экспериментальные исследования в рамках задачи распознавания изолированных слов. Эксперимент проводился с использованием речевой базы, состоящей из 11 слов английского языка one, two, nine zero o . Каждое слово проговаривалось в среднем по 2 раза группой из 208 дикторов. Представленная в базе речь хранится в виде соответствующих звуковых файлов формата PCM WAVE с частотой дискретизации 8 кГц, 16 бит. Данные файлы разделены на обучающее и тестовое множество. Обучающее множество содержит речь 95 дикторов 38 мужчин и 57 женщин, всего по 188 реализаций каждого слова. Тестовое множество содержит речь 113 дикторов 56 мужчин и 57 женщин, всего по 225 реализаций каждого слова. Следует отметить, что обучающее и тестовое множества не пересекаются друг с другом по дикторам. Несмотря на некоторую несбалансированность обучающего множества по числу мужчин и женщин, можно говорить о том, что применяемая речевая база в целом является достаточно представительной. В ходе экспериментальных исследований все реализации слов разбивались на квазистационарные сегменты длительностью 20 мс с перекрытием смежных сегментов в 10 мс. Далее вычислялись векторы признаков размерности 12, описывающих соответствующие сегменты. Для сравнения использовались четыре наиболее широко распространенных вида векторов признаков 1 коэффициенты линейного предсказания LPC 24, которые являются эквивалентом рассматриваемых в данной работе коэффициентов авторегрессии 2 кепстральные коэффициенты, вычисленные по рекуррентной формуле из коэффициентов линейного предсказания CC-LPC 18 19 3 коэффициенты линейного предсказания с неравномерным частотным разрешением WLPC 25. Для их вычисления вектор коэффициентов автокорреляции пропускается через набор всепропускающих фильтров первого порядка следующего вида Здесь 1 1 коэффициент деформации. Параметр выбирается таким образом, чтобы получаемая частотная шкала была близка к шкале барк, а сам параметр может быть приближенно рассчитан по следующей формуле где частота дискретизации, Гц. В дальнейшем используется автокорреляционный метод расчета коэффициентов линейного предсказания 16 4 кепстральные коэффициенты, рассчитанные по коэффициентам линейного предсказания с неравномерным частотным разрешением CCWLPC. Для этого также применялась формула 19. В качестве меры расстояния между векторами признаков типа LPC и WLPC использовалось информационное рассогласование в виде 2. Вместе с тем в качестве меры расстояния при использовании CC-LPC и CC-WLPC была выбрана евклидова метрика. На подготовительном этапе из сегментов, полученных из обучающего множества слов, были сформированы кластеры с помощью алгоритма -средних. При этом производилось несколько запусков алгоритма с различными начальными условиями для нахождения оптимального разбиения. Таким образом, для каждого значения числа кластеров Г от 8 до 1024 было найдено свое разбиение исходного множества по кластерам и их центры, которые будем называть кодовой книгой, . Следует отметить, что построение кодовой книги для признаков LPC и WLPC выполнялось с помощью модифицированного алгоритма средних с использованием алгоритма 1116 для вычисления центров кластеров. Для иллюстрации свойств получаемой по алгоритму 1116 оптимальной АР-модели на рис. 2, представлены графики функции для двух реализаций английской фонемы и полученной на их основе оптимальной АР-модели ЭРЕ. Данная функция может рассматриваться как спектральная плотность мощности СПМ нерекурсивного фильтра, коэффициенты которого задаются вектором авторегрессии . Здесь тонкими сплошными линиями показаны СПМ выбранных реализаций, а полужирная линия соответствует СПМ, найденной с помощью алгоритма 1116 оптимальной АР-модели. Видно, что полученная результирующая модель учитывает особенности обеих реализаций фонемы . Дополнительно на рис. 2, показан увеличенный фрагмент СПМ всех трех моделей в интервале относительной частоты 0,030,12. Как можно видеть, СПМ оптимальной модели в районе 0,06 проходит над СПМ исходных АРмоделей и не является их простой комбинацией. Для обеспечения возможности применять полученную кодовую книгу в задаче распознавания речи каждому ее элементу был сопоставлен символ из некоторого алфавита, . Далее было проведено векторное квантование последовательностей признаков по всем реализациям каждого слова из обучающего множества. При этом для каждого слова было сформировано множество последовательностей наблюдений элементы которого представляют собой последовательности символов из алфавита, полученных в результате выполнения векторного квантования. Полный набор таких последовательностей образует обучающее множество для настройки скрытой марковской модели СММ с дискретной плотностью наблюдений 18. При этом вычисляются оптимальные параметры СММ, для заданной обучающей выборки. Оптимальными параметрами СММ называются те, которые максимизируют вероятность по всем возможным последовательностям, из обучающей выборки. Если обозначить состояние в момент времени, то 1 матрица вероятностей переходов, содержащая вероятность перехода из состояния в состояние матрица распределения вероятностей наблюдения символа в состоянии в момент времени, а начальное распределение вероятностей состояний. В приводимом эксперименте использовался набор из лево-правых СММ или моделей Бакиса с семью состояниями для каждого из слов. Выбор указанного числа состояний основывается на ранее проведенных исследованиях см., например 18, с. 380, в которых показано, что для систем автоматического распознавания речи с малым словарем хорошие результаты распознавания могут быть получены при числе состояний, находящемся в диапазоне 6 8 и одинаковом для всех СММ. Тем не менее, в настоящее время разработаны различные методы оптимизации структуры СММ числа состояний и переходов между ними, которые позволяют во многих случаях снизить вероятность ошибок распознавания. Однако рассмотрение указанных методов находится за рамками данной статьи, а заинтересованный читатель может обратиться к работам 2629 для получения подробной информации. Найденная кодовая книга и модели на следующем этапе использовались для распознавания слов из тестового множества. Для этого аналогичным образом слова сегментировались, признаки, выделенные из сегментов, квантовались с использованием кодовой книги и, исходя из получившейся последовательности наблюдений, при помощи алгоритма Витерби 18, 30 для каждой СММ вычислялись оптимальные последовательности состояний, максимизирующих правдоподобие log . Решение о том, какое слово распознано, принималось по критерию максимума правдоподобия В результате сравнения решения, принятого при распознавании, с априорными данными о классификации слова получаем зависимость величины ошибки распознавания по тестовому набору слов WER word error rate от размера кодовой книги для каждого способа выделения признаков где число правильно распознанных реализаций слов, а общее число реализаций. Результаты проведенного эксперимента приведены в таблице. Из полученных результатов видно, что практически для всех алгоритмов значение минимальной величины ошибки WER достигается при размере кодовой книги, равном 256. При этом наилучшее значение показал алгоритм, использующий коэффициенты линейного предсказания с неравномерным частотным разрешением и модифицированный алгоритм -средних для вычисления кодовой книги. Минимальное значение ошибки WER для него составило 0,035. В работе предложен подход для кластеризации множества АР-моделей речевых сигналов. Для этого вначале был разработан алгоритм для расчета коэффициентов оптимальной по критерию минимума информационного рассогласования АР-модели ЭРЕ, заданной множеством одноименных реализаций. Показано, что используемая в представленной работе в качестве расстояния между АР-моделями мера относится к классу рассогласований Брэгмана. Для решения собственно задачи кластеризации рассмотрена возможность модификации известного алгоритма кластеризации -средних, суть которой заключалась в изменении процедуры вычисления центров кластеров в том случае, если они заданы АР-моделями. Дано обоснование сходимости модифицированного алгоритма. Рассмотренная иллюстрация работы предложенного алгоритма вычисления центроида множества АР-моделей как минимума среднего информационных рассогласований Кульбака Лейблера показывает, что результирующая модель не является простой комбинацией исходных. Для оценки эффективности разработанных алгоритмов были проведены их экспериментальные исследования на примере задачи распознавания ограниченного набора слов английского языка с применением аппарата СММ и различных векторов признаков. В результате было показано, что минимальное значение ошибки распознавания достигается при размере кодовой книги числе кластеров, используемых для представления речевого сигнала в пространстве признаков, равном 256, для большинства рассмотренных векторов признаков. Также показано, что наилучшие результаты достигаются при использовании в качестве признаков коэффициентов линейного предсказания с неравномерным частотным разрешением и соответствующей кодовой книги, найденной при помощи модифицированного алгоритма кластеризации -средних. Это позволяет говорить о возможности применения предложенных в данной работе алгоритмов при решении задач обработки и распознавания речи. Дальнейшее исследование эффективности применения разработанных алгоритмов для распознавания большого набора слов из слитной речи представляется интересной задачей. Ее решение требует большого объема размеченных данных для обработки, чему будет посвящена следующая работа. 