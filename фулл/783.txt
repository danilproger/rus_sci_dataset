УЛУЧШЕНИЕ КАЧЕСТВА СЖАТЫХ ИЗОБРАЖЕНИЙ  ПРЕДВАРИТЕЛЬНЫМ МАСШТАБИРОВАНИЕМ 

Рассматривается метод улучшения качества изображений, сжимаемых по алгоритму JPEG, предварительным масштабированием. Обосновывается выбор количественной оценки качества изображения. Анализируются методы масштабирования с точки зрения скорости обработки и качества восстановленного изображения. Ключевые слова  — сжатие изображений, алгоритм JPEG, масштабирование изображений. 

Результаты исследований перспектив развития телекоммуникаций 1 показывают, что к 2013 г. суммарный поток видеоданных составит примерно 90 пользовательского телекоммуникационного трафика, включая видеоконференции, мобильную телефонию и видеонаблюдение. В связи с данной тенденцией все более актуальной становится проблема эффективного сжатия видеоинформации для передачи по телекоммуникационным сетям с сохранением высокого качества изображения на стороне пользователя. Максимально возможное повышение степени сжатия передаваемых видеоданных без существенного ухудшения качества может обеспечить значительное увеличение доходов магистральных операторов и интернет-провайдеров за счет увеличения объема передаваемой информации, приходящейся на единицу сетевого трафика. Все известные в настоящее время методы сжатия видеопотока можно разделить на две большие группы методы, основанные на анализе соседних кадров в целях компенсации движения, например стандарты Н.264 или MPEG-4 2, и методы, выполняющие сжатие каждого кадра в отдельности, например стандарты MPEG-2 или JPEG 3. Если методы сжатия второй группы являются симметричными, т. е. у них время компрессии практически совпадает со временем декомпрессии, то методы первой группы несимметричны, так как у них время компрессии существенно превышает время декомпрессии, причем с увеличением степени сжатия растет и несимметричность метода. Учитывая вышесказанное, можно считать, что для передачи изображения в режиме on-line наиболее подходят методы второй группы, многие из которых основаны на поблочном дискретном косинусном преобразовании ДКП изображения. Однако при высокой степени сжатия такими методами на декомпрессированном изображении становятся заметны границы блоков, на которые разбивается изображение при сжатии, что значительно снижает визуальное качество. Один из возможных способов избежать подобных искажений при сохранении степени сжатия заключается в предварительном масштабировании изображения каким-либо алгоритмом сжатия вниз перед компрессией, т. е. в уменьшении размера изображения. Отмасштабированное вниз изображение сжимают, а после передачи по каналу и декомпрессии восстанавливают до исходного размера, т. е. масштабируют вверх с помощью алгоритмов интерполяции изображения. Цветное исходное изображение рис. 1, размером 800 600 пикселей в bmp-формате имеет объем файла 350 КБ. После компрессии изображения алгоритмом JPEG с коэффициентом качества 10 объем сжатого файла составил 35 КБ. Следует отметить, что коэффициент качества у используемого при проведении экспериментов алгоритма JPEG меняется в пределах 1100 и представляет собой некий условный коэффициент сохранения качества при сжатии, т. е. чем выше коэффициент, тем лучше качество и соответственно меньше степень сжатия. Результат декомпрессии с хорошо заметной блочной структурой показан на рис. 1, . Изображение на рис. 1, было предварительно масштабировано вниз с коэффициентом 1,5, т. е. размер изображения был уменьшен в полтора раза, затем выполнена компрессия алгоритмом JPEG с коэффициентом качества 25, что обеспечило размер сжатого файла 35 КБ для объективности сравнения результатов. После декомпрессии изображение было восстановлено до первоначального размера с использованием интерполирующего алгоритма Lanczos. Блочная структура менее заметна на рис. 1, что позволяет говорить о возможности применения предложенной последовательности операций для повышения качества результирующего изображения после декомпрессии. Показанный на рис. 1, результат можно объяснить следующим образом. Потеря информации на изображении при JPEG-компрессии происходит 2 раза 3. Первый раз на этапе прореживания, когда после преобразования из цветового пространства RGB в YCbCr изображение делится на блоки из 4 пикселей 2 2 пикселя и вместо 12 значений 4 Y, 4 Cb, 4 Cr используется 6 4 Y и по одному усредненному Cb и Cr. Второй раз качество теряется на этапе ДКП. Изображение делится на блоки 8 8 пикселей, подвергается ДКП и квантованию. Матрица, используемая для квантования, строится таким образом, что более сильному квантованию подвергается высокочастотная составляющая, что приводит к исчезновению на декомпрессированном изображении малоразмерных и слаборазличимых фрагментов. В блоках, соответствующих таким фрагментам, при большой компрессии после квантования нулевыми становятся все значения, кроме начального, которое соответствует средней яркости изображения. В результате на декомпрессированном изображении проявляется блочная структура, причем она наиболее заметна в областях с практически постоянной яркостью, например на изображениях неба, воды и т. п. см. рис. 1, . Масштабирование исходного изображения вниз дает возможность повысить качество изображения, уменьшив коэффициент компрессии JPEG. В результате в блоках после квантования появляется больше ненулевых значений, что делает менее заметной блочную структуру декомпрессированного изображения. Масштабирование исходного изображения вверх выполняется интерполяционным методом, что приводит к некоторому размыванию перепадов яркости, но позволяет избежать появления клетчатой структуры. Для того чтобы рекомендовать данный метод к применению в системах передачи видеопотока в режиме on-line, необходимо выбрать наиболее подходящую методику для количественной оценки качества результирующего изображения по сравнению с исходным подобрать алгоритм интерполяции, наилучший по отношению качествовремя обработки найти оптимальное с точки зрения качества результирующего изображения соотношение коэффициентов масштабирования и компрессии оценить симметричность метода проанализировать результаты обработки изображений различного типа цветных, монохромных, контрастных, размытых, с мелкими деталями и т. д.. Для обеспечения возможности объективного сравнения результатов при проведении экспериментов коэффициенты масштабирования вниз и компрессии следует подбирать так, чтобы размер полученного изображения был равен размеру изображения после компрессии без предварительного масштабирования. В данной статье рассмотрены вопросы выбора методики оценки качества изображения, восстановленного после сжатия, и алгоритма интерполяции, применяемого при восстановлении изображения. Для анализа тестовых изображений, полученных в результате экспериментов, необходимо выбрать методику оценки качества восстановленного изображения по сравнению с исходным. Существуют два подхода к оценке качества изображения. Первый количественная оценка, опирающаяся на вычисление некоторых характеристик изображения, второй субъективная оценка, основывающаяся на статистической обработке экспертных оценок. Каждый подход можно разделить на две группы абсолютные и сравнительные меры. Абсолютные меры используют для оценки одного изображения изображению присваивается коэффициент качества по рейтинговой шкале, сравнительные меры используются для ранжирования набора изображений по качественной шкале от лучше всего до хуже всего или взаимного сравнения двух изображений 4. Получение субъективной оценки долгий и сложный процесс, требующий наличия опыта у экспертной группы, благоприятных условий труда качественных мониторов, освещения, а также специальных методов статистической обработки для компенсации человеческого фактора. При выборе количественной оценки следует отдать предпочтение той, которая учитывает особенности восприятия изображений человеческим глазом 5 цветовое разрешение человеческого зрения ниже яркостного, человек маловосприимчив к мелким цветным деталям и т. п.. С учетом сложности получения субъективной оценки и наличия эталонных изображений для сравнения результатов сжатия изображений была выбрана группа количественных сравнительных оценок качества. Рассмотрим кратко наиболее распространенные. Среднеквадратическое отклонение значений пикселей 6 1 где, яркости соответствующих пикселей сравниваемых кадров и одинакового размера ширина кадра высота кадра. Это наиболее часто используемая на практике легко вычисляемая мера. Недостаток меры состоит в том, что по ней изображение будет считаться сильно испорченным при понижении яркости всех пикселей всего на 5 человеческий взгляд не всегда улавливает, а изображения с резким изменением цвета отдельных точек со снегом, слабыми полосами или муаром будут признаны почти не изменившимися. Максимальное отклонение 3 . 2 Эта мера очень чувствительна к отклонению отдельных пикселей, т. е. практически незаметное для человеческого взгляда резкое изменение яркости только одного пикселя приводит к существенному снижению оценки качества всего изображения. Отношение полезного сигнала к шуму 3 3 где Max максимум модуля разности цветовой компоненты. Это наиболее часто используемая на практике сравнительная мера, ее можно вычислять по всем компонентам цветовых пространств YUV и RGB и по компоненте L пространства LUV 7. легко вычислять, но она имеет очень приближенное отношение к расхождениям, которые обнаруживаются человеческим глазом. Высокое значение означает определенную схожесть восстановленного и исходного изображений, но оно не дает гарантию того, что зритель будет удовлетворен восстановленным кадром. Сравнительная мера усредненная абсолютная разность значений цветовых компонент в соответствующих пикселях сравниваемых изображений 8 4 где, значения цветовых компонент соответствующих пикселей сравниваемых кадров и . Этой мере присущи те же недостатки, что и среднеквадратическому отклонению. усредненная разность значений цветовых компонент в соответствующих пикселях сравниваемых изображений 8, вычисляется для каждой компоненты по формуле 5 где, значения цветовых компонент соответствующих пикселей сравниваемых кадров и . Недостатки меры совпадают с недостатками меры . Сравнивая формулы 15 для определения качества изображения по различным мерам, можно сделать вывод, что все они однокомпонентные, т. е. опираются на вычисление какой-то одной характеристики разности значений яркости 2, 4, 5 или среднеквадратического отклонения яркости 1, 3. Применение перечисленных мер не всегда дает положительный результат. В литературе 8 можно найти примеры изображений, существенно отличающихся по качеству при визуальной оценке, но имеющих практически одинаковую количественную оценку качества по однокомпонентной мере. Мера структурного подобия, предложенная американским ученым из Нью-Йоркского университета Зоу Вангом для сравнения полутоновых изображений, основывается на вычислении трех компонент сходства яркости, контраста и структуры и объединении их значений в итоговый результат 9, 10 2 2 2, 6 где средняя яркость пикселей сравниваемых кадров и дисперсия яркости пикселей, ковариация кадров. Первая составляющая выражения является коэффициентом корреляции между изображениями и . Вторая и третья составляющие соответственно характеризуют сходство средних значений яркостей и сходство контрастов двух сравниваемых изображений. Чем выше значение, тем больше совпадают сравниваемые изображения. В последнее время данная мера широко используется при сравнительной оценке качества изображений в силу того, что она наилучшим образом учитывает особенности восприятия человеческим глазом. При проведении экспериментов сравнение качества изображений, восстановленных после сжатия, выполнялось по метрикам, и . Результаты сравнения по метрикам и практически совпали. По ним ошибка у контрастного изображения, полученного с использованием предварительного масштабирования, становится меньше, начиная с коэффициента качества алгоритма JPEG, равного 13. По метрике это значение составляет 26. Результаты аналогичных измерений по другим тестовым изображениям представлены в табл. 1. В дальнейшем для оценки качества восстановленного изображения использовалась мера, как наиболее адекватно отображающая разницу между изображениями за счет анализа сходства изображений по яркости, контрасту и структуре. Важной составляющей эффективного применения предварительного масштабирования является выбор алгоритма интерполяции после декомпрессии. Интерполяцией, или интерполированием, в вычислительной математике называется способ нахождения промежуточных значений величины по имеющемуся дискретному набору известных значений 11. Алгоритм интерполяции должен обеспечивать максимальное качество картинки при минимальных временных затратах, а время работы алгоритма должно удовлетворять требованию симметричности. Наиболее распространенные алгоритмы увеличения масштаба растрового изображения кратко рассмотрены далее. копирование ближайшего соседа самый простой с точки зрения реализации метод 12. В нем для получения неизвестных значений пикселей не делается никаких сложных математических вычислений неизвестная яркость пикселя принимается равной яркости ближайшего к нему пикселя. Этот метод рекомендуется использовать для изображений, в которых нет плавных цветовых переходов, но есть четкие границы. билинейная интерполяция. В вычислительной математике билинейной интерполяцией называют расширение линейной интерполяции для функций в двух переменных. Для вычисления неизвестного значения яркости искомого пикселя используются 4 соседних с ним пикселя 12. Сначала в соответствии с координатами искомого пикселя линейно интерполируются значения вспомогательных точек вдоль оси абсцисс, потом проводится линейная интерполяция между этими точками по оси ординат. бикубическая интерполяция. В вычислительной математике бикубической интерполяцией называется расширение кубической интерполяции на случай функции двух переменных, значения которой заданы на двумерной регулярной сетке 13. Поверхность, полученная в результате бикубической интерполяции, является гладкой функцией, в отличие от поверхностей, полученных в результате билинейной интерполяции или интерполяции методом ближайшего соседа. Бикубическая интерполяция дает более качественное изображение по сравнению с билинейной интерполяцией, но требует больше времени. один из наиболее распространенных алгоритмов, применяемых для интерполяции графических изображений, основанный на интерполяционном полиноме Эрмита, получившего свое название в честь великого французского математика Шарля Эрмита Charles Hermite 14. Для нахождения значения функции в точке необходимо найти полином степени 2 1, значения которого и его производной в узлах, 0, удовлетворяют заданным соотношениям. Эту задачу как раз и решает интерполяционный полином Эрмита еще один фильтр, который занимает одно из лидирующих мест в цифровом увеличении изображения. Этот многомерный метод назван в честь Корнелиуса Ланцоша Cornelius Lanczos, впервые показавшего, как можно применить полиномы Чебышева и ряды Фурье для решения прикладных задач. Фильтр Ланцоша построен на основе оконного sinc-фильтра 13. Импульсная характеристика оконного sincфильтра образуется путем умножения импульсной характеристики идеального фильтра низких частот на оконную функцию. В результате получается фильтр с хорошими спектральными свойствами. Применение данного фильтра к изображению позволяет сохранить относительно высокую четкость даже при значительном увеличении, но может быть сильно заметен эффект Гиббса. представитель группы так называемых кусочно-кубических алгоритмов кубический сплайн 4-го порядка Термин B-spline был введен И. Шнбергом Isaac Jacob Schoenberg и является сокращением от словосочетания базисный сплайн. В вычислительной математике B-spline называют сплайн-функцию, имеющую наименьший носитель для заданной степени, порядка гладкости и разбиения области определения. В системах автоматизированного проектирования и компьютерной графике термин B-spline часто описывает сплайн-кривую, которая задана сплайн-функциями, выраженными линейными комбинациями B-spline 15. Существует несколько модификаций этого алгоритма. Первая модификация принадлежит американскому ученому Эдвину Катмулу Edwin Catmull, известному по своим работам в области киноиндустрии, и Рафаэлю Рому Raphael Rom из Израильского технологического университета. Алгоритм назван в их честь и известен во всем мире как . Вторая принадлежит Дону Митчелу Don Mitchell и Аруну Нетравали Arun N. Netravali и ее название или носит их имена, причем это даже не модификация, а сочетание B-spline и CatmullRom 1517. Алгоритм масштабирования, или как его еще называют, с колоколообразной характеристикой помогает за счет применения преобразований Фурье удалить высокочастотные шумы и aliasing лестничный эффект, которые могут появиться при масштабировании 18. Изображения при использовании этого алгоритма получаются немного размытыми, даже с небольшим коэффициентом масштабирования, поэтому алгоритм имеет еще название 16. Можно сказать, что размытие это та дань, которую приходится платить за удаление шумов. Компания BenVista, известная своей программой для масштабирования изображения с одноименным названием, выпустила и запатентовала свой алгоритм масштабирования . Как утверждают разработчики, этот алгоритм можно отнести к адаптивным алгоритмам, т. е. он учитывает характеристики изображения и неплохо работает на границах цветов 19. основывается на кубическом сплайне. Кубический сплайн задается значениями функции в узлах и значениями производных на границе отрезка интерполяции либо первых, либо вторых производных. Для любой функции и любого разбиения отрезка интерполяции существует естественный, удовлетворяющий заданным условиям, сплайн 20. Масштабирование изображений всегда связано с потерей их качества. При этом возникают артефакты масштабирования заметные искажения изображения. Наиболее часто встречаются следующие артефакты 21 ringing возникновение волны около резкой границы на изображении overshooting возникновение двух или трех волн aliasing неравномерности изображения на резких, диагональных границах изображения unsharpening размывание, недостаточная четкость изображения после масштабирования. Повышение четкости, как правило, приводит к увеличению остальных артефактов и наоборот подавление артефактов подавляет также и четкость sub-pixel shift субпиксельный сдвиг изображения, связанный, как правило, с особенностями реализации алгоритма. Практически не влияет на визуальное качество, однако существенно влияет на количественную оценку. Для получения полной картины о качестве интерполяции различными алгоритмами были выбраны разные по своей структуре тестовые изображения рис. 2, . Каждое тестовое изображение масштабировалось вниз с коэффициентами 1,5 2 2,5 7,5 8, после чего масштабировалось до исходного размера тестируемым алгоритмом интерполяции. Далее вычислялась мера для эталонного и восстановленного изображений. Результаты вычисления для контрастного изображения с разным коэффициентом масштабирования при различных алгоритмах интерполяции представлены на рис. 3. Из графиков отчетливо видна зависимость значения при одинаковом коэффициенте масштабирования от алгоритма интерполяции. С уменьшением коэффициента масштабирования после восстановления изображения до исходных размеров практически совпадает у всех алгоритмов интерполяции. Из этого можно сделать вывод, что с увеличением коэффициента масштабирования исчезает разница в качестве между ними. Лидирующую позицию занимают алгоритмы Catmull-Rom и Bicubic. Следующим шагом в оценке качества алгоритмов масштабирования изображений было определение зависимости качества от типа изображения. Как говорилось выше, в качестве тестовых изображений были выбраны разные типы изображений см. рис. 2. В экспериментах использовался небольшой коэффициент масштабирования все тестовые изображения масштабировались вниз с коэффициентом 1,5. Полученные изображения восстанавливались до исходного тестируемыми алгоритмами интерполяции с вычислением для них меры . Результат вычислений представлен на рис. 4. Из гистограммы видно, что за редким исключением для всех типов изображений прослеживается зависимость качества изображения от алгоритма интерполяции. Как и в первом случае, лидирующую позицию занимают алгоритмы Catmull-Rom и Bicubic. Результаты усреднения экспериментальных данных табл. 2, полученных для каждого типа изображения, позволяют увидеть наглядную картину оценки качества. Несмотря на то, что алгоритм Catmull-Rom практически везде показывал наилучшие результаты, в некоторых случаях для какого-то конкретного типа изображения метрика сильно выбивалась из группы. Это повлияло на результаты усреднения, и лидирующие позиции заняли алгоритмы Bicubic и Bilinear, показавшие наиболее стабильные результаты для всех групп изображений с различными коэффициентами масштабирования. Для оценки времени работы алгоритмов масштабирования измерялось время работы их программной реализации. В качестве ядра была взята условно бесплатная библиотека FINEGraphics. dll, написанная на языке ассемблера и оптимизированная. Реализованные алгоритмы этой библиотеки вызывались из программы, написанной на языке Delphi. Исходное изображение размером 800 600 пикселей было отмасштабировано вниз с семью различными коэффициентами, которые приведены в табл. 3. Каждое сжатое изображение восстанавливалось до исходного размера перечисленными выше методами, время восстановления или масштабирования вверх заносилось в таблицу с округлением до десятых миллисекунды. Фрагмент полученных данных приведен в табл. 4. Для наглядности был построен график рис. 5. Из графика видно, что чем меньше размер изображения, тем быстрее оно масштабируется. Как и следовало ожидать, самым быстрым оказался метод ближайшего Nearest neighbor в нем новые пиксели не вычисляются математическим путем, а копируются, а самыми долгими методы на основе сплайнов. По скорости работы можно выделить четыре группы алгоритмов масштабирования 1 Nearest neighbor 2 Bilinear, Hermite 3 B-spline, Bell 4 S-spline, Mitchel, Lanczos, Bicubic, CatmullRom. Анализируя данные, полученные при измерении для тестового изображения, и данные измерения времени работы алгоритмов интерполяции, можно сделать следующие выводы. С увеличением времени работы алгоритма масштабирования растет качество масштабируемой картинки. Соответственно, чем меньше размер файла сжатого изображения, тем ниже качество восстановленного изображения и больше времени потребуется алгоритму масштабирования на его восстановление до исходного размера. Это справедливо для всех алгоритмов масштабирования. Наибольший интерес представляет сравнение алгоритмов масштабирования между собой. Самый долгий алгоритм Catmull-Rom вопреки ожиданиям не оказывается самым лучшим по качеству получаемой картинки, а самый быстрый алгоритм Nearest neighbor при небольшом коэффициенте компрессии оказывается лучше B-spline и Mitchel. Наибольшего интереса достоин алгоритм Bilinear. Принимая во внимание количественную оценку качества алгоритмов масштабирования, можно сказать, что алгоритм Bilinear является фаворитом, так как при минимальных временных затратах на выходе получается отмасштабированное изображение хорошего качества. Выбор алгоритма масштабирования совпадает с выбором производителей ЖК-телевизоров, так как именно этот алгоритм масштабирования, реализованный аппаратно, используется для масштабирования в ЖК-телевизорах 21. Проведенные эксперименты подтверждают целесообразность использования предварительного масштабирования изображения перед компрессией для повышения качества восстановленного изображения. По соотношению качество восстановления время обработки для этой задачи наиболее подходит алгоритм масштабирования Bilinear. В дальнейшем планируется проведение экспериментов для нахождения оптимального соотношения коэффициентов масштабирования и компрессии с точки зрения качества результирующего изображения, а также оценки симметричности рассмотренного метода для его использования в режиме прямой передачи видеопотока. 