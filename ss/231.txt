НЕЙРО-НЕЧЕТКИЙ МЕТОД СНИЖЕНИЯ ЧУВСТВИТЕЛЬНОСТИ РЕШЕНИЯ ОБРАТНЫХ ЗАДАЧ К ВАРИАЦИЯМ ДАННЫХ 

Рассмотрена процедура решения некорректных задач с использованием фильтра Калмана. Предложен подход к применению нейро-нечетких алгоритмов для снижения чувствительности модели фильтра Калмана при решении обратных задач..

 Исследователей в различных областях науки и техники давно интересует решение некорректных задач, к которым относятся и так называемые обратные задачи, когда значения параметров модели должны быть получены из наблюдаемых данных. Из трех условий корректно поставленной задачи существование решения, его единственность, а также устойчивость по отношению к малым вариациям данных задачи в обратных задачах наиболее часто нарушается последнее 1. При математической формализации физическая некорректность проявляется уже в неустойчивости решения. Таким образом, обратные задачи представляют собой типичный пример некорректно поставленных задач. Для решения некорректных задач, как правило, берутся упрощенные модели объекта или явления, характеризующиеся небольшим числом параметров. Понятно, что на этом пути можно получить лишь приближенные представления о свойствах объекта или характеристиках определяемых величин. Данный подход к решению задачи не использует всех возможностей, предоставляемых современным уровнем точности наблюдений и развитием вычислительной техники. Эти возможности могут найти применение при изучении новых постановок обратных задач и создании устойчивых алгоритмов их решения. К таким алгоритмам можно отнести решения, базирующиеся на методах искусственного интеллекта, в частности, на аппарате искусственных нейронных сетей, широко применяемых в различных прикладных областях 2. Многообразие типов обратных задач обусловило создание соответствующих методов решения, учитывающих специфику их постановки. Вариантом решения этих задач может быть применение искусственных нейронных сетей с одновременным использованием нечетко-логических методов оценки состояния системы. Основная идея предлагаемого подхода, позволяющего снизить чувствительность решения обратной задачи к вариациям исходных данных, базируется на предварительном применении алгоритма оценивания состояния исследуемой системы, а именно нечеткого фильтра Калмана. Проиллюстрировать подход можно следующей аналогией. Человеческий мозг как биологическая нейронная сеть ежеминутно решает некорректные и обратные задачи, то есть, несмотря на неединственность и неустойчивость решения, восстанавливает по нескольким точкам наблюдаемый объект и все, что его окружает. Делает он это эффективно и быстро, так как использует богатый опыт . Последовательное применение методов статистики с учетом априорной информации, реально доступной исследователю, позволяет получать устойчивые и эффективные решения обратных задач 3. Фильтр Калмана как раз позволяет использовать часть априорной информации и, в свою очередь, снизить неопределенность данных для решения обратной задачи нейронной сетью. Применение фильтра Калмана для оценки состояния сталкивается с проблемой получения модели исследуемого объекта, которую называют формирующим фильтром. Эту модель не всегда можно получить на основе применения физических законов, связывающих исследуемые параметры. Например, для экономических объектов такой подход не срабатывает, так как отличительной особенностью источников информации о них является субъективность, а в ряде случаев и противоречивость данных. В этих условиях для решения указанной проблемы вполне уместно использовать методы искусственного интеллекта, а именно методы нечеткой логики, которые позволяют успешно преодолевать отмеченные особенности исходной информации. Структура предлагаемого к решению обратных задач подхода показана на рисунке 1. Применение фильтра Калмана, обозначенного на рисунке FK, позволяет снизить дисперсию входных данных нейронной сети, а следовательно, обеспечить ее работу в менее зашумленном пространстве исходной информации, что, в свою очередь, сказывается на окончательном решении. Блок BFL реализует механизм нечеткого логического вывода, с помощью которого проводится коррекция модели объекта или явления. Правила нечеткого вывода, лежащие в основе GNN, могут корректироваться экспертами, тем самым предоставляя возможность учета дополнительной информации. Эта возможность отражена блоком BCR. Пунктирными линиями на рисунке обозначены сигналы, участвующие в процессе обучения GNN. В векторно-матричной форме запишем как АХ, где матрица А имеет вид А а а а а а а а а а. Для определения a используется процедура нечеткого вывода, в основе которой лежит база знаний, содержащая продукционные правила вида П11 ЕСЛИ r ЕСТЬ D11 И r ЕСТЬ D21 И. r ЕСТЬ Dn1, ТО a ЕСТЬ A11, П12 ЕСЛИ r ЕСТЬ D12 И r ЕСТЬ D21 И. r ЕСТЬ Dn1, ТО a ЕСТЬ A12,. . П1m ЕСЛИ r ЕСТЬ D1m И r ЕСТЬ D21 И. r ЕСТЬ Dn1, ТО a ЕСТЬ A1m, П1m1 ЕСЛИ r ЕСТЬ D11 И r ЕСТЬ D22 И. Здесь предполагается, что каждый фактор r имеет одинаковое количество терм-множеств. Это не является обязательным требованием. Суждения о параметрах модели объекта эксперты дают на основе статистических данных, представленных с какой-либо временной дискретностью, но, несмотря на это, человеку удобнее и G C FK GNN BCR BFL интуитивно понятнее отражать процессы в непрерывном времени. Поэтому можно считать, что полученное описание формирующего фильтра представлено в непрерывном времени. В свою очередь, решение обратной задачи с помощью нейронной сети осуществляется для дискретных моментов времени t, поэтому удобнее применять дискретный алгоритм фильтра Калмана, согласуя интервал дискретизации по времени с t. Описание дискретного формирующего фильтра сходно с описанием непрерывного, но вид матрицы системы А в этом случае зависел бы от величины t, что усложнило бы базу правил ввиду необходимости учитывать в них еще и t. При выборе t учитывают, что оно не должно быть больше времени корреляции исследуемого процесса. Дальнейший расчет дискретного фильтра Калмана осуществляется по следующей методике 4. 1. В начале такта вычисления происходит расчет оценки Ф где Ф матрица перехода, подобная матрице А в описании . 2. 3. 4. На следующем такте понадобится значение апостериорной матрицы ошибок оценивания Р. Поэтому после вычисления К находят Р Р где I единичная матрица. 5. В конце такта корректируется априорная оценка с учетом текущих измерений. 6. В следующем такте процедура повторяется на основе найденных для такта значений, Р. С учетом специфики задачи предложено использовать нейронные сети Элмана, которые относятся к классу рекуррентных нейронных сетей 5. Важной особенностью архитектуры рекуррентных сетей является наличие блоков динамической задержки и обратных связей, что позволяет таким сетям обрабатывать динамические модели. Сети Элмана состоят их двух слоев выходного и входного, при этом входной слой охвачен динамической обратной связью с использованием линии задержки. Такая связь позволяет учесть предысторию наблюдаемых процессов и накопить информацию для выработки правильной стратегии управления. Для иллюстрации рассматриваемого подхода была использована среда MatLAB, обладающая широким спектром функций для создания и применения нейронных сетей разных типов, а именно пакет Neural Network. Численный эксперимент проводился с использованием встроенного типа обобщенной регрессионной сети Elman backprop. Алгоритм эксперимента состоит в следующем. 1. Подготовка выборок для обучения сети. Для этого в соответствии с рассчитываются векторы состояний при заданной матрице эволюции системы и подаче на вход гармонического сигнала. Матрица эволюции взята размером 2 2, поэтому векторы состояний имеют по две компоненты х и х. В результате реализации этого этапа сформируются выборки для обучения нейронной сети, на вход которой будут подаваться векторы состояний, а на выходе получаться значения входного сигнала. Данная процедура отражает процесс решения обратной задачи нахождения причин, которые перевели систему в данное состояние. Будут сформированы две обучающие выборки train1.dat для нейронной сети, имеющей один вход и один выход train2.dat для нейронной сети, имеющей два входа и один выход. 2. Создание и обучение нейронных сетей nn1 и nn2. Имитируя возможность измерения только одной компоненты вектора состояния, обучение nn1 будет проводиться только по одной компоненте х на основе данных train1.dat, а сети nn2 по двум компонентам х и х на основе данных train2.dat. 3. Наложение шума измерений N и входного случайного процесса V на значения выборки train1.dat и получение тестирующей выборки testing1.dat. 4. Тестирование сети. На вход сети nn1 зашумленная выборка testing1.dat подается непосредственно, а на вход сети nn2 после предварительной обработки фильтром Калмана в соответствии с пунктами 16. В результате получаются оценки для компоненты х с меньшей дисперсией, а также компоненты х, явно не измеряемой, что позволяет применить сеть nn2 с двумя входами. Результаты численного эксперимента показаны на рисунке 2. Визуальное сравнение этих кривых показывает, что сеть с применением фильтра Калмана значительно лучше справляется с задачей нахождения u. Такой запас позволяет сети nn2 находить решение обратной задачи при больших вариациях исходных данных, которые моделируются векторами N и V. В частности, для достижения сетью nn2 значения ошибки примерно 0,38 потребовалось увеличение дисперсии входного процесса V с 0,1 до 0,19, то есть почти в два раза большее, чем при проведении эксперимента. Предложенный подход для снижения чувствительности решения обратной задачи к вариациям исходных данных может использоваться при реализации программ и вычислительных алгоритмов в различных прикладных областях, в том числе и экономических, где решения базируются на обработке большого количества статистических данных. 