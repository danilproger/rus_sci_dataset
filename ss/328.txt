ОРГАНИЗАЦИЯ ЭФФЕКТИВНЫХ ВЫЧИСЛЕНИЙ ДЛЯ РАСЧЕТА ЭЛЕКТРОННОЙ СТРУКТУРЫ БОЛЬШИХ МОЛЕКУЛ 

Представлены параллельный алгоритм расчета электронной структуры молекул, разработанный на основе метода Пальцера–Манолополиса, и его реализация в рамках вычислительной модели передачи сообщений для плотных и разреженных структур данных. Приводятся оценки трудоемкости алгоритма..

 Расчеты электронной структуры гигантских молекул являются одними из самых сложных в современной науке и требуют использования высокопроизводительных вычислительных архитектур. Например, вычислительный эксперимент по изучению свойств молекулы октана C H на кластере HP, содержащем 1 400 процессоров Itanium 2, потребовал более 23 часов работы. Расчеты электронной структуры, в частности, биомолекул и наночастиц, актуальны для химии, биохимии, физики конденсированного состояния вещества и других областей науки. В практическом плане эти расчеты важны для фармакологии, нанотехнологий, исследований явлений сверхпроводимости, разработки квантовых компьютеров. По прогнозам, такая мощность будет достигнута не ранее 2030 года 2. Таким образом, задача сводится к обработке матрицы размерности N, где N размерность задачи, пропорциональная числу атомов. Основными методами расчетов электронной структуры молекул являются неэмпирические и полуэмпирические методы квантовой химии 3. Для расчета больших молекулярных систем, которые могут содержать от 10 до 10 атомов, целесообразно применение полуэмпирических методов квантовой химии в так называемом приближении нулевого дифференциального перекрывания 3, в общем случае имеющих асимптотическую сложность расчета O. Центральным звеном при расчете молекулярных систем является решение симметричной задачи на собственные значения методом матричной диагонализации. Для расчета физико-химических свойств нужны не сами собственные векторы, а матрица плотности P, являющаяся функцией от них. При нахождении матрицы плотности P начальное приближение матрицы формируется из исходного фокиана F. Фокиан, в свою очередь, строится по определенным правилам на основе декартовых координат атомов, входящих в молекулу 3, 4. Сложность расчета фокиана для плотных матриц составляет O. Методы расчета Другой путь нахождения P, альтернативный решению задачи на собственные значения, прямое извлечение P из фокиана. Одним из численных методов прямого нахождения матрицы плотности P является метод очистки 5, разработанный еще в 1960 г.Однако в силу отсутствия в то время необходимых вычислительных ресурсов его применение было ограничено расчетом только небольших молекул. В 90-х годах ХХ века на основе этого метода разработаны различные модификации, позволяющие ускорить процесс вычислений. Можно показать, что вложенная последовательность таких многочленов сходится к ступенчатой функции со ступенькой где-то на 0, 1. В одной из современных модификаций методе ПальцераМанолополиса 5 итерационная формула для нахождения матрицы плотности P выглядит следующим образом где n номер шага итерационного процесса P матрица плотности tr след матрицы c коэффициент. Из анализа выражения следует, что основной вклад в вычислительную трудоемкость вносят матричные операции. Для нахождения матрицы плотности P необходимо определить начальное приближение P, например, как фокиан, нормализованный таким образом, что все его собственные значения E лежат на отрезке -1, 1, то есть В связи со значительной вычислительной сложностью задачи расчета больших молекулярных систем одним из путей ускорения расчетов является построение эффективных алгоритмов и программ с использованием технологии параллельных вычислений. На рисунке 1 приведена структурная схема параллельного алгоритма расчета по методу ПальцераМанолополиса, разработанная в рамках модели распределенных вычислений, которая представляет вычисления в виде совокупности взаимодействующих, последовательно выполняемых процессов. Для организации взаимодействия используются стандартные коммуникационные библиотеки, например MPI . Главный процесс рассылает матрицу исходного фокиана F, затем оценивает минимальное и максимальное собственные значения матрицы. Далее все процессы выполняют параллельную нормализацию фокиана. Для параллельной реализации целесообразно применить блочное умножение матриц, а также провести расчеты этих блоков в разных процессах параллельно. При реализации параллельного алгоритма с использованием функций MPI возможны два варианта рассылки данных широковещательная рассылка или попарные вызовы точка-точка. Как показывают проведенные исследования 4, 6, в реальных экспериментах попарные вызовы имеют преимущества по сравнениию с широковещательной рассылкой. Разреженная структура матрицы плотности Поскольку при построении математической модели достаточно большого класса молекул возникают массивы данных разреженной структуры, целесообразно использовать это свойство для повышения эффективности расчетов. Свойство разреженности используется для снижения требований к представлению в памяти данных очень больших размеров и сокращения вычислительной сложности алгоритмов обработки матриц. Можно показать, что в общем случае матрицы фокиана F и плотности P являются разреженными 5. Рассмотрим разреженность матрицы блочно-трехдиагонального вида, которая соответствует описанию достаточно большого класса молекул, а именно полимеров и линейных несвернутых протеинов. Представим блочно-трехдиагональную матрицу. Количество блоков nbl может быть ограничено только доступными ресурсами памяти. Для эффективной реализации метода ПальцераМанолополиса в случае представления матрицы фокиана в форме блочно-трехдиагонального вида необходимо организовать эффективное выполнение операций сложения, умножения на число и умножения матриц. При умножении двух блочно-трехдиагональных матриц A и B в матрице результата R появляется четвертая ненулевая блочная диагональ, значениями которой можно пренебречь с точки зрения анализа электронной структуры молекул. Таким образом, матрица R представляется в форме блочно-трехдиагональной. Для представления всех трех матриц A, B, R предлагается специальная схема хранения в виде трехмерных массивов. Если учесть, что матрица фокиана F является симметричной и блоки на главной диагонали квадратные, то можно сэкономить память на хранении массивов блоков верхней наддиагонали и после упрощений получить выражения для R Факторизованные выражения для первых и последних блоков можно получить из общей формулы . Вычислительная сложность параллельной обработки разреженных матриц может быть уменьшена за счет оптимального варианта организации обмена блоками. В отличие от реализации метода для плотных матриц нет необходимости рассылать в качестве начальных данных матрицу целиком. Теперь каждый процесс получает только те блоки матриц, которые необходимы для расчетов. По завершении вычислений происходит сбор всех результатов в главном процессе. Следовательно, можно выполнять множество распределенных расчетов. Вопервых, это расчет следа матрицы. Каждый процесс считает только свою часть, а затем главный процесс собирает результаты. Это позволяет в отдельно взятом процессе выполнять действия по умножению матриц только над теми блоками, которые назначены процессу. Процесс вычислений повторяется итерационно до достижения заданной точности матрицы плотности, определяемой выражением . На рисунке 2 представлена схема организации обменов между процессами по типу точка-точка некрайними блоками. Взаимодействие между различными процессами минимально большая часть вычислений происходит независимо, а данные от других процессов требуются только для пограничных блоков. Более того, на каждой заданной итерации возможно заранее сделать все необходимые пересылки данных и уже затем производить умножение блоков. Для произвольного некрайнего блока в k-м процессе следует получить блок A1 из процесса и послать ему блок A2, а также отправить блок A1 из процесса k в процесс и получить блок A2 из процесса . Использование описанных выше схем хранения и организации пересылок в параллельной программе повысило эффективность расчетов и увеличило допустимую размерность решаемой задачи. Так, при обработке плотных матриц в системе с объемом памяти 2 Гб максимальная размерность задачи составляет не более 8 500, а для разреженных матриц до 150 000 6. Оценка трудоемкости параллельной модификации алгоритма с учетом разреженности матриц Оценим вычислительную сложность реализованных параллельных алгоритмов на множестве вычислителей p при следующих предположениях, которые могут быть получены из формулы для P. Так как вычисления распределяются в среднем между вычислителями равномерно, то без ограничения общности положим, что каждый вычислитель обрабатывает одинаковое число блоков. В качестве скорости передачи для функции Fswap взята производительность коммуникационной технологии межсоединения узлов Myrinet 2000 для сообщений подобного размера 230 Мбайтс. Таким образом, использование свойств разреженности в сочетании с параллельной модификацией метода ПальцераМанолополиса позволило существенно увеличить размерность решаемых задач, резко повысило скорость расчетов. Теоретические оценки трудоемкости соответствуют ранее полученным экспериментальным данным 4, 6 и позволяют давать прогнозы о достигаемых значениях ускорения и эффективности на конкретной вычислительной системе. 